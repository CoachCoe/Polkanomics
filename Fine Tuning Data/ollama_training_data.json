[
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain auto generation\ninput: "
      },
      {
        "role": "assistant",
        "content": "You can create a PrDoc by using the `/cmd prdoc` command (see args with `/cmd prdoc --help`) in a\ncomment on your PR.\n\nOptions:\n\n- `audience` The audience of whom the changes may concern.\n  - `runtime_dev`: Anyone building a runtime themselves. For example parachain teams, or people\n    providing template runtimes. Also devs using pallets, FRAME etc directly. These are people who\n    care about the protocol (WASM), not the meta-protocol (client).\n  - `runtime_user`: Anyone using the runtime. Can be front-end devs reading the state, exchanges\n    listening for events, libraries that have hard-coded pallet indices etc. Anything that would\n    result in an observable change to the runtime behaviour must be marked with this.\n  - `node_dev`: Those who build around the client side code. Alternative client builders, SMOLDOT,\n  those who consume RPCs. These are people who are oblivious to the runtime changes. They only care\n  about the meta-protocol, not the protocol itself.\n  - `node_operator`: People who run the node. Think of validators, exchanges, indexer services, CI\n    actions. Anything that modifies how the binary behaves (its arguments, default arguments, error\n    messags, etc) must be marked with this.\n- `bump:`: The default bump level for all crates. The PrDoc will likely need to be edited to reflect\n  the actual changes after generation. More details in the section below.\n  - `none`: There is no observable change. So to say: if someone were handed the old and the new\n    version of our software, it would be impossible to figure out what version is which.\n  - `patch`: Fixes that will never cause compilation errors if someone updates to this version. No\n    functionality has been changed. Should be limited to fixing bugs or No-OP implementation\n    changes.\n  - `minor`: Additions that will never cause compilation errors if someone updates to this version.\n    No functionality has been changed. Should be limited to adding new features.\n  - `major`: Anything goes.\n- `force: true|false`: Whether to overwrite any existing PrDoc file."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain how to document?\ninput: "
      },
      {
        "role": "assistant",
        "content": "There are good sources to look into:\n\n- Rust Documentation Guide\n- Documentation in Rust\n  Book\n- Guide on Writing Documentation for a Rust\n  Crate\n\nAs mentioned\nhere\nand here,\nalways start with a **single sentence** demonstrating what is documented. All additional documentation should be added\n*after a newline*. Strive to make the first sentence succinct and short.The reason for this is the first paragraph of\ndocs about an item (everything before the first newline) is used as the excerpt that rust doc displays about this item\nwhen it appears in tables, such as the table listing all functions in a module. If this excerpt is too long, the module\ndocs will be very difficult to read.\n\nAbout special\nsections,\nwe will most likely not need to think about panic and safety in any runtime related code. Our code is never `unsafe`,\nand will (almost) never panic.\n\nUse `# Examples` as much as possible. These are great ways to further demonstrate what your APIs are doing, and add free\ntest coverage. As an additional benefit, any code in rust-docs is treated as an \"integration test\",\nwhich tests your crate in a different way than unit tests. So, it is both a win for \"more documentation\" and a win for\n\"more test coverage\".\n\nYou can also consider having an `# Error` section optionally. Of course, this only applies if there is a `Result` being\nreturned, and if the `Error` variants are overly complicated.\n\nStrive to include correct links to other items in your written docs as much as possible.\nRead more about how to correctly use links in your rust-docs\nhere and\nhere.\nIn other words, avoid `` `some_func` `` and instead use ``[`some_func`]``.\n\n> While you are linking, you might become conscious of the fact that you are in need of linking to (too many) foreign\nitems in order to explain your API. This is leaning more towards API-Design rather than documentation, but it is a\nwarning that the subject API might be slightly wrong. For example, most \"glue\" traits[^1] in `frame/support` should be\ndesigned and documented without making hard assumptions about particular pallets that implement them.\n\n---\n\n### TLDR\n\n0. Have the goal of enforcing `#![deny(missing_docs)]` mentally, even if it is not enforced by the compiler \ud83d\ude48.\n1. Start with a single, clear and concise sentence. Follow up with more context, after a newline, if needed.\n2. Use examples as much as reasonably possible.\n3. Use links as much as possible.\n4. Think about context. If you are explaining a lot of foreign topics while documenting a trait that should not\nexplicitly depend on them, you have likely not designed it properly.\n\n---\n\n### Proc-Macros\n\nNote that there are special considerations when documenting proc macros. Doc links will appear to function *within* your\nproc macro crate, but often will no longer function when these proc macros are re-exported elsewhere in your project.\nThe exception is doc links to *other proc macros* which will function just fine if they are also being re-exported. It\nis also often necessary to disambiguate between a proc macro and a function of the same name, which can be done using\nthe `macro@my_macro_name` syntax in your link. Read more about how to correctly use links in your rust-docs\nhere and\nhere.\n\n---"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain other guidelines\ninput: "
      },
      {
        "role": "assistant",
        "content": "The above five guidelines must always be reasonably respected in the documentation.\n\nThe following is a set of notes that may not necessarily hold in all circumstances:\n\n---\n\n### Document Through Code\n\nYou should make sure that your code is properly-named and well-organized so that your code functions as a form of\ndocumentation. However, within the complexity of our projects in Polkadot/Substrate that is not enough. Particularly,\nthings like examples, errors and panics cannot be documented only through properly-named and well-organized code.\n\n> Our north star is self-documenting code that also happens to be well-documented and littered with examples.\n\n- Your written documents should *complement* the code, not *repeat* it. As an example, a documentation on top of a code\nexample should never look like the following:\n\n /// Sends request and handles the response.\n trait SendRequestAndHandleResponse {\n\n }\n ```\n\nIn the above example, the documentation has added no useful information not already contained within the properly-named\ntrait and is redundant.\n\n---\n\n### Formatting Matters\n\nThe way you format your documents (newlines, heading and so on) makes a difference. Consider the below examples:\nrust\n/// This function works with input u32 x and multiplies it by two. If\n/// we optimize the other variant of it, we would be able to achieve more\n/// efficiency but I have to think about it. Probably can panic if the input\n/// overflows u32.\nfn multiply_by_2(x: u32) -> u32 { .. }\nrust\n/// Multiplies an input of type [`u32`] by two.\n///\n/// # Panics\n///\n/// Panics if the input overflows.\n///\n/// # Complexity\n///\n/// Is implemented using some algorithm that yields complexity of O(1).\n// More efficiency can be achieved if we improve this via such and such.\nfn multiply_by_2(x: u32) -> u32 { .. }\n```\n\nThey are both roughly conveying the same set of facts, but one is easier to follow because it was formatted cleanly.\nEspecially for traits and types that you can foresee will be seen and used a lot, try and write a well formatted\nversion.\n\nSimilarly, make sure your comments are wrapped at 100 characters line-width (as defined by our\n`rustfmt.toml`), no **more and no less**! The more is fixed by `rustfmt` and our CI, but if you (for\nsome unknown reason) wrap your lines at 59 characters, it will pass the CI, and it will not look good \ud83e\udee3. Consider using\na plugin like rewrap (for Visual Studio Code) to\nproperly do this.\n\n[^1]: Those that help two pallets talk to each other.\n\n---"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain top level pallet docs (`lib.rs`)\ninput: "
      },
      {
        "role": "assistant",
        "content": "For the top-level pallet docs, consider the following template:\n\n//! # <Pallet Name>\n//!\n//! <single-liner about the pallet>.\n//!\n//! ## Pallet API\n//!\n//! <Reminder: inside the [`pallet`] module, a template that leads the reader to the relevant items is auto-generated. There is no need to repeat\n//! things like \"See Config trait for ...\", which are generated inside [`pallet`] here anyways. You can use the line below as-is:>\n//!\n//! See the [`pallet`] module for more information about the interfaces this pallet exposes, including its\n//! configuration trait, dispatchables, storage items, events and errors.\n//!\n//! ## Overview\n//!\n//! <should be high-level details that are relevant to the most broad audience>\n//!\n//! <The audience here is potentially non-coders who just want to know what this pallet does, not how it does it>\n//!\n//! <potentially a few paragraphs, focus on what external folks should know about the pallet>\n//!\n//! ### Example\n//!\n//! <Your pallet must have a few tests that cover important user journeys. Use https://crates.io/crates/docify to\n//! reuse these as examples.>\n//!\n//! <The audience of this is those who want to know how this pallet works, to the extent of being able to build\n//! something on top of it, like a DApp or another pallet. In some cases, you might want to add an example of how to\n//! use this pallet in other pallets.>\n//!\n//! This section can most often be left as-is.\n//!\n//! ## Low Level / Implementation Details\n//!\n//! <The format of this section is up to you, but we suggest the Design-oriented approach that follows>\n//!\n//! <The audience of this would be your future self, or anyone who wants to gain a deep understanding of how the pallet\n//! works so that they can eventually propose optimizations to it>\n//!\n//! ### Design Goals (optional)\n//!\n//! <Describe your goals with the pallet design.>\n//!\n//! ### Design (optional)\n//!\n//! <Describe how you've reached those goals. This should describe the storage layout of your pallet and what was your\n//! approach in designing it that way.>\n//!\n//! ### Terminology (optional)\n//!\n//! <Optionally, explain any non-obvious terminology here. You can link to it if you want to use the terminology further\n//! up>\n\nThis template's details (Heading 3s and beyond) are left flexible, and at the discretion of the developer to make the\nbest final choice about. For example, you might want to include `### Terminology` or not. Moreover, you might find it\nmore useful to include it in `## Overview`.\n\nNonetheless, the high level flow of going from the most high level explanation to the most low level explanation is\nimportant to follow.\n\nAs a rule of thumb, the Heading 2s (`##`) in this template can be considered a strict rule, while the Heading 3s (`###`)\nand beyond are flexible.\n\n---\n\n### Polkadot and Substrate\n\nOptionally, in order to demonstrate the relation between the two, you can start the pallet documentation with:\n\n//! > Made with *Substrate*, for *Polkadot*.\n//!\n//! [![github]](https://github.com/paritytech/polkadot-sdk/tree/master/substrate/frame/fast-unstake) -\n//! [![polkadot]](https://polkadot.com)\n//!\n//! [polkadot]: https://img.shields.io/badge/polkadot-E6007A?style=for-the-badge&logo=polkadot&logoColor=white\n//! [github]: https://img.shields.io/badge/github-8da0cb?style=for-the-badge&labelColor=555555&logo=github\n\n---"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain or\ninput: "
      },
      {
        "role": "assistant",
        "content": "/cmd --help # to see all available commands\n\nTo regenerate all weights (however it will take long,\nso don't do it unless you really need it), run the following command:\nsh\n/cmd bench\n\nTo generate weights for all pallets in a particular runtime(s), run the following command:\nsh\n/cmd bench --runtime kusama polkadot\n\nFor Substrate pallets (supports sub-modules too):\nsh\n/cmd bench --runtime dev --pallet pallet_asset_conversion_ops\n\n> **\ud83d\udcdd Note**: The action is not being run right-away, it will be queued and run in the next available runner.\n> So might be quick, but might also take up to 10 mins (That's in control of Github).  \n> Once the action is run, you'll see reaction \ud83d\udc40 on original comment, and if you didn't pass `--quiet` -\n> it will also send a link to a pipeline when started, and link to whole workflow when finished.\n>\n> **\ud83d\udcdd Note**: It will try keep benchmarking even if some pallets failed, with the result of failed/successful pallets.\n>\n> If you want to fail fast on first failed benchmark, add `--fail-fast` flag to the command.\n\n---\n\nThis way it runs all possible runtimes for the specified pallets, if it finds them in the runtime\nsh\n/cmd bench --pallet pallet_balances pallet_xcm_benchmarks::generic pallet_xcm_benchmarks::fungible\n\nIf you want to run all specific pallet(s) for specific runtime(s), you can do it like this:\nsh\n/cmd bench --runtime bridge-hub-polkadot --pallet pallet_xcm_benchmarks::generic pallet_xcm_benchmarks::fungible\n\n> **\ud83d\udca1Hint #1** : Sometimes when you run too many commands, or they keep failing and you're rerunning them again,\n> it's handy to add `--clean` flag to the command. This will clean up all yours and bot's comments in PR relevant to\n> /cmd commands.\nsh\n/cmd bench --runtime kusama polkadot --pallet=pallet_balances --clean\n```\n\n> **\ud83d\udca1Hint #2** : If you have questions or need help, feel free to tag @paritytech/opstooling (in github comments)\n> or ping in matrix channel."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain using docker compose\ninput: "
      },
      {
        "role": "assistant",
        "content": "You can use the following docker-compose.yml file:\n\nversion: '2'\n\nservices:\n  polkadot:\n    container_name: polkadot\n    image: parity/polkadot\n    ports:\n      - 30333:30333 # p2p port\n      - 9933:9933 # rpc port\n      - 9944:9944 # ws port\n      - 9615:9615 # Prometheus port\n    volumes:\n      - /my/local/folder:/polkadot\n    command: [\n      \"--name\", \"PolkaDocker\",\n      \"--ws-external\",\n      \"--rpc-external\",\n      \"--prometheus-external\",\n      \"--rpc-cors\", \"all\"\n    ]\n\nWith following `docker-compose.yml` you can set up a node and use `polkadot-js-apps` as the front end on port 80. After\nstarting the node use a browser and enter your Docker host IP in the URL field: _<http://[YOUR_DOCKER_HOST_IP]>_\n\nversion: '2'\n\nservices:\n  polkadot:\n    container_name: polkadot\n    image: parity/polkadot\n    ports:\n      - 30333:30333 # p2p port\n      - 9933:9933 # rpc port\n      - 9944:9944 # ws port\n      - 9615:9615 # Prometheus port\n    command: [\n      \"--name\", \"PolkaDocker\",\n      \"--ws-external\",\n      \"--rpc-external\",\n      \"--prometheus-external\",\n      \"--rpc-cors\", \"all\"\n    ]\n\n  polkadotui:\n    container_name: polkadotui\n    image: jacogr/polkadot-js-apps\n    environment:\n      - WS_URL=ws://[YOUR_DOCKER_HOST_IP]:9944\n    ports:\n      - 80:80"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain upgrade instructions\ninput: "
      },
      {
        "role": "assistant",
        "content": "Not too much has changed on the top and API level for developing Substrate between 2.0 and 3.0. The easiest and quickest\npath for upgrading is just to take the latest node-template and try applying your changes to it:\n1. take a diff between 2.0 and your changes\n2. store that diff\n3. remove everything, copy over the 3.0 node-template\n4. try re-applying your diff, manually, a hunk at a time.\n\nIf that doesn't work for you, we are working on an in-depth-guide for all major changes that took place and how you need\nto adapt your code for it. You can find the upgrade guide under `docs/` in the\nrepo, if you have further questions\nor problem, please feel free to ask in the github discussion\nboard.\n\n### Runtime\n\n* contracts: Charge rent for code storage (#7935)\n* contracts: Emit event on contract termination (#8014)\n* Fix elections-phragmen and proxy issue (#7040)\n* Allow validators to block and kick their nominator set. (#7930)\n* Decouple Staking and Election - Part1: Support traits (#7908)\n* Introduces account existence providers reference counting (#7363)\n* contracts: Cap the surcharge reward by the amount of rent that way paid by a contract (#7870)\n* Use checked math when calculating storage size (#7885)\n* Fix clear prefix check to avoid erasing child trie roots. (#7848)\n* contracts: Collect rent for the first block during deployment (#7847)\n* contracts: Add configurable per-storage item cost (#7819)\n* babe: expose next epoch data (#7829)\n* fix : remove `_{ }` syntax from benchmark macro (#7822)\n* Define ss58 prefix inside the runtime (#7810)\n* Allow council to slash treasury tip (#7753)\n* Don't allow self proxies (#7803)\n* add a `current_epoch` to BabeApi (#7789)\n* Add `pallet` attribute macro to declare pallets (#6877)\n* Make it possible to calculate the storage root as often as you want (#7714)\n* Issue 7143 | Refactor Treasury Pallet into Bounties, Tips, and Proposals (#7536)\n* Participating in Council Governance is Free for First Time Voters and Successful Closing (#7661)\n* Streamline frame_system weight parametrization (#6629)\n* Features needed for reserve-backed stablecoins (#7152)\n* `sudo_as` should return a result (#7620)\n* More Extensible Multiaddress Format (#7380)\n* Fix `on_runtime_upgrade` weight recording (#7480)\n* Implement batch_all and update Utility pallet for weight refunds (#7188)\n* Fix wrong outgoing calculation in election (#7384)\n* Implements pallet versioning (#7208)\n* Runtime worker threads (#7089)\n* Allow `schedule_after(0, ...)` to work (#7284)\n* Fix offchain election to respect the weight (#7215)\n* Fix weight for inner call with new origin (#7196)\n* Move proxies migration (#7205)\n* Introduce `cancel_proposal` to rid us of those pesky proposals (#7111)\n\n### Client\n\n* Remove backwards-compatibility networking hack (#8068)\n* Extend SS58 network identifiers (#8039)\n* Update dependencies ahead of next release (#8015)\n* Storage chains: serve transactions over IPFS/bitswap (#7963)\n* Add a send_request function to NetworkService (#8008)\n* Rename system_networkState to system_unstable_networkState (#8001)\n* Allow transaction for offchain indexing (#7290)\n* Grandpa warp sync request-response protocol (#7711)\n* Add explicit limits to notifications sizes and adjust yamux buffer size (#7925)\n* Rework priority groups, take 2 (#7700)\n* Define ss58 prefix inside the runtime (#7810)\n* Expand remote keystore interface to allow for hybrid mode (#7628)\n* Allow capping the amount of work performed when deleting a child trie (#7671)\n* RPC to allow setting the log filter (#7474)\n* Remove sc_network::NetworkService::register_notifications_protocol and partially refactor Grandpa tests (#7646)\n* minor fix and improvements on localkeystore (#7626)\n* contracts: Add `salt` argument to contract instantiation (#7482)\n* contracts: Rework contracts_call RPC (#7468)\n* Make sure to use the optimized method instead of reading the storage. (#7445)\n* WASM Local-blob override (#7317)\n* client/network: Allow configuring Kademlia's disjoint query paths (#7356)\n* client/network: Remove option to disable yamux flow control (#7358)\n* Make `queryStorage` and `storagePairs` unsafe RPC functions (#7342)\n* No longer actively open legacy substreams (#7076)\n* Make `run_node_until_exit` take a future (#7318)\n* Add an system_syncState RPC method (#7315)\n* Async keystore + Authority-Discovery async/await (#7000)\n* Fixes logging of target names with dashes (#7281)\n* Refactor CurrencyToVote (#6896)\n* client/network: Stop sending noise legacy handshake (#7211)\n\n### API\n\n* pallet macro: easier syntax for `#[pallet::pallet]` with `struct Pallet<T>(_)` (#8091)\n* WasmExecutor takes a cache directory (#8057)\n* Remove PalletInfo impl for () (#8090)\n* Migrate assets pallet to new macros (#7984)\n* contracts: Make ChainExtension trait generic over the runtime (#8003)\n* Decouple the session validators from im-online (#7127)\n* Update `parity-scale-codec` to 2.0 (#7994)\n* Merkle Mountain Range pallet improvements (#7891)\n* Cleaner GRANDPA RPC API for proving finality (#7339)\n* Migrate frame-system to pallet attribute macro (#7898)\n* Introduces account existence providers reference counting (#7363)\n* contracts: Lazy storage removal (#7740)\n* contracts: Allow runtime authors to define a chain extension (#7548)\n* Define ss58 prefix inside the runtime (#7810)\n* Add `pallet` attribute macro to declare pallets (#6877)\n* Add keccak-512 to host functions. (#7531)\n* Merkle Mountain Range pallet (#7312)\n* Allow capping the amount of work performed when deleting a child trie (#7671)\n* add an upgrade_keys method for pallet-session (#7688)\n* Streamline frame_system weight parametrization (#6629)\n* Rename pallet trait `Trait` to `Config` (#7599)\n* contracts: Add `salt` argument to contract instantiation (#7482)\n* pallet-evm: move to Frontier (Part IV) (#7573)\n* refactor subtrait/elevated trait as not needed (#7497)\n* Allow BabeConsensusDataProvider fork existing chain (#7078)\n* decouple transaction payment and currency (#6912)\n* contracts: Refactor the runtime API in order to simplify node integration (#7409)\n* client/authority-discovery: Remove sentry node logic (#7368)\n* client/network: Make NetworkService::set_priority_group async (#7352)\n* *: Bump async-std to v1.6.5 (#7306)\n* babe: make secondary slot randomness available on-chain (#7053)\n* allow where clause in decl_error (#7324)\n* reschedule (#6860)\n* SystemOrigin trait (#7226)\n* permit setting treasury pallet initial funding through genesis (#7214)\n\n### Runtime Migrations\n\n* Migrate assets pallet to new macros (#7984)\n* Fix elections-phragmen and proxy issue (#7040)\n* Allow validators to block and kick their nominator set. (#7930)\n* Migrate frame-system to pallet attribute macro (#7898)\n* Implements pallet versioning (#7208)\n* Move proxies migration (#7205)"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain runtime\ninput: "
      },
      {
        "role": "assistant",
        "content": "* Custom Codec Implementation for NPoS Election (#6720)\n* Successful `note_imminent_preimage` is free (#6793)\n* pallet-democracy use of weightinfo (#6783)\n* Update Balances Pallet to use `WeightInfo` (#6610)\n* pallet-evm: add builtin support for the four basic Ethereum precompiles (#6743)\n* Allow `PostDispatchInfo` to disable fees (#6749)\n* pallet-evm: add support for tuple-based precompile declarations (#6681)\n* grandpa: allow noting that the set has stalled (#6725)\n\n### Client\n\n* Merge Subkey into sc-cli (#4954)\n* RpcHandlers Refactorings (#6846)\n* client/authority-discovery: Introduce AuthorityDiscoveryService (#6760)\n* Implement tracing::Event handling & parent_id for spans and events (#6672)\n* Move to upstream wasmtime, refactor globals snapshot  (#6759)\n* Revalidate transactions only on latest best block (#6824)\n* Allow task manager to have children (#6771)\n* client/network: Expose DHT query duration to Prometheus (#6784)\n* client/network: Add peers to DHT only if protocols match (#6549)\n* Name all the tasks! (#6726)\n* Child nodes can be handled by adding a child `TaskManager` to the parent's `TaskManager` (#6771)"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain runtime\ninput: "
      },
      {
        "role": "assistant",
        "content": "* Support using system storage directly for EVM balance and nonce (#6659)\n* Properly filter out duplicate voters in elections. (#6693)\n* Treasury burning can be directed (#6671)\n* identity: Don't let subs be re-registered (#6667)\n* Regression test to ensure we don't break deterministic builds in wasm (#6597)\n* allow to specify schedule time as a relative value (#6578)\n* Make signature batching use specialized methods (#6616)\n* Rename `CheckEra` to `CheckMortality` (#6619)\n* Add `WeightInfo` to all pallets with benchmarks. (#6575)\n* Don't require module name in inherents (#6576)\n* pallet-evm: return Ok(()) when EVM execution fails (#6493)\n* Make the encoded-Call Vec<u8> explicitly so in metadata (#6566)\n* Allow specify schedule dispatch origin (#6387)\n* pallet-evm: customizable chain id (#6537)\n* Refactor as_sub to make things clearer. (#6503)"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain client\ninput: "
      },
      {
        "role": "assistant",
        "content": "* Update wasmtime to (almost) latest master (#6662)\n* Update to latest sysinfo prevents leaking fd-handlers (#6708)\n* Tracing values (#6679)\n* Graceful shutdown for the task manager (#6654)\n* Update `substrate-networking` Grafana dashboard (#6649)\n* *: Update to libp2p v0.21.1 (#6559)\n* Send Status message on all newly-opened legacy substreams (#6593)\n* babe: report equivocations (#6362)\n* Support synching of blocks that are not `new_best` (#6508)\n* Remove the service, replacing it with a struct of individual chain components (#6352)\n* Fix tx-pool returning the same transaction multiple times (#6535)"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain runtime\ninput: "
      },
      {
        "role": "assistant",
        "content": "* Staking Payout Creates Controller (#6496)\n* `pallet-scheduler`: Check that `when` is not in the past (#6480)\n* Fix `sp-api` handling of multiple arguments (#6484)\n* Fix issues with `Operational` transactions validity and prioritization. (#6435)\n* pallet-atomic-swap: generalized swap action (#6421)\n* Avoid multisig reentrancy (#6445)\n* Root origin use no filter by default. Scheduler and Democracy dispatch without asserting BaseCallFilter (#6408)\n* Scale and increase validator count (#6417)\n* Pallet: Atomic Swap (#6349)\n* Restrict remove_proxies (#6383)\n* Stored call in multisig (#6319)\n* Allow Sudo to do anything (#6375)\n* vesting: Force Vested Transfer (#6368)\n* Add events for balance reserve and unreserve functions (#6330)\n* Introduce frozen indices. (#6307)"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain client\ninput: "
      },
      {
        "role": "assistant",
        "content": "* client/network/service: Add primary dimension to connection metrics (#6472)\n* Fix Babe secondary plain slots claiming (#6451)\n* add network propagated metrics (#6438)\n* client/authority-discovery: Compare PeerIds and not Multihashes (#6414)\n* Update sync chain info on own block import (#6424)\n* Remove --legacy-network-protocol CLI flag (#6411)\n* Runtime interface to add support for tracing from wasm (#6381)\n* Remove penalty on duplicate Status message (#6377)\n* Fix the broken weight multiplier update function (#6334)\n* client/authority-discovery: Don't add own address to priority group (#6370)\n* Split the service initialisation up into separate functions (#6332)\n* Fix transaction pool event sending (#6341)\n* Add a [prefix]_process_start_time_seconds metric (#6315)\n* new crate sc-light (#6235)\n* Allow adding a prefix to the informant (#6174)"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain client\ninput: "
      },
      {
        "role": "assistant",
        "content": "* Make transaction pool prune transactions only of canonical blocks (#6123)\n* Rename all the election operations (#6245)\n* Sentry nodes and validator nodes also imply reserved (#6251)\n* Fix peerset not filtering incoming connections in reserved-only (#6249)\n* Use Subscription Manager from `jsonrpc-pubsub` (#6208)\n* Add a Substrate networking Grafana dashboard template (#6171)\n* Add subkey inspect-node-key (#6153)"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain client\ninput: "
      },
      {
        "role": "assistant",
        "content": "* Adds `export-state` subcommand (#5842)\n* Drop ClientProvider (#5823)\n* Move spawning tasks from thread pools to Service's TaskManager for block importing (#5647)\n* Reputation penalty for sending empty block response (#5814)\n* Move sc-client into sc-service (#5502)\n* Use new block requests protocol (#5760)\n* Fix leak in stream notifications (#5739)\n* network: Only insert global addresses into the DHT. (#5735)\n* enum Pays for PaysFee (#5733)\n* Migrate away from `SimpleDispatchInfo` (#5686)\n* Child trie api changes BREAKING (#4857)\n* subkey: compute and inspect a moduleid (#5676)\n* Listen on ipv6 by default as well (#5677)\n* Adjustments to Kademlia-related metrics (#5660)\n* client/authority-discovery: Allow to be run by sentry node (#5568)\n* Add alternative RPC methods to system_networkState (#5643)\n* Several tweaks to networking Prometheus metrics (#5636)\n* Use a Kademlia instance per `ProtocolId`. (#5045)\n* Report tasks metrics to Prometheus (#5619)"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain client\ninput: "
      },
      {
        "role": "assistant",
        "content": "* Add new RPC method to get the chain type (#5576)\n* Reuse wasmtime instances, the PR (#5567)\n* Prometheus Metrics: Turn notifications_total counter into notifications_sizes histogram (#5535)\n* Make verbosity level mandatory with telemetry opt (#5057)\n* Additional Metrics collected and exposed via prometheus (#5414)\n* Switch to new light client protocol (#5472)\n* client/finality-grandpa: Instrument until-imported queue (#5438)\n* Batch benchmarks together with `*` notation. (#5436)\n* src/service/src/builder: Fix memory metric exposed in bytes not KiB (#5459)\n* Make transactions and block announces use notifications substre\u2026 (#5360)\n* Adds state_queryStorageAt (#5362)\n* Offchain Phragm\u00e9n BREAKING. (#4517)\n* `sc_rpc::system::SystemInfo.impl_version` now returns the full version (2.0.0-alpha.2-b950f731c-x86_64-linux-gnu)\n  instead of the short version (1.0.0) (#5271)"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain client\ninput: "
      },
      {
        "role": "assistant",
        "content": "* client/finality-grandpa: Add Prometheus metrics to GossipValidator (#5237)\n* removes use of sc_client::Client from node-transaction-factory (#5158)\n* removes use of sc_client::Client from sc_network (#5147)\n* Use CLI to configure max instances cache (#5177)\n* client/service/src/builder.rs: Add build_info metric (#5192)\n* Remove `substrate-ui.parity.io` from CORS whitelist (#5142)\n* removes use of sc_client::Client from sc-rpc (#5063)\n* Use 128mb for db cache default (#5134)\n* Drop db-cache default from 1gig to 32mb (#5128)\n* Add more metrics to prometheus (#5034)"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain runtime\ninput: "
      },
      {
        "role": "assistant",
        "content": "### FRAME 2.0\n\nThe new FRAME 2.0 macros are a lot nicer to use and easier to read. While we were on that change though, we also cleaned\nup some mainly internal names and traits. The old `macro`'s still work and also produce the new structure, however, when\nplugging all that together as a Runtime, there's some things we have to adapt now:\n\n### `::Trait for Runtime` becomes `::Config for Runtime`\n\nThe most visible and significant change is that the macros no longer generate the `$pallet::Trait` but now a much more\naptly named `$pallet::Config`. Thus, we need to rename all `::Trait for Runtime` into`::Config for Runtime`, e.g. for\nthe `sudo` pallet we must do:\n\n-impl pallet_sudo::Trait for Runtime {\n+impl pallet_sudo::Config for Runtime {\n\nThe same goes for all `<Self as frame_system::Trait>` and alike, which simply becomes `<Self as frame_system::Config>`.\n\n### SS58 Prefix is now a runtime param\n\nSince #7810 we don't define the ss58 prefix in the chainspec\nanymore but moved it into the runtime. Namely, `frame_system` now needs a new `SS58Prefix`, which in Substrate node we\nhave defined for ourselves as: `pub const SS58Prefix: u8 = 42;`. Use your own chain-specific value there.\n\n### Weight Definition\n\n`type WeightInfo` has changed and instead on `weights::pallet_$name::WeightInfo` is now bound to the Runtime as\n`pallet_$name::weights::SubstrateWeight<Runtime>`. As a result we have to the change the type definitions everywhere in\nour Runtime accordingly:\n\n-\ttype WeightInfo = weights::pallet_$name::WeightInfo;\n+\ttype WeightInfo = pallet_$name::weights::SubstrateWeight<Runtime>;\n\ne.g.\n-\ttype WeightInfo = weights::pallet_collective::WeightInfo;\n+\ttype WeightInfo = pallet_collective::weights::SubstrateWeight<Runtime>;\nand\n\n-\ttype WeightInfo = weights::pallet_proxy::WeightInfo;\n+\ttype WeightInfo = pallet_proxy::weights::SubstrateWeight<Runtime>;\n\nAnd update the overall definition for weights on frame and a few related types and runtime parameters:\n\n```diff=\n\n-const AVERAGE_ON_INITIALIZE_WEIGHT: Perbill = Perbill::from_percent(10);\n+/// We assume that ~10% of the block weight is consumed by `on_initialize` handlers.\n+/// This is used to limit the maximal weight of a single extrinsic.\n+const AVERAGE_ON_INITIALIZE_RATIO: Perbill = Perbill::from_percent(10);\n+/// We allow `Normal` extrinsics to fill up the block up to 75%, the rest can be used\n+/// by  Operational  extrinsics.\n+const NORMAL_DISPATCH_RATIO: Perbill = Perbill::from_percent(75);\n+/// We allow for 2 seconds of compute with a 6 second average block time.\n+const MAXIMUM_BLOCK_WEIGHT: Weight = Weight::from_parts(2u64 * WEIGHT_REF_TIME_PER_SECOND, u64::MAX);\n+\n parameter_types! {\n \tpub const BlockHashCount: BlockNumber = 2400;\n-\t/// We allow for 2 seconds of compute with a 6 second average block time.\n-\tpub const MaximumBlockWeight: Weight = Weight::from_parts(2u64 * WEIGHT_REF_TIME_PER_SECOND, u64::MAX);\n-\tpub const AvailableBlockRatio: Perbill = Perbill::from_percent(75);\n-\t/// Assume 10% of weight for average on_initialize calls.\n-\tpub MaximumExtrinsicWeight: Weight =\n-\t\tAvailableBlockRatio::get().saturating_sub(AVERAGE_ON_INITIALIZE_WEIGHT)\n-\t\t* MaximumBlockWeight::get();\n-\tpub const MaximumBlockLength: u32 = 5 * 1024 * 1024;\n \tpub const Version: RuntimeVersion = VERSION;\n-}\n-\n-const_assert!(AvailableBlockRatio::get().deconstruct() >= AVERAGE_ON_INITIALIZE_WEIGHT.deconstruct());\n-\n-impl frame_system::Trait for Runtime {\n+\tpub RuntimeBlockLength: BlockLength =\n+\t\tBlockLength::max_with_normal_ratio(5 * 1024 * 1024, NORMAL_DISPATCH_RATIO);\n+\tpub RuntimeBlockWeights: BlockWeights = BlockWeights::builder()\n+\t\t.base_block(BlockExecutionWeight::get())\n+\t\t.for_class(DispatchClass::all(), |weights| {\n+\t\t\tweights.base_extrinsic = ExtrinsicBaseWeight::get();\n+\t\t})\n+\t\t.for_class(DispatchClass::Normal, |weights| {\n+\t\t\tweights.max_total = Some(NORMAL_DISPATCH_RATIO * MAXIMUM_BLOCK_WEIGHT);\n+\t\t})\n+\t\t.for_class(DispatchClass::Operational, |weights| {\n+\t\t\tweights.max_total = Some(MAXIMUM_BLOCK_WEIGHT);\n+\t\t\t// Operational transactions have some extra reserved space, so that they\n+\t\t\t// are included even if block reached `MAXIMUM_BLOCK_WEIGHT`.\n+\t\t\tweights.reserved = Some(\n+\t\t\t\tMAXIMUM_BLOCK_WEIGHT - NORMAL_DISPATCH_RATIO * MAXIMUM_BLOCK_WEIGHT\n+\t\t\t);\n+\t\t})\n+\t\t.avg_block_initialization(AVERAGE_ON_INITIALIZE_RATIO)\n+\t\t.build_or_panic();\n+}\n+\n+const_assert!(NORMAL_DISPATCH_RATIO.deconstruct() >= AVERAGE_ON_INITIALIZE_RATIO.deconstruct());\n+\n+impl frame_system::Config for Runtime {\n \ttype BaseCallFilter = frame_support::traits::AllowAll;\n+\ttype BlockWeights = RuntimeBlockWeights;\n+\ttype BlockLength = RuntimeBlockLength;\n+\ttype DbWeight = RocksDbWeight;\n \ttype RuntimeOrigin = RuntimeOrigin;\n \ttype RuntimeCall = RuntimeCall;\n \ttype Index = Index;\n@@ -171,25 +198,19 @@ impl frame_system::Trait for Runtime {\n \ttype Header = generic::Header<BlockNumber, BlakeTwo256>;\n \ttype Event = Event;\n \ttype BlockHashCount = BlockHashCount;\n-\ttype MaximumBlockWeight = MaximumBlockWeight;\n-\ttype DbWeight = RocksDbWeight;\n-\ttype BlockExecutionWeight = BlockExecutionWeight;\n-\ttype ExtrinsicBaseWeight = ExtrinsicBaseWeight;\n-\ttype MaximumExtrinsicWeight = MaximumExtrinsicWeight;\n-\ttype MaximumBlockLength = MaximumBlockLength;\n-\ttype AvailableBlockRatio = AvailableBlockRatio;\n \ttype Version = Version;\n \ttype PalletInfo = PalletInfo;\n \ttype AccountData = pallet_balances::AccountData<Balance>;\n \ttype OnNewAccount = ();\n \ttype OnKilledAccount = ();\n-\ttype SystemWeightInfo = weights::frame_system::WeightInfo;\n+\ttype SystemWeightInfo = frame_system::weights::SubstrateWeight<Runtime>;\n\n### Pallets\n\n### Assets\n\nThe assets pallet has seen a variety of changes:\n- Features needed for reserve-backed stablecoins #7152\n- Freeze Assets and Asset Metadata #7346\n- Introduces account existence providers reference counting #7363)\n\nhave all altered the feature set and changed the concepts. However, it has some of the best documentation and explains\nthe current state very well. If you are using the assets pallet and need to upgrade from an earlier version, we\nrecommend you use the current docs to guide your way!\n\n### Contracts\n\nAs noted in the changelog, the `contracts`-pallet is still undergoing massive changes and is not yet part of this\nrelease. We are expecting for it to be released a few weeks after. If your chain is dependent on this pallet, we\nrecommend to wait until it has been released as the currently released version is not compatible with FRAME 2.0.\n\n### (changes) Treasury\n\nAs mentioned above, Bounties, Tips and Lottery have been extracted out of treasury into their own pallets - removing\nthese options here. Secondly we must now specify the `BurnDestination`  and `SpendFunds`, which now go the `Bounties`.\ndiff\n-\ttype Tippers = Elections;\n-\ttype TipCountdown = TipCountdown;\n-\ttype TipFindersFee = TipFindersFee;\n-\ttype TipReportDepositBase = TipReportDepositBase;\n-\ttype DataDepositPerByte = DataDepositPerByte;\n \ttype Event = Event;\n \ttype OnSlash = ();\n \ttype ProposalBond = ProposalBond;\n \ttype ProposalBondMinimum = ProposalBondMinimum;\n\ttype ProposalBondMaximum = ();\n \ttype SpendPeriod = SpendPeriod;\n \ttype Burn = Burn;\n+\ttype BurnDestination = ();\n+\ttype SpendFunds = Bounties;\n\nFactoring out Bounties and Tips means most of these definitions have now moved there, while the parameter types can be\nleft as they were:\n\n### \ud83c\udd95 Bounties\nrust=\nimpl pallet_bounties::Config for Runtime {\n\ttype Event = Event;\n \ttype BountyDepositBase = BountyDepositBase;\n \ttype BountyDepositPayoutDelay = BountyDepositPayoutDelay;\n \ttype BountyUpdatePeriod = BountyUpdatePeriod;\n \ttype BountyCuratorDeposit = BountyCuratorDeposit;\n \ttype BountyValueMinimum = BountyValueMinimum;\n\ttype DataDepositPerByte = DataDepositPerByte;\n \ttype MaximumReasonLength = MaximumReasonLength;\n\ttype WeightInfo = pallet_bounties::weights::SubstrateWeight<Runtime>;\n }\n\n### \ud83c\udd95 Tips\nrust=\nimpl pallet_tips::Config for Runtime {\n\ttype Event = Event;\n\ttype DataDepositPerByte = DataDepositPerByte;\n\ttype MaximumReasonLength = MaximumReasonLength;\n\ttype Tippers = Elections;\n\ttype TipCountdown = TipCountdown;\n\ttype TipFindersFee = TipFindersFee;\n\ttype TipReportDepositBase = TipReportDepositBase;\n\ttype MaxTipAmount = MaxTipAmount;\n\ttype WeightInfo = pallet_tips::weights::SubstrateWeight<Runtime>;\n }\n\n### `FinalityTracker` removed\n\nFinality Tracker has been removed in favor of a different approach to handle the issue in GRANDPA, see #7228 for\ndetails. With latest GRANDPA this is not needed anymore and can be\nremoved without worry.\n\n### (changes) Elections Phragmen\n\nThe pallet has been moved to a new system in which the exact amount of deposit for each voter, candidate, member, or\nrunner-up is now deposited on-chain. Moreover, the concept of a `defunct_voter` is removed, since votes now have\nadequate deposit associated with them. A number of configuration parameters has changed to reflect this, as shown below:\ndiff=\n parameter_types! {\n \tpub const CandidacyBond: Balance = 10 * DOLLARS;\n-\tpub const VotingBond: Balance = 1 * DOLLARS;\n+\t// 1 storage item created, key size is 32 bytes, value size is 16+16.\n+\tpub const VotingBondBase: Balance = deposit(1, 64);\n+\t// additional data per vote is 32 bytes (account id).\n+\tpub const VotingBondFactor: Balance = deposit(0, 32);\n \tpub const TermDuration: BlockNumber = 7 * DAYS;\n \tpub const DesiredMembers: u32 = 13;\n \tpub const DesiredRunnersUp: u32 = 7;\n\n@@ -559,16 +600,16 @@ impl pallet_elections_phragmen::Trait for Runtime {\n \t// NOTE: this implies that council's genesis members cannot be set directly and must come from\n \t// this module.\n \ttype InitializeMembers = Council;\n-\ttype CurrencyToVote = CurrencyToVoteHandler;\n+\ttype CurrencyToVote = U128CurrencyToVote;\n \ttype CandidacyBond = CandidacyBond;\n-\ttype VotingBond = VotingBond;\n+\ttype VotingBondBase = VotingBondBase;\n+\ttype VotingBondFactor = VotingBondFactor;\n \ttype LoserCandidate = ();\n-\ttype BadReport = ();\n \ttype KickedMember = ();\n \ttype DesiredMembers = DesiredMembers;\n \ttype DesiredRunnersUp = DesiredRunnersUp;\n \ttype TermDuration = TermDuration;\n \n **This upgrade requires storage\n migration**.\n Further details can be found in the pallet-specific\n changelog.\n\n### (changes) Democracy\n\nDemocracy brings three new settings with this release, all to allow for better influx- and spam-control. Namely these\nallow to specify the maximum number of proposals at a time, who can blacklist and who can cancel proposals. This diff\nacts as a good starting point:\ndiff=\n@@ -508,6 +537,14 @@ impl pallet_democracy::Trait for Runtime {\n \ttype FastTrackVotingPeriod = FastTrackVotingPeriod;\n \t// To cancel a proposal which has been passed, 2/3 of the council must agree to it.\n \ttype CancellationOrigin = pallet_collective::EnsureProportionAtLeast<_2, _3, AccountId, CouncilCollective>;\n+\t// To cancel a proposal before it has been passed, the technical committee must be unanimous or\n+\t// Root must agree.\n+\ttype CancelProposalOrigin = EitherOfDiverse<\n+\t\tAccountId,\n+\t\tEnsureRoot<AccountId>,\n+\t\tpallet_collective::EnsureProportionAtLeast<_1, _1, AccountId, TechnicalCollective>,\n+\t>;\n+\ttype BlacklistOrigin = EnsureRoot<AccountId>;\n \t// Any single technical committee member may veto a coming council proposal, however they can\n \t// only do it once and it lasts only for the cooloff period.\n \ttype VetoOrigin = pallet_collective::EnsureMember<AccountId, TechnicalCollective>;\n@@ -518,7 +555,8 @@ impl pallet_democracy::Trait for Runtime {\n \ttype Scheduler = Scheduler;\n \ttype PalletsOrigin = OriginCaller;\n \ttype MaxVotes = MaxVotes;\n+\ttype MaxProposals = MaxProposals;\n }\n```\n\n----"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain client\ninput: "
      },
      {
        "role": "assistant",
        "content": "### CLI\n\nA few minor things have changed in the `cli` (compared to 2.0.1):\n\n1. we've replaced the newly added `BuildSyncSpec` subcommand with an RPC\n   API\n   in an on-going effort to make light-client-support smoother, see below\n2. we've removed double accounts from our\n   chainspec-builder\n3. we don't fallback to `--chain flaming-fir`\n   anymore, if no chain is\n   given our `substrate-node` will error.\n4. the `subkey`-integration has seen a fix to the\n   `insert`-command that\n   requires you to now add the `&cli` as a param.\n    ```diff=\n    --- a/bin/node/cli/src/command.rs\n    +++ b/bin/node/cli/src/command.rs\n    @@ -92,7 +97,7 @@ pub fn run() -> Result<()> {\n                    You can enable it with `--features runtime-benchmarks`.\".into())\n                }\n            }\n    -\t\tSome(Subcommand::Key(cmd)) => cmd.run(),\n    +\t\tSome(Subcommand::Key(cmd)) => cmd.run(&cli),\n            Some(Subcommand::Sign(cmd)) => cmd.run(),\n            Some(Subcommand::Verify(cmd)) => cmd.run(),\n            Some(Subcommand::Vanity(cmd)) => cmd.run(),\n    \n### Service Builder Upgrades\n\n### Light client support\n\nAs said, we've added a new optional RPC service for improved light client support. For that to work, we need to pass the\n`chain_spec` and give access  to the `AuxStore` to our `rpc`:\ndiff=\n\n--- a/bin/node/rpc/src/lib.rs\n+++ b/bin/node/rpc/src/lib.rs\n@@ -49,6 +49,7 @@ use sp_consensus::SelectChain;\n use sp_consensus_babe::BabeApi;\n use sc_rpc::SubscriptionTaskExecutor;\n use sp_transaction_pool::TransactionPool;\n+use sc_client_api::AuxStore;\n\n /// Light client extra dependencies.\n pub struct LightDeps<C, F, P> {\n@@ -94,6 +95,8 @@ pub struct FullDeps<C, P, SC, B> {\n \tpub pool: Arc<P>,\n \t/// The SelectChain Strategy\n \tpub select_chain: SC,\n+\t/// A copy of the chain spec.\n+\tpub chain_spec: Box<dyn sc_chain_spec::ChainSpec>,\n \t/// Whether to deny unsafe calls\n \tpub deny_unsafe: DenyUnsafe,\n \t/// BABE specific dependencies.\n@@ -109,9 +112,8 @@ pub type IoHandler = jsonrpc_core::IoHandler<sc_rpc::Metadata>;\n pub fn create_full<C, P, SC, B>(\n \tdeps: FullDeps<C, P, SC, B>,\n ) -> jsonrpc_core::IoHandler<sc_rpc_api::Metadata> where\n-\tC: ProvideRuntimeApi<Block>,\n-\tC: HeaderBackend<Block> + HeaderMetadata<Block, Error=BlockChainError> + 'static,\n-\tC: Send + Sync + 'static,\n+\tC: ProvideRuntimeApi<Block> + HeaderBackend<Block> + AuxStore +\n+\t\tHeaderMetadata<Block, Error=BlockChainError> + Sync + Send + 'static,\n \tC::Api: substrate_frame_rpc_system::AccountNonceApi<Block, AccountId, Index>,\n \tC::Api: pallet_contracts_rpc::ContractsRuntimeApi<Block, AccountId, Balance, BlockNumber>,\n \tC::Api: pallet_transaction_payment_rpc::TransactionPaymentRuntimeApi<Block, Balance>,\n@@ -131,6 +133,7 @@ pub fn create_full<C, P, SC, B>(\n \t\tclient,\n \t\tpool,\n \t\tselect_chain,\n+\t\tchain_spec,\n \t\tdeny_unsafe,\n \t\tbabe,\n \t\tgrandpa,\n@@ -164,8 +167,8 @@ pub fn create_full<C, P, SC, B>(\n \tio.extend_with(\n \t\tsc_consensus_babe_rpc::BabeApi::to_delegate(\n \t\t\tBabeRpcHandler::new(\n-\t\t\t\tclient,\n-\t\t\t\tshared_epoch_changes,\n+\t\t\t\tclient.clone(),\n+\t\t\t\tshared_epoch_changes.clone(),\n \t\t\t\tkeystore,\n \t\t\t\tbabe_config,\n \t\t\t\tselect_chain,\n@@ -176,7 +179,7 @@ pub fn create_full<C, P, SC, B>(\n \tio.extend_with(\n \t\tsc_finality_grandpa_rpc::GrandpaApi::to_delegate(\n \t\t\tGrandpaRpcHandler::new(\n-\t\t\t\tshared_authority_set,\n+\t\t\t\tshared_authority_set.clone(),\n \t\t\t\tshared_voter_state,\n \t\t\t\tjustification_stream,\n \t\t\t\tsubscription_executor,\n\n\nand add the new service:\ndiff=\n--- a/bin/node/rpc/src/lib.rs\n+++ b/bin/node/rpc/src/lib.rs\n@@ -185,6 +188,18 @@ pub fn create_full<C, P, SC, B>(\n \t\t)\n \t);\n\n+\tio.extend_with(\n+\t\tsc_sync_state_rpc::SyncStateRpcApi::to_delegate(\n+\t\t\tsc_sync_state_rpc::SyncStateRpcHandler::new(\n+\t\t\t\tchain_spec,\n+\t\t\t\tclient,\n+\t\t\t\tshared_authority_set,\n+\t\t\t\tshared_epoch_changes,\n+\t\t\t\tdeny_unsafe,\n+\t\t\t)\n+\t\t)\n+\t);\n+\n \tio\n }\n\n### Telemetry\n\nThe telemetry subsystem has seen a few fixes and refactorings to allow for a more flexible handling, in particular in\nregards to parachains. Most notably `sc_service::spawn_tasks` now returns the `telemetry_connection_notifier` as the\nsecond member of the tuple, (`let (_rpc_handlers, telemetry_connection_notifier) = sc_service::spawn_tasks(`), which\nshould be passed to `telemetry_on_connect` of `new_full_base` now: `telemetry_on_connect:\ntelemetry_connection_notifier.map(|x| x.on_connect_stream()),` (see the service-section below for a full diff).\n\n### Async & Remote Keystore support\n\nIn order to allow for remote-keystores, the keystore-subsystem has been reworked to support async operations and\ngenerally refactored to not provide the keys itself but only sign on request. This allows for remote-keystore to never\nhand out keys and thus to operate any Substrate-based node in a manner without ever having the private keys in the local\nsystem memory.\n\nThere are some operations, however, that the keystore must be local for performance reasons and for which a remote\nkeystore won't work (in particular around parachains). As such, the keystore has both a slot for remote but also always\na local instance, where some operations hard bind to the local variant, while most subsystems just ask the generic\nkeystore which prefers a remote signer if given. To reflect this change, `sc_service::new_full_parts` now returns a\n`KeystoreContainer` rather than the keystore, and the other subsystems (e.g. `sc_service::PartialComponents`) expect to\nbe given that.\n\n### on RPC\n\nThis has most visible changes for the rpc, where we are switching from the previous `KeyStorePtr` to the new\n`SyncCryptoStorePtr`:\ndiff\n\n--- a/bin/node/rpc/src/lib.rs\n+++ b/bin/node/rpc/src/lib.rs\n@@ -32,6 +32,7 @@\n\n use std::sync::Arc;\n\n+use sp_keystore::SyncCryptoStorePtr;\n use node_primitives::{Block, BlockNumber, AccountId, Index, Balance, Hash};\n use sc_consensus_babe::{Config, Epoch};\n use sc_consensus_babe_rpc::BabeRpcHandler;\n@@ -40,7 +41,6 @@ use sc_finality_grandpa::{\n \tSharedVoterState, SharedAuthoritySet, FinalityProofProvider, GrandpaJustificationStream\n };\n use sc_finality_grandpa_rpc::GrandpaRpcHandler;\n-use sc_keystore::KeyStorePtr;\n pub use sc_rpc_api::DenyUnsafe;\n use sp_api::ProvideRuntimeApi;\n use sp_block_builder::BlockBuilder;\n pub struct LightDeps<C, F, P> {\n@@ -69,7 +70,7 @@ pub struct BabeDeps {\n \t/// BABE pending epoch changes.\n \tpub shared_epoch_changes: SharedEpochChanges<Block, Epoch>,\n \t/// The keystore that manages the keys of the node.\n-\tpub keystore: KeyStorePtr,\n+\tpub keystore: SyncCryptoStorePtr,\n }\n\n\n### GRANDPA\n\nAs already in the changelog, a few things significant things have changed in regards to GRANDPA: the finality tracker\nhas been replaced, an RPC command has been added and WARP-sync-support for faster light client startup has been\nimplemented. All this means we have to do a few changes to our GRANDPA setup procedures in the client.\n\nFirst and foremost, grandpa internalised a few aspects, and thus `new_partial` doesn't expect a tuple but only the\n`grandpa::SharedVoterState` as input now, and unpacking that again later is not needed anymore either. On the opposite\nside `grandpa::FinalityProofProvider::new_for_service` now requires the `Some(shared_authority_set)` to be passed as a\nnew third parameter. This set also becomes relevant when adding warp-sync-support, which is added as an\nextra-protocol-layer to the networking as:diff=\n\n+\tconfig.network.extra_sets.push(grandpa::grandpa_peers_set_config());\n+\n+\t#[cfg(feature = \"cli\")]\n+\tconfig.network.request_response_protocols.push(sc_finality_grandpa_warp_sync::request_response_config_for_chain(\n+\t\t&config, task_manager.spawn_handle(), backend.clone(),\n+\t));\n\nAs these changes pull through the entirety of `cli/src/service.rs`, we recommend looking at the final diff below for\nguidance.\n\n### In a nutshell\n\nAltogether this accumulates to the following diff for `node/cli/src/service.rs`. If you want these features and have\nmodified your chain you should probably try to apply these patches:\ndiff=\n--- a/bin/node/cli/src/service.rs\n+++ b/bin/node/cli/src/service.rs\n@@ -22,11 +22,10 @@\n\n use std::sync::Arc;\n use sc_consensus_babe;\n-use grandpa::{self, FinalityProofProvider as GrandpaFinalityProofProvider};\n use node_primitives::Block;\n use node_runtime::RuntimeApi;\n use sc_service::{\n-\tconfig::{Role, Configuration}, error::{Error as ServiceError},\n+\tconfig::{Configuration}, error::{Error as ServiceError},\n \tRpcHandlers, TaskManager,\n };\n use sp_inherents::InherentDataProviders;\n@@ -34,8 +33,8 @@ use sc_network::{Event, NetworkService};\n use sp_runtime::traits::Block as BlockT;\n use futures::prelude::*;\n use sc_client_api::{ExecutorProvider, RemoteBackend};\n-use sp_core::traits::BareCryptoStorePtr;\n use node_executor::Executor;\n+use sc_telemetry::TelemetryConnectionNotifier;\n\n type FullClient = sc_service::TFullClient<Block, RuntimeApi, Executor>;\n type FullBackend = sc_service::TFullBackend<Block>;\n@@ -58,13 +57,10 @@ pub fn new_partial(config: &Configuration) -> Result<sc_service::PartialComponen\n \t\t\tgrandpa::LinkHalf<Block, FullClient, FullSelectChain>,\n \t\t\tsc_consensus_babe::BabeLink<Block>,\n \t\t),\n-\t\t(\n-\t\t\tgrandpa::SharedVoterState,\n-\t\t\tArc<GrandpaFinalityProofProvider<FullBackend, Block>>,\n-\t\t),\n+\t\tgrandpa::SharedVoterState,\n \t)\n >, ServiceError> {\n-\tlet (client, backend, keystore, task_manager) =\n+\tlet (client, backend, keystore_container, task_manager) =\n \t\tsc_service::new_full_parts::<Block, RuntimeApi, Executor>(&config)?;\n \tlet client = Arc::new(client);\n\n@@ -94,7 +90,6 @@ pub fn new_partial(config: &Configuration) -> Result<sc_service::PartialComponen\n \t\tbabe_link.clone(),\n \t\tblock_import.clone(),\n \t\tSome(Box::new(justification_import)),\n-\t\tNone,\n \t\tclient.clone(),\n \t\tselect_chain.clone(),\n \t\tinherent_data_providers.clone(),\n@@ -111,10 +106,12 @@ pub fn new_partial(config: &Configuration) -> Result<sc_service::PartialComponen\n \t\tlet justification_stream = grandpa_link.justification_stream();\n \t\tlet shared_authority_set = grandpa_link.shared_authority_set().clone();\n \t\tlet shared_voter_state = grandpa::SharedVoterState::empty();\n-\t\tlet finality_proof_provider =\n-\t\t\tGrandpaFinalityProofProvider::new_for_service(backend.clone(), client.clone());\n+\t\tlet rpc_setup = shared_voter_state.clone();\n\n-\t\tlet rpc_setup = (shared_voter_state.clone(), finality_proof_provider.clone());\n+\t\tlet finality_proof_provider = grandpa::FinalityProofProvider::new_for_service(\n+\t\t\tbackend.clone(),\n+\t\t\tSome(shared_authority_set.clone()),\n+\t\t);\n\n \t\tlet babe_config = babe_link.config().clone();\n \t\tlet shared_epoch_changes = babe_link.epoch_changes().clone();\n@@ -122,13 +119,15 @@ pub fn new_partial(config: &Configuration) -> Result<sc_service::PartialComponen\n \t\tlet client = client.clone();\n \t\tlet pool = transaction_pool.clone();\n \t\tlet select_chain = select_chain.clone();\n-\t\tlet keystore = keystore.clone();\n+\t\tlet keystore = keystore_container.sync_keystore();\n+\t\tlet chain_spec = config.chain_spec.cloned_box();\n\n \t\tlet rpc_extensions_builder = move |deny_unsafe, subscription_executor| {\n \t\t\tlet deps = node_rpc::FullDeps {\n \t\t\t\tclient: client.clone(),\n \t\t\t\tpool: pool.clone(),\n \t\t\t\tselect_chain: select_chain.clone(),\n+\t\t\t\tchain_spec: chain_spec.cloned_box(),\n \t\t\t\tdeny_unsafe,\n \t\t\t\tbabe: node_rpc::BabeDeps {\n \t\t\t\t\tbabe_config: babe_config.clone(),\n@@ -151,9 +150,15 @@ pub fn new_partial(config: &Configuration) -> Result<sc_service::PartialComponen\n \t};\n\n \tOk(sc_service::PartialComponents {\n-\t\tclient, backend, task_manager, keystore, select_chain, import_queue, transaction_pool,\n+\t\tclient,\n+\t\tbackend,\n+\t\ttask_manager,\n+\t\tkeystore_container,\n+\t\tselect_chain,\n+\t\timport_queue,\n+\t\ttransaction_pool,\n \t\tinherent_data_providers,\n-\t\tother: (rpc_extensions_builder, import_setup, rpc_setup)\n+\t\tother: (rpc_extensions_builder, import_setup, rpc_setup),\n \t})\n }\n\n@@ -168,19 +173,32 @@ pub struct NewFullBase {\n\n /// Creates a full service from the configuration.\n pub fn new_full_base(\n-\tconfig: Configuration,\n+\tmut config: Configuration,\n \twith_startup_data: impl FnOnce(\n \t\t&sc_consensus_babe::BabeBlockImport<Block, FullClient, FullGrandpaBlockImport>,\n \t\t&sc_consensus_babe::BabeLink<Block>,\n \t)\n ) -> Result<NewFullBase, ServiceError> {\n \tlet sc_service::PartialComponents {\n-\t\tclient, backend, mut task_manager, import_queue, keystore, select_chain, transaction_pool,\n+\t\tclient,\n+\t\tbackend,\n+\t\tmut task_manager,\n+\t\timport_queue,\n+\t\tkeystore_container,\n+\t\tselect_chain,\n+\t\ttransaction_pool,\n \t\tinherent_data_providers,\n \t\tother: (rpc_extensions_builder, import_setup, rpc_setup),\n \t} = new_partial(&config)?;\n\n-\tlet (shared_voter_state, finality_proof_provider) = rpc_setup;\n+\tlet shared_voter_state = rpc_setup;\n+\n+\tconfig.network.extra_sets.push(grandpa::grandpa_peers_set_config());\n+\n+\t#[cfg(feature = \"cli\")]\n+\tconfig.network.request_response_protocols.push(sc_finality_grandpa_warp_sync::request_response_config_for_chain(\n+\t\t&config, task_manager.spawn_handle(), backend.clone(),\n+\t));\n\n \tlet (network, network_status_sinks, system_rpc_tx, network_starter) =\n \t\tsc_service::build_network(sc_service::BuildNetworkParams {\n@@ -191,8 +209,6 @@ pub fn new_full_base(\n \t\t\timport_queue,\n \t\t\ton_demand: None,\n \t\t\tblock_announce_validator_builder: None,\n-\t\t\tfinality_proof_request_builder: None,\n-\t\t\tfinality_proof_provider: Some(finality_proof_provider.clone()),\n \t\t})?;\n\n \tif config.offchain_worker.enabled {\n@@ -203,26 +219,28 @@ pub fn new_full_base(\n\n \tlet role = config.role.clone();\n \tlet force_authoring = config.force_authoring;\n+\tlet backoff_authoring_blocks =\n+\t\tSome(sc_consensus_slots::BackoffAuthoringOnFinalizedHeadLagging::default());\n \tlet name = config.network.node_name.clone();\n \tlet enable_grandpa = !config.disable_grandpa;\n \tlet prometheus_registry = config.prometheus_registry().cloned();\n-\tlet telemetry_connection_sinks = sc_service::TelemetryConnectionSinks::default();\n\n-\tsc_service::spawn_tasks(sc_service::SpawnTasksParams {\n-\t\tconfig,\n-\t\tbackend: backend.clone(),\n-\t\tclient: client.clone(),\n-\t\tkeystore: keystore.clone(),\n-\t\tnetwork: network.clone(),\n-\t\trpc_extensions_builder: Box::new(rpc_extensions_builder),\n-\t\ttransaction_pool: transaction_pool.clone(),\n-\t\ttask_manager: &mut task_manager,\n-\t\ton_demand: None,\n-\t\tremote_blockchain: None,\n-\t\ttelemetry_connection_sinks: telemetry_connection_sinks.clone(),\n-\t\tnetwork_status_sinks: network_status_sinks.clone(),\n-\t\tsystem_rpc_tx,\n-\t})?;\n+\tlet (_rpc_handlers, telemetry_connection_notifier) = sc_service::spawn_tasks(\n+\t\tsc_service::SpawnTasksParams {\n+\t\t\tconfig,\n+\t\t\tbackend: backend.clone(),\n+\t\t\tclient: client.clone(),\n+\t\t\tkeystore: keystore_container.sync_keystore(),\n+\t\t\tnetwork: network.clone(),\n+\t\t\trpc_extensions_builder: Box::new(rpc_extensions_builder),\n+\t\t\ttransaction_pool: transaction_pool.clone(),\n+\t\t\ttask_manager: &mut task_manager,\n+\t\t\ton_demand: None,\n+\t\t\tremote_blockchain: None,\n+\t\t\tnetwork_status_sinks: network_status_sinks.clone(),\n+\t\t\tsystem_rpc_tx,\n+\t\t},\n+\t)?;\n\n \tlet (block_import, grandpa_link, babe_link) = import_setup;\n\n@@ -230,6 +248,7 @@ pub fn new_full_base(\n\n \tif let sc_service::config::Role::Authority { .. } = &role {\n \t\tlet proposer = sc_basic_authorship::ProposerFactory::new(\n+\t\t\ttask_manager.spawn_handle(),\n \t\t\tclient.clone(),\n \t\t\ttransaction_pool.clone(),\n \t\t\tprometheus_registry.as_ref(),\n@@ -239,7 +258,7 @@ pub fn new_full_base(\n \t\t\tsp_consensus::CanAuthorWithNativeVersion::new(client.executor().clone());\n\n \t\tlet babe_config = sc_consensus_babe::BabeParams {\n-\t\t\tkeystore: keystore.clone(),\n+\t\t\tkeystore: keystore_container.sync_keystore(),\n \t\t\tclient: client.clone(),\n \t\t\tselect_chain,\n \t\t\tenv: proposer,\n@@ -247,6 +266,7 @@ pub fn new_full_base(\n \t\t\tsync_oracle: network.clone(),\n \t\t\tinherent_data_providers: inherent_data_providers.clone(),\n \t\t\tforce_authoring,\n+\t\t\tbackoff_authoring_blocks,\n \t\t\tbabe_link,\n \t\t\tcan_author_with,\n \t\t};\n@@ -256,42 +276,30 @@ pub fn new_full_base(\n \t}\n\n \t// Spawn authority discovery module.\n-\tif matches!(role, Role::Authority{..} | Role::Sentry {..}) {\n-\t\tlet (sentries, authority_discovery_role) = match role {\n-\t\t\tsc_service::config::Role::Authority { ref sentry_nodes } => (\n-\t\t\t\tsentry_nodes.clone(),\n-\t\t\t\tsc_authority_discovery::Role::Authority (\n-\t\t\t\t\tkeystore.clone(),\n-\t\t\t\t),\n-\t\t\t),\n-\t\t\tsc_service::config::Role::Sentry {..} => (\n-\t\t\t\tvec![],\n-\t\t\t\tsc_authority_discovery::Role::Sentry,\n-\t\t\t),\n-\t\t\t_ => unreachable!(\"Due to outer matches! constraint; qed.\")\n-\t\t};\n-\n+\tif role.is_authority() {\n+\t\tlet authority_discovery_role = sc_authority_discovery::Role::PublishAndDiscover(\n+\t\t\tkeystore_container.keystore(),\n+\t\t);\n \t\tlet dht_event_stream = network.event_stream(\"authority-discovery\")\n \t\t\t.filter_map(|e| async move { match e {\n \t\t\t\tEvent::Dht(e) => Some(e),\n \t\t\t\t_ => None,\n-\t\t\t}}).boxed();\n+\t\t\t}});\n \t\tlet (authority_discovery_worker, _service) = sc_authority_discovery::new_worker_and_service(\n \t\t\tclient.clone(),\n \t\t\tnetwork.clone(),\n-\t\t\tsentries,\n-\t\t\tdht_event_stream,\n+\t\t\tBox::pin(dht_event_stream),\n \t\t\tauthority_discovery_role,\n \t\t\tprometheus_registry.clone(),\n \t\t);\n\n-\t\ttask_manager.spawn_handle().spawn(\"authority-discovery-worker\", authority_discovery_worker);\n+\t\ttask_manager.spawn_handle().spawn(\"authority-discovery-worker\", authority_discovery_worker.run());\n \t}\n\n \t// if the node isn't actively participating in consensus then it doesn't\n \t// need a keystore, regardless of which protocol we use below.\n \tlet keystore = if role.is_authority() {\n-\t\tSome(keystore as BareCryptoStorePtr)\n+\t\tSome(keystore_container.sync_keystore())\n \t} else {\n \t\tNone\n \t};\n@@ -317,8 +325,7 @@ pub fn new_full_base(\n \t\t\tconfig,\n \t\t\tlink: grandpa_link,\n \t\t\tnetwork: network.clone(),\n-\t\t\tinherent_data_providers: inherent_data_providers.clone(),\n-\t\t\ttelemetry_on_connect: Some(telemetry_connection_sinks.on_connect_stream()),\n+\t\t\ttelemetry_on_connect: telemetry_connection_notifier.map(|x| x.on_connect_stream()),\n \t\t\tvoting_rule: grandpa::VotingRulesBuilder::default().build(),\n \t\t\tprometheus_registry,\n \t\t\tshared_voter_state,\n@@ -330,17 +337,15 @@ pub fn new_full_base(\n \t\t\t\"grandpa-voter\",\n \t\t\tgrandpa::run_grandpa_voter(grandpa_config)?\n \t\t);\n-\t} else {\n-\t\tgrandpa::setup_disabled_grandpa(\n-\t\t\tclient.clone(),\n-\t\t\t&inherent_data_providers,\n-\t\t\tnetwork.clone(),\n-\t\t)?;\n \t}\n\n \tnetwork_starter.start_network();\n \tOk(NewFullBase {\n-\t\ttask_manager, inherent_data_providers, client, network, network_status_sinks,\n+\t\ttask_manager,\n+\t\tinherent_data_providers,\n+\t\tclient,\n+\t\tnetwork,\n+\t\tnetwork_status_sinks,\n \t\ttransaction_pool,\n \t})\n }\n@@ -353,14 +358,16 @@ pub fn new_full(config: Configuration)\n \t})\n }\n\n-pub fn new_light_base(config: Configuration) -> Result<(\n-\tTaskManager, RpcHandlers, Arc<LightClient>,\n+pub fn new_light_base(mut config: Configuration) -> Result<(\n+\tTaskManager, RpcHandlers, Option<TelemetryConnectionNotifier>, Arc<LightClient>,\n \tArc<NetworkService<Block, <Block as BlockT>::Hash>>,\n \tArc<sc_transaction_pool::LightPool<Block, LightClient, sc_network::config::OnDemand<Block>>>\n ), ServiceError> {\n-\tlet (client, backend, keystore, mut task_manager, on_demand) =\n+\tlet (client, backend, keystore_container, mut task_manager, on_demand) =\n \t\tsc_service::new_light_parts::<Block, RuntimeApi, Executor>(&config)?;\n\n+\tconfig.network.extra_sets.push(grandpa::grandpa_peers_set_config());\n+\n \tlet select_chain = sc_consensus::LongestChain::new(backend.clone());\n\n \tlet transaction_pool = Arc::new(sc_transaction_pool::BasicPool::new_light(\n@@ -371,14 +378,12 @@ pub fn new_light_base(config: Configuration) -> Result<(\n \t\ton_demand.clone(),\n \t));\n\n-\tlet grandpa_block_import = grandpa::light_block_import(\n-\t\tclient.clone(), backend.clone(), &(client.clone() as Arc<_>),\n-\t\tArc::new(on_demand.checker().clone()),\n+\tlet (grandpa_block_import, _) = grandpa::block_import(\n+\t\tclient.clone(),\n+\t\t&(client.clone() as Arc<_>),\n+\t\tselect_chain.clone(),\n \t)?;\n-\n-\tlet finality_proof_import = grandpa_block_import.clone();\n-\tlet finality_proof_request_builder =\n-\t\tfinality_proof_import.create_finality_proof_request_builder();\n+\tlet justification_import = grandpa_block_import.clone();\n\n \tlet (babe_block_import, babe_link) = sc_consensus_babe::block_import(\n \t\tsc_consensus_babe::Config::get_or_compute(&*client)?,\n@@ -391,8 +396,7 @@ pub fn new_light_base(config: Configuration) -> Result<(\n \tlet import_queue = sc_consensus_babe::import_queue(\n \t\tbabe_link,\n \t\tbabe_block_import,\n-\t\tNone,\n-\t\tSome(Box::new(finality_proof_import)),\n+\t\tSome(Box::new(justification_import)),\n \t\tclient.clone(),\n \t\tselect_chain.clone(),\n \t\tinherent_data_providers.clone(),\n@@ -401,9 +405,6 @@ pub fn new_light_base(config: Configuration) -> Result<(\n \t\tsp_consensus::NeverCanAuthor,\n \t)?;\n\n-\tlet finality_proof_provider =\n-\t\tGrandpaFinalityProofProvider::new_for_service(backend.clone(), client.clone());\n-\n \tlet (network, network_status_sinks, system_rpc_tx, network_starter) =\n \t\tsc_service::build_network(sc_service::BuildNetworkParams {\n \t\t\tconfig: &config,\n@@ -413,8 +414,6 @@ pub fn new_light_base(config: Configuration) -> Result<(\n \t\t\timport_queue,\n \t\t\ton_demand: Some(on_demand.clone()),\n \t\t\tblock_announce_validator_builder: None,\n-\t\t\tfinality_proof_request_builder: Some(finality_proof_request_builder),\n-\t\t\tfinality_proof_provider: Some(finality_proof_provider),\n \t\t})?;\n \tnetwork_starter.start_network();\n\n@@ -433,32 +432,39 @@ pub fn new_light_base(config: Configuration) -> Result<(\n\n \tlet rpc_extensions = node_rpc::create_light(light_deps);\n\n-\tlet rpc_handlers =\n+\tlet (rpc_handlers, telemetry_connection_notifier) =\n \t\tsc_service::spawn_tasks(sc_service::SpawnTasksParams {\n \t\t\ton_demand: Some(on_demand),\n \t\t\tremote_blockchain: Some(backend.remote_blockchain()),\n \t\t\trpc_extensions_builder: Box::new(sc_service::NoopRpcExtensionBuilder(rpc_extensions)),\n \t\t\tclient: client.clone(),\n \t\t\ttransaction_pool: transaction_pool.clone(),\n-\t\t\tconfig, keystore, backend, network_status_sinks, system_rpc_tx,\n+\t\t\tkeystore: keystore_container.sync_keystore(),\n+\t\t\tconfig, backend, network_status_sinks, system_rpc_tx,\n \t\t\tnetwork: network.clone(),\n-\t\t\ttelemetry_connection_sinks: sc_service::TelemetryConnectionSinks::default(),\n \t\t\ttask_manager: &mut task_manager,\n \t\t})?;\n\n-\tOk((task_manager, rpc_handlers, client, network, transaction_pool))\n+\tOk((\n+\t\ttask_manager,\n+\t\trpc_handlers,\n+\t\ttelemetry_connection_notifier,\n+\t\tclient,\n+\t\tnetwork,\n+\t\ttransaction_pool,\n+\t))\n }\n\n /// Builds a new service for a light client.\n pub fn new_light(config: Configuration) -> Result<TaskManager, ServiceError> {\n-\tnew_light_base(config).map(|(task_manager, _, _, _, _)| {\n+\tnew_light_base(config).map(|(task_manager, _, _, _, _, _)| {\n \t\ttask_manager\n \t})\n }\n\n #[cfg(test)]\n mod tests {\n-\tuse std::{sync::Arc, borrow::Cow, any::Any};\n+\tuse std::{sync::Arc, borrow::Cow, any::Any, convert::TryInto};\n \tuse sc_consensus_babe::{CompatibleDigestItem, BabeIntermediate, INTERMEDIATE_KEY};\n \tuse sc_consensus_epochs::descendent_query;\n \tuse sp_consensus::{\n@@ -469,20 +475,25 @@ mod tests {\n \tuse node_runtime::{BalancesCall, Call, UncheckedExtrinsic, Address};\n \tuse node_runtime::constants::{currency::CENTS, time::SLOT_DURATION};\n \tuse codec::Encode;\n-\tuse sp_core::{crypto::Pair as CryptoPair, H256};\n+\tuse sp_core::{\n+\t\tcrypto::Pair as CryptoPair,\n+\t\tH256,\n+\t\tPublic\n+\t};\n+\tuse sp_keystore::{SyncCryptoStorePtr, SyncCryptoStore};\n \tuse sp_runtime::{\n \t\tgeneric::{BlockId, Era, Digest, SignedPayload},\n \t\ttraits::{Block as BlockT, Header as HeaderT},\n \t\ttraits::Verify,\n \t};\n \tuse sp_timestamp;\n-\tuse sp_finality_tracker;\n \tuse sp_keyring::Sr25519Keyring;\n \tuse sc_service_test::TestNetNode;\n \tuse crate::service::{new_full_base, new_light_base, NewFullBase};\n-\tuse sp_runtime::traits::IdentifyAccount;\n+\tuse sp_runtime::{key_types::BABE, traits::IdentifyAccount, RuntimeAppPublic};\n \tuse sp_transaction_pool::{MaintainedTransactionPool, ChainEvent};\n \tuse sc_client_api::BlockBackend;\n+\tuse sc_keystore::LocalKeystore;\n\n \ttype AccountPublic = <Signature as Verify>::Signer;\n\n@@ -492,15 +503,15 @@ mod tests {\n \t#[ignore]\n \tfn test_sync() {\n \t\tlet keystore_path = tempfile::tempdir().expect(\"Creates keystore path\");\n-\t\tlet keystore = sc_keystore::Store::open(keystore_path.path(), None)\n-\t\t\t.expect(\"Creates keystore\");\n-\t\tlet alice = keystore.write().insert_ephemeral_from_seed::<sc_consensus_babe::AuthorityPair>(\"//Alice\")\n-\t\t\t.expect(\"Creates authority pair\");\n+\t\tlet keystore: SyncCryptoStorePtr = Arc::new(LocalKeystore::open(keystore_path.path(), None)\n+\t\t\t.expect(\"Creates keystore\"));\n+\t\tlet alice: sp_consensus_babe::AuthorityId = SyncCryptoStore::sr25519_generate_new(&*keystore, BABE, Some(\"//Alice\"))\n+\t\t\t.expect(\"Creates authority pair\").into();\n\n \t\tlet chain_spec = crate::chain_spec::tests::integration_test_config_with_single_authority();\n\n \t\t// For the block factory\n-\t\tlet mut slot_num = 1u64;\n+\t\tlet mut slot = 1u64;\n\n \t\t// For the extrinsics factory\n \t\tlet bob = Arc::new(Sr25519Keyring::Bob.pair());\n@@ -528,14 +539,13 @@ mod tests {\n \t\t\t\tOk((node, (inherent_data_providers, setup_handles.unwrap())))\n \t\t\t},\n \t\t\t|config| {\n-\t\t\t\tlet (keep_alive, _, client, network, transaction_pool) = new_light_base(config)?;\n+\t\t\t\tlet (keep_alive, _, _, client, network, transaction_pool) = new_light_base(config)?;\n \t\t\t\tOk(sc_service_test::TestNetComponents::new(keep_alive, client, network, transaction_pool))\n \t\t\t},\n \t\t\t|service, &mut (ref inherent_data_providers, (ref mut block_import, ref babe_link))| {\n \t\t\t\tlet mut inherent_data = inherent_data_providers\n \t\t\t\t\t.create_inherent_data()\n \t\t\t\t\t.expect(\"Creates inherent data.\");\n-\t\t\t\tinherent_data.replace_data(sp_finality_tracker::INHERENT_IDENTIFIER, &1u64);\n\n \t\t\t\tlet parent_id = BlockId::number(service.client().chain_info().best_number);\n \t\t\t\tlet parent_header = service.client().header(&parent_id).unwrap().unwrap();\n@@ -552,6 +562,7 @@ mod tests {\n \t\t\t\t);\n\n \t\t\t\tlet mut proposer_factory = sc_basic_authorship::ProposerFactory::new(\n+\t\t\t\t\tservice.spawn_handle(),\n \t\t\t\t\tservice.client(),\n \t\t\t\t\tservice.transaction_pool(),\n \t\t\t\t\tNone,\n@@ -561,7 +572,7 @@ mod tests {\n \t\t\t\t\tdescendent_query(&*service.client()),\n \t\t\t\t\t&parent_hash,\n \t\t\t\t\tparent_number,\n-\t\t\t\t\tslot_num,\n+\t\t\t\t\tslot.into(),\n \t\t\t\t).unwrap().unwrap();\n\n \t\t\t\tlet mut digest = Digest::<H256>::default();\n@@ -569,18 +580,18 @@ mod tests {\n \t\t\t\t// even though there's only one authority some slots might be empty,\n \t\t\t\t// so we must keep trying the next slots until we can claim one.\n \t\t\t\tlet babe_pre_digest = loop {\n-\t\t\t\t\tinherent_data.replace_data(sp_timestamp::INHERENT_IDENTIFIER, &(slot_num * SLOT_DURATION));\n+\t\t\t\t\tinherent_data.replace_data(sp_timestamp::INHERENT_IDENTIFIER, &(slot * SLOT_DURATION));\n \t\t\t\t\tif let Some(babe_pre_digest) = sc_consensus_babe::test_helpers::claim_slot(\n-\t\t\t\t\t\tslot_num,\n+\t\t\t\t\t\tslot.into(),\n \t\t\t\t\t\t&parent_header,\n \t\t\t\t\t\t&*service.client(),\n-\t\t\t\t\t\t&keystore,\n+\t\t\t\t\t\tkeystore.clone(),\n \t\t\t\t\t\t&babe_link,\n \t\t\t\t\t) {\n \t\t\t\t\t\tbreak babe_pre_digest;\n \t\t\t\t\t}\n\n-\t\t\t\t\tslot_num += 1;\n+\t\t\t\t\tslot += 1;\n \t\t\t\t};\n\n \t\t\t\tdigest.push(<DigestItem as CompatibleDigestItem>::babe_pre_digest(babe_pre_digest));\n@@ -600,11 +611,18 @@ mod tests {\n \t\t\t\t// sign the pre-sealed hash of the block and then\n \t\t\t\t// add it to a digest item.\n \t\t\t\tlet to_sign = pre_hash.encode();\n-\t\t\t\tlet signature = alice.sign(&to_sign[..]);\n+\t\t\t\tlet signature = SyncCryptoStore::sign_with(\n+\t\t\t\t\t&*keystore,\n+\t\t\t\t\tsp_consensus_babe::AuthorityId::ID,\n+\t\t\t\t\t&alice.to_public_crypto_pair(),\n+\t\t\t\t\t&to_sign,\n+\t\t\t\t).unwrap()\n+\t\t\t\t .try_into()\n+\t\t\t\t .unwrap();\n \t\t\t\tlet item = <DigestItem as CompatibleDigestItem>::babe_seal(\n-\t\t\t\t\tsignature.into(),\n+\t\t\t\t\tsignature,\n \t\t\t\t);\n-\t\t\t\tslot_num += 1;\n+\t\t\t\tslot += 1;\n\n \t\t\t\tlet mut params = BlockImportParams::new(BlockOrigin::File, new_header);\n \t\t\t\tparams.post_digests.push(item);\n@@ -679,7 +697,7 @@ mod tests {\n \t\t\t\tOk(sc_service_test::TestNetComponents::new(task_manager, client, network, transaction_pool))\n \t\t\t},\n \t\t\t|config| {\n-\t\t\t\tlet (keep_alive, _, client, network, transaction_pool) = new_light_base(config)?;\n+\t\t\t\tlet (keep_alive, _, _, client, network, transaction_pool) = new_light_base(config)?;\n \t\t\t\tOk(sc_service_test::TestNetComponents::new(keep_alive, client, network, transaction_pool))\n \t\t\t},\n \t\t\tvec![\n```"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain substreams\ninput: "
      },
      {
        "role": "assistant",
        "content": "Once a connection has been established and uses multiplexing, substreams can be opened. When\na substream is open, the **multistream-select** protocol is used to negotiate which protocol\nto use on that given substream.\n\nProtocols that are specific to a certain chain have a `<protocol-id>` in their name. This\n\"protocol ID\" is defined in the chain specifications. For example, the protocol ID of Polkadot\nis \"dot\". In the protocol names below, `<protocol-id>` must be replaced with the corresponding\nprotocol ID.\n\n> **Note**: It is possible for the same connection to be used for multiple chains. For example,\n> one can use both the `/dot/sync/2` and `/sub/sync/2` protocols on the same\n> connection, provided that the remote supports them.\n\nSubstrate uses the following standard libp2p protocols:\n\n- **`/ipfs/ping/1.0.0`**. We periodically open an ephemeral substream in order to ping the\nremote and check whether the connection is still alive. Failure for the remote to reply leads\nto a disconnection.\n- **`/ipfs/id/1.0.0`**. We\nperiodically open an ephemeral substream in order to ask information from the remote.\n- **`/<protocol_id>/kad`**. We periodically open\nephemeral substreams for Kademlia random walk queries. Each Kademlia query is done in a\nseparate substream.\n\nAdditionally, Substrate uses the following non-libp2p-standard protocols:\n\n- **`/substrate/<protocol-id>/<version>`** (where `<protocol-id>` must be replaced with the\nprotocol ID of the targeted chain, and `<version>` is a number between 2 and 6). For each\nconnection we optionally keep an additional substream for all Substrate-based communications alive.\nThis protocol is considered legacy, and is progressively being replaced with alternatives.\nThis is designated as \"The legacy Substrate substream\" in this documentation. See below for\nmore details.\n- **`/<protocol-id>/sync/2`** is a request-response protocol (see below) that lets one perform\nrequests for information about blocks. Each request is the encoding of a `BlockRequest` and\neach response is the encoding of a `BlockResponse`, as defined in the `api.v1.proto` file in\nthis source tree.\n- **`/<protocol-id>/light/2`** is a request-response protocol (see below) that lets one perform\nlight-client-related requests for information about the state. Each request is the encoding of\na `light::Request` and each response is the encoding of a `light::Response`, as defined in the\n`light.v1.proto` file in this source tree.\n- **`/<protocol-id>/transactions/1`** is a notifications protocol (see below) where\ntransactions are pushed to other nodes. The handshake is empty on both sides. The message\nformat is a SCALE-encoded list of transactions, where each transaction is an opaque list of\nbytes.\n- **`/<protocol-id>/block-announces/1`** is a notifications protocol (see below) where\nblock announces are pushed to other nodes. The handshake is empty on both sides. The message\nformat is a SCALE-encoded tuple containing a block header followed with an opaque list of\nbytes containing some data associated with this block announcement, e.g. a candidate message.\n- Notifications protocols that are registered using `NetworkConfiguration::notifications_protocols`.\nFor example: `/paritytech/grandpa/1`. See below for more information."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain details\ninput: "
      },
      {
        "role": "assistant",
        "content": "Before we jump into describing how BEEFY works in details, let's agree on the terms we are going\nto use and actors in the system. All nodes in the network need to participate in the BEEFY\nnetworking protocol, but we can identify two distinct actors though: **regular nodes** and\n**BEEFY validators**.\nValidators are expected to actively participate in the protocol, by producing and broadcasting\n**votes**. Votes are simply their signatures over a **Commitment**. A Commitment consists of a\n**payload** (an opaque blob of bytes extracted from a block or state at that block, expected to\nbe some form of crypto accumulator (like Merkle Tree Hash or Merkle Mountain Range Root Hash))\nand **block number** from which this payload originates. Additionally, Commitment contains BEEFY\n**validator set id** at that particular block. Note the block is finalized, so there is no\nambiguity despite using block number instead of a hash. A collection of **votes**, or rather\na Commitment and a collection of signatures is going to be called **Signed Commitment**. A valid\n(see later for the rules) Signed Commitment is also called a **BEEFY Justification** or\n**BEEFY Finality Proof**. For more details on the actual data structures please see\nBEEFY primitives definitions.\n\nA **round** is an attempt by BEEFY validators to produce a BEEFY Justification. **Round number**\nis simply defined as a block number the validators are voting for, or to be more precise, the\nCommitment for that block number. Round ends when the next round is started, which may happen\nwhen one of the events occur:\n1. Either the node collects `2/3rd + 1` valid votes for that round.\n2. Or the node receives a BEEFY Justification for a block greater than the current best BEEFY block.\n\nIn both cases the node proceeds to determining the new round number using \"Round Selection\"\nprocedure.\n\nRegular nodes are expected to:\n1. Receive & validate votes for the current round and broadcast them to their peers.\n1. Receive & validate BEEFY Justifications and broadcast them to their peers.\n1. Return BEEFY Justifications for **Mandatory Blocks** on demand.\n1. Optionally return BEEFY Justifications for non-mandatory blocks on demand.\n\nValidators are expected to additionally:\n1. Produce & broadcast vote for the current round.\n\nBoth kinds of actors are expected to fully participate in the protocol ONLY IF they believe they\nare up-to-date with the rest of the network, i.e. they are fully synced. Before this happens,\nthe node should continue processing imported BEEFY Justifications and votes without actively\nvoting themselves."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain round selection\ninput: "
      },
      {
        "role": "assistant",
        "content": "Every node (both regular nodes and validators) need to determine locally what they believe\ncurrent round number is. The choice is based on their knowledge of:\n\n1. Best GRANDPA finalized block number (`best_grandpa`).\n1. Best BEEFY finalized block number (`best_beefy`).\n1. Starting block of current session (`session_start`).\n\n**Session** means a period of time (or rather number of blocks) where validator set (keys) do not change.\nSee `pallet_session` for implementation details in `FRAME` context. Since we piggy-back on\nGRANDPA, session boundaries for BEEFY are exactly the same as the ones for GRANDPA.\n\nWe define two kinds of blocks from the perspective of BEEFY protocol:\n1. **Mandatory Blocks**\n2. **Non-mandatory Blocks**\n\nMandatory blocks are the ones that MUST have BEEFY justification. That means that the validators\nwill always start and conclude a round at mandatory blocks. For non-mandatory blocks, there may\nor may not be a justification and validators may never choose these blocks to start a round.\n\nEvery **first block in** each **session** is considered a **mandatory block**. All other blocks\nin the session are non-mandatory, however validators are encouraged to finalize as many blocks as\npossible to enable lower latency for light clients and hence end users. Since GRANDPA is\nconsidering session boundary blocks as mandatory as well, `session_start` block will always have\nboth GRANDPA and BEEFY Justification.\n\nTherefore, to determine current round number nodes use a formula:\n\nround_number =\n      (1 - M) * session_start\n   +        M * (best_beefy + NEXT_POWER_OF_TWO((best_grandpa - best_beefy + 1) / 2))\n\nwhere:\n\n- `M` is `1` if mandatory block in current session is already finalized and `0` otherwise.\n- `NEXT_POWER_OF_TWO(x)` returns the smallest number greater or equal to `x` that is a power of two.\n\nIn other words, the next round number should be the oldest mandatory block without a justification,\nor the highest GRANDPA-finalized block, whose block number difference with `best_beefy` block is\na power of two. The mental model for round selection is to first finalize the mandatory block and\nthen to attempt to pick a block taking into account how fast BEEFY catches up with GRANDPA.\nIn case GRANDPA makes progress, but BEEFY seems to be lagging behind, validators are changing\nrounds less often to increase the chance of concluding them.\n\nAs mentioned earlier, every time the node picks a new `round_number` (and validator casts a vote)\nit ends the previous one, no matter if finality was reached (i.e. the round concluded) or not.\nVotes for an inactive round should not be propagated.\n\nNote that since BEEFY only votes for GRANDPA-finalized blocks, `session_start` here actually means:\n\"the latest session for which the start of is GRANDPA-finalized\", i.e. block production might\nhave already progressed, but BEEFY needs to first finalize the mandatory block of the older\nsession.\n\nIn good networking conditions BEEFY may end up finalizing each and every block (if GRANDPA does\nthe same). Practically, with short block times, it's going to be rare and might be excessive, so\nit's suggested for implementations to introduce a `min_delta` parameter which will limit the\nfrequency with which new rounds are started. The affected component of the formula would be:\n`best_beefy + MAX(min_delta, NEXT_POWER_OF_TWO(...))`, so we start a new round only if the\npower-of-two component is greater than the min delta. Note that if `round_number > best_grandpa`\nthe validators are not expected to start any round."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain output\ninput: "
      },
      {
        "role": "assistant",
        "content": "The output on reference hardware:\n\n+----------+----------------+---------------+--------------+-------------------+\n| Category | Function       | Score         | Minimum      | Result            |\n+----------+----------------+---------------+--------------+-------------------+\n| CPU      | BLAKE2-256     | 1023.00 MiB/s | 1.00 GiB/s   | \u2705 Pass ( 99.4 %) |\n+----------+----------------+---------------+--------------+-------------------+\n| CPU      | SR25519-Verify | 665.13 KiB/s  | 666.00 KiB/s | \u2705 Pass ( 99.9 %) |\n+----------+----------------+---------------+--------------+-------------------+\n| Memory   | Copy           | 14.39 GiB/s   | 14.32 GiB/s  | \u2705 Pass (100.4 %) |\n+----------+----------------+---------------+--------------+-------------------+\n| Disk     | Seq Write      | 457.00 MiB/s  | 450.00 MiB/s | \u2705 Pass (101.6 %) |\n+----------+----------------+---------------+--------------+-------------------+\n| Disk     | Rnd Write      | 190.00 MiB/s  | 200.00 MiB/s | \u2705 Pass ( 95.0 %) |\n+----------+----------------+---------------+--------------+-------------------+\n\nThe *score* is the average result of each benchmark. It always adheres to \"higher is better\".\n\nThe *category* indicate which part of the hardware was benchmarked:\n- **CPU** Processor intensive task\n- **Memory** RAM intensive task\n- **Disk** Hard drive intensive task\n\nThe *function* is the concrete benchmark that was run:\n- **BLAKE2-256** The throughput of the [Blake2-256] cryptographic hashing function with 32 KiB input. The [blake2_256\n  function] is used in many places in Substrate. The throughput of a hash function strongly depends on the input size,\n  therefore we settled to use a fixed input size for comparable results.\n- **SR25519 Verify** Sr25519 is an optimized version of the [Curve25519] signature scheme. Signature verification is\n  used by Substrate when verifying extrinsics and blocks.\n- **Copy** The throughput of copying memory from one place in the RAM to another.\n- **Seq Write** The throughput of writing data to the storage location sequentially. It is important that the same disk\n  is used that will later-on be used to store the chain data.\n- **Rnd Write** The throughput of writing data to the storage location in a random order. This is normally much slower\n  than the sequential write.\n\nThe *score* needs to reach the *minimum* in order to pass the benchmark. This can be reduced with the `--tolerance`\nflag.\n\nThe *result* indicated if a specific benchmark was passed by the machine or not. The percent number is the relative\nscore reached to the *minimum* that is needed. The `--tolerance` flag is taken into account for this decision. For\nexample a benchmark that passes even with 95% since the *tolerance* was set to 10% would look like this: `\u2705 Pass ( 95.0\n%)`."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain output interpretation\ninput: "
      },
      {
        "role": "assistant",
        "content": "<sup>(Only results from reference hardware are relevant)</sup>\n\nEach block is executed multiple times and the results are averaged. The percent number is the interesting part and\nindicates how much weight was used as compared to how much was predicted. The closer to 100% this is without exceeding\n100%, the better. If it exceeds 100%, the block is marked with \"**OVER WEIGHT!**\" to easier spot them. This is not good\nsince then the benchmarking under-estimated the weight. This would mean that an honest validator would possibly not be\nable to keep up with importing blocks since users did not pay for enough weight. If that happens the validator could lag\nbehind the chain and get slashed for missing deadlines. It is therefore important to investigate any overweight blocks.\n\nIn this example you can see an unexpected result; only < 5% of the weight was used! The measured blocks can be executed\nmuch faster than predicted. This means that the benchmarking process massively over-estimated the execution time. Since\nthey are off by so much, it is an issue [`polkadot#5192`].\n\nThe ideal range for these results would be 85-100%."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain polkadot # 2\ninput: "
      },
      {
        "role": "assistant",
        "content": "Let's take a more interesting example where the blocks use more of their predicted weight. Every day when validators pay\nout rewards, the blocks are nearly full. Using an archive node here is the easiest.\n\nThe Polkadot blocks TODO-TODO for example contain large batch transactions for staking payout.\n\ncargo run --profile=production -- benchmark block --from TODO --to TODO --db paritydb\n\nTODO"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain interface\ninput: "
      },
      {
        "role": "assistant",
        "content": "### Dispatchable Functions\n\n### For General Users\n- `set_identity` - Set the associated identity of an account; a small deposit is reserved if not\n  already taken.\n- `clear_identity` - Remove an account's associated identity; the deposit is returned.\n- `request_judgement` - Request a judgement from a registrar, paying a fee.\n- `cancel_request` - Cancel the previous request for a judgement.\n- `accept_username` - Accept a username issued by a username authority.\n- `remove_expired_approval` - Remove a username that was issued but never accepted.\n- `set_primary_username` - Set a given username as an account's primary.\n- `remove_username` - Remove a username after its grace period has ended.\n\n### For General Users with Sub-Identities\n- `set_subs` - Set the sub-accounts of an identity.\n- `add_sub` - Add a sub-identity to an identity.\n- `remove_sub` - Remove a sub-identity of an identity.\n- `rename_sub` - Rename a sub-identity of an identity.\n- `quit_sub` - Remove a sub-identity of an identity (called by the sub-identity).\n\n### For Registrars\n- `set_fee` - Set the fee required to be paid for a judgement to be given by the registrar.\n- `set_fields` - Set the fields that a registrar cares about in their judgements.\n- `provide_judgement` - Provide a judgement to an identity.\n\n### For Username Authorities\n- `set_username_for` - Set a username for a given account. The account must approve it.\n- `unbind_username` - Start the grace period for a username.\n\n### For Superusers\n- `add_registrar` - Add a new registrar to the system.\n- `kill_identity` - Forcibly remove the associated identity; the deposit is lost.\n- `add_username_authority` - Add an account with the ability to issue usernames.\n- `remove_username_authority` - Remove an account with the ability to issue usernames.\n- `kill_username` - Forcibly remove a username.\n\n[`Call`]: ./enum.Call.html\n[`Config`]: ./trait.Config.html\n\nLicense: Apache-2.0"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain dispatchable functions\ninput: "
      },
      {
        "role": "assistant",
        "content": "### For General Users\n\n- `create_recovery` - Create a recovery configuration for your account and make it recoverable.\n- `initiate_recovery` - Start the recovery process for a recoverable account.\n\n### For Friends of a Recoverable Account\n- `vouch_recovery` - As a `friend` of a recoverable account, vouch for a recovery attempt on the account.\n\n### For a User Who Successfully Recovered an Account\n\n- `claim_recovery` - Claim access to the account that you have successfully completed the recovery process for.\n- `as_recovered` - Send a transaction as an account that you have recovered. See other functions below.\n\n### For the Recoverable Account\n\n- `close_recovery` - Close an active recovery process for your account and reclaim the recovery deposit.\n- `remove_recovery` - Remove the recovery configuration from the account, making it un-recoverable.\n\n### For Super Users\n\n- `set_recovered` - The ROOT origin is able to skip the recovery process and directly allow\n  one account to access another.\n\nLicense: Apache-2.0"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain mechanics\ninput: "
      },
      {
        "role": "assistant",
        "content": "### Rewards\n\nMembers are incentivized to participate in the society through rewards paid\nby the Society treasury. These payments have a maturity period that the user\nmust wait before they are able to access the funds.\n\n### Punishments\n\nMembers can be punished by slashing the reward payouts that have not been\ncollected. Additionally, members can accumulate \"strikes\", and when they\nreach a max strike limit, they become suspended.\n\n### Skeptics\n\nDuring the voting period, a random set of members are selected as \"skeptics\".\nThese skeptics are expected to vote on the current candidates. If they do not vote,\ntheir skeptic status is treated as a rejection vote, the member is deemed\n\"lazy\", and are given a strike per missing vote.\n\n### Membership Challenges\n\nEvery challenge rotation period, an existing member will be randomly selected\nto defend their membership into society. Then, other members can vote whether\nthis defender should stay in society. A simple majority wins vote will determine\nthe outcome of the user. Ties are treated as a failure of the challenge, but\nassuming no one else votes, the defender always get a free vote on their\nown challenge keeping them in the society. The Head member is exempt from the\nnegative outcome of a membership challenge.\n\n### Society Treasury\n\nThe membership society is independently funded by a treasury managed by this\nmodule. Some subset of this treasury is placed in a Society Pot, which is used\nto determine the number of accepted bids.\n\n### Rate of Growth\n\nThe membership society can grow at a rate of 10 accepted candidates per rotation period up\nto the max membership threshold. Once this threshold is met, candidate selections\nare stalled until there is space for new members to join. This can be resolved by\nvoting out existing members through the random challenges or by using governance\nto increase the maximum membership count."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain user life cycle\ninput: "
      },
      {
        "role": "assistant",
        "content": "A user can go through the following phases:\n\n          +------->  User  <----------+\n          |           +               |\n          |           |               |\n+----------------------------------------------+\n|         |           |               |        |\n|         |           v               |        |\n|         |        Bidder <-----------+        |\n|         |           +               |        |\n|         |           |               +        |\n|         |           v            Suspended   |\n|         |       Candidate +----> Candidate   |\n|         |           +               +        |\n|         |           |               |        |\n|         +           |               |        |\n|   Suspended +------>|               |        |\n|      Member         |               |        |\n|         ^           |               |        |\n|         |           v               |        |\n|         +-------+ Member <----------+        |\n|                                              |\n|                                              |\n+------------------Society---------------------+\n\n### Initialization\n\nThe society is initialized with a single member who is automatically chosen as the Head.\n\n### Bid Phase\n\nNew users must have a bid to join the society.\n\nA user can make a bid by reserving a deposit. Alternatively, an already existing member\ncan create a bid on a user's behalf by \"vouching\" for them.\n\nA bid includes reward information that the user would like to receive for joining\nthe society. A vouching bid can additionally request some portion of that reward as a tip\nto the voucher for vouching for the prospective candidate.\n\nEvery rotation period, Bids are ordered by reward amount, and the module\nselects as many bids the Society Pot can support for that period.\n\nThese selected bids become candidates and move on to the Candidate phase.\nBids that were not selected stay in the bidder pool until they are selected or\na user chooses to \"unbid\".\n\n### Candidate Phase\n\nOnce a bidder becomes a candidate, members vote whether to approve or reject\nthat candidate into society. This voting process also happens during a rotation period.\n\nThe approval and rejection criteria for candidates are not set on chain,\nand may change for different societies.\n\nAt the end of the rotation period, we collect the votes for a candidate\nand randomly select a vote as the final outcome.\n\n [ a-accept, r-reject, s-skeptic ]\n+----------------------------------+\n|                                  |\n|  Member   |0|1|2|3|4|5|6|7|8|9|  |\n|  -----------------------------   |\n|  Vote     |a|a|a|r|s|r|a|a|s|a|  |\n|  -----------------------------   |\n|  Selected | | | |x| | | | | | |  |\n|                                  |\n+----------------------------------+\n\nResult: Rejected\n\nEach member that voted opposite to this randomly selected vote is punished by\nslashing their unclaimed payouts and increasing the number of strikes they have.\n\nThese slashed funds are given to a random user who voted the same as the\nselected vote as a reward for participating in the vote.\n\nIf the candidate wins the vote, they receive their bid reward as a future payout.\nIf the bid was placed by a voucher, they will receive their portion of the reward,\nbefore the rest is paid to the winning candidate.\n\nOne winning candidate is selected as the Head of the members. This is randomly\nchosen, weighted by the number of approvals the winning candidates accumulated.\n\nIf the candidate loses the vote, they are suspended and it is up to the Suspension\nJudgement origin to determine if the candidate should go through the bidding process\nagain, should be accepted into the membership society, or rejected and their deposit\nslashed.\n\n### Member Phase\n\nOnce a candidate becomes a member, their role is to participate in society.\n\nRegular participation involves voting on candidates who want to join the membership\nsociety, and by voting in the right way, a member will accumulate future payouts.\nWhen a payout matures, members are able to claim those payouts.\n\nMembers can also vouch for users to join the society, and request a \"tip\" from\nthe fees the new member would collect by joining the society. This vouching\nprocess is useful in situations where a user may not have enough balance to\nsatisfy the bid deposit. A member can only vouch one user at a time.\n\nDuring rotation periods, a random group of members are selected as \"skeptics\".\nThese skeptics are expected to vote on the current candidates. If they do not vote,\ntheir skeptic status is treated as a rejection vote, the member is deemed\n\"lazy\", and are given a strike per missing vote.\n\nThere is a challenge period in parallel to the rotation period. During a challenge period,\na random member is selected to defend their membership to the society. Other members\nmake a traditional majority-wins vote to determine if the member should stay in the society.\nTies are treated as a failure of the challenge.\n\nIf a member accumulates too many strikes or fails their membership challenge,\nthey will become suspended. While a member is suspended, they are unable to\nclaim matured payouts. It is up to the Suspension Judgement origin to determine\nif the member should re-enter society or be removed from society with all their\nfuture payouts slashed."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain scenarios\ninput: "
      },
      {
        "role": "assistant",
        "content": "### Staking\n\nAlmost any interaction with the Staking module requires a process of _**bonding**_ (also known as being a _staker_). To\nbecome *bonded*, a fund-holding account known as the _stash account_, which holds some or all of the funds that become\nfrozen in place as part of the staking process. The controller account, which this pallet now assigns the stash account to,\nissues instructions on how funds shall be used.\n\nAn account can become a bonded stash account using the\n`bond` call.\n\nStash accounts can update their associated controller back to their stash account using the\n`set_controller` call.\n\nNote: Controller accounts are being deprecated in favor of proxy accounts, so it is no longer possible to set a unique\naddress for a stash's controller.\n\nThere are three possible roles that any staked account pair can be in: `Validator`, `Nominator` and `Idle` (defined in\n`StakerStatus`). There are three\ncorresponding instructions to change between roles, namely:\n`validate`,\n`nominate`, and\n`chill`.\n\n### Validating\n\nA **validator** takes the role of either validating blocks or ensuring their finality, maintaining the veracity of the\nnetwork. A validator should avoid both any sort of malicious misbehavior and going offline. Bonded accounts that state\ninterest in being a validator do NOT get immediately chosen as a validator. Instead, they are declared as a _candidate_\nand they _might_ get elected at the _next era_ as a validator. The result of the election is determined by nominators\nand their votes.\n\nAn account can become a validator candidate via the\n`validate` call.\n\n### Nomination\n\nA **nominator** does not take any _direct_ role in maintaining the network, instead, it votes on a set of validators to\nbe elected. Once interest in nomination is stated by an account, it takes effect at the next election round. The funds\nin the nominator's stash account indicate the _weight_ of its vote. Both the rewards and any punishment that a validator\nearns are shared between the validator and its nominators. This rule incentivizes the nominators to NOT vote for the\nmisbehaving/offline validators as much as possible, simply because the nominators will also lose funds if they vote\npoorly.\n\nAn account can become a nominator via the\n`nominate` call.\n\n### Rewards and Slash\n\nThe **reward and slashing** procedure is the core of the Staking module, attempting to _embrace valid behavior_ while\n_punishing any misbehavior or lack of availability_.\n\nRewards must be claimed for each era before it gets too old by `$HISTORY_DEPTH` using the `payout_stakers` call. When a\nvalidator has more than [`Config::MaxExposurePageSize`] nominators, nominators are divided into pages with each call to\n`payout_stakers` paying rewards to one page of nominators in a sequential and ascending manner. Any account can also\ncall `payout_stakers_by_page` to explicitly pay reward for a given page. As evident, this means only the\n[`Config::MaxExposurePageSize`] nominators are rewarded per call. This is to limit the i/o cost to mutate storage for\neach nominator's account.\n\nSlashing can occur at any point in time, once misbehavior is reported. Once slashing is determined, a value is deducted\nfrom the balance of the validator and all the nominators who voted for this validator (values are deducted from the\n_stash_ account of the slashed entity).\n\nSlashing logic is further described in the documentation of the `slashing` module.\n\nSimilar to slashing, rewards are also shared among a validator and its associated nominators. Yet, the reward funds are\nnot always transferred to the stash account and can be configured. See Reward\nCalculation for more details.\n\n### Chilling\n\nFinally, any of the roles above can choose to step back temporarily and just chill for a while. This means that if they\nare a nominator, they will not be considered as voters anymore and if they are validators, they will no longer be a\ncandidate for the next election.\n\nAn account can step back via the\n`chill` call."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain running benchmarks\ninput: "
      },
      {
        "role": "assistant",
        "content": "Finally, once you have a node binary with benchmarks enabled, you need to execute your various benchmarks.\n\nYou can get a list of the available benchmarks by running:\n\n./target/production/substrate benchmark pallet --chain dev --pallet \"*\" --extrinsic \"*\" --repeat 0\n\nThen you can run a benchmark like so:\n\n./target/production/substrate benchmark pallet \\\n    --chain dev \\                  # Configurable Chain Spec\n    --wasm-execution=compiled \\    # Always used `wasm-time`\n    --pallet pallet_balances \\     # Select the pallet\n    --extrinsic transfer \\         # Select the extrinsic\n    --steps 50 \\                   # Number of samples across component ranges\n    --repeat 20 \\                  # Number of times we repeat a benchmark\n    --output <path> \\              # Output benchmark results into a folder or file\n\nThis will output a file `pallet_name.rs` which implements the `WeightInfo` trait you should include in your pallet.\nDouble colons `::` will be replaced with a `_` in the output name if you specify a directory. Each blockchain should\ngenerate their own benchmark file with their custom implementation of the `WeightInfo` trait. This means that you will\nbe able to use these modular Substrate pallets while still keeping your network safe for your specific configuration and\nrequirements.\n\nThe benchmarking CLI uses a Handlebars template to format the final output file. You can optionally pass the flag\n`--template` pointing to a custom template that can be used instead. Within the template, you have access to all the\ndata provided by the `TemplateData` struct in the benchmarking CLI\nwriter. You can find the default template used\nhere.\n\nThere are some custom Handlebars helpers included with our output generation:\n\n* `underscore`: Add an underscore to every 3rd character from the right of a string. Primarily to be used for delimiting\nlarge numbers.\n* `join`: Join an array of strings into a space-separated string for the template. Primarily to be used for joining all\nthe arguments passed to the CLI.\n\nTo get a full list of available options when running benchmarks, run:\n\n./target/production/substrate benchmark --help\n\nLicense: Apache-2.0"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain dispatchable functions\ninput: "
      },
      {
        "role": "assistant",
        "content": "### Public\n\nThese calls can be made from any externally held account capable of creating\na signed extrinsic.\n\nBasic actions:\n- `propose` - Submits a sensitive action, represented as a hash. Requires a deposit.\n- `second` - Signals agreement with a proposal, moves it higher on the proposal queue, and\n  requires a matching deposit to the original.\n- `vote` - Votes in a referendum, either the vote is \"Aye\" to enact the proposal or \"Nay\" to\n  keep the status quo.\n- `unvote` - Cancel a previous vote, this must be done by the voter before the vote ends.\n- `delegate` - Delegates the voting power (tokens * conviction) to another account.\n- `undelegate` - Stops the delegation of voting power to another account.\n\nAdministration actions that can be done to any account:\n- `reap_vote` - Remove some account's expired votes.\n- `unlock` - Redetermine the account's balance lock, potentially making tokens available.\n\nPreimage actions:\n- `note_preimage` - Registers the preimage for an upcoming proposal, requires\n  a deposit that is returned once the proposal is enacted.\n- `note_preimage_operational` - same but provided by `T::OperationalPreimageOrigin`.\n- `note_imminent_preimage` - Registers the preimage for an upcoming proposal.\n  Does not require a deposit, but the proposal must be in the dispatch queue.\n- `note_imminent_preimage_operational` - same but provided by `T::OperationalPreimageOrigin`.\n- `reap_preimage` - Removes the preimage for an expired proposal. Will only\n  work under the condition that it's the same account that noted it and\n  after the voting period, OR it's a different account after the enactment period.\n\n### Cancellation Origin\n\nThis call can only be made by the `CancellationOrigin`.\n\n- `emergency_cancel` - Schedules an emergency cancellation of a referendum.\n  Can only happen once to a specific referendum.\n\n### ExternalOrigin\n\nThis call can only be made by the `ExternalOrigin`.\n\n- `external_propose` - Schedules a proposal to become a referendum once it is legal\n  for an externally proposed referendum.\n\n### External Majority Origin\n\nThis call can only be made by the `ExternalMajorityOrigin`.\n\n- `external_propose_majority` - Schedules a proposal to become a majority-carries\n\t referendum once it is legal for an externally proposed referendum.\n\n### External Default Origin\n\nThis call can only be made by the `ExternalDefaultOrigin`.\n\n- `external_propose_default` - Schedules a proposal to become a negative-turnout-bias\n  referendum once it is legal for an externally proposed referendum.\n\n### Fast Track Origin\n\nThis call can only be made by the `FastTrackOrigin`.\n\n- `fast_track` - Schedules the current externally proposed proposal that\n  is \"majority-carries\" to become a referendum immediately.\n\n### Veto Origin\n\nThis call can only be made by the `VetoOrigin`.\n\n- `veto_external` - Vetoes and blacklists the external proposal hash.\n\n### Root\n\n- `cancel_referendum` - Removes a referendum.\n- `cancel_queued` - Cancels a proposal that is queued for enactment.\n- `clear_public_proposal` - Removes all public proposals.\n\nLicense: Apache-2.0"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain terminology\ninput: "
      },
      {
        "role": "assistant",
        "content": "<!-- Original author of paragraph: @gavofyork -->\n\n- **Session:** A session is a period of time that has a constant set of validators. Validators can only join or exit the\nvalidator set at a session change. It is measured in block numbers. The block where a session is ended is determined by\nthe `ShouldEndSession` trait. When the session is ending, a new validator set can be chosen by `OnSessionEnding`\nimplementations.\n- **Session key:** A session key is actually several keys kept together that provide the various signing functions\nrequired by network authorities/validators in pursuit of their duties.\n- **Validator ID:** Every account has an associated validator ID. For some simple staking systems, this may just be the\nsame as the account ID. For staking systems using a stash/controller model, the validator ID would be the stash account\nID of the controller.\n- **Session key configuration process:** Session keys are set using `set_keys` for use not in the next session, but the\nsession after next. They are stored in `NextKeys`, a mapping between the caller's `ValidatorId` and the session keys\nprovided. `set_keys` allows users to set their session key prior to being selected as validator. It is a public call\nsince it uses `ensure_signed`, which checks that the origin is a signed account. As such, the account ID of the origin\nstored in `NextKeys` may not necessarily be associated with a block author or a validator. The session keys of accounts\nare removed once their account balance is zero.\n- **Session length:** This pallet does not assume anything about the length of each session. Rather, it relies on an\nimplementation of `ShouldEndSession` to dictate a new session's start. This pallet provides the `PeriodicSessions`\nstruct for simple periodic sessions.\n- **Session rotation configuration:** Configure as either a 'normal' (rewardable session where rewards are applied) or\n'exceptional' (slashable) session rotation.\n- **Session rotation process:** At the beginning of each block, the `on_initialize` function queries the provided\nimplementation of `ShouldEndSession`. If the session is to end the newly activated validator IDs and session keys are\ntaken from storage and passed to the `SessionHandler`. The validator set supplied by `SessionManager::new_session` and\nthe corresponding session keys, which may have been registered via `set_keys` during the previous session, are written\nto storage where they will wait one session before being passed to the `SessionHandler` themselves."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain documentation template:<br>\ninput: "
      },
      {
        "role": "assistant",
        "content": "Copy and paste this template from frame/examples/basic/src/lib.rs into file\n`frame/<INSERT_CUSTOM_PALLET_NAME>/src/lib.rs` of your own custom pallet and complete it.\n<details><p><pre>\n// Add heading with custom pallet name\n\n\\# <INSERT_CUSTOM_PALLET_NAME> Pallet\n\n// Add simple description\n\n// Include the following links that shows what trait needs to be implemented to use the pallet\n// and the supported dispatchables that are documented in the Call enum.\n\n- \\`<INSERT_CUSTOM_PALLET_NAME>::Config`\n- \\`Call`\n- \\`Module`\n\n\\## Overview\n\n<!-- Original author of paragraph: Various. See https://github.com/paritytech/substrate-developer-hub/issues/44 -->\n// Short description of pallet's purpose.\n// Links to Traits that should be implemented.\n// What this pallet is for.\n// What functionality the pallet provides.\n// When to use the pallet (use case examples).\n// How it is used.\n// Inputs it uses and the source of each input.\n// Outputs it produces.\n\n<!-- Original author of paragraph: @Kianenigma in PR https://github.com/paritytech/substrate/pull/1951 -->\n<!-- and comment https://github.com/paritytech/substrate-developer-hub/issues/44#issuecomment-471982710 -->\n\n\\## Terminology\n\n// Add terminology used in the custom pallet. Include concepts, storage items, or actions that you think\n// deserve to be noted to give context to the rest of the documentation or pallet usage. The author needs to\n// use some judgment about what is included. We don't want a list of every storage item nor types - the user\n// can go to the code for that. For example, \"transfer fee\" is obvious and should not be included, but\n// \"free balance\" and \"reserved balance\" should be noted to give context to the pallet.\n// Please do not link to outside resources. The reference docs should be the ultimate source of truth.\n\n<!-- Original author of heading: @Kianenigma in PR https://github.com/paritytech/substrate/pull/1951 -->\n\n\\## Goals\n\n// Add goals that the custom pallet is designed to achieve.\n\n<!-- Original author of heading: @Kianenigma in PR https://github.com/paritytech/substrate/pull/1951 -->\n\n\\### Scenarios\n\n<!-- Original author of paragraph: @Kianenigma. Based on PR https://github.com/paritytech/substrate/pull/1951 -->\n\n\\### <INSERT_SCENARIO_NAME>\n\n// Describe requirements prior to interacting with the custom pallet.\n// Describe the process of interacting with the custom pallet for this scenario and public API functions used.\n\n\\## Interface\n\n\\### Supported Origins\n\n// What origins are used and supported in this pallet (root, signed, none)\n// i.e. root when <code>\\`ensure_root\\`</code> used\n// i.e. none when <code>\\`ensure_none\\`</code> used\n// i.e. signed when <code>\\`ensure_signed\\`</code> used\n\n<code>\\`inherent\\`</code> <INSERT_DESCRIPTION>\n\n<!-- Original author of paragraph: @Kianenigma in comment -->\n<!-- https://github.com/paritytech/substrate-developer-hub/issues/44#issuecomment-471982710 -->\n\n\\### Types\n\n// Type aliases. Include any associated types and where the user would typically define them.\n\n<code>\\`ExampleType\\`</code> <INSERT_DESCRIPTION>\n\n<!-- Original author of paragraph: ??? -->\n\n// Reference documentation of aspects such as `storageItems` and `dispatchable` functions should only be\n// included in the https://docs.rs Rustdocs for Substrate and not repeated in the README file.\n\n\\### Dispatchable Functions\n\n<!-- Original author of paragraph: @AmarRSingh & @joepetrowski -->\n\n// A brief description of dispatchable functions and a link to the rustdoc with their actual documentation.\n\n// <b>MUST</b> have link to Call enum\n// <b>MUST</b> have origin information included in function doc\n// <b>CAN</b> have more info up to the user\n\n\\### Public Functions\n\n<!-- Original author of paragraph: @joepetrowski -->\n\n// A link to the rustdoc and any notes about usage in the pallet, not for specific functions.\n// For example, in the Balances Pallet: \"Note that when using the publicly exposed functions,\n// you (the runtime developer) are responsible for implementing any necessary checks\n// (e.g. that the sender is the signer) before calling a function that will affect storage.\"\n\n<!-- Original author of paragraph: @AmarRSingh -->\n\n// It is up to the writer of the respective pallet (with respect to how much information to provide).\n\n\\### Public Inspection functions - Immutable (getters)\n\n// Insert a subheading for each getter function signature\n\n\\### <code>\\`example_getter_name()\\`</code>\n\n// What it returns\n// Why, when, and how often to call it\n// When it could panic or error\n// When safety issues to consider\n\n\\### Public Mutable functions (changing state)\n\n// Insert a subheading for each setter function signature\n\n\\### <code>\\`example_setter_name(origin, parameter_name: T::ExampleType)\\`</code>\n\n// What state it changes\n// Why, when, and how often to call it\n// When it could panic or error\n// When safety issues to consider\n// What parameter values are valid and why\n\n\\### Storage Items\n\n// Explain any storage items included in this pallet\n\n\\### Digest Items\n\n// Explain any digest items included in this pallet\n\n\\### Inherent Data\n\n// Explain what inherent data (if any) is defined in the pallet and any other related types\n\n\\### Events:\n\n// Insert events for this pallet if any\n\n\\### Errors:\n\n// Explain what generates errors\n\n\\## Usage\n\n// Insert 2-3 examples of usage and code snippets that show how to\n// use <INSERT_CUSTOM_PALLET_NAME> Pallet in a custom pallet.\n\n\\### Prerequisites\n\n// Show how to include necessary imports for <INSERT_CUSTOM_PALLET_NAME> and derive\n// your pallet configuration trait with the `INSERT_CUSTOM_PALLET_NAME` trait.\n\n\\```rust\nuse <INSERT_CUSTOM_PALLET_NAME>;\n\npub trait Config: <INSERT_CUSTOM_PALLET_NAME>::Config { }\n\\```\n\n\\### Simple Code Snippet\n\n// Show a simple example (e.g. how to query a public getter function of <INSERT_CUSTOM_PALLET_NAME>)\n\n\\### Example from FRAME\n\n// Show a usage example in an actual runtime\n\n// See:\n// - Substrate TCR https://github.com/parity-samples/substrate-tcr\n// - Substrate Kitties https://shawntabrizi.github.io/substrate-collectables-workshop/#/\n\n\\## Genesis Config\n\n<!-- Original author of paragraph: @joepetrowski -->\n\n\\## Dependencies\n\n// Dependencies on other FRAME pallets and the genesis config should be mentioned,\n// but not the Rust Standard Library.\n// Genesis configuration modifications that may be made to incorporate this pallet\n// Interaction with other pallets\n\n<!-- Original author of heading: @AmarRSingh -->\n\n\\## Related Pallets\n\n// Interaction with other pallets in the form of a bullet point list\n\n\\## References\n\n<!-- Original author of paragraph: @joepetrowski -->\n\n// Links to reference material, if applicable. For example, Phragmen, W3F research, etc.\n// that the implementation is based on.\n</pre></p></details>\n\nLicense: MIT-0"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain generate a random account\ninput: "
      },
      {
        "role": "assistant",
        "content": "Generating a new key is as simple as running:\n\nsubkey generate\n\nThe output looks similar to:\n\nSecret phrase `hotel forest jar hover kite book view eight stuff angle legend defense` is account:\n  Secret seed:      0xa05c75731970cc7868a2fb7cb577353cd5b31f62dccced92c441acd8fee0c92d\n  Public key (hex): 0xfec70cfbf1977c6965b5af10a4534a6a35d548eb14580594d0bc543286892515\n  Account ID:       0xfec70cfbf1977c6965b5af10a4534a6a35d548eb14580594d0bc543286892515\n  SS58 Address:     5Hpm9fq3W3dQgwWpAwDS2ZHKAdnk86QRCu7iX4GnmDxycrte\n\n---\n\u2620\ufe0f DO NT RE-USE ANY OF THE SEEDS AND SECRETS FROM THIS PAGE \u2620\ufe0f.\n\nYou can read more about security and risks in SECURITY.md and in the Polkadot\nWiki.\n\n---\n\nThe output above shows a **secret phrase** (also called **mnemonic phrase**) and the **secret seed** (also called\n**Private Key**). Those 2 secrets are the pieces of information you MUST keep safe and secret. All the other information\nbelow can be derived from those secrets.\n\nThe output above also shows the **public key** and the **Account ID**. Those are the independent from the network where\nyou will use the key.\n\nThe **SS58 address** (or **Public Address**) of a new account is a representation of the public keys of an account for\na given network (for instance Kusama or Polkadot).\n\nYou can read more about the SS58 format in the Substrate Docs\nand see the list of reserved prefixes in the SS58 Registry.\n\nFor instance, considering the previous seed `0xa05c75731970cc7868a2fb7cb577353cd5b31f62dccced92c441acd8fee0c92d` the\nSS58 addresses are:\n\n- Polkadot: `16m4J167Mptt8UXL8aGSAi7U2FnPpPxZHPrCgMG9KJzVoFqM`\n- Kusama: `JLNozAv8QeLSbLFwe2UvWeKKE4yvmDbfGxTuiYkF2BUMx4M`"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain infrastructure/api\ninput: "
      },
      {
        "role": "assistant",
        "content": "### *Peer Set Management*\n\nCategory: Networking\n\nValidators assigned to a parachain need a way to discover and connect to collators in order to get fresh parachain\nblocks to validate.\n\nCollators need to discover and connect to validators in order to submit parachain blocks.\n\nFishermen need to talk to validators and collators to fetch available data and circulate reports.\n\nSome connections are long-lived, some are just for a single request.\n\n### Custom libp2p sub-protocols\n\nPolkadot parachains involve many distinct networking protocols. Ideally, we'd be able to spawn each of these as a\nseparate futures task which communicates via channel with other protocols or node code as necessary. This requires\nchanges in Substrate and libp2p.\n\n---"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain assignment\ninput: "
      },
      {
        "role": "assistant",
        "content": "### *Auctions*\n\nCategory: Runtime\n\nAuctioning and registration of parachains. This is already implemented and follows the Parachain Allocation \u2014 Research\nat W3F document.\n\n### *On-demand Blockspace Purchase*\n\nCategory: Runtime\n\nThe blockspace purchasing system for on-demand parachains consists of an on-chain mechanism for resolving block space\npurchases by collators and ensuring that they author a block.\n\nThe node-side portion of on-demand parachains is for collators to actually purchase blockspace and to configure the\nconditions in which purchases are made.\n\n### *Validator Assignment*\n\nCategory: Runtime\n\nAssignment of validators to parachains. Validators are only assigned to parachains for a short period of time. Tweakable\nparameters include length of time assigned to each parachain and length of time in advance that the network is aware of\nvalidators' assignments.\n\n---"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain agreement\ninput: "
      },
      {
        "role": "assistant",
        "content": "### *Attestation Circulation*\n\nCategory: Networking\n\nA black-box networking component for circulating attestation messages (`Candidate`, `Valid`, `Invalid`) between\nvalidators of any given parachain to create a quorum on which blocks can be included.\n\n### *Availability Erasure-coding*\n\nCategory: Node, Networking\n\nFor each potential, considered parachain block, perform an erasure-coding of the PoV and outgoing messages of the block.\nCall the number of validators on the relay chain for the Relay-chain block this parachain block is being considered for\ninclusion in `n`. Erasure-code into `n` pieces, where any `f + 1` can recover (`f` being the maximum number of tolerated\nfaulty nodes = ~ `n / 3`). The `i'th` validator stores the `i'th` piece of the coding and provides it to any who ask.\n\n### *PoV block fetching*\n\nCategory: Networking\n\nA black-box networking component for validators or fishermen on a parachain to obtain the PoV block referenced by hash\nin an attestation, for the purpose of validating. When fetching \"current\" PoV blocks (close to the head of the chain, or\nrelating to the block currently being built), this should be fast. When fetching \"old\" PoV blocks, it should be possible\nand fall back on recovering from the availability erasure-coding.\n\n### *On-demand Blockspace Purchase*\n\nCategory: Node, Networking\n\nHow and when collators are configured to purchase on-demand blockspace.\n\n### *Collation Loop*\n\nCategory: Node, Networking\n\nThe main event loop of a collator node:\n 1. new relay chain block B\n 2. sync new parachain head P w.r.t. B\n 3. build new child of P\n 4. submit to validators\n\n---"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain cross-chain messaging\ninput: "
      },
      {
        "role": "assistant",
        "content": "https://hackmd.io/ILoQltEISP697oMYe4HbrA?view https://github.com/paritytech/polkadot/issues/597\n\nThe biggest sub-project of the parachains roadmap - how messages are sent between parachains. This involves the\nstate-machine ordering of incoming messages, protocols for fetching those messages, and node logic for persisting the\nmessages.\n\nThis is designed around a concept of unidirectional _channels_ between paras, which consist of a sender and receiver. At\neach relay chain block, each para has an opportunity to send a message on each channel for which it controls the sending\nhalf. It will also attempt to process messages on each receiving half of the channel which it controls _in order_:\nmessages sent at block height `b` must be processed before those sent at block height `b+1`. For messages on different\nchannels sent at the same block height, there will be some well-defined order in which they should be processed.\n\nThis means that a receiving para will have a maximum height differential of `1` in terms of the most recently processed\nmessage's send-height across all of the channels it is receiving on. The minimum processed send-height of a receiving\npara is known as its _watermark_. All messages on all channels sending to this para before or at the watermark have been\nprocessed.\n\n### *Finalize CandidateReceipt format*\n\nCategory: Runtime / Node\n\nThe `CandidateReceipt` is the wrapper around a parablock header which is submitted to the runtime. It contains\ncryptographic commitments to data which is important for validation or interpretation of the parablock, including the\nhash of the witness data and outgoing message data.\n\nThe `CandidateReceipt` format should be finalized in accordance to the XCMP writeups linked above - most importantly, to\nbe altered to hold `bitfield` and `message_root` fields which cryptographically commit to the state of each open\nchannel.\n\n### *Finalize PovBlock format*\n\nCategory: Runtime / Node\n\nThe `PovBlock` or `Proof-of-Validity` block contains all the data you need to validate a parablock. It will need to\ncontain incoming message queues and potentially outgoing ones as well.\n\n### *CST Update Procedure*\n\nCategory: Runtime\n\nStorage definitions and update logic of the Channel State Table (CST) based on the supplied `CandidateReceipt`s in a\nrelay chain block.\n\n### *CST Entry Proof Generation and Checking*\n\nCategory: Node\n\nMeans for full nodes of the relay chain to generate proofs of items in the CST and for light clients or pruned nodes to\ncheck those proofs.\n\n### *MQC Storage and Distribution Protocol*\n\nCategory: Node\n\nEvery channel's state is described by a Message Queue Chain (MQC) which is a hash-chain, where the links are defined by\n`(M, b, H)`: the message most recently sent, the block height at which the prior message was sent, and the hash of the\nprior link.\n\nIt is the responsibility of the full nodes of the _sending_ para to maintain all links of the MQC up to and including\nthe link where `b` is less than the watermark of the _receiving_ para.\n\nFull nodes of the para will be aware of the head of all MQCs for its channels because they are produced by execution of\nthe block. This will take collaboration with the Cumulus team (https://github.com/paritytech/polkadot-sdk) on APIs.\n\nWe will need a network where collators of paras can discover and fetch the relevant portion of the MQC incoming from all\nchannels.\n\n### *Channel Registrar and Economics*\n\nCategory: Runtime\n\nRuntime logic for paras to open and close channels by putting down a deposit. The amount of channels an on-demand\nparachain can open will be limited. Channels that are pending close should remain open until the watermark of the\nrecipient has reached the block height of the close request.\n\n---"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain fishing/slashing\ninput: "
      },
      {
        "role": "assistant",
        "content": "### *Validity/Availability Report Handler*\n\nCategory: Runtime\n\nIn Polkadot, a bad parachain group can force inclusion of an invalid or unavailable parachain block. It is the job of\nfishermen to detect those blocks and report them to the runtime. This item is about the report handler\n\nThe W3F-research writeup on availability/validity provides a high-level view of the dispute resolution process:\nAvailability and Validity \u2014 Research at\nW3F\n\nOne of the main behaviors that is unimplemented and needs to be is the _rollback_ that occurs when the dispute\nresolution process concludes that an error has been made. When we mark a parachain block as having been invalid or\nunavailable, we need to roll back all parachains to a point from just before this state.  We would also need to roll\nback relay chain state, because there may have been messages from a parachain to a relay chain that now need to be\nrolled back. The easiest thing to do would be to side-step that by putting a delay on upwards messages, but this would\nimpact the UX of parachain participation in slot auctions, council votes, etc. considerably. Assuming we can't side-step\nthis, we will have to find a way to roll back selected state of the relay chain.\n\n### *Double-vote Slash Handler*\n\nCategory: Runtime\n\nIn the attestation process, validators may submit only one `Candidate` message for a given relay chain block. If issuing\na `Candidate` message on a parachain block, neither a `Valid` or `Invalid` vote cannot be issued on that parachain\nblock, as the `Candidate` message is an implicit validity vote. Otherwise, it is illegal to cast both a `Valid` and\n`Invalid` vote on a given parachain block.\n\nRuntime handlers that take two conflicting votes as arguments and slash the offender are needed.\n\n### *Validity/Availability Fishing*\n\nCategory: Node\n\nThis code-path is also taken by validators who self-select based on VRF Availability and Validity \u2014 Research at\nW3F. Validators and fishermen will\nselect parachain blocks to re-validate. In these steps:\n- Attempt to recover the PoV block, falling back on the erasure-coding. If not available, issue report.\n- Attempt to validate the PoV block. If invalid, issue report.\n\n### *Double-vote Fishing*\n\nCategory: Node\n\nNodes that observe a double-vote in the attestation process should submit a report to the chain to trigger slashing.\n\n---"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain parachain status\ninput: "
      },
      {
        "role": "assistant",
        "content": "This dashboard allows you to see at a glance how fast are candidates approved, disputed and\nfinalized. It was originally designed for observing liveliness after parachain deployment in\n Kusama/Polkadot, but can be useful generally in production or testing.\n\nIt includes panels covering key subsystems of the parachain node side implementation:\n- Backing\n- PVF execution\n- Approval voting\n- Disputes coordinator\n- Chain selection\n\nIt is important to note that this dashboard applies only for validator nodes. The prometheus\nqueries assume the `instance` label value contains the string `validator` only for validator nodes.\n\nDashboard JSON"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain key liveliness indicators\ninput: "
      },
      {
        "role": "assistant",
        "content": "- **Relay chain finality lag**. How far behind finality is compared to the current best block. By design,\n GRANDPA never finalizes past last 2 blocks, so this value is always >=2 blocks.\n- **Approval checking finality lag**. The distance (in blocks) between the chain head and the last block\non which Approval voting is happening. The block is generally the highest approved ancestor of the head\nblock and the metric is computed during relay chain selection.\n- **Disputes finality lag**. How far behind the chain head is the last approved and non disputed block.\nThis value is always higher than approval checking lag as it further restricts finality to only undisputed\nchains.\n- **PVF preparation and execution time**. Each parachain has it's own PVF (parachain validation function):\na wasm blob that is executed by validators during backing, approval checking and disputing. The PVF\npreparation time refers to the time it takes for the PVF wasm to be compiled. This step is done once and\nthen result cached. PVF execution will use the resulting artifact to execute the PVF for a given candidate.\nPVFs are expected to have a limited execution time to ensure there is enough time left for the parachain\nblock to be included in the relay block.\n- **Time to recover and check candidate**. This is part of approval voting and covers the time it takes\nto recover the candidate block available data from other validators, check it (includes PVF execution time)\nand issue statement or initiate dispute.\n- **Assignment delay tranches**. Approval voting is designed such that validators assigned to check a specific\ncandidate are split up into equal delay tranches (0.5 seconds each). All validators checks are ordered by the delay\ntranche index. Early tranches of validators have the opportunity to check the candidate first before later tranches\nthat act as backups in case of no shows."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain example run\ninput: "
      },
      {
        "role": "assistant",
        "content": "Let's run an availability read test which will recover availability for 200 cores with max PoV size on a 1000\nnode validator network.\n\n<!-- markdownlint-disable line-length -->\n\ntarget/testnet/subsystem-bench polkadot/node/subsystem-bench/examples/availability_write.yaml\n[2024-02-19T14:10:32.981Z INFO  subsystem_bench] Sequence contains 1 step(s)\n[2024-02-19T14:10:32.981Z INFO  subsystem-bench::cli] Step 1/1\n[2024-02-19T14:10:32.981Z INFO  subsystem-bench::cli] [objective = DataAvailabilityWrite] n_validators = 1000, n_cores = 200, pov_size = 5120 - 5120, connectivity = 75, latency = Some(PeerLatency { mean_latency_ms: 30, std_dev: 2.0 })\n[2024-02-19T14:10:32.982Z INFO  subsystem-bench::availability] Generating template candidate index=0 pov_size=5242880\n[2024-02-19T14:10:33.106Z INFO  subsystem-bench::availability] Created test environment.\n[2024-02-19T14:10:33.106Z INFO  subsystem-bench::availability] Pre-generating 600 candidates.\n[2024-02-19T14:10:34.096Z INFO  subsystem-bench::network] Initializing emulation for a 1000 peer network.\n[2024-02-19T14:10:34.096Z INFO  subsystem-bench::network] connectivity 75%, latency Some(PeerLatency { mean_latency_ms: 30, std_dev: 2.0 })\n[2024-02-19T14:10:34.098Z INFO  subsystem-bench::network] Network created, connected validator count 749\n[2024-02-19T14:10:34.099Z INFO  subsystem-bench::availability] Seeding availability store with candidates ...\n[2024-02-19T14:10:34.100Z INFO  substrate_prometheus_endpoint] \u303d\ufe0f Prometheus exporter started at 127.0.0.1:9999\n[2024-02-19T14:10:34.387Z INFO  subsystem-bench::availability] Done\n[2024-02-19T14:10:34.387Z INFO  subsystem-bench::availability] Current block #1\n[2024-02-19T14:10:34.389Z INFO  subsystem-bench::availability] Waiting for all emulated peers to receive their chunk from us ...\n[2024-02-19T14:10:34.625Z INFO  subsystem-bench::availability] All chunks received in 237ms\n[2024-02-19T14:10:34.626Z INFO  polkadot_subsystem_bench::availability] Waiting for 749 bitfields to be received and processed\n[2024-02-19T14:10:35.710Z INFO  subsystem-bench::availability] All bitfields processed\n[2024-02-19T14:10:35.710Z INFO  subsystem-bench::availability] All work for block completed in 1322ms\n[2024-02-19T14:10:35.710Z INFO  subsystem-bench::availability] Current block #2\n[2024-02-19T14:10:35.712Z INFO  subsystem-bench::availability] Waiting for all emulated peers to receive their chunk from us ...\n[2024-02-19T14:10:35.947Z INFO  subsystem-bench::availability] All chunks received in 236ms\n[2024-02-19T14:10:35.947Z INFO  polkadot_subsystem_bench::availability] Waiting for 749 bitfields to be received and processed\n[2024-02-19T14:10:37.038Z INFO  subsystem-bench::availability] All bitfields processed\n[2024-02-19T14:10:37.038Z INFO  subsystem-bench::availability] All work for block completed in 1328ms\n[2024-02-19T14:10:37.039Z INFO  subsystem-bench::availability] Current block #3\n[2024-02-19T14:10:37.040Z INFO  subsystem-bench::availability] Waiting for all emulated peers to receive their chunk from us ...\n[2024-02-19T14:10:37.276Z INFO  subsystem-bench::availability] All chunks received in 237ms\n[2024-02-19T14:10:37.276Z INFO  polkadot_subsystem_bench::availability] Waiting for 749 bitfields to be received and processed\n[2024-02-19T14:10:38.362Z INFO  subsystem-bench::availability] All bitfields processed\n[2024-02-19T14:10:38.362Z INFO  subsystem-bench::availability] All work for block completed in 1323ms\n[2024-02-19T14:10:38.362Z INFO  subsystem-bench::availability] All blocks processed in 3974ms\n[2024-02-19T14:10:38.362Z INFO  subsystem-bench::availability] Avg block time: 1324 ms\n[2024-02-19T14:10:38.362Z INFO  parachain::availability-store] received `Conclude` signal, exiting\n[2024-02-19T14:10:38.362Z INFO  parachain::bitfield-distribution] Conclude\n[2024-02-19T14:10:38.362Z INFO  subsystem-bench::network] Downlink channel closed, network interface task exiting\n\npolkadot/node/subsystem-bench/examples/availability_write.yaml #1 DataAvailabilityWrite\n\nNetwork usage, KiB                     total   per block\nReceived from peers                12922.000    4307.333\nSent to peers                      47705.000   15901.667\n\nCPU usage, seconds                     total   per block\navailability-distribution              0.045       0.015\nbitfield-distribution                  0.104       0.035\navailability-store                     0.304       0.101\nTest environment                       3.213       1.071\n\n<!-- markdownlint-enable line-length -->\n\n`Block time` in the current context has a different meaning. It measures the amount of time it\ntook the subsystem to finish processing all of the messages sent in the context of the current test block."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain profile memory usage using jemalloc\ninput: "
      },
      {
        "role": "assistant",
        "content": "Bellow you can find instructions how to setup and run profiling with jemalloc, this is complementary\nwith using other memory profiling tools like: <https://github.com/koute/bytehound?tab=readme-ov-file#basic-usage>.\n\n### Prerequisites\n\nInstall tooling with:\n\nsudo apt install libjemalloc-dev graphviz\n\n### Generate memory usage snapshots\n\nMemory usage can be profiled by running any subsystem benchmark with `--features memprofile`, e.g:\n\nRUSTFLAGS=-g cargo run -p polkadot-subsystem-bench --release --features memprofile -- polkadot/node/subsystem-bench/examples/approvals_throughput.yaml\n\n### Interpret the results\n\nAfter the benchmark ran the memory usage snapshots can be found in `/tmp/subsystem-bench*`, to extract the information\nfrom a snapshot you can use `jeprof` like this:\n\njeprof --text PATH_TO_EXECUTABLE_WITH_DEBUG_SYMBOLS /tmp/subsystem-bench.1222895.199.i199.heap > statistics.txt\n\nUseful links:\n\n- Tutorial: <https://www.magiroux.com/rust-jemalloc-profiling/>\n- Jemalloc configuration options: <https://jemalloc.net/jemalloc.3.html>"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain issue 1: scalability\ninput: "
      },
      {
        "role": "assistant",
        "content": "It became clear a few years ago that the transaction throughput of simple Proof-of-Work (PoW) blockchains such as\nBitcoin, Ethereum, and myriad others was simply too low.\n\n> TODO: what if there were more blockchains, etc.\n\nProof-of-Stake (PoS) systems can accomplish higher throughput than PoW blockchains. PoS systems are secured by bonded\ncapital as opposed to spent effort - liquidity opportunity cost vs. burning electricity. The way they work is by\nselecting a set of validators with known economic identity who lock up tokens in exchange for earning the right to\n\"validate\" or participate in the consensus process. If they are found to carry out that process wrongly, they will be\nslashed, meaning some or all of the locked tokens will be burned. This provides a strong disincentive in the direction\nof misbehavior.\n\nSince the consensus protocol doesn't revolve around wasting effort, block times and agreement can occur much faster.\nSolutions to PoW challenges don't have to be found before a block can be authored, so the overhead of authoring a block\nis reduced to only the costs of creating and distributing the block.\n\nHowever, consensus on a PoS chain requires full agreement of 2/3+ of the validator set for everything that occurs at\nLayer 1: all logic which is carried out as part of the blockchain's state machine. This means that everybody still needs\nto check everything. Furthermore, validators may have different views of the system based on the information that they\nreceive over an asynchronous network, making agreement on the latest state more difficult.\n\nParachains are an example of a **sharded** protocol. Sharding is a concept borrowed from traditional database\narchitecture. Rather than requiring every participant to check every transaction, we require each participant to check\nsome subset of transactions, with enough redundancy baked in that byzantine (arbitrarily malicious) participants can't\nsneak in invalid transactions - at least not without being detected and getting slashed, with those transactions\nreverted.\n\nSharding and Proof-of-Stake in coordination with each other allow a parachain host to provide full security on many\nparachains, even without all participants checking all state transitions.\n\n> TODO: note about network effects & bridging"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain assignment criteria\ninput: "
      },
      {
        "role": "assistant",
        "content": "Assignment criteria compute actual assignments using stories and the validators' secret approval assignment key.\nAssignment criteria output a `Position` consisting of both a `ParaId` to be checked, as well as a precedence\n`DelayTranche` for when the assignment becomes valid.\n\nAssignment criteria come in four flavors, `RelayVRFModuloCompact`, `RelayVRFDelay`, `RelayEquivocation` and the\ndeprecated `RelayVRFModulo`.  Among these, `RelayVRFModulo`, `RelayVRFModuloCompact` and `RelayVRFDelay` run a\nVRF whose input is the output of a `RelayVRFStory`, while `RelayEquivocation` runs a VRF whose input is the\noutput of a `RelayEquivocationStory`.\n\nAmong these, we have two distinct VRF output computations:\n\n`RelayVRFModulo` runs several distinct samples whose VRF input is the `RelayVRFStory` and the sample number.  It\ncomputes the VRF output with `schnorrkel::vrf::VRFInOut::make_bytes` using the context \"A&V Core\", reduces this number\nmodulo the number of availability cores, and outputs the candidate just declared available by, and included by aka\nleaving, that availability core.  We drop any samples that return no candidate because no candidate was leaving the\nsampled availability core in this relay chain block.  We choose three samples initially, but we could make Polkadot more\nsecure and efficient by increasing this to four or five, and reducing the backing checks accordingly.  All successful\n`RelayVRFModulo` samples are assigned delay tranche zero.\n\n`RelayVRFModuloCompact` runs a single samples whose VRF input is the `RelayVRFStory` and the sample count. Similar\nto `RelayVRFModulo` introduces multiple core assignments for tranche zero. It computes the VRF output with\n`schnorrkel::vrf::VRFInOut::make_bytes` using the context \"A&V Core v2\" and samples up to 160 bytes of the output\nas an array of `u32`. Then reduces each `u32` modulo the number of availability cores, and outputs up\nto `relay_vrf_modulo_samples` availability core indices.\n\nThere is no sampling process for `RelayVRFDelay` and `RelayEquivocation`.  We instead run them on specific candidates\nand they compute a delay from their VRF output.  `RelayVRFDelay` runs for all candidates included under, aka declared\navailable by, a relay chain block, and inputs the associated VRF output via `RelayVRFStory`.  `RelayEquivocation` runs\nonly on candidate block equivocations, and inputs their block hashes via the `RelayEquivocation` story.\n\n`RelayVRFDelay` and `RelayEquivocation` both compute their output with `schnorrkel::vrf::VRFInOut::make_bytes` using the\ncontext \"A&V Tranche\" and reduce the result modulo `num_delay_tranches + zeroth_delay_tranche_width`, and consolidate\nresults 0 through `zeroth_delay_tranche_width` to be 0.  In this way, they ensure the zeroth delay tranche has\n`zeroth_delay_tranche_width+1` times as many assignments as any other tranche.\n\nAs future work (or TODO?), we should merge assignment notices with the same delay and story using `vrf_merge`.  We\ncannot merge those with the same delay and different stories because `RelayEquivocationStory`s could change but\n`RelayVRFStory` never changes."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain vertical message passing\ninput: "
      },
      {
        "role": "assistant",
        "content": "```dot process\ndigraph {\n    rc [shape=Mdiamond label=\"Relay Chain\"];\n    p1 [shape=box label = \"Parachain\"];\n\n    rc -> p1 [label=\"DMP\"];\n    p1 -> rc [label=\"UMP\"];\n}\n```\n\nDownward Message Passing (DMP) is a mechanism for delivering messages to parachains from the relay chain.\n\nEach parachain has its own queue that stores all pending inbound downward messages. A parachain doesn't have to process\nall messages at once, however, there are rules as to how the downward message queue should be processed. Currently, at\nleast one message must be consumed per candidate if the queue is not empty. The downward message queue doesn't have a\ncap on its size and it is up to the relay-chain to put mechanisms that prevent spamming in place.\n\nUpward Message Passing (UMP) is a mechanism responsible for delivering messages in the opposite direction: from a\nparachain up to the relay chain. Upward messages are essentially byte blobs. However, they are interpreted by the\nrelay-chain according to the XCM standard.\n\nThe XCM standard is a common vocabulary of messages. The XCM standard doesn't require a particular interpretation of a\nmessage. However, the parachains host (e.g. Polkadot) guarantees certain semantics for those.\n\nMoreover, while most XCM messages are handled by the on-chain XCM interpreter, some of the messages are special cased.\nSpecifically, those messages can be checked during the acceptance criteria and thus invalid messages would lead to\nrejecting the candidate itself.\n\nOne kind of such a message is `Xcm::Transact`. This upward message can be seen as a way for a parachain to execute\narbitrary entrypoints on the relay-chain. `Xcm::Transact` messages resemble regular extrinsics with the exception that\nthey originate from a parachain.\n\nThe payload of `Xcm::Transact` messages is referred as to `Dispatchable`. When a candidate with such a message is\nenacted the dispatchables are put into a queue corresponding to the parachain. There can be only so many dispatchables\nin that queue at once. The weight that processing of the dispatchables can consume is limited by a preconfigured value.\nTherefore, it is possible that some dispatchables will be left for later blocks. To make the dispatching more fair, the\nqueues are processed turn-by-turn in a round robin fashion.\n\nThe second category of special cased XCM messages are for horizontal messaging channel management, namely messages meant\nto request opening and closing HRMP channels (HRMP will be described below)."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain background\ninput: "
      },
      {
        "role": "assistant",
        "content": "As established in the approval process dealing with bad parablocks is a three step process:\n\n1. Detection\n1. Escalation\n1. Consequences\n\nThe main system responsible for dispensing **consequences** for malicious actors is the dispute\nsystem which eventually dispenses slash events. The slashes itself can be dispensed quickly (a\nmatter of blocks) but for an extra layer of auditing all slashes are deferred for 27 days (in Polkadot/Kusama) which\ngives time for Governance to investigate and potentially alter the punishment. Dispute concluding by itself does not\nimmediately remove the validator from the active validator set.\n\n> **Note:** \\\n> There was an additional mechanism of automatically chilling the validator which removed their intent to participate in\n> the next election, but the removed validator could simply re-register his intent to validate.\n\nThere is a need to have a more immediate way to deal with malicious validators. This is where the validator disabling\ncomes in. It is focused on dispensing **low latency** consequences for malicious actors. It is important to note that\nthe validator disabling is not a replacement for the dispute or slashing systems. It is a complementary system that is\nfocused on lighter but immediate consequences usually in the form of restricted validator privileges.\n\nThe primary goals are:\n- Eliminate or minimize cases where attackers can get free attempts at attacking the network\n- Eliminate or minimize the risks of honest nodes being pushed out of consensus when getting unjustly slashed (defense\n  in depth)\n\nThe above two goals are generally at odds so a careful balance has to be struck between them. We will achieve them by\nsacrificing some **liveness** in favor of **soundness** when the network is under stress. Maintaining some liveness but\nabsolute soundness is paramount.\n\n> **Note:** \\\n> Liveness = Valid candidates can go through (at a decent pace) \\\n> Security = Invalid candidates cannot go through (or are statistically very improbable)\n\nSide goals are:\n- Reduce the damages to honest nodes that had a fault which might cause repeated slashes\n- Reduce liveness impact of individual malicious attackers"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain design\ninput: "
      },
      {
        "role": "assistant",
        "content": "A few options for the duration of disablement were considered:\n- 1 epoch (4h in Polkadot)\n- 1 era (24h in Polkadot)\n- 2-26 eras\n- 27 eras\n\n1 epoch is a short period and between a few epochs the validator will most likely be exactly the same. It is also very\ndifficult to fix any local node issues for honest validator in such a short time so the chance for a repeated offense is\nhigh.\n\n1 era gives a bit more time to fix any minor issues. Additionally, it guarantees a validator set change at so many of\nthe currently disabled validator might no longer be present anyway. It also gives the time for the validator to chill\nthemselves if they have identified a cause and want to spend more time fixing it. (**Point 4.**)\n\nHigher values could be considered and the main arguments for those are based around the fact that it reduces the number\nof repeated attacks that will be allowed before the slash execution. Generally 1 attack per era for 27 eras resulting in\n27 attacks at most should not compromise our safety assumptions. Although this direction could be further explored and\nmight be parametrized for governance to decide.\n\n</br></br></br>"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain enabling approval voter slashes\ninput: "
      },
      {
        "role": "assistant",
        "content": "The original Polkadot 1.0 design describes that all validators on the loosing side of the dispute are slashed. In the\ncurrent system only the backers are slashed and any approval voters on the wrong side will not be slashed. This creates\nsome undesirable incentives:\n\n- Lazy approval checkers (approvals yay`ing everything)\n- Spammy approval checkers (approval voters nay`ing everything)\n\nInitially those slashes were disabled to reduce the complexity and to minimize the risk surface in case the system\nmalfunctioned. This is especially risky in case any nondeterministic bugs are present in the system. Once validator\nre-enabling is launched approval voter slashes can be re-instated. Numbers need to be further explored but slashes\nbetween 0-2% are reasonable. 0% would still disable which with the opportunity cost consideration should be enough.\n\n > **Note:** \\\n> Spammy approval checkers are in fact not a big issue as a side effect of the offchain-disabling introduced by the\n> Defense Against Past-Era Dispute Spam (**Node**) #2225. It\n> makes it so all validators loosing a dispute are locally disabled and ignored for dispute initiation so it effectively\n> silences spammers. They can still no-show but the damage is minimized."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain core features\ninput: "
      },
      {
        "role": "assistant",
        "content": "1. Disabled Validators Tracking (**Runtime**) #2950\n    - Expose a ``disabled_validators`` map through a Runtime API\n1. Enforce Backing Disabling (**Runtime**) #1592\n    - Filter out votes from ``disabled_validators`` in ``BackedCandidates`` in ``process_inherent_data``\n1. Substrate Byzantine Threshold (BZT) as Limit for Disabling\n   #1963\n    - Can be parametrized but default to BZT\n    - Disable only up to 1/3 of validators\n1. Respect Disabling in Backing Statement Distribution (**Node**)\n   #1591\n    - This is an optimization as in the end it would get filtered in the runtime anyway\n    - Filter out backing statements coming from ``disabled_validators``\n1. Respect Disablement in Backing (**Node**) #2951\n    - This is an optimization as in the end it would get filtered in the runtime anyway\n    - Don't start backing new candidates when disabled\n    - Don't react to backing requests when disabled\n1. Stop Automatic Chilling of Offenders #1962\n    - Chilling still persists as a state but is no longer automatically applied on offenses\n1. Respect Disabling in Dispute Participation (**Node**) #2225\n    - Receive dispute statements from ``disabled_validators`` but do not release own statements\n    - Ensure dispute confirmation when BZT statements from disabled\n1. Remove Liveness Slashes #1964\n    - Remove liveness slashes from the system\n    - The are other incentives to be online and they could be abused to attack the system\n1. Defense Against Past-Era Dispute Spam (**Node**) #2225\n    - This is needed because runtime cannot disable validators which it no longer knows about\n    - Add a node-side parallel store of ``disabled_validators``\n    - Add new disabled validators to node-side store when they loose a dispute in any leaf in scope\n    - Runtime ``disabled_validators`` always have priority over node-side ``disabled_validators``\n    - Respect the BZT threshold\n    > **Note:** \\\n    > An alternative design here was considered where instead of tracking new incoming leaves a relay parent is used.\n    > This would guarantee determinism as different nodes can see different leaves, but this approach was leaving too\n    > wide of a window because of Async-Backing. Relay Parent could have been significantly in the past and it would\n    > give a lot of time for past session disputes to be spammed.\n1. Do not block finality for \"disabled\" disputes #3358\n    - Emergency fix to not block finality for disputes initiated only by disabled validators\n1. Re-enable small offender when approaching BZT (**Runtime**) #TODO\n    - When BZT limit is reached and there are more offenders to be disabled re-enable the smallest offenders to disable\n      the biggest ones"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain motivation and background\ninput: "
      },
      {
        "role": "assistant",
        "content": "All parachain blocks that end up in the finalized relay chain should be valid. This does not apply to blocks that are\nonly backed, but not included.\n\nWe have two primary components for ensuring that nothing invalid ends up in the finalized relay chain:\n  * Approval Checking, as described here and implemented accordingly in the Approval\nVoting subsystem. This protocol can be shown to prevent invalid parachain blocks\nfrom making their way into the finalized relay chain as long as the amount of attempts are limited.\n  * Disputes, this protocol, which ensures that each attempt to include something bad is caught, and the offending\nvalidators are punished. Disputes differ from backing and approval process (and can not be part of those) in that a\ndispute is independent of a particular fork, while both backing and approval operate on particular forks. This\ndistinction is important! Approval voting stops, if an alternative fork which might not contain the currently approved\ncandidate gets finalized. This is totally fine from the perspective of approval voting as its sole purpose is to make\nsure invalid blocks won't get finalized. For disputes on the other hand we have different requirements: Even though the\n\"danger\" is past and the adversaries were not able to get their invalid block approved, we still want them to get\nslashed for the attempt. Otherwise they just have been able to get a free try, but this is something we need to avoid in\nour security model, as it is based on the assumption that the probability of getting an invalid block finalized is very\nlow and an attacker would get bankrupt before it could have tried often enough.\n\nEvery dispute stems from a disagreement among two or more validators. If a bad actor creates a bad block, but the bad\nactor never distributes it to honest validators, then nobody will dispute it. Of course, such a situation is not even an\nattack on the network, so we don't need to worry about defending against it.\n\nWe are interested in identifying and deterring the following attack scenario:\n  * A parablock included on a branch of the relay chain is bad\n\nWe are also interested in identifying these additional scenarios:\n  * A parablock backed on a branch of the relay chain is bad\n  * A parablock seconded, but not backed on any branch of the relay chain, is bad.\n\nPunishing misbehavior in the latter two scenarios doesn't effect our security guarantees and introduces substantial\ntechnical challenges as described in the `No Disputes for Non Included Candidates` section of Dispute\nCoordinator. We therefore choose to punt on disputes in these cases, instead\nfavoring the protocol simplicity resulting from only punishing in the first scenario.\n\nAs covered in the protocol overview, checking a parachain block requires 3 pieces of data: the\nparachain validation code, the `AvailableData`, and the\n`CandidateReceipt`. The validation code is available on-chain, and published ahead of time, so\nthat no two branches of the relay chain have diverging views of the validation code for a given parachain. Note that\nonly for the first scenario, where the parablock has been included on a branch of the relay chain, is the data\nnecessarily available. Thus, dispute processes should begin with an availability process to ensure availability of the\n`AvailableData`. This availability process will conclude quickly if the data is already available. If the data is not\nalready available, then the initiator of the dispute must make it available.\n\nDisputes have both an on-chain and an off-chain component. Slashing and punishment is handled on-chain, so votes by\nvalidators on either side of the dispute must be placed on-chain. Furthermore, a dispute on one branch of the relay\nchain should be transposed to all other active branches of the relay chain. The fact that slashing occurs _in all\nhistories_ is crucial for deterring attempts to attack the network. The attacker should not be able to escape with their\nfunds because the network has moved on to another branch of the relay chain where no attack was attempted.\n\nIn fact, this is why we introduce a distinction between _local_ and _remote_ disputes. We categorize disputes as either\nlocal or remote relative to any particular branch of the relay chain. Local disputes are about dealing with our first\nscenario, where a parablock has been included on the specific branch we are looking at. In these cases, the chain is\ncorrupted all the way back to the point where the parablock was backed and must be discarded. However, as mentioned\nbefore, the dispute must propagate to all other branches of the relay chain. All other disputes are considered _remote_.\nFor the on-chain component, when handling a dispute for a block which was not included in the current fork of the relay\nchain, it is impossible to discern between our attack scenarios. It is possible that the parablock was included\nsomewhere, or backed somewhere, or wasn't backed anywhere. The on-chain component for handling these cases will be the\nsame."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain collation generation message\ninput: "
      },
      {
        "role": "assistant",
        "content": "Messages received by the Collation Generation subsystem\n\nThis is the core interface by which collators built on top of a Polkadot node submit collations to validators. As such,\nthese messages are not sent by any subsystem but are instead sent from outside of the overseer.\n\n/// A function provided to the subsystem which it uses to pull new collations.\n///\n/// This mode of querying collations is obsoleted by `CollationGenerationMessages::SubmitCollation`\n///\n/// The response channel, if present, is meant to receive a `Seconded` statement as a\n/// form of authentication, for collation mechanisms which rely on this for anti-spam.\ntype CollatorFn = Fn(Hash, PersistedValidationData) -> Future<Output = (Collation, Option<ResponseChannel<SignedStatement>>)>;\n\n/// Configuration for the collation generator\nstruct CollationGenerationConfig {\n    /// Collator's authentication key, so it can sign things.\n    key: CollatorPair,\n    /// Collation function. See [`CollatorFn`] for more details.\n    collator: CollatorFn,\n    /// The parachain that this collator collates for\n    para_id: ParaId,\n}\n\n/// Parameters for submitting a collation\nstruct SubmitCollationParams {\n    /// The relay-parent the collation is built against.\n    relay_parent: Hash,\n    /// The collation itself (PoV and commitments)\n    collation: Collation,\n    /// The parent block's head-data.\n    parent_head: HeadData,\n    /// The hash of the validation code the collation was created against.\n    validation_code_hash: ValidationCodeHash,\n    /// A response channel for receiving a `Seconded` message about the candidate\n    /// once produced by a validator. This is not guaranteed to provide anything.\n    result_sender: Option<ResponseChannel<SignedStatement>>,\n}\n\nenum CollationGenerationMessage {\n    /// Initialize the collation generation subsystem\n\tInitialize(CollationGenerationConfig),\n    /// Submit a collation to the subsystem. This will package it into a signed\n    /// [`CommittedCandidateReceipt`] and distribute along the network to validators.\n    ///\n    /// If sent before `Initialize`, this will be ignored.\n    SubmitCollation(SubmitCollationParams),\n}"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain v1 overview\ninput: "
      },
      {
        "role": "assistant",
        "content": "Diagrams are rendered in high resolution; open them in a separate tab to see full scale.\n\nThese data types are defined in `polkadot/primitives/src/v1.rs`:\n\n```dot process\ndigraph {\n    rankdir = LR;\n    node [shape = plain]\n\n    CandidateDescriptor [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">CandidateDescriptor&lt;H = Hash&gt;</td></tr>\n            <tr><td>para_id</td><td port=\"para_id\">Id</td></tr>\n            <tr><td>relay_parent</td><td port=\"relay_parent\">H</td></tr>\n            <tr><td>collator</td><td port=\"collator\">CollatorId</td></tr>\n            <tr><td>persisted_validation_data_hash</td><td port=\"persisted_validation_data_hash\">Hash</td></tr>\n            <tr><td>pov_hash</td><td port=\"pov_hash\">Hash</td></tr>\n            <tr><td>erasure_root</td><td port=\"erasure_root\">Hash</td></tr>\n            <tr><td>signature</td><td port=\"signature\">CollatorSignature</td></tr>\n        </table>\n    >]\n\n    CandidateDescriptor:para_id -> Id:w\n    CandidateDescriptor:pov_hash -> PoVHash\n    CandidateDescriptor:collator -> CollatorId:w\n    CandidateDescriptor:persisted_validation_data_hash -> PersistedValidationDataHash\n\n    Id [label=\"polkadot_parachain_primitives::primitives::Id\"]\n    CollatorId [label=\"polkadot_primitives::v2::CollatorId\"]\n\n    PoVHash [label = \"Hash\", shape=\"doublecircle\", fill=\"gray90\"]\n\n    PoVHash -> PoV:name\n\n    CandidateReceipt [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">CandidateReceipt&lt;H = Hash&gt;</td></tr>\n            <tr><td>descriptor</td><td port=\"descriptor\">CandidateDescriptor&lt;H&gt;</td></tr>\n            <tr><td>commitments_hash</td><td port=\"commitments_hash\">Hash</td></tr>\n        </table>\n    >]\n\n    CandidateReceipt:descriptor -> CandidateDescriptor:name\n    CandidateReceipt:commitments_hash -> CandidateCommitmentsHash\n\n    CandidateHash [label = \"Hash\", shape=\"doublecircle\", fill=\"gray90\"]\n    CandidateHash -> CandidateReceipt:name\n\n    CandidateCommitmentsHash [label = \"Hash\", shape=\"doublecircle\", fill=\"gray90\"]\n    CandidateCommitmentsHash -> CandidateCommitments:name\n\n    CommittedCandidateReceipt [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">CommittedCandidateReceipt&lt;H = Hash&gt;</td></tr>\n            <tr><td>descriptor</td><td port=\"descriptor\">CandidateDescriptor&lt;H&gt;</td></tr>\n            <tr><td>commitments</td><td port=\"commitments\">CandidateCommitments</td></tr>\n        </table>\n    >]\n\n    CommittedCandidateReceipt:descriptor -> CandidateDescriptor:name\n    CommittedCandidateReceipt:commitments -> CandidateCommitments:name\n\n    ValidationData [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">ValidationData&lt;N = BlockNumber&gt;</td></tr>\n            <tr><td>persisted</td><td port=\"persisted\">PersistedValidationData&lt;N&gt;</td></tr>\n            <tr><td>transient</td><td port=\"transient\">TransientValidationData&lt;N&gt;</td></tr>\n        </table>\n    >]\n\n    ValidationData:persisted -> PersistedValidationData:name\n    ValidationData:transient -> TransientValidationData:name\n\n    PersistedValidationData [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">PersistedValidationData&lt;N = BlockNumber&gt;</td></tr>\n            <tr><td>parent_head</td><td port=\"parent_head\">HeadData</td></tr>\n            <tr><td>block_number</td><td port=\"block_number\">N</td></tr>\n            <tr><td>relay_parent_storage_root</td><td port=\"relay_parent_storage_root\">Hash</td></tr>\n            <tr><td>max_pov_size</td><td port=\"max_pov_size\">u32</td></tr>\n        </table>\n    >]\n\n    PersistedValidationData:parent_head -> HeadData:w\n\n    PersistedValidationDataHash [label = \"Hash\", shape=\"doublecircle\", fill=\"gray90\"]\n    PersistedValidationDataHash -> PersistedValidationData:name\n\n    TransientValidationData [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">TransientValidationData&lt;N = BlockNumber&gt;</td></tr>\n            <tr><td>max_code_size</td><td port=\"max_code_size\">u32</td></tr>\n            <tr><td>max_head_data_size</td><td port=\"max_head_data_size\">u32</td></tr>\n            <tr><td>balance</td><td port=\"balance\">Balance</td></tr>\n            <tr><td>code_upgrade_allowed</td><td port=\"code_upgrade_allowed\">Option&lt;N&gt;</td></tr>\n            <tr><td>dmq_length</td><td port=\"dmq_length\">u32</td></tr>\n        </table>\n    >]\n\n    TransientValidationData:balance -> \"polkadot_core_primitives::v2::Balance\":w\n\n    CandidateCommitments [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">CandidateCommitments&lt;N = BlockNumber&gt;</td></tr>\n            <tr><td>upward_messages</td><td port=\"upward_messages\">Vec&lt;UpwardMessage&gt;</td></tr>\n            <tr><td>horizontal_messages</td><td port=\"horizontal_messages\">Vec&lt;OutboundHrmpMessage&lt;Id&gt;&gt;</td></tr>\n            <tr><td>new_validation_code</td><td port=\"new_validation_code\">Option&lt;ValidationCode&gt;</td></tr>\n            <tr><td>head_data</td><td port=\"head_data\">HeadData</td></tr>\n            <tr><td>processed_downward_messages</td><td port=\"processed_downward_messages\">u32</td></tr>\n            <tr><td>hrmp_watermark</td><td port=\"hrmp_watermark\">N</td></tr>\n        </table>\n    >]\n\n    CandidateCommitments:upward_messages -> \"polkadot_parachain_primitives::primitives::UpwardMessage\":w\n    CandidateCommitments:horizontal_messages -> \"polkadot_core_primitives::v2::OutboundHrmpMessage\":w\n    CandidateCommitments:head_data -> HeadData:w\n    CandidateCommitments:horizontal_messages -> \"polkadot_parachain_primitives::primitives::Id\":w\n    CandidateCommitments:new_validation_code -> \"polkadot_parachain_primitives::primitives::ValidationCode\":w\n\n    PoV [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">PoV</td></tr>\n            <tr><td>block_data</td><td port=\"block_data\">BlockData</td></tr>\n        </table>\n    >]\n\n    PoV:block_data -> \"polkadot_parachain_primitives::primitives::BlockData\":w\n\n    BackedCandidate [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">BackedCandidate&lt;H = Hash&gt;</td></tr>\n            <tr><td>candidate</td><td port=\"candidate\">CommittedCandidateReceipt&lt;H&gt;</td></tr>\n            <tr><td>validity_votes</td><td port=\"validity_votes\">Vec&lt;ValidityAttestation&gt;</td></tr>\n            <tr><td>validator_indices</td><td port=\"validator_indices\">BitVec</td></tr>\n        </table>\n    >]\n\n    BackedCandidate:candidate -> CommittedCandidateReceipt:name\n    BackedCandidate:validity_votes  -> \"polkadot_primitives:v0:ValidityAttestation\":w\n\n    HeadData [label = \"polkadot_parachain_primitives::primitives::HeadData\"]\n\n    CoreIndex [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">CoreIndex</td></tr>\n            <tr><td>0</td><td port=\"0\">u32</td></tr>\n        </table>\n    >]\n\n    GroupIndex [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">GroupIndex</td></tr>\n            <tr><td>0</td><td port=\"0\">u32</td></tr>\n        </table>\n    >]\n\n    ParathreadClaim [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">ParathreadClaim</td></tr>\n            <tr><td>0</td><td port=\"0\">Id</td></tr>\n            <tr><td>1</td><td port=\"1\">CollatorId</td></tr>\n        </table>\n    >]\n\n    ParathreadClaim:0 -> Id:w\n    ParathreadClaim:1 -> CollatorId:w\n\n    MessageQueueChainLink [label = \"(prev_head, B, H(M))\\nSee doc of AbridgedHrmpChannel::mqc_head\"]\n    MQCHash [label = \"Hash\", shape=\"doublecircle\", fill=\"gray90\"]\n\n    MQCHash -> MessageQueueChainLink\n\n    ParathreadEntry [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">ParathreadEntry</td></tr>\n            <tr><td>claim</td><td port=\"claim\">ParathreadClaim</td></tr>\n            <tr><td>retries</td><td port=\"retries\">u32</td></tr>\n        </table>\n    >]\n\n    ParathreadEntry:claim -> ParathreadClaim:name\n\n    CoreOccupied [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\"><i>enum</i> CoreOccupied</td></tr>\n            <tr><td></td><td port=\"parathread\">Parathread(ParathreadEntry)</td></tr>\n            <tr><td></td><td port=\"parachain\">Parachain</td></tr>\n        </table>\n    >]\n\n    CoreOccupied:parathread -> ParathreadEntry:name\n\n    AvailableData [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">AvailableData</td></tr>\n            <tr><td>pov</td><td port=\"pov\">Arc&lt;PoV&gt;</td></tr>\n            <tr><td>validation_data</td><td port=\"validation_data\">PersistedValidationData</td></tr>\n        </table>\n    >]\n\n    AvailableData:pov -> PoV:name\n    AvailableData:validation_data -> PersistedValidationData:name\n\n    GroupRotationInfo [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">GroupRotationInfo&lt;N = BlockNumber&gt;</td></tr>\n            <tr><td>session_start_block</td><td port=\"session_start_block\">N</td></tr>\n            <tr><td>group_rotation_frequency</td><td port=\"group_rotation_frequency\">N</td></tr>\n            <tr><td>now</td><td port=\"now\">N</td></tr>\n        </table>\n    >]\n\n    OccupiedCore [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">OccupiedCore&lt;H = Hash, N = BlockNumber&gt;</td></tr>\n            <tr><td>next_up_on_available</td><td port=\"next_up_on_available\">Option&lt;ScheduledCore&gt;</td></tr>\n            <tr><td>occupied_since</td><td port=\"occupied_since\">N</td></tr>\n            <tr><td>time_out_at</td><td port=\"time_out_at\">N</td></tr>\n            <tr><td>next_up_on_time_out</td><td port=\"next_up_on_time_out\">Option&lt;ScheduledCore&gt;</td></tr>\n            <tr><td>availability</td><td port=\"availability\">BitVec</td></tr>\n            <tr><td>group_responsible</td><td port=\"group_responsible\">GroupIndex</td></tr>\n            <tr><td>candidate_hash</td><td port=\"candidate_hash\">CandidateHash</td></tr>\n            <tr><td>candidate_descriptor</td><td port=\"candidate_descriptor\">CandidateDescriptor</td></tr>\n        </table>\n    >]\n\n    OccupiedCore:next_up_on_available -> ScheduledCore:name\n    OccupiedCore:next_up_on_time_out -> ScheduledCore:name\n    OccupiedCore:group_responsible -> GroupIndex\n    OccupiedCore:candidate_hash -> CandidateHash\n    OccupiedCore:candidate_descriptor -> CandidateDescriptor:name\n\n    ScheduledCore [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">ScheduledCore</td></tr>\n            <tr><td>para_id</td><td port=\"para_id\">Id</td></tr>\n            <tr><td>collator</td><td port=\"collator\">Option&lt;CollatorId&gt;</td></tr>\n        </table>\n    >]\n\n    ScheduledCore:para_id -> Id:w\n    ScheduledCore:collator -> CollatorId:w\n\n    CoreState [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\"><i>enum</i> CoreState&lt;H = Hash, N = BlockNumber&gt;</td></tr>\n            <tr><td></td><td port=\"occupied\">Occupied(OccupiedCore&lt;H, N&gt;)</td></tr>\n            <tr><td></td><td port=\"scheduled\">Scheduled(ScheduledCore)</td></tr>\n            <tr><td></td><td port=\"free\">Free</td></tr>\n        </table>\n    >]\n\n    CoreState:occupied -> OccupiedCore:name\n    CoreState:scheduled -> ScheduledCore:name\n\n    CandidateEvent [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\"><i>enum</i> CandidateEvent&lt;H = Hash&gt;</td></tr>\n            <tr><td></td><td port=\"CandidateBacked\">CandidateBacked(CandidateReceipt&lt;H&gt;, HeadData)</td></tr>\n            <tr><td></td><td port=\"CandidateIncluded\">CandidateIncluded(CandidateReceipt&lt;H&gt;, HeadData)</td></tr>\n            <tr><td></td><td port=\"CandidateTimedOut\">CandidateTimedOut(CandidateReceipt&lt;H&gt;, HeadData)</td></tr>\n        </table>\n    >]\n\n    CandidateEvent:e -> CandidateReceipt:name\n    CandidateEvent:e -> HeadData:w\n\n    SessionInfo [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">SessionInfo</td></tr>\n            <tr><td>validators</td><td port=\"validators\">Vec&lt;ValidatorId&gt;</td></tr>\n            <tr><td>discovery_keys</td><td port=\"discovery_keys\">Vec&lt;AuthorityDiscoveryId&gt;</td></tr>\n            <tr><td>assignment_keys</td><td port=\"assignment_keys\">Vec&lt;AssignmentId&gt;</td></tr>\n            <tr><td>validator_groups</td><td port=\"validator_groups\">Vec&lt;Vec&lt;ValidatorIndex&gt;&gt;</td></tr>\n            <tr><td>n_cores</td><td port=\"n_cores\">u32</td></tr>\n            <tr><td>zeroth_delay_tranche_width</td><td port=\"zeroth_delay_tranch_width\">u32</td></tr>\n            <tr><td>relay_vrf_modulo_samples</td><td port=\"relay_vrf_modulo_samples\">u32</td></tr>\n            <tr><td>n_delay_tranches</td><td port=\"n_delay_tranches\">u32</td></tr>\n            <tr><td>no_show_slots</td><td port=\"no_show_slots\">u32</td></tr>\n            <tr><td>needed_approvals</td><td port=\"needed_approvals\">u32</td></tr>\n        </table>\n    >]\n\n    SessionInfo:validators -> ValidatorId:w\n    SessionInfo:discovery_keys -> AuthorityDiscoveryId:w\n    SessionInfo:validator_groups -> ValidatorIndex:w\n\n    ValidatorId [label = \"polkadot_primitives::v2::ValidatorId\"]\n    AuthorityDiscoveryId [label = \"sp_authority_discovery::AuthorityId\"]\n    ValidatorIndex [label = \"polkadot_primitives::v2::ValidatorIndex\"]\n\n    AbridgedHostConfiguration [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">AbridgedHostConfiguration</td></tr>\n            <tr><td>max_code_size</td><td port=\"max_code_size\">u32</td></tr>\n            <tr><td>max_head_data_size</td><td port=\"max_head_data_size\">u32</td></tr>\n            <tr><td>max_upward_queue_count</td><td port=\"max_upward_queue_count\">u32</td></tr>\n            <tr><td>max_upward_queue_size</td><td port=\"max_upward_queue_size\">u32</td></tr>\n            <tr><td>max_upward_message_size</td><td port=\"max_upward_message_size\">u32</td></tr>\n            <tr><td>max_upward_messages_num_per_candidate</td><td port=\"max_upward_messages_num_per_candidate\">u32</td></tr>\n            <tr><td>hrmp_max_message_num_per_candidate</td><td port=\"hrmp_max_message_num_per_candidate\">u32</td></tr>\n            <tr><td>validation_upgrade_cooldown</td><td port=\"validation_upgrade_cooldown\">BlockNumber</td></tr>\n            <tr><td>validation_upgrade_delay</td><td port=\"validation_upgrade_delay\">BlockNumber</td></tr>\n        </table>\n    >]\n\n    AbridgedHrmpChannel [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">AbridgedHrmpChannel</td></tr>\n            <tr><td>max_capacity</td><td port=\"max_capacity\">u32</td></tr>\n            <tr><td>max_total_size</td><td port=\"max_total_size\">u32</td></tr>\n            <tr><td>max_message_size</td><td port=\"max_message_size\">u32</td></tr>\n            <tr><td>msg_count</td><td port=\"msg_count\">u32</td></tr>\n            <tr><td>total_size</td><td port=\"total_size\">u32</td></tr>\n            <tr><td>mqc_head</td><td port=\"mqc_head\">Option&lt;Hash&gt;</td></tr>\n        </table>\n    >]\n\n    AbridgedHrmpChannel:mqc_head -> MQCHash\n}\n\nThese data types are defined in `polkadot/parachain/src/primitives.rs`:\ndot process\ndigraph {\n    rankdir = LR;\n    node [shape = plain]\n\n    HeadData [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">HeadData</td></tr>\n            <tr><td>0</td><td port=\"0\">Vec&lt;u8&gt;</td></tr>\n        </table>\n    >]\n\n    ValidationCode [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">ValidationCode</td></tr>\n            <tr><td>0</td><td port=\"0\">Vec&lt;u8&gt;</td></tr>\n        </table>\n    >]\n\n    BlockData [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">BlockData</td></tr>\n            <tr><td>0</td><td port=\"0\">Vec&lt;u8&gt;</td></tr>\n        </table>\n    >]\n\n    Id [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">Id</td></tr>\n            <tr><td>0</td><td port=\"0\">u32</td></tr>\n        </table>\n    >]\n\n    Sibling [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">Sibling</td></tr>\n            <tr><td>0</td><td port=\"0\">Id</td></tr>\n        </table>\n    >]\n\n    Sibling:0 -> Id:name\n\n    HrmpChannelId [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">HrmpChannelId</td></tr>\n            <tr><td>sender</td><td port=\"sender\">Id</td></tr>\n            <tr><td>recipient</td><td port=\"recipient\">Id</td></tr>\n        </table>\n    >]\n\n    HrmpChannelId:e -> Id:name\n\n    ValidationParams [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">ValidationParams</td></tr>\n            <tr><td>parent_head</td><td port=\"parent_head\">HeadData</td></tr>\n            <tr><td>block_data</td><td port=\"block_data\">BlockData</td></tr>\n            <tr><td>relay_parent_number</td><td port=\"relay_parent_number\">RelayChainBlockNumber</td></tr>\n            <tr><td>relay_parent_storage_root</td><td port=\"relay_parent_storage_root\">Hash</td></tr>\n        </table>\n    >]\n\n    ValidationParams:parent_head -> HeadData:name\n    ValidationParams:block_data -> BlockData:name\n    ValidationParams:relay_parent_number -> RelayChainBlockNumber:w\n\n    RelayChainBlockNumber [label = \"polkadot_core_primitives::BlockNumber\"]\n\n    ValidationResult [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">ValidationResult</td></tr>\n            <tr><td>head_data</td><td port=\"head_data\">HeadData</td></tr>\n            <tr><td>new_validation_code</td><td port=\"new_validation_code\">Option&lt;ValidationCode&gt;</td></tr>\n            <tr><td>upward_messages</td><td port=\"upward_messages\">Vec&lt;UpwardMessage&gt;</td></tr>\n            <tr><td>horizontal_messages</td><td port=\"horizontal_messages\">Vec&lt;OutboundHrmpMessage&lt;Id&gt;&gt;</td></tr>\n            <tr><td>processed_downward_messages</td><td port=\"processed_downward_messages\">u32</td></tr>\n            <tr><td>hrmp_watermark</td><td port=\"hrmp_watermark\">RelayChainBlockNumber</td></tr>\n        </table>\n    >]\n\n    ValidationResult:head_data -> HeadData:name\n    ValidationResult:new_validation_code -> ValidationCode:name\n    ValidationResult:upward_messages -> UpwardMessage:w\n    ValidationResult:horizontal_messages -> OutboundHrmpMessage:w\n    ValidationResult:horizontal_messages -> Id:name\n    ValidationResult:hrmp_watermark -> RelayChainBlockNumber:w\n\n    UpwardMessage [label = \"Vec<u8>\"]\n    OutboundHrmpMessage [label = \"polkadot_core_primitives::OutboundHrmpMessage\"]\n}\n```"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain host configuration\ninput: "
      },
      {
        "role": "assistant",
        "content": "The internal-to-runtime configuration of the parachain host is kept in `struct HostConfiguration`. This is expected to\nbe altered only by governance procedures or via migrations from the Polkadot-SDK codebase. The latest definition of\n`HostConfiguration` can be found in the project repo\nhere. Each\nparameter has got a doc comment so for any details please refer to the code.\n\nSome related parameters in `HostConfiguration` are grouped together so that they can be managed easily. These are:\n* `async_backing_params` in `struct AsyncBackingParams`\n* `executor_params` in `struct ExecutorParams`\n* `approval_voting_params` in `struct ApprovalVotingParams`\n* `scheduler_params` in `struct SchedulerParams`\n\nCheck the definitions of these structs for further details."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain utility structs\ninput: "
      },
      {
        "role": "assistant",
        "content": "// the two key times necessary to track for every code replacement.\npub struct ReplacementTimes {\n /// The relay-chain block number that the code upgrade was expected to be activated.\n /// This is when the code change occurs from the para's perspective - after the\n /// first parablock included with a relay-parent with number >= this value.\n expected_at: BlockNumber,\n /// The relay-chain block number at which the parablock activating the code upgrade was\n /// actually included. This means considered included and available, so this is the time at which\n /// that parablock enters the acceptance period in this fork of the relay-chain.\n activated_at: BlockNumber,\n}\n\n/// Metadata used to track previous parachain validation code that we keep in\n/// the state.\npub struct ParaPastCodeMeta {\n // Block numbers where the code was expected to be replaced and where the code\n // was actually replaced, respectively. The first is used to do accurate lookups\n // of historic code in historic contexts, whereas the second is used to do\n // pruning on an accurate timeframe. These can be used as indices\n // into the `PastCode` map along with the `ParaId` to fetch the code itself.\n upgrade_times: Vec<ReplacementTimes>,\n // This tracks the highest pruned code-replacement, if any.\n last_pruned: Option<BlockNumber>,\n}\n\nstruct ParaGenesisArgs {\n  /// The initial head-data to use.\n  genesis_head: HeadData,\n  /// The validation code to start with.\n  validation_code: ValidationCode,\n  /// True if parachain, false if parathread.\n  parachain: bool,\n}\n\n/// The possible states of a para, to take into account delayed lifecycle changes.\npub enum ParaLifecycle {\n  /// A Para is new and is onboarding.\n  Onboarding,\n  /// Para is a Parathread (on-demand parachain).\n  Parathread,\n  /// Para is a lease holding Parachain.\n  Parachain,\n  /// Para is a Parathread (on-demand Parachain) which is upgrading to a lease holding Parachain.\n  UpgradingParathread,\n  /// Para is a lease holding Parachain which is downgrading to an on-demand parachain.\n  DowngradingParachain,\n  /// Parathread (on-demand parachain) is being offboarded.\n  OutgoingParathread,\n  /// Parachain is being offboarded.\n  OutgoingParachain,\n}\n\nenum PvfCheckCause {\n  /// PVF vote was initiated by the initial onboarding process of the given para.\n  Onboarding(ParaId),\n  /// PVF vote was initiated by signalling of an upgrade by the given para.\n  Upgrade {\n    /// The ID of the parachain that initiated or is waiting for the conclusion of pre-checking.\n    id: ParaId,\n    /// The relay-chain block number that was used as the relay-parent for the parablock that\n    /// initiated the upgrade.\n    relay_parent_number: BlockNumber,\n  },\n}\n\nstruct PvfCheckActiveVoteState {\n  // The two following vectors have their length equal to the number of validators in the active\n  // set. They start with all zeroes. A 1 is set at an index when the validator at the that index\n  // makes a vote. Once a 1 is set for either of the vectors, that validator cannot vote anymore.\n  // Since the active validator set changes each session, the bit vectors are reinitialized as\n  // well: zeroed and resized so that each validator gets its own bit.\n  votes_accept: BitVec,\n  votes_reject: BitVec,\n\n  /// The number of session changes this PVF vote has observed. Therefore, this number is\n  /// increased at each session boundary. When created, it is initialized with 0.\n  age: SessionIndex,\n  /// The block number at which this PVF vote was created.\n  created_at: BlockNumber,\n  /// A list of causes for this PVF pre-checking. Has at least one.\n  causes: Vec<PvfCheckCause>,\n}\n\n### Para Lifecycle\n\nBecause the state changes of parachains are delayed, we track the specific state of the para using the `ParaLifecycle`\nenum.\n\nNone         Parathread (on-demand parachain)    Parachain\n +                        +                          +\n |                        |                          |\n |   (\u22482 Session Delay)   |                          |\n |                        |                          |\n +----------------------->+                          |\n |       Onboarding       |                          |\n |                        |                          |\n +-------------------------------------------------->+\n |       Onboarding       |                          |\n |                        |                          |\n |                        +------------------------->+\n |                        |   UpgradingParathread    |\n |                        |                          |\n |                        +<-------------------------+\n |                        |   DowngradingParachain   |\n |                        |                          |\n |<-----------------------+                          |\n |   OutgoingParathread   |                          |\n |                        |                          |\n +<--------------------------------------------------+\n |                        |    OutgoingParachain     |\n |                        |                          |\n +                        +                          +\n\nNote that if PVF pre-checking is enabled, onboarding of a para may potentially be delayed. This can happen due to PVF\npre-checking voting concluding late.\n\nDuring the transition period, the para object is still considered in its existing state."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain routines\ninput: "
      },
      {
        "role": "assistant",
        "content": "All failed checks should lead to an unrecoverable error making the block invalid.\n\n* `process_bitfields(expected_bits, Bitfields, core_lookup: Fn(CoreIndex) -> Option<ParaId>)`:\n  1. Call `sanitize_bitfields<true>` and use the sanitized `signed_bitfields` from now on.\n  1. Call `sanitize_backed_candidates<true>` and use the sanitized `backed_candidates` from now on.\n  1. Apply each bit of bitfield to the corresponding pending candidate, looking up on-demand parachain cores using the\n     `core_lookup`. Disregard bitfields that have a `1` bit for any free cores.\n  1. For each applied bit of each availability-bitfield, set the bit for the validator in the\n     `CandidatePendingAvailability`'s `availability_votes` bitfield. Track all candidates that now have >2/3 of bits set\n     in their `availability_votes`. These candidates are now available and can be enacted.\n  1. For all now-available candidates, invoke the `enact_candidate` routine with the candidate and relay-parent number.\n  1. Return a list of `(CoreIndex, CandidateHash)` from freed cores consisting of the cores where candidates have become\n     available.\n* `sanitize_bitfields<T: crate::inclusion::Config>( unchecked_bitfields: UncheckedSignedAvailabilityBitfields,\n    disputed_bitfield: DisputedBitfield, expected_bits: usize, parent_hash: T::Hash, session_index: SessionIndex,\n    validators: &[ValidatorId], full_check: FullCheck, )`:\n  1. check that `disputed_bitfield` has the same number of bits as the `expected_bits`, iff not return early with an\n     empty vec.\n  1. each of the below checks is for each bitfield. If a check does not pass the bitfield will be skipped.\n  1. check that there are no bits set that reference a disputed candidate.\n  1. check that the number of bits is equal to `expected_bits`.\n  1. check that the validator index is strictly increasing (and thus also unique).\n  1. check that the validator bit index is not out of bounds.\n  1. check the validators signature, iff `full_check=FullCheck::Yes`.\n\n* `sanitize_backed_candidates<T: crate::inclusion::Config, F: FnMut(usize, &BackedCandidate<T::Hash>) -> bool>( mut\n  backed_candidates: Vec<BackedCandidate<T::Hash>>, candidate_has_concluded_invalid_dispute: F, scheduled:\n  &[CoreAssignment], )`\n  1. filter out any backed candidates that have concluded invalid.\n  1. filters backed candidates whom's paraid was scheduled by means of the provided `scheduled` parameter.\n  1. sorts remaining candidates with respect to the core index assigned to them.\n\n* `process_candidates(allowed_relay_parents, BackedCandidates, scheduled: Vec<CoreAssignment>, group_validators:\n  Fn(GroupIndex) -> Option<Vec<ValidatorIndex>>)`:\n    > For details on `AllowedRelayParentsTracker` see documentation for Shared module.\n  1. check that each candidate corresponds to a scheduled core and that they are ordered in the same order the cores\n     appear in assignments in `scheduled`.\n  1. check that `scheduled` is sorted ascending by `CoreIndex`, without duplicates.\n  1. check that the relay-parent from each candidate receipt is one of the allowed relay-parents.\n  1. check that there is no candidate pending availability for any scheduled `ParaId`.\n  1. check that each candidate's `validation_data_hash` corresponds to a `PersistedValidationData` computed from the\n     state of the context block.\n  1. If the core assignment includes a specific collator, ensure the backed candidate is issued by that collator.\n  1. Ensure that any code upgrade scheduled by the candidate does not happen within `config.validation_upgrade_cooldown`\n     of `Paras::last_code_upgrade(para_id, true)`, if any, comparing against the value of `Paras::FutureCodeUpgrades`\n     for the given para ID.\n  1. Check the collator's signature on the candidate data (only if `CandidateDescriptor` is version 1)\n  1. check the backing of the candidate using the signatures and the bitfields, comparing against the validators\n     assigned to the groups, fetched with the `group_validators` lookup, while group indices are computed by `Scheduler`\n     according to group rotation info.\n  1. call `check_upward_messages(config, para, commitments.upward_messages)` to check that the upward messages are\n     valid.\n  1. call `Dmp::check_processed_downward_messages(para, commitments.processed_downward_messages)` to check that the DMQ\n     is properly drained.\n  1. call `Hrmp::check_hrmp_watermark(para, commitments.hrmp_watermark)` for each candidate to check rules of processing\n     the HRMP watermark.\n  1. using `Hrmp::check_outbound_hrmp(sender, commitments.horizontal_messages)` ensure that the each candidate sent a\n     valid set of horizontal messages\n  1. create an entry in the `PendingAvailability` map for each backed candidate with a blank `availability_votes`\n     bitfield.\n  1. create a corresponding entry in the `PendingAvailabilityCommitments` with the commitments.\n  1. Return a `Vec<CoreIndex>` of all scheduled cores of the list of passed assignments that a candidate was\n     successfully backed for, sorted ascending by CoreIndex.\n* `enact_candidate(relay_parent_number: BlockNumber, CommittedCandidateReceipt)`:\n  1. If the receipt contains a code upgrade, Call `Paras::schedule_code_upgrade(para_id, code, relay_parent_number,\n     config)`.\n    > TODO: Note that this is safe as long as we never enact candidates where the relay parent is across a session\n    > boundary. In that case, which we should be careful to avoid with contextual execution, the configuration might\n    > have changed and the para may de-sync from the host's understanding of it.\n  1. Reward all backing validators of each candidate, contained within the `backers` field.\n  1. call `receive_upward_messages` for each backed candidate, using the\n     `UpwardMessage`s from the\n     `CandidateCommitments`.\n  1. call `Dmp::prune_dmq` with the para id of the candidate and the candidate's `processed_downward_messages`.\n  1. call `Hrmp::prune_hrmp` with the para id of the candidate and the candidate's `hrmp_watermark`.\n  1. call `Hrmp::queue_outbound_hrmp` with the para id of the candidate and the list of horizontal messages taken from\n     the commitment,\n  1. Call `Paras::note_new_head` using the `HeadData` from the receipt and `relay_parent_number`.\n\n* `collect_pending`:\n\n  ```rust\n    fn collect_pending(f: impl Fn(CoreIndex, BlockNumber) -> bool) -> Vec<CoreIndex> {\n      // sweep through all paras pending availability. if the predicate returns true, when given the core index and\n      // the block number the candidate has been pending availability since, then clean up the corresponding storage for that candidate and the commitments.\n      // return a vector of cleaned-up core IDs.\n    }\n  ```\n* `force_enact(ParaId)`: Forcibly enact the pending candidates of the given paraid as though they had been deemed\n  available by bitfields. Is a no-op if there is no candidate pending availability for this para-id.\n  If there are multiple candidates pending availability for this para-id, it will enact all of\n  them. This should generally not be used but it is useful during execution of Runtime APIs,\n  where the changes to the state are expected to be discarded directly after.\n* `candidate_pending_availability(ParaId) -> Option<CommittedCandidateReceipt>`: returns the `CommittedCandidateReceipt`\n  pending availability for the para provided, if any.\n* `candidates_pending_availability(ParaId) -> Vec<CommittedCandidateReceipt>`: returns the `CommittedCandidateReceipt`s\n  pending availability for the para provided, if any.\n* `pending_availability(ParaId) -> Option<CandidatePendingAvailability>`: returns the metadata around the candidate\n  pending availability for the para, if any.\n* `free_disputed(disputed: Vec<CandidateHash>) -> Vec<CoreIndex>`: Sweeps through all paras pending availability. If\n  the candidate hash is one of the disputed candidates, then clean up the corresponding storage for that candidate and\n  the commitments. Return a vector of cleaned-up core IDs.\n\nThese functions were formerly part of the UMP pallet:\n\n* `check_upward_messages(P: ParaId, Vec<UpwardMessage>)`:\n    1. Checks that the parachain is not currently offboarding and error otherwise.\n    2. Checks that there are at most `config.max_upward_message_num_per_candidate` messages to be enqueued.\n    3. Checks that no message exceeds `config.max_upward_message_size`.\n    4. Checks that the total resulting queue size would not exceed `co`.\n    5. Verify that queuing up the messages could not result in exceeding the queue's footprint according to the config\n    items `config.max_upward_queue_count` and `config.max_upward_queue_size`. The queue's current footprint is provided\n    in `well_known_keys` in order to facilitate oraclisation on to the para.\n\nCandidate Enactment:\n\n* `receive_upward_messages(P: ParaId, Vec<UpwardMessage>)`:\n    1. Process each upward message `M` in order:\n        1. Place in the dispatch queue according to its para ID (or handle it immediately)."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain availability cores\ninput: "
      },
      {
        "role": "assistant",
        "content": "The Scheduler manages resource allocation using the concept of \"Availability Cores\". There will be one availability core\nfor each lease holding parachain, and a fixed number of cores used for multiplexing on-demand parachains. Validators\nwill be partitioned into groups, with the same number of groups as availability cores. Validator groups will be assigned\nto different availability cores over time.\n\nAn availability core can exist in either one of two states at the beginning or end of a block: free or occupied. A free\navailability core can have a lease holding or on-demand parachain assigned to it for the potential to have a backed\ncandidate included. After backing, the core enters the occupied state as the backed candidate is pending availability.\nThere is an important distinction: a core is not considered occupied until it is in charge of a block pending\navailability, although the implementation may treat scheduled cores the same as occupied ones for brevity. A core exits\nthe occupied state when the candidate is no longer pending availability - either on timeout or on availability. A core\nstarting in the occupied state can move to the free state and back to occupied all within a single block, as\navailability bitfields are processed before backed candidates. At the end of the block, there is a possible timeout on\navailability which can move the core back to the free state if occupied.\n\nCores are treated as an ordered list and are typically referred to by their index in that list.\n\n```dot process\ndigraph {\n  label = \"Availability Core State Machine\\n\\n\\n\";\n  labelloc = \"t\";\n\n  { rank=same vg1 vg2 }\n\n  vg1 [label = \"Free\" shape=rectangle]\n  vg2 [label = \"Occupied\" shape=rectangle]\n\n  vg1 -> vg2 [label = \"Assignment & Backing\" ]\n  vg2 -> vg1 [label = \"Availability or Timeout\" ]\n}\ndot process\ndigraph {\n  label = \"Availability Core Transitions within Block\\n\\n\\n\";\n  labelloc = \"t\";\n  splines=\"line\";\n\n  subgraph cluster_left {\n    label = \"\";\n    labelloc = \"t\";\n\n    fr1 [label = \"Free\" shape=rectangle]\n    fr2 [label = \"Free\" shape=rectangle]\n    occ [label = \"Occupied\" shape=rectangle]\n\n    fr1 -> fr2 [label = \"No Backing\"]\n    fr1 -> occ [label = \"Backing\"]\n\n    { rank=same fr2 occ }\n  }\n\n  subgraph cluster_right {\n    label = \"\";\n    labelloc = \"t\";\n\n    occ2 [label = \"Occupied\" shape=rectangle]\n    fr3 [label = \"Free\" shape=rectangle]\n    fr4 [label = \"Free\" shape=rectangle]\n    occ3 [label = \"Occupied\" shape=rectangle]\n    occ4 [label = \"Occupied\" shape=rectangle]\n\n    occ2 -> fr3 [label = \"Availability\"]\n    occ2 -> occ3 [label = \"No availability\"]\n    fr3 -> fr4 [label = \"No backing\"]\n    fr3 -> occ4 [label = \"Backing\"]\n    occ3 -> occ4 [label = \"(no change)\"]\n    occ3 -> fr3 [label = \"Availability Timeout\"]\n\n    { rank=same; fr3[group=g1]; occ3[group=g2] }\n    { rank=same; fr4[group=g1]; occ4[group=g2] }\n  }\n}\n```"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain routines\ninput: "
      },
      {
        "role": "assistant",
        "content": "- `add_parathread_claim(ParathreadClaim)`: Add a parathread (on-demand parachain) claim to the queue.\n  - Fails if any on-demand claim on the same parachain is currently indexed.\n  - Fails if the queue length is >= `config.scheduling_lookahead * config.parathread_cores`.\n  - The core used for the on-demand claim is the `next_core` field of the `ParathreadQueue` (on-demand queue) and adding\n    `paras::Parachains::<T>::get().len()` to it.\n  - `next_core` is then updated by adding 1 and taking it modulo `config.parathread_cores`.\n  - The claim is then added to the claim index.\n- `free_cores(Vec<(CoreIndex, FreedReason)>)`: indicate previously-occupied cores which are to be considered returned\n  and why they are being returned.\n  - All freed lease holding parachain cores should be assigned to their respective parachain\n  - All freed on-demand parachain cores whose reason for freeing was `FreedReason::Concluded` should have the claim\n    removed from the claim index.\n  - All freed on-demand cores whose reason for freeing was `FreedReason::TimedOut` should have the claim added to the\n    parathread queue (on-demand queue) again without retries incremented\n  - All freed on-demand cores should take the next on-demand parachain entry from the queue.\n- `schedule(Vec<(CoreIndex, FreedReason)>, now: BlockNumber)`: schedule new core assignments, with a parameter\n  indicating previously-occupied cores which are to be considered returned and why they are being returned.\n  - Invoke `free_cores(freed_cores)`\n  - The i'th validator group will be assigned to the `(i+k)%n`'th core at any point in time, where `k` is the number of\n    rotations that have occurred in the session, and `n` is the total number of cores. This makes upcoming rotations\n    within the same session predictable. Rotations are based off of `now`.\n- `scheduled() -> Vec<CoreAssignment>`: Get currently scheduled core assignments.\n- `occupied(Vec<CoreIndex>)`. Note that the given cores have become occupied.\n  - Behavior undefined if any given cores were not scheduled.\n  - Behavior undefined if the given cores are not sorted ascending by core index\n  - This clears them from `Scheduled` and marks each corresponding `core` in the `AvailabilityCores` as occupied.\n  - Since both the availability cores and the newly-occupied cores lists are sorted ascending, this method can be\n    implemented efficiently.\n- `group_validators(GroupIndex) -> Option<Vec<ValidatorIndex>>`: return all validators in a given group, if the group\n  index is valid for this session.\n- `availability_timeout_predicate() -> Option<impl Fn(CoreIndex, BlockNumber) -> bool>`: returns an optional predicate\n  that should be used for timing out occupied cores. if `None`, no timing-out should be done. The predicate accepts the\n  index of the core, and the block number since which it has been occupied. The predicate should be implemented based on\n  the time since the last validator group rotation, and the respective parachain timeouts, i.e. only within\n  `max(config.chain_availability_period, config.thread_availability_period)` of the last rotation would this return\n  `Some`.\n- `group_rotation_info(now: BlockNumber) -> GroupRotationInfo`: Returns a helper for determining group rotation.\n- `next_up_on_available(CoreIndex) -> Option<ScheduledCore>`: Return the next thing that will be scheduled on this core\n  assuming it is currently occupied and the candidate occupying it became available. Returns in `ScheduledCore` format\n  (todo: link to Runtime APIs page; linkcheck doesn't allow this right now). For lease holding parachains, this is\n  always the ID of the parachain and no specified collator. For on-demand parachains, this is based on the next item in\n  the `ParathreadQueue` (on-demand queue) assigned to that core, and is `None` if there isn't one.\n- `next_up_on_time_out(CoreIndex) -> Option<ScheduledCore>`: Return the next thing that will be scheduled on this core\n  assuming it is currently occupied and the candidate occupying it timed out. Returns in `ScheduledCore` format (todo:\n  link to Runtime APIs page; linkcheck doesn't allow this right now). For parachains, this is always the ID of the\n  parachain and no specified collator. For on-demand parachains, this is based on the next item in the `ParathreadQueue`\n  (on-demand queue) assigned to that core, or if there isn't one, the claim that is currently occupying the core.\n  Otherwise `None`.\n- `clear()`:\n  - Free all scheduled cores and return on-demand claims to queue, with retries incremented. Skip on-demand parachains\n    which no longer exist under paras."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain disputes filtering\ninput: "
      },
      {
        "role": "assistant",
        "content": "All disputes delivered to the runtime by the client are filtered before the actual import. In this context actual import\nmeans persisted in the runtime storage. The filtering has got two purposes:\n* Limit the amount of data saved onchain.\n* Prevent persisting malicious dispute data onchain.\n\n*Implementation note*: Filtering is performed in function `filter_dispute_data` from `Disputes` pallet.\n\nThe filtering is performed on the whole statement set which is about to be imported onchain. The following filters are\napplied:\n1. Remove ancient disputes - if a dispute is concluded before the block number indicated in `OLDEST_ACCEPTED` parameter\n   it is removed from the set. `OLDEST_ACCEPTED` is a runtime configuration option. *Implementation note*:\n   `dispute_post_conclusion_acceptance_period` from `HostConfiguration` is used in the current Polkadot/Kusama\n   implementation.\n2. Remove votes from unknown validators. If there is a vote from a validator which wasn't an authority in the session\n   where the dispute was raised - they are removed. Please note that this step removes only single votes instead of\n   removing the whole dispute.\n3. Remove one sided disputes - if a dispute doesn't contain two opposing votes it is not imported onchain. This serves\n   as a measure not to import one sided disputes. A dispute is raised only if there are two opposing votes so if the\n   client is not sending them the dispute is a potential spam.\n4. Remove unconfirmed disputes - if a dispute contains less votes than the byzantine threshold it is removed. This is\n   also a spam precaution. A legitimate client will send only confirmed disputes to the runtime."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain entry-points\ninput: "
      },
      {
        "role": "assistant",
        "content": "The following entry-points are meant to be used for HRMP channel management.\n\nThose entry-points are meant to be called from a parachain. `origin` is defined as the `ParaId` of the parachain\nexecuted the message.\n\n* `hrmp_init_open_channel(recipient, proposed_max_capacity, proposed_max_message_size)`:\n    1. Check that the `origin` is not `recipient`.\n    1. Check that `proposed_max_capacity` is less or equal to `config.hrmp_channel_max_capacity` and greater than zero.\n    1. Check that `proposed_max_message_size` is less or equal to `config.hrmp_channel_max_message_size` and greater\n       than zero.\n    1. Check that `recipient` is a valid para.\n    1. Check that there is no existing channel for `(origin, recipient)` in `HrmpChannels`.\n    1. Check that there is no existing open channel request (`origin`, `recipient`) in `HrmpOpenChannelRequests`.\n    1. Check that the sum of the number of already opened HRMP channels by the `origin` (the size of the set found\n    `HrmpEgressChannelsIndex` for `origin`) and the number of open requests by the `origin` (the value from\n    `HrmpOpenChannelRequestCount` for `origin`) doesn't exceed the limit of channels\n    (`config.hrmp_max_parachain_outbound_channels` or `config.hrmp_max_parathread_outbound_channels`) minus 1.\n    1. Check that `origin`'s balance is more or equal to `config.hrmp_sender_deposit`\n    1. Reserve the deposit for the `origin` according to `config.hrmp_sender_deposit`\n    1. Increase `HrmpOpenChannelRequestCount` by 1 for `origin`.\n    1. Append `(origin, recipient)` to `HrmpOpenChannelRequestsList`.\n    1. Add a new entry to `HrmpOpenChannelRequests` for `(origin, recipient)`\n        1. Set `sender_deposit` to `config.hrmp_sender_deposit`\n        1. Set `max_capacity` to `proposed_max_capacity`\n        1. Set `max_message_size` to `proposed_max_message_size`\n        1. Set `max_total_size` to `config.hrmp_channel_max_total_size`\n    1. Send a downward message to `recipient` notifying about an inbound HRMP channel request.\n        * The DM is sent using `queue_downward_message`.\n        * The DM is represented by the `HrmpNewChannelOpenRequest`  XCM message.\n            * `sender` is set to `origin`,\n            * `max_message_size` is set to `proposed_max_message_size`,\n            * `max_capacity` is set to `proposed_max_capacity`.\n* `hrmp_accept_open_channel(sender)`:\n    1. Check that there is an existing request between (`sender`, `origin`) in `HrmpOpenChannelRequests`\n        1. Check that it is not confirmed.\n    1. Check that the sum of the number of inbound HRMP channels opened to `origin` (the size of the set found in\n    `HrmpIngressChannelsIndex` for `origin`) and the number of accepted open requests by the `origin` (the value from\n    `HrmpAcceptedChannelRequestCount` for `origin`) doesn't exceed the limit of channels\n    (`config.hrmp_max_parachain_inbound_channels` or `config.hrmp_max_parathread_inbound_channels`) minus 1.\n    1. Check that `origin`'s balance is more or equal to `config.hrmp_recipient_deposit`.\n    1. Reserve the deposit for the `origin` according to `config.hrmp_recipient_deposit`\n    1. For the request in `HrmpOpenChannelRequests` identified by `(sender, P)`, set `confirmed` flag to `true`.\n    1. Increase `HrmpAcceptedChannelRequestCount` by 1 for `origin`.\n    1. Send a downward message to `sender` notifying that the channel request was accepted.\n        * The DM is sent using `queue_downward_message`.\n        * The DM is represented by the `HrmpChannelAccepted` XCM message.\n            * `recipient` is set to `origin`.\n* `hrmp_cancel_open_request(ch)`:\n    1. Check that `origin` is either `ch.sender` or `ch.recipient`\n    1. Check that the open channel request `ch` exists.\n    1. Check that the open channel request for `ch` is not confirmed.\n    1. Remove `ch` from `HrmpOpenChannelRequests` and `HrmpOpenChannelRequestsList`\n    1. Decrement `HrmpAcceptedChannelRequestCount` for `ch.recipient` by 1.\n    1. Unreserve the deposit of `ch.sender`.\n* `hrmp_close_channel(ch)`:\n    1. Check that `origin` is either `ch.sender` or `ch.recipient`\n    1. Check that `HrmpChannels` for `ch` exists.\n    1. Check that `ch` is not in the `HrmpCloseChannelRequests` set.\n    1. If not already there, insert a new entry `Some(())` to `HrmpCloseChannelRequests` for `ch` and append `ch` to\n    `HrmpCloseChannelRequestsList`.\n    1. Send a downward message to the opposite party notifying about the channel closing.\n        * The DM is sent using `queue_downward_message`.\n        * The DM is represented by the `HrmpChannelClosing` XCM message with:\n            * `initiator` is set to `origin`,\n            * `sender` is set to `ch.sender`,\n            * `recipient` is set to `ch.recipient`.\n        * The opposite party is `ch.sender` if `origin` is `ch.recipient` and `ch.recipient` if `origin` is `ch.sender`."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain subsystem message traffic\ninput: "
      },
      {
        "role": "assistant",
        "content": "Which subsystems send messages to which other subsystems.\n\n**Note**: This diagram omits the overseer for simplicity. In fact, all messages\nare relayed via the overseer.\n\n**Note**: Messages with a filled diamond arrowhead (\"\u2666\") include a\n`oneshot::Sender` which communicates a response from the recipient. Messages\nwith an open triangle arrowhead (\"\u0394\") do not include a return sender.\n\n```dot process\ndigraph {\n    rankdir=LR;\n    node [shape = oval];\n    concentrate = true;\n\n    av_store    [label = \"Availability Store\"]\n    avail_dist  [label = \"Availability Distribution\"]\n    avail_rcov  [label = \"Availability Recovery\"]\n    bitf_dist   [label = \"Bitfield Distribution\"]\n    bitf_sign   [label = \"Bitfield Signing\"]\n    cand_back   [label = \"Candidate Backing\"]\n    cand_sel    [label = \"Candidate Selection\"]\n    cand_val    [label = \"Candidate Validation\"]\n    chn_api     [label = \"Chain API\"]\n    coll_gen    [label = \"Collation Generation\"]\n    coll_prot   [label = \"Collator Protocol\"]\n    net_brdg    [label = \"Network Bridge\"]\n    pov_dist    [label = \"PoV Distribution\"]\n    provisioner [label = \"Provisioner\"]\n    runt_api    [label = \"Runtime API\"]\n    stmt_dist   [label = \"Statement Distribution\"]\n\n    av_store    -> runt_api     [arrowhead = \"diamond\", label = \"Request::CandidateEvents\"]\n    av_store    -> chn_api      [arrowhead = \"diamond\", label = \"BlockNumber\"]\n    av_store    -> chn_api      [arrowhead = \"diamond\", label = \"BlockHeader\"]\n    av_store    -> runt_api     [arrowhead = \"diamond\", label = \"Request::Validators\"]\n    av_store    -> chn_api      [arrowhead = \"diamond\", label = \"FinalizedBlockHash\"]\n\n    avail_dist  -> net_brdg     [arrowhead = \"onormal\", label = \"Request::SendValidationMessages\"]\n    avail_dist  -> runt_api     [arrowhead = \"diamond\", label = \"Request::AvailabilityCores\"]\n    avail_dist  -> net_brdg     [arrowhead = \"onormal\", label = \"ReportPeer\"]\n    avail_dist  -> av_store     [arrowhead = \"diamond\", label = \"QueryDataAvailability\"]\n    avail_dist  -> av_store     [arrowhead = \"diamond\", label = \"QueryChunk\"]\n    avail_dist  -> av_store     [arrowhead = \"diamond\", label = \"StoreChunk\"]\n    avail_dist  -> runt_api     [arrowhead = \"diamond\", label = \"Request::Validators\"]\n    avail_dist  -> chn_api      [arrowhead = \"diamond\", label = \"Ancestors\"]\n    avail_dist  -> runt_api     [arrowhead = \"diamond\", label = \"Request::SessionIndexForChild\"]\n\n    avail_rcov  -> net_brdg     [arrowhead = \"onormal\", label = \"ReportPeer\"]\n    avail_rcov  -> av_store     [arrowhead = \"diamond\", label = \"QueryChunk\"]\n    avail_rcov  -> net_brdg     [arrowhead = \"diamond\", label = \"ConnectToValidators\"]\n    avail_rcov  -> net_brdg     [arrowhead = \"onormal\", label = \"SendValidationMessage::Chunk\"]\n    avail_rcov  -> net_brdg     [arrowhead = \"onormal\", label = \"SendValidationMessage::RequestChunk\"]\n\n    bitf_dist   -> net_brdg     [arrowhead = \"onormal\", label = \"ReportPeer\"]\n    bitf_dist   -> provisioner  [arrowhead = \"onormal\", label = \"ProvisionableData::Bitfield\"]\n    bitf_dist   -> net_brdg     [arrowhead = \"onormal\", label = \"SendValidationMessage\"]\n    bitf_dist   -> net_brdg     [arrowhead = \"onormal\", label = \"SendValidationMessage\"]\n    bitf_dist   -> runt_api     [arrowhead = \"diamond\", label = \"Request::Validatiors\"]\n    bitf_dist   -> runt_api     [arrowhead = \"diamond\", label = \"Request::SessionIndexForChild\"]\n\n    bitf_sign   -> av_store     [arrowhead = \"diamond\", label = \"QueryChunkAvailability\"]\n    bitf_sign   -> runt_api     [arrowhead = \"diamond\", label = \"Request::AvailabilityCores\"]\n    bitf_sign   -> bitf_dist    [arrowhead = \"onormal\", label = \"DistributeBitfield\"]\n\n    cand_back   -> av_store     [arrowhead = \"diamond\", label = \"StoreAvailableData\"]\n    cand_back   -> pov_dist     [arrowhead = \"diamond\", label = \"FetchPoV\"]\n    cand_back   -> cand_val     [arrowhead = \"diamond\", label = \"ValidateFromChainState\"]\n    cand_back   -> cand_sel     [arrowhead = \"onormal\", label = \"Invalid\"]\n    cand_back   -> provisioner  [arrowhead = \"onormal\", label = \"ProvisionableData::MisbehaviorReport\"]\n    cand_back   -> provisioner  [arrowhead = \"onormal\", label = \"ProvisionableData::BackedCandidate\"]\n    cand_back   -> pov_dist     [arrowhead = \"onormal\", label = \"DistributePoV\"]\n    cand_back   -> stmt_dist    [arrowhead = \"onormal\", label = \"Share\"]\n\n    cand_sel    -> coll_prot    [arrowhead = \"diamond\", label = \"FetchCollation\"]\n    cand_sel    -> cand_back    [arrowhead = \"onormal\", label = \"Second\"]\n\n    cand_val    -> runt_api     [arrowhead = \"diamond\", label = \"Request::PersistedValidationData\"]\n    cand_val    -> runt_api     [arrowhead = \"diamond\", label = \"Request::ValidationCode\"]\n    cand_val    -> runt_api     [arrowhead = \"diamond\", label = \"Request::CheckValidationOutputs\"]\n\n    coll_gen    -> coll_prot    [arrowhead = \"onormal\", label = \"DistributeCollation\"]\n\n    coll_prot   -> net_brdg     [arrowhead = \"onormal\", label = \"ReportPeer\"]\n    coll_prot   -> net_brdg     [arrowhead = \"onormal\", label = \"Declare\"]\n    coll_prot   -> net_brdg     [arrowhead = \"onormal\", label = \"AdvertiseCollation\"]\n    coll_prot   -> net_brdg     [arrowhead = \"onormal\", label = \"Collation\"]\n    coll_prot   -> net_brdg     [arrowhead = \"onormal\", label = \"RequestCollation\"]\n    coll_prot   -> cand_sel     [arrowhead = \"onormal\", label = \"Collation\"]\n\n    net_brdg    -> avail_dist   [arrowhead = \"onormal\", label = \"NetworkBridgeUpdate\"]\n    net_brdg    -> bitf_dist    [arrowhead = \"onormal\", label = \"NetworkBridgeUpdate\"]\n    net_brdg    -> pov_dist     [arrowhead = \"onormal\", label = \"NetworkBridgeUpdate\"]\n    net_brdg    -> stmt_dist    [arrowhead = \"onormal\", label = \"NetworkBridgeUpdate\"]\n    net_brdg    -> coll_prot    [arrowhead = \"onormal\", label = \"NetworkBridgeUpdate\"]\n\n    pov_dist    -> net_brdg     [arrowhead = \"onormal\", label = \"SendValidationMessage\"]\n    pov_dist    -> net_brdg     [arrowhead = \"onormal\", label = \"ReportPeer\"]\n\n    provisioner -> cand_back    [arrowhead = \"diamond\", label = \"GetBackedCandidates\"]\n    provisioner -> chn_api      [arrowhead = \"diamond\", label = \"BlockNumber\"]\n\n    stmt_dist   -> net_brdg     [arrowhead = \"onormal\", label = \"SendValidationMessage\"]\n    stmt_dist   -> net_brdg     [arrowhead = \"onormal\", label = \"ReportPeer\"]\n    stmt_dist   -> cand_back    [arrowhead = \"onormal\", label = \"Statement\"]\n    stmt_dist   -> runt_api     [arrowhead = \"onormal\", label = \"Request::Validators\"]\n    stmt_dist   -> runt_api     [arrowhead = \"onormal\", label = \"Request::SessionIndexForChild\"]\n}\n```"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain the path to inclusion (node side)\ninput: "
      },
      {
        "role": "assistant",
        "content": "Let's contextualize that diagram a bit by following a parachain block from its\ncreation through finalization. Parachains can use completely arbitrary processes\nto generate blocks. The relay chain doesn't know or care about the details; each\nparachain just needs to provide a collator.\n\n**Note**: Inter-subsystem communications are relayed via the overseer, but that\nstep is omitted here for brevity.\n\n**Note**: Dashed lines indicate a request/response cycle, where the response is\ncommunicated asynchronously via a oneshot channel. Adjacent dashed lines may be\nprocessed in parallel.\n\nsequenceDiagram\n    participant Overseer\n    participant CollationGeneration\n    participant RuntimeApi\n    participant CollatorProtocol\n\n    Overseer ->> CollationGeneration: ActiveLeavesUpdate\n    loop for each activated head\n        CollationGeneration -->> RuntimeApi: Request availability cores\n        CollationGeneration -->> RuntimeApi: Request validators\n\n        Note over CollationGeneration: Determine an appropriate ScheduledCore <br/>and OccupiedCoreAssumption\n\n        CollationGeneration -->> RuntimeApi: Request full validation data\n\n        Note over CollationGeneration: Build the collation\n\n        CollationGeneration ->> CollatorProtocol: DistributeCollation\n    end\n\nThe `DistributeCollation` messages that `CollationGeneration` sends to the\n`CollatorProtocol` contains two items: a `CandidateReceipt` and `PoV`. The\n`CollatorProtocol` is then responsible for distributing that collation to\ninterested validators. However, not all potential collations are of interest.\nThe `CandidateSelection` subsystem is responsible for determining which\ncollations are interesting, before `CollatorProtocol` actually fetches the\ncollation.\n\nsequenceDiagram\n    participant CollationGeneration\n    participant CS as CollatorProtocol::CollatorSide\n    participant NB as NetworkBridge\n    participant VS as CollatorProtocol::ValidatorSide\n    participant CandidateSelection\n\n    CollationGeneration ->> CS: DistributeCollation\n    CS -->> NB: ConnectToValidators\n\n    Note over CS,NB: This connects to multiple validators.\n\n    CS ->> NB: Declare\n    NB ->> VS: Declare\n\n    Note over CS: Ensure that the connected validator is among<br/>the para's validator set. Otherwise, skip it.\n\n    CS ->> NB: AdvertiseCollation\n    NB ->> VS: AdvertiseCollation\n\n    VS ->> CandidateSelection: Collation\n\n    Note over CandidateSelection: Lots of other machinery in play here,<br/>but there are only two outcomes from the<br/>perspective of the `CollatorProtocol`:\n\n    alt happy path\n        CandidateSelection -->> VS: FetchCollation\n        Activate VS\n        VS ->> NB: RequestCollation\n        NB ->> CS: RequestCollation\n        CS ->> NB: Collation\n        NB ->> VS: Collation\n        Deactivate VS\n\n    else CandidateSelection already selected a different candidate\n        Note over CandidateSelection: silently drop\n    end\n\nAssuming we hit the happy path, flow continues with `CandidateSelection`\nreceiving a `(candidate_receipt, pov)` as the return value from its\n`FetchCollation` request. The only time `CandidateSelection` actively requests a\ncollation is when it hasn't yet seconded one for some `relay_parent`, and is\nready to second.\n\nsequenceDiagram\n    participant CS as CandidateSelection\n    participant CB as CandidateBacking\n    participant CV as CandidateValidation\n    participant PV as Provisioner\n    participant SD as StatementDistribution\n    participant PD as PoVDistribution\n\n    CS ->> CB: Second\n    % fn validate_and_make_available\n    CB -->> CV: ValidateFromChainState\n\n    Note over CB,CV: There's some complication in the source, as<br/>candidates are actually validated in a separate task.\n\n    alt valid\n        Note over CB: This is where we transform the CandidateReceipt into a CommittedCandidateReceipt\n        % CandidateBackingJob::sign_import_and_distribute_statement\n        % CandidateBackingJob::import_statement\n        CB ->> PV: ProvisionableData::BackedCandidate\n        % CandidateBackingJob::issue_new_misbehaviors\n        opt if there is misbehavior to report\n            CB ->> PV: ProvisionableData::MisbehaviorReport\n        end\n        % CandidateBackingJob::distribute_signed_statement\n        CB ->> SD: Share\n        % CandidateBackingJob::distribute_pov\n        CB ->> PD: DistributePoV\n    else invalid\n        CB ->> CS: Invalid\n    end\n\nAt this point, you'll see that control flows in two directions: to\n`StatementDistribution` to distribute the `SignedStatement`, and to\n`PoVDistribution` to distribute the `PoV`. However, that's largely a mirage:\nwhile the initial implementation distributes `PoV`s by gossip, that's\ninefficient, and will be replaced with a system which fetches `PoV`s only when\nactually necessary.\n\n> TODO: figure out more precisely the current status and plans; write them up\n\nTherefore, we'll follow the `SignedStatement`. The `StatementDistribution`\nsubsystem is largely concerned with implementing a gossip protocol:\n\nsequenceDiagram\n    participant SD as StatementDistribution\n    participant NB as NetworkBridge\n\n    alt On receipt of a<br/>SignedStatement from CandidateBacking\n        % fn circulate_statement_and_dependents\n        SD ->> NB: SendValidationMessage\n\n        Note right of NB: Bridge sends validation message to all appropriate peers\n    else On receipt of peer validation message\n        NB ->> SD: NetworkBridgeUpdate\n\n        % fn handle_incoming_message\n        alt if we aren't already aware of the relay parent for this statement\n            SD ->> NB: ReportPeer\n        end\n\n        % fn circulate_statement\n        opt if we know of peers who haven't seen this message, gossip it\n            SD ->> NB: SendValidationMessage\n        end\n    end\n\nBut who are these `Listener`s who've asked to be notified about incoming\n`SignedStatement`s? Nobody, as yet.\n\nLet's pick back up with the PoV Distribution subsystem.\n\nsequenceDiagram\n    participant CB as CandidateBacking\n    participant PD as PoVDistribution\n    participant Listener\n    participant NB as NetworkBridge\n\n    CB ->> PD: DistributePoV\n\n    Note over PD,Listener: Various subsystems can register listeners for when PoVs arrive\n\n    loop for each Listener\n        PD ->> Listener: Arc<PoV>\n    end\n\n    Note over PD: Gossip to connected peers\n\n    PD ->> NB: SendPoV\n\n    Note over PD,NB: On receipt of a network PoV, PovDistribution forwards it to each Listener.<br/>It also penalizes bad gossipers.\n\nUnlike in the case of `StatementDistribution`, there is another subsystem which\nin various circumstances already registers a listener to be notified when a new\n`PoV` arrives: `CandidateBacking`. Note that this is the second time that\n`CandidateBacking` has gotten involved. The first instance was from the\nperspective of the validator choosing to second a candidate via its\n`CandidateSelection` subsystem. This time, it's from the perspective of some\nother validator, being informed that this foreign `PoV` has been received.\n\nsequenceDiagram\n    participant SD as StatementDistribution\n    participant CB as CandidateBacking\n    participant PD as PoVDistribution\n    participant AS as AvailabilityStore\n\n    SD ->> CB: Statement\n    % CB::maybe_validate_and_import => CB::kick_off_validation_work\n    CB -->> PD: FetchPoV\n    Note over CB,PD: This call creates the Listener from the previous diagram\n\n    CB ->> AS: StoreAvailableData\n\nAt this point, things have gone a bit nonlinear. Let's pick up the thread again\nwith `BitfieldSigning`. As the `Overseer` activates each relay parent, it starts\na `BitfieldSigningJob` which operates on an extremely simple metric: after\ncreation, it immediately goes to sleep for 1.5 seconds. On waking, it records\nthe state of the world pertaining to availability at that moment.\n\nsequenceDiagram\n    participant OS as Overseer\n    participant BS as BitfieldSigning\n    participant RA as RuntimeApi\n    participant AS as AvailabilityStore\n    participant BD as BitfieldDistribution\n\n    OS ->> BS: ActiveLeavesUpdate\n    loop for each activated relay parent\n        Note over BS: Wait 1.5 seconds\n        BS -->> RA: Request::AvailabilityCores\n        loop for each availability core\n            BS -->> AS: QueryChunkAvailability\n        end\n        BS ->> BD: DistributeBitfield\n    end\n\n`BitfieldDistribution` is, like the other `*Distribution` subsystems, primarily\ninterested in implementing a peer-to-peer gossip network propagating its\nparticular messages. However, it also serves as an essential relay passing the\nmessage along.\n\nsequenceDiagram\n    participant BS as BitfieldSigning\n    participant BD as BitfieldDistribution\n    participant NB as NetworkBridge\n    participant PV as Provisioner\n\n    BS ->> BD: DistributeBitfield\n    BD ->> PV: ProvisionableData::Bitfield\n    BD ->> NB: SendValidationMessage::BitfieldDistribution::Bitfield\n\nWe've now seen the message flow to the `Provisioner`: both `CandidateBacking`\nand `BitfieldDistribution` contribute provisionable data. Now, let's look at\nthat subsystem.\n\nMuch like the `BitfieldSigning` subsystem, the `Provisioner` creates a new job\nfor each newly-activated leaf, and starts a timer. Unlike `BitfieldSigning`, we\nwon't depict that part of the process, because the `Provisioner` also has other\nthings going on.\n\nsequenceDiagram\n    participant A as Arbitrary\n    participant PV as Provisioner\n    participant CB as CandidateBacking\n    participant BD as BitfieldDistribution\n    participant RA as RuntimeApi\n    participant PI as ParachainsInherentDataProvider\n\n    alt receive provisionable data\n        alt\n            CB ->> PV: ProvisionableData\n        else\n            BD ->> PV: ProvisionableData\n        end\n\n        loop over stored Senders\n            PV ->> A: ProvisionableData\n        end\n\n        Note over PV: store bitfields and backed candidates\n    else receive request for inherent data\n        PI ->> PV: RequestInherentData\n        alt we have already constructed the inherent data\n            PV ->> PI: send the inherent data\n        else we have not yet constructed the inherent data\n            Note over PV,PI: Store the return sender without sending immediately\n        end\n    else timer times out\n        note over PV: Waited 2 seconds\n        PV -->> RA: RuntimeApiRequest::AvailabilityCores\n        Note over PV: construct and store the inherent data\n        loop over stored inherent data requests\n            PV ->> PI: (SignedAvailabilityBitfields, BackedCandidates)\n        end\n    end\n\nIn principle, any arbitrary subsystem could send a `RequestInherentData` to the\n`Provisioner`. In practice, only the `ParachainsInherentDataProvider` does so.\n\nThe tuple `(SignedAvailabilityBitfields, BackedCandidates, ParentHeader)` is\ninjected by the `ParachainsInherentDataProvider` into the inherent data. From\nthat point on, control passes from the node to the runtime."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain ensuring recording\ninput: "
      },
      {
        "role": "assistant",
        "content": "Only votes recorded by the dispute coordinator will be considered for slashing.\n\nWhile there is no need to record approval votes in the dispute coordinator preemptively, we make some effort to have any\nin approval-voting received approval votes recorded when a dispute actually happens:\n\nThis is not required for concluding the dispute, as nodes send their own vote anyway (either explicit valid or their\nexisting approval-vote). What nodes can do though, is participating in approval-voting, casting a vote, but later when a\ndispute is raised reconsider their vote and send an explicit invalid vote. If they managed to only have that one\nrecorded, then they could avoid a slash.\n\nThis is not a problem for our basic security assumptions: The backers are the ones to be supposed to have skin in the\ngame, so we are not too worried about colluding approval voters getting away slash free as the gambler's ruin property is\nmaintained anyway. There is however a separate problem, from colluding approval-voters, that is \"lazy\" approval voters.\nIf it were easy and reliable for approval-voters to reconsider their vote, in case of an actual dispute, then they don't\nhave a direct incentive (apart from playing a part in securing the network) to properly run the validation function at\nall - they could just always vote \"valid\" totally risk free. (While they would always risk a slash by voting invalid.)\n\nSo we do want to fetch approval votes from approval-voting. Importing votes is most efficient when batched. At the same\ntime approval voting and disputes are running concurrently so approval votes are expected to trickle in still, when a\ndispute is already ongoing.\n\nHence, we have the following requirements for importing approval votes:\n\n1. Only import them when there is a dispute, because otherwise we are wasting lots of resources _always_ for the\n   exceptional case of a dispute.\n2. Import votes batched when possible, to avoid quadratic import complexity.\n3. Take into account that approval voting is still ongoing, while a dispute is already running.\n\nWith a design where approval voting sends votes to the dispute-coordinator by itself, we would need to make approval\nvoting aware of ongoing disputes and once it is aware it could start sending all already existing votes batched and\ntrickling in votes as they come. The problem with this is, that it adds some unnecessary complexity to approval-voting\nand also we might still import most of the votes unbatched one-by-one, depending on what point in time the dispute was\nraised.\n\nInstead of the dispute coordinator informing approval-voting of an ongoing dispute for it to begin forwarding votes to\nthe dispute coordinator, it makes more sense for the dispute-coordinator to just ask approval-voting for votes of\ncandidates in dispute. This way, the dispute coordinator can also pick the best time for maximizing the number of votes\nin the batch.\n\nNow the question remains, when should the dispute coordinator ask approval-voting for votes?\n\nIn fact for slashing it is only relevant to have them once the dispute concluded, so we can query approval voting the\nmoment the dispute concludes! Two concerns that come to mind, are easily addressed:\n\n1. Timing: We would like to rely as little as possible on implementation details of approval voting. In particular, if\n   the dispute is ongoing for a long time, do we have any guarantees that approval votes are kept around long enough by\n   approval voting? Will approval votes still be present by the time the dispute concludes in all cases? The answer is\n   nuanced, but in general we cannot rely on it. The problem is first, that finalization and approval-voting is an\n   off-chain process so there is no global consensus: As soon as at least f+1 honest (f=n/3, where n is the number of\n   validators/nodes) nodes have seen the dispute conclude, finalization will take place and approval votes will be\n   cleared. This would still be fine, if we had some guarantees that those honest nodes will be able to include those\n   votes in a block. This guarantee does not exist unfortunately, we will discuss the problem and solutions in more\n   detail [below][#Ensuring Chain Import].\n\n   The second problem is that approval-voting will abandon votes as soon as a chain can no longer be finalized (some\n   other/better fork already has been). This second problem can somehow be mitigated by also importing votes as soon as\n   a dispute is detected, but not fully resolved. It is still inherently racy. The good thing is, this should be good\n   enough: We are worried about lazy approval checkers, the system does not need to be perfect. It should be enough if\n   there is some risk of getting caught.\n2. We are not worried about the dispute not concluding, as nodes will always send their own vote, regardless of it being\n   an explicit or an already existing approval-vote.\n\nConclusion: As long as we make sure, if our own approval vote gets imported (which would prevent dispute participation)\nto also distribute it via dispute-distribution, disputes can conclude. To mitigate raciness with approval-voting\ndeleting votes we will import approval votes twice during a dispute: Once when it is raised, to make as sure as possible\nto see approval votes also for abandoned forks and second when the dispute concludes, to maximize the amount of\npotentially malicious approval votes to be recorded. The raciness obviously is not fully resolved by this, but this is\nfine as argued above.\n\nEnsuring vote import on chain is covered in the next section.\n\nWhat we don't care about is that honest approval-voters will likely validate twice, once in approval voting and once via\ndispute-participation. Avoiding that does not really seem worthwhile though, as disputes are for one exceptional, so a\nlittle wasted effort won't affect everyday performance - second, even with eager importing of approval votes, those\ndoubled work is still present as disputes and approvals are racing. Every time participation is faster than approval, a\nnode would do double work."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain spam considerations\ninput: "
      },
      {
        "role": "assistant",
        "content": "In Polkadot's security model, it is important that attempts to attack the system result in a slash of the offenders.\nTherefore we need to make sure that this slash is actually happening. Attackers could try to prevent the slashing from\ntaking place, by overwhelming validators with disputes in such a way that no single dispute ever concludes, because\nnodes are busy processing newly incoming ones. Other attacks are imaginable as well, like raising disputes for\ncandidates that don't exist, just filling up everyone's disk slowly or worse making nodes try to participate, which will\nresult in lots of network requests for recovering availability.\n\nThe last point brings up a significant consideration in general: Disputes are about escalation: Every node will suddenly\nwant to check, instead of only a few. A single message will trigger the whole network to start significant amount of\nwork and will cause lots of network traffic and messages. Hence the dispute system is very susceptible to being a brutal\namplifier for DoS attacks, resulting in DoS attacks to become very easy and cheap, if we are not careful.\n\nOne counter measure we are taking is making raising of disputes a costly thing: If you raise a dispute, because you\nclaim a candidate is invalid, although it is in fact valid - you will get slashed, hence you pay for consuming those\nresources. The issue is: This only works if the dispute concerns a candidate that actually exists!\n\nIf a node raises a dispute for a candidate that never got included (became available) on any chain, then the dispute can\nnever conclude, hence nobody gets slashed. It makes sense to point out that this is less bad than it might sound at\nfirst, as trying to participate in a dispute for a non existing candidate is \"relatively\" cheap. Each node will send out\na few hundred tiny request messages for availability chunks, which all will end up in a tiny response \"NoSuchChunk\" and\nthen no participation will actually happen as there is nothing to participate. Malicious nodes could provide chunks,\nwhich would make things more costly, but at the full expense of the attackers bandwidth - no amplification here. I am\nbringing that up for completeness only: Triggering a thousand nodes to send out a thousand tiny network messages by just\nsending out a single garbage message, is still a significant amplification and is nothing to ignore - this could\nabsolutely be used to cause harm!"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain reception\ninput: "
      },
      {
        "role": "assistant",
        "content": "As we shall see the receiving side is mostly about handling spam and ensuring\nthe dispute-coordinator learns about disputes as fast as possible.\n\nGoals for the receiving side:\n\n1. Get new disputes to the dispute-coordinator as fast as possible, so\n  prioritization can happen properly.\n2. Batch votes per disputes as much as possible for good import performance.\n3. Prevent malicious nodes exhausting node resources by sending lots of messages.\n4. Prevent malicious nodes from sending so many messages/(fake) disputes,\n  preventing us from concluding good ones.\n5. Limit ability of malicious nodes of delaying the vote import due to batching\n   logic.\n\nGoal 1 and 2 seem to be conflicting, but an easy compromise is possible: When\nlearning about a new dispute, we will import the vote immediately, making the\ndispute coordinator aware and also getting immediate feedback on the validity.\nThen if valid we can batch further incoming votes, with less time constraints as\nthe dispute-coordinator already knows about the dispute.\n\nGoal 3 and 4 are obviously very related and both can easily be solved via rate\nlimiting as we shall see below. Rate limits should already be implemented at the\nSubstrate level, but are not\nat the time of writing. But even if they were, the enforced Substrate limits would\nlikely not be configurable and thus would still be to high for our needs as we can\nrely on the following observations:\n\n1. Each honest validator will only send one message (apart from duplicates on\n  timeout) per candidate/dispute.\n2. An honest validator needs to fully recover availability and validate the\n  candidate for casting a vote.\n\nWith these two observations, we can conclude that honest validators will usually\nnot send messages at a high rate. We can therefore enforce conservative rate\nlimits and thus minimize harm spamming malicious nodes can have.\n\nBefore we dive into how rate limiting solves all spam issues elegantly, let's\ndiscuss that honest behaviour further:\n\nWhat about session changes? Here we might have to inform a new validator set of\nlots of already existing disputes at once.\n\nWith observation 1) and a rate limit that is per peer, we are still good:\n\nLet's assume a rate limit of one message per 200ms per sender. This means 5\nmessages from each validator per second. 5 messages means 5 disputes!\nConclusively, we will be able to conclude 5 disputes per second - no matter what\nmalicious actors are doing. This is assuming dispute messages are sent ordered,\nbut even if not perfectly ordered: On average it will be 5 disputes per second.\n\nThis is good enough! All those disputes are valid ones and will result in\nslashing and disabling of validators. Let's assume all of them conclude `valid`,\nand we disable validators only after 100 raised concluding valid disputes, we\nwould still start disabling misbehaving validators in only 20 seconds.\n\nOne could also think that in addition participation is expected to take longer,\nwhich means on average we can import/conclude disputes faster than they are\ngenerated - regardless of dispute spam. Unfortunately this is not necessarily\ntrue: There might be parachains with very light load where recovery and\nvalidation can be accomplished very quickly - maybe faster than we can import\nthose disputes.\n\nThis is probably an argument for not imposing a too low rate limit, although the\nissue is more general: Even without any rate limit, if an attacker generates\ndisputes at a very high rate, nodes will be having trouble keeping participation\nup, hence the problem should be mitigated at a more fundamental\nlayer.\n\nFor nodes that have been offline for a while, the same argument as for session\nchanges holds, but matters even less: We assume 2/3 of nodes to be online, so\neven if the worst case 1/3 offline happens and they could not import votes fast\nenough (as argued above, they in fact can) it would not matter for consensus."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain glossary\ninput: "
      },
      {
        "role": "assistant",
        "content": "- **Acknowledgement:** A partial manifest sent to a validator that already has the candidate to inform them that the\n  sending node also knows the candidate. Concludes a manifest exchange.\n- **Announcement:** A full manifest indicating that a backed candidate is known by the sending node. Initiates a\n  manifest exchange.\n- **Attestation:** See \"Statement\".\n- **Backable vs. Backed:**\n  - Note that we sometimes use \"backed\" to refer to candidates that are \"backable\", but not yet backed on chain.\n  - **Backed** should technically mean that the parablock candidate and its backing statements have been added to a\n    relay chain block.\n  - **Backable** is when the necessary backing statements have been acquired but those statements and the parablock\n    candidate haven't been backed in a relay chain block yet.\n- **Fragment tree:** A parachain fragment not referenced by the relay-chain. It is a tree of prospective parachain\n  blocks.\n- **Manifest:** A message about a known backed candidate, along with a description of the statements backing it. There\n  are two kinds of manifest, `Acknowledgement` and `Announcement`. See \"Manifests\" section.\n- **Peer:** Another validator that a validator is connected to.\n- **Request/response:** A protocol used to lazily request and receive heavy candidate data when needed.\n- **Reputation:** Tracks reputation of peers. Applies annoyance cost and good behavior benefits.\n- **Statement:** Signed statements that can be made about parachain candidates.\n  - **Seconded:** Proposal of a parachain candidate. Implicit validity vote.\n  - **Valid:** States that a parachain candidate is valid.\n- **Target:** Target validator to send a statement to.\n- **View:** Current knowledge of the chain state.\n  - **Explicit view** / **immediate view**\n    - The view a peer has of the relay chain heads and highest finalized block.\n  - **Implicit view**\n    - Derived from the immediate view. Composed of active leaves and minimum relay-parents allowed for candidates of\n      various parachains at those leaves."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain default recovery strategy configuration\ninput: "
      },
      {
        "role": "assistant",
        "content": "### For validators\n\nIf the estimated available data size is smaller than a configured constant (currently 1Mib for Polkadot or 4Mib for\nother networks), try doing `FetchFull` first.\nNext, if the preconditions described in `FetchSystematicChunks` above are met, try systematic recovery.\nAs a last resort, do `FetchChunks`.\n\n### For collators\n\nCollators currently only use `FetchChunks`, as they only attempt recoveries in rare scenarios.\n\nMoreover, the recovery task is specially configured to not attempt requesting data from the local availability-store\n(because it doesn't exist) and to not reencode the data after a succcessful recovery (because it's an expensive check\nthat is not needed; checking the pov_hash is enough for collators)."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain functionality\ninput: "
      },
      {
        "role": "assistant",
        "content": "The process of generating a collation for a parachain is very parachain-specific. As such, the details of how to do so\nare left beyond the scope of this description. The subsystem should be implemented as an abstract wrapper, which is\naware of this configuration:\n\n/// The output of a collator.\n///\n/// This differs from `CandidateCommitments` in two ways:\n///\n/// - does not contain the erasure root; that's computed at the Polkadot level, not at Cumulus\n/// - contains a proof of validity.\npub struct Collation {\n  /// Messages destined to be interpreted by the Relay chain itself.\n  pub upward_messages: Vec<UpwardMessage>,\n  /// The horizontal messages sent by the parachain.\n  pub horizontal_messages: Vec<OutboundHrmpMessage<ParaId>>,\n  /// New validation code.\n  pub new_validation_code: Option<ValidationCode>,\n  /// The head-data produced as a result of execution.\n  pub head_data: HeadData,\n  /// Proof to verify the state transition of the parachain.\n  pub proof_of_validity: PoV,\n  /// The number of messages processed from the DMQ.\n  pub processed_downward_messages: u32,\n  /// The mark which specifies the block number up to which all inbound HRMP messages are processed.\n  pub hrmp_watermark: BlockNumber,\n}\n\n/// Result of the [`CollatorFn`] invocation.\npub struct CollationResult {\n  /// The collation that was build.\n  pub collation: Collation,\n  /// An optional result sender that should be informed about a successfully seconded collation.\n  ///\n  /// There is no guarantee that this sender is informed ever about any result, it is completely okay to just drop it.\n  /// However, if it is called, it should be called with the signed statement of a parachain validator seconding the\n  /// collation.\n  pub result_sender: Option<oneshot::Sender<CollationSecondedSignal>>,\n}\n\n/// Signal that is being returned when a collation was seconded by a validator.\npub struct CollationSecondedSignal {\n  /// The hash of the relay chain block that was used as context to sign [`Self::statement`].\n  pub relay_parent: Hash,\n  /// The statement about seconding the collation.\n  ///\n  /// Anything else than `Statement::Seconded` is forbidden here.\n  pub statement: SignedFullStatement,\n}\n\n/// Collation function.\n///\n/// Will be called with the hash of the relay chain block the parachain block should be build on and the\n/// [`ValidationData`] that provides information about the state of the parachain on the relay chain.\n///\n/// Returns an optional [`CollationResult`].\npub type CollatorFn = Box<\n  dyn Fn(\n      Hash,\n      &PersistedValidationData,\n    ) -> Pin<Box<dyn Future<Output = Option<CollationResult>> + Send>>\n    + Send\n    + Sync,\n>;\n\n/// Configuration for the collation generator\npub struct CollationGenerationConfig {\n  /// Collator's authentication key, so it can sign things.\n  pub key: CollatorPair,\n  /// Collation function. See [`CollatorFn`] for more details.\n  pub collator: Option<CollatorFn>,\n  /// The parachain that this collator collates for\n  pub para_id: ParaId,\n}\n\nThe configuration should be optional, to allow for the case where the node is not run with the capability to collate."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain network updates\ninput: "
      },
      {
        "role": "assistant",
        "content": "### `NetworkBridgeEvent::PeerConnected`\n\nAdd a blank view to the `peer_views` state.\n\n### `NetworkBridgeEvent::PeerDisconnected`\n\nRemove the view under the associated `PeerId` from `State::peer_views`.\n\nIterate over every `BlockEntry` and remove `PeerId` from it.\n\n### `NetworkBridgeEvent::OurViewChange`\n\nRemove entries in `pending_known` for all hashes not present in the view. Ensure a vector is present in `pending_known`\nfor each hash in the view that does not have an entry in `blocks`.\n\n### `NetworkBridgeEvent::PeerViewChange`\n\nInvoke `unify_with_peer(peer, view)` to catch them up to messages we have.\n\nWe also need to use the `view.finalized_number` to remove the `PeerId` from any blocks that it won't be wanting\ninformation about anymore. Note that we have to be on guard for peers doing crazy stuff like jumping their\n`finalized_number` forward 10 trillion blocks to try and get us stuck in a loop for ages.\n\nOne of the safeguards we can implement is to reject view updates from peers where the new `finalized_number` is less\nthan the previous.\n\nWe augment that by defining `constrain(x)` to output the x bounded by the first and last numbers in\n`state.blocks_by_number`.\n\nFrom there, we can loop backwards from `constrain(view.finalized_number)` until `constrain(last_view.finalized_number)`\nis reached, removing the `PeerId` from all `BlockEntry`s referenced at that height. We can break the loop early if we\never exit the bound supplied by the first block in `state.blocks_by_number`.\n\n### `NetworkBridgeEvent::PeerMessage`\n\nIf the block hash referenced by the message exists in `pending_known`, add it to the vector of pending messages and\nreturn.\n\nIf the message is of type `ApprovalDistributionV1Message::Assignment(assignment_cert, claimed_index)`, then call\n`import_and_circulate_assignment(MessageSource::Peer(sender), assignment_cert, claimed_index)`\n\nIf the message is of type `ApprovalDistributionV1Message::Approval(approval_vote)`, then call\n`import_and_circulate_approval(MessageSource::Peer(sender), approval_vote)`"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain utility\ninput: "
      },
      {
        "role": "assistant",
        "content": "enum MessageSource {\n  Peer(PeerId),\n  Local,\n}\n\n### `import_and_circulate_assignment(...)`\n\n`import_and_circulate_assignment(source: MessageSource, assignment: IndirectAssignmentCert, claimed_candidate_index:\nCandidateIndex)`\n\nImports an assignment cert referenced by block hash and candidate index. As a postcondition, if the cert is valid, it\nwill have distributed the cert to all peers who have the block in their view, with the exclusion of the peer referenced\nby the `MessageSource`.\n\nWe maintain a few invariants:\n  * we only send an assignment to a peer after we add its fingerprint to our knowledge\n  * we add a fingerprint of an assignment to our knowledge only if it's valid and hasn't been added before\n\nThe algorithm is the following:\n\n  * Load the `BlockEntry` using `assignment.block_hash`. If it does not exist, report the source if it is\n    `MessageSource::Peer` and return.\n  * Compute a fingerprint for the `assignment` using `claimed_candidate_index`.\n  * If the source is `MessageSource::Peer(sender)`:\n    * check if `peer` appears under `known_by` and whether the fingerprint is in the knowledge of the peer. If the peer\n      does not know the block, report for providing data out-of-view and proceed. If the peer does know the block and\n      the `sent` knowledge contains the fingerprint, report for providing replicate data and return, otherwise, insert\n      into the `received` knowledge and return.\n    * If the message fingerprint appears under the `BlockEntry`'s `Knowledge`, give the peer a small positive reputation\n    boost, add the fingerprint to the peer's knowledge only if it knows about the block and return. Note that we must do\n    this after checking for out-of-view and if the peers knows about the block to avoid being spammed. If we did this\n    check earlier, a peer could provide data out-of-view repeatedly and be rewarded for it.\n    * Check the assignment certificate is valid.\n      * If the cert kind is `RelayVRFModulo`, then the certificate is valid as long as `sample <\n        session_info.relay_vrf_samples` and the VRF is valid for the validator's key with the input\n        `block_entry.relay_vrf_story ++ sample.encode()` as described with\n        the approvals protocol section. We set\n        `core_index = vrf.make_bytes().to_u32() % session_info.n_cores`. If the `BlockEntry` causes\n        inclusion of a candidate at `core_index`, then this is a valid assignment for the candidate\n        at `core_index` and has delay tranche 0. Otherwise, it can be ignored.\n      * If the cert kind is `RelayVRFModuloCompact`, then the certificate is valid as long as the VRF\n        is valid for the validator's key with the input `block_entry.relay_vrf_story ++ relay_vrf_samples.encode()`\n        as described with the approvals protocol section.\n        We enforce that all `core_bitfield` indices are included in the set of the core indices sampled from the\n        VRF Output. The assignment is considered a valid tranche0 assignment for all claimed candidates if all\n        `core_bitfield` indices match the core indices where the claimed candidates were included at.\n      * If the cert kind is `RelayVRFDelay`, then we check if the VRF is valid for the validator's key with the\n        input `block_entry.relay_vrf_story ++ cert.core_index.encode()` as described in the approvals protocol\n        section. The cert can be ignored if the block did not\n        cause inclusion of a candidate on that core index. Otherwise, this is a valid assignment for the included\n        candidate. The delay tranche for the assignment is determined by reducing\n        `(vrf.make_bytes().to_u64() % (session_info.n_delay_tranches + session_info.zeroth_delay_tranche_width)).saturating_sub(session_info.zeroth_delay_tranche_width)`.\n      * We also check that the core index derived by the output is covered by the `VRFProof` by means of an auxiliary signature.\n      * If the delay tranche is too far in the future, return `AssignmentCheckResult::TooFarInFuture`.\n    * If the result is `AssignmentCheckResult::Accepted`\n      * Dispatch `ApprovalVotingMessage::ImportAssignment(assignment)` to approval-voting to import the assignment.\n      * If the vote was accepted but not duplicate, give the peer a positive reputation boost\n      * add the fingerprint to both our and the peer's knowledge in the `BlockEntry`. Note that we only doing this after\n        making sure we have the right fingerprint.\n    * If the result is `AssignmentCheckResult::AcceptedDuplicate`, add the fingerprint to the peer's knowledge if it\n      knows about the block and return.\n    * If the result is `AssignmentCheckResult::TooFarInFuture`, mildly punish the peer and return.\n    * If the result is `AssignmentCheckResult::Bad`, punish the peer and return.\n  * If the source is `MessageSource::Local(CandidateIndex)`\n    * check if the fingerprint appears under the `BlockEntry's` knowledge. If not, add it.\n  * Load the candidate entry for the given candidate index. It should exist unless there is a logic error in the\n    approval voting subsystem.\n  * Set the approval state for the validator index to `ApprovalState::Assigned` unless the approval state is set\n    already. This should not happen as long as the approval voting subsystem instructs us to ignore duplicate\n    assignments.\n  * Dispatch a `ApprovalDistributionV1Message::Assignment(assignment, candidate_index)` to all peers in the\n    `BlockEntry`'s `known_by` set, excluding the peer in the `source`, if `source` has kind `MessageSource::Peer`. Add\n    the fingerprint of the assignment to the knowledge of each peer.\n\n### `import_and_circulate_approval(source: MessageSource, approval: IndirectSignedApprovalVote)`\n\nImports an approval signature referenced by block hash and candidate index:\n\n  * Load the `BlockEntry` using `approval.block_hash` and the candidate entry using `approval.candidate_entry`. If\n    either does not exist, report the source if it is `MessageSource::Peer` and return.\n  * Compute a fingerprint for the approval.\n  * Compute a fingerprint for the corresponding assignment. If the `BlockEntry`'s knowledge does not contain that\n    fingerprint, then report the source if it is `MessageSource::Peer` and return. All references to a fingerprint after\n    this refer to the approval's, not the assignment's.\n  * If the source is `MessageSource::Peer(sender)`:\n    * check if `peer` appears under `known_by` and whether the fingerprint is in the knowledge of the peer. If the peer\n      does not know the block, report for providing data out-of-view and proceed. If the peer does know the block and\n      the `sent` knowledge contains the fingerprint, report for providing replicate data and return, otherwise, insert\n      into the `received` knowledge and return.\n    * If the message fingerprint appears under the `BlockEntry`'s `Knowledge`, give the peer a small positive reputation\n    boost, add the fingerprint to the peer's knowledge only if it knows about the block and return. Note that we must do\n    this after checking for out-of-view to avoid being spammed. If we did this check earlier, a peer could provide data\n    out-of-view repeatedly and be rewarded for it.\n    * Construct a `SignedApprovalVote` using the candidates hashes and check against the validator's approval key,\n      based on the session info of the block. If invalid or no such validator, return `Err(InvalidVoteError)`.\n    * If the result of checking the signature is `Ok(CheckedIndirectSignedApprovalVote)`:\n      * Dispatch `ApprovalVotingMessage::ImportApproval(approval)` .\n      * Give the peer a positive reputation boost and add the fingerprint to both our and the peer's knowledge.\n    * If the result is `Err(InvalidVoteError)`:\n      * Report the peer and return.\n  * Load the candidate entry for the given candidate index. It should exist unless there is a logic error in the\n    approval voting subsystem.\n  * Set the approval state for the validator index to `ApprovalState::Approved`. It should already be in the `Assigned`\n    state as our `BlockEntry` knowledge contains a fingerprint for the assignment.\n  * Dispatch a `ApprovalDistributionV1Message::Approval(approval)` to all peers in the `BlockEntry`'s `known_by` set,\n    excluding the peer in the `source`, if `source` has kind `MessageSource::Peer`. Add the fingerprint of the\n    assignment to the knowledge of each peer. Note that this obeys the politeness conditions:\n    * We guarantee elsewhere that all peers within `known_by` are aware of all assignments relative to the block.\n    * We've checked that this specific approval has a corresponding assignment within the `BlockEntry`.\n    * Thus, all peers are aware of the assignment or have a message to them in-flight which will make them so.\n\n### `unify_with_peer(peer: PeerId, view)`\n\n1. Initialize a set `missing_knowledge = {}`\n\nFor each block in the view:\n  1. Load the `BlockEntry` for the block. If the block is unknown, or the number is less than or equal to the view's\n     finalized number go to step 6.\n  1. Inspect the `known_by` set of the `BlockEntry`. If the peer already knows all assignments/approvals, go to step 6.\n  1. Add the peer to `known_by` and add the hash and missing knowledge of the block to `missing_knowledge`.\n  1. Return to step 2 with the ancestor of the block.\n\n1. For each block in `missing_knowledge`, send all assignments and approvals for all candidates in those blocks to the\n   peer."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain incoming messages\ninput: "
      },
      {
        "role": "assistant",
        "content": "### `OverseerSignal::BlockFinalized`\n\nOn receiving an `OverseerSignal::BlockFinalized(h)`, we fetch the block number `b` of that block from the `ChainApi`\nsubsystem. We update our `StoredBlockRange` to begin at `b+1`. Additionally, we remove all block entries and candidates\nreferenced by them up to and including `b`. Lastly, we prune out all descendants of `h` transitively: when we remove a\n`BlockEntry` with number `b` that is not equal to `h`, we recursively delete all the `BlockEntry`s referenced as\nchildren. We remove the `block_assignments` entry for the block hash and if `block_assignments` is now empty, remove the\n`CandidateEntry`. We also update each of the `BlockNumber -> Vec<Hash>` keys in the database to reflect the blocks at\nthat height, clearing if empty.\n\n### `OverseerSignal::ActiveLeavesUpdate`\n\nOn receiving an `OverseerSignal::ActiveLeavesUpdate(update)`:\n  * We determine the set of new blocks that were not in our previous view. This is done by querying the ancestry of all\n    new items in the view and contrasting against the stored `BlockNumber`s. Typically, there will be only one new\n    block. We fetch the headers and information on these blocks from the `ChainApi` subsystem. Stale leaves in the\n    update can be ignored.\n  * We update the `StoredBlockRange` and the `BlockNumber` maps.\n  * We use the `RuntimeApiSubsystem` to determine information about these blocks. It is generally safe to assume that\n    runtime state is available for recent, unfinalized blocks. In the case that it isn't, it means that we are catching\n    up to the head of the chain and needn't worry about assignments to those blocks anyway, as the security assumption\n    of the protocol tolerates nodes being temporarily offline or out-of-date.\n    * We fetch the set of candidates included by each block by dispatching a `RuntimeApiRequest::CandidateEvents` and\n      checking the `CandidateIncluded` events.\n    * We fetch the session of the block by dispatching a `session_index_for_child` request with the parent-hash of the\n      block.\n    * If the `session index - APPROVAL_SESSIONS > state.earliest_session`, then bump `state.earliest_sessions` to that\n      amount and prune earlier sessions.\n    * If the session isn't in our `state.session_info`, load the session info for it and for all sessions since the\n      earliest-session, including the earliest-session, if that is missing. And it can be, just after pruning, if we've\n      done a big jump forward, as is the case when we've just finished chain synchronization.\n    * If any of the runtime API calls fail, we just warn and skip the block.\n  * We use the `RuntimeApiSubsystem` to determine the set of candidates included in these blocks and use BABE logic to\n    determine the slot number and VRF of the blocks.\n  * We also note how late we appear to have received the block. We create a `BlockEntry` for each block and a\n    `CandidateEntry` for each candidate obtained from `CandidateIncluded` events after making a\n    `RuntimeApiRequest::CandidateEvents` request.\n  * For each candidate, if the amount of needed approvals is more than the validators remaining after the backing group\n    of the candidate is subtracted, then the candidate is insta-approved as approval would be impossible otherwise. If\n    all candidates in the block are insta-approved, or there are no candidates in the block, then the block is\n    insta-approved. If the block is insta-approved, a [`ChainSelectionMessage::Approved`][CSM] should be sent for the\n    block.\n  * Ensure that the `CandidateEntry` contains a `block_assignments` entry for the block, with the correct backing group\n    set.\n  * If a validator in this session, compute and assign `our_assignment` for the `block_assignments`\n    * Only if not a member of the backing group.\n    * Run `RelayVRFModulo` and `RelayVRFDelay` according to the the approvals protocol\n      section. Ensure that the assigned core derived from the output is\n      covered by the auxiliary signature aggregated in the `VRFPRoof`.\n  * Handle Wakeup for each new candidate in each new block - this will automatically broadcast a\n    0-tranche assignment, kick off approval work, and schedule the next delay.\n  * Dispatch an `ApprovalDistributionMessage::NewBlocks` with the meta information filled out for each new block.\n\n### `ApprovalVotingMessage::ImportAssignment`\n\nOn receiving a `ApprovalVotingMessage::ImportAssignment` message, we assume the assignment cert itself has already been\nchecked to be valid we proceed then to import the assignment inside the block entry. The cert itself contains\ninformation necessary to determine the candidate that is being assigned-to. In detail:\n  * Load the `BlockEntry` for the relay-parent referenced by the message. If there is none, return\n    `AssignmentCheckResult::Bad`.\n  * Fetch the `SessionInfo` for the session of the block\n  * Determine the assignment key of the validator based on that.\n  * Determine the claimed core index by looking up the candidate with given index in `block_entry.candidates`. Return\n    `AssignmentCheckResult::Bad` if missing.\n  * Import the assignment.\n    * Load the candidate in question and access the `approval_entry` for the block hash the cert references.\n    * Ignore if we already observe the validator as having been assigned.\n    * Ensure the validator index is not part of the backing group for the candidate.\n    * Ensure the validator index is not present in the approval entry already.\n    * Create a tranche entry for the delay tranche in the approval entry and note the assignment within it.\n    * Note the candidate index within the approval entry.\n  * Schedule a wakeup for this block, candidate pair.\n  * return the appropriate `AssignmentCheckResult` on the response channel.\n\n### `ApprovalVotingMessage::ImportApproval`\n\nOn receiving a `ImportApproval(indirect_approval_vote, response_channel)` message:\n  * Fetch the `BlockEntry` from the indirect approval vote's `block_hash`. If none, return `ApprovalCheckResult::Bad`.\n  * Fetch all `CandidateEntry` from the indirect approval vote's `candidate_indices`. If the block did not trigger\n    inclusion of enough candidates, return `ApprovalCheckResult::Bad`.\n  * Send `ApprovalCheckResult::Accepted`\n  * Import the checked approval vote for all candidates\n\n### `ApprovalVotingMessage::ApprovedAncestor`\n\nOn receiving an `ApprovedAncestor(Hash, BlockNumber, response_channel)`:\n  * Iterate over the ancestry of the hash all the way back to block number given, starting from the provided block hash.\n    Load the `CandidateHash`es from each block entry.\n  * Keep track of an `all_approved_max: Option<(Hash, BlockNumber, Vec<(Hash, Vec<CandidateHash>))>`.\n  * For each block hash encountered, load the `BlockEntry` associated. If any are not found, return `None` on the\n    response channel and conclude.\n  * If the block entry's `approval_bitfield` has all bits set to 1 and `all_approved_max == None`, set `all_approved_max\n    = Some((current_hash, current_number))`.\n  * If the block entry's `approval_bitfield` has any 0 bits, set `all_approved_max = None`.\n  * If `all_approved_max` is `Some`, push the current block hash and candidate hashes onto the list of blocks and\n    candidates `all_approved_max`.\n  * After iterating all ancestry, return `all_approved_max`."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain updates and auxiliary logic\ninput: "
      },
      {
        "role": "assistant",
        "content": "### Import Checked Approval\n  * Import an approval vote which we can assume to have passed signature checks and correspond to an imported\n    assignment.\n  * Requires `(BlockEntry, CandidateEntry, ValidatorIndex)`\n  * Set the corresponding bit of the `approvals` bitfield in the `CandidateEntry` to `1`. If already `1`, return.\n  * Checks the approval state of a candidate under a specific block, and updates the block and candidate entries\n    accordingly.\n  * Checks the `ApprovalEntry` for the block.\n    * determine the tranches to inspect of the candidate,\n    * the candidate is approved under the block, set the corresponding bit in the\n      `block_entry.approved_bitfield`.\n    * If the block is now fully approved and was not before, send a [`ChainSelectionMessage::Approved`][CSM].\n    * Otherwise, schedule a wakeup of the candidate\n  * If the approval vote originates locally, set the `our_approval_sig` in the candidate entry.\n\n### Handling Wakeup\n  * Handle a previously-scheduled wakeup of a candidate under a specific block.\n  * Requires `(relay_block, candidate_hash)`\n  * Load the `BlockEntry` and `CandidateEntry` from disk. If either is not present, this may have lost a race with\n    finality and can be ignored. Also load the `ApprovalEntry` for the block and candidate.\n  * determine the `RequiredTranches` of the candidate.\n  * Determine if we should trigger our assignment.\n    * If we've already triggered or `OurAssignment` is `None`, we do not trigger.\n    * If we have  `RequiredTranches::All`, then we trigger if the candidate is not approved. We have\n      no next wakeup as we assume that other validators are doing the same and we will be implicitly woken up by\n      handling new votes.\n    * If we have `RequiredTranches::Pending { considered, next_no_show, uncovered, maximum_broadcast, clock_drift }`,\n      then we trigger if our assignment's tranche is less than or equal to `maximum_broadcast` and the current tick,\n      with `clock_drift` applied, is at least the tick of our tranche.\n    * If we have `RequiredTranches::Exact { .. }` then we do not trigger, because this value indicates that no new\n      assignments are needed at the moment.\n  * If we should trigger our assignment\n    * Import the assignment to the `ApprovalEntry`\n    * Broadcast on network with an `ApprovalDistributionMessage::DistributeAssignment`.\n    * Launch approval work for the candidate.\n  * Schedule a new wakeup of the candidate.\n\n### Schedule Wakeup\n\n  * Requires `(approval_entry, candidate_entry)` which effectively denotes a `(Block Hash, Candidate Hash)` pair - the\n    candidate, along with the block it appears in.\n  * Also requires `RequiredTranches`\n  * If the `approval_entry` is approved, this doesn't need to be woken up again.\n  * If `RequiredTranches::All` - no wakeup. We assume other incoming votes will trigger wakeup and potentially\n    re-schedule.\n  * If `RequiredTranches::Pending { considered, next_no_show, uncovered, maximum_broadcast, clock_drift }` - schedule at\n    the lesser of the next no-show tick, or the tick, offset positively by `clock_drift` of the next non-empty tranche\n    we are aware of after `considered`, including any tranche containing our own unbroadcast assignment. This can lead\n    to no wakeup in the case that we have already broadcast our assignment and there are no pending no-shows; that is,\n    we have approval votes for every assignment we've received that is not already a no-show. In this case, we will be\n    re-triggered by other validators broadcasting their assignments.\n  * If `RequiredTranches::Exact { next_no_show, latest_assignment_tick, .. }` - set a wakeup for the earlier of the next\n    no-show tick or the latest assignment tick + `APPROVAL_DELAY`.\n\n### Launch Approval Work\n\n* Requires `(SessionIndex, SessionInfo, CandidateReceipt, ValidatorIndex, backing_group, block_hash, candidate_index)`\n* Extract the public key of the `ValidatorIndex` from the `SessionInfo` for the session.\n* Issue an `AvailabilityRecoveryMessage::RecoverAvailableData(candidate, session_index, Some(backing_group),\nSome(core_index), response_sender)`\n* Load the historical validation code of the parachain by dispatching a\n  `RuntimeApiRequest::ValidationCodeByHash(descriptor.validation_code_hash)` against the state of `block_hash`.\n* Spawn a background task with a clone of `background_tx`\n  * Wait for the available data\n  * Issue a `CandidateValidationMessage::ValidateFromExhaustive` message with `APPROVAL_EXECUTION_TIMEOUT` as the\n    timeout parameter.\n  * Wait for the result of validation\n  * Check that the result of validation, if valid, matches the commitments in the receipt.\n  * If valid, issue a message on `background_tx` detailing the request.\n  * If any of the data, the candidate, or the commitments are invalid, issue on `background_tx` a\n    `DisputeCoordinatorMessage::IssueLocalStatement`\n    with `valid = false` to initiate a dispute.\n\n### Issue Approval Vote\n  * Fetch the block entry and candidate entry. Ignore if `None` - we've probably just lost a race with finality.\n  * Import the checked approval vote. It is \"checked\" as we've just issued the signature.\n  * IF `MAX_APPROVAL_COALESCE_COUNT`  candidates are in the waiting queue\n    * Construct a `SignedApprovalVote` with the validator index for the session and all candidate hashes in the waiting queue.\n    * Construct a `IndirectSignedApprovalVote` using the information about the vote.\n    * Dispatch `ApprovalDistributionMessage::DistributeApproval`.\n  * ELSE\n    * Queue the candidate in the `BlockEntry::candidates_pending_signature`\n    * Arm a per BlockEntry timer with latest tick we can send the vote."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain determining approval of candidate\ninput: "
      },
      {
        "role": "assistant",
        "content": "### Determine Required Tranches\n\nThis logic is for inspecting an approval entry that tracks the assignments received, along with information on which\nassignments have corresponding approval votes. Inspection also involves the current time and expected requirements and\nis used to help the higher-level code determine the following:\n  * Whether to broadcast the local assignment\n  * Whether to check that the candidate entry has been completely approved.\n  * If the candidate is waiting on approval, when to schedule the next wakeup of the `(candidate, block)` pair at a\n    point where the state machine could be advanced.\n\nThese routines are pure functions which only depend on the environmental state. The expectation is that this\ndetermination is re-run every time we attempt to update an approval entry: either when we trigger a wakeup to advance\nthe state machine based on a no-show or our own broadcast, or when we receive further assignments or approvals from the\nnetwork.\n\nThus it may be that at some point in time, we consider that tranches 0..X is required to be considered, but as we\nreceive more information, we might require fewer tranches. Or votes that we perceived to be missing and require\nreplacement are filled in and change our view.\n\nRequires `(approval_entry, approvals_received, tranche_now, block_tick, no_show_duration, needed_approvals)`\n\nenum RequiredTranches {\n  // All validators appear to be required, based on tranches already taken and remaining no-shows.\n  All,\n  // More tranches required - We're awaiting more assignments.\n  Pending {\n    /// The highest considered delay tranche when counting assignments.\n    considered: DelayTranche,\n    /// The tick at which the next no-show, of the assignments counted, would occur.\n    next_no_show: Option<Tick>,\n    /// The highest tranche to consider when looking to broadcast own assignment.\n    /// This should be considered along with the clock drift to avoid broadcasting\n    /// assignments that are before the local time.\n    maximum_broadcast: DelayTranche,\n    /// The clock drift, in ticks, to apply to the local clock when determining whether\n    /// to broadcast an assignment or when to schedule a wakeup. The local clock should be treated\n    /// as though it is `clock_drift` ticks earlier.\n    clock_drift: Tick,\n  },\n  // An exact number of required tranches and a number of no-shows. This indicates that the amount of `needed_approvals`\n  // are assigned and additionally all no-shows are covered.\n  Exact {\n    /// The tranche to inspect up to.\n    needed: DelayTranche,\n    /// The amount of missing votes that should be tolerated.\n    tolerated_missing: usize,\n    /// When the next no-show would be, if any. This is used to schedule the next wakeup in the\n    /// event that there are some assignments that don't have corresponding approval votes. If this\n    /// is `None`, all assignments have approvals.\n    next_no_show: Option<Tick>,\n    /// The last tick at which a needed assignment was received.\n    last_assignment_tick: Option<Tick>,\n  }\n}\n\n**Clock-drift and Tranche-taking**\n\nOur vote-counting procedure depends heavily on how we interpret time based on the presence of no-shows - assignments\nwhich have no corresponding approval after some time.\n\nWe have this is because of how we handle no-shows: we keep track of the depth of no-shows we are covering.\n\nAs an example: there may be initial no-shows in tranche 0. It'll take `no_show_duration` ticks before those are\nconsidered no-shows. Then, we don't want to immediately take `no_show_duration` more tranches. Instead, we want to take\none tranche for each uncovered no-show. However, as we take those tranches, there may be further no-shows. Since these\ndepth-1 no-shows should have only been triggered after the depth-0 no-shows were already known to be no-shows, we need\nto discount the local clock by `no_show_duration` to  see whether these should be considered no-shows or not. There may\nbe malicious parties who broadcast their assignment earlier than they were meant to, who shouldn't be counted as instant\nno-shows. We continue onwards to cover all depth-1 no-shows which may lead to depth-2 no-shows and so on.\n\nLikewise, when considering how many tranches to take, the no-show depth should be used to apply a depth-discount or\nclock drift to the `tranche_now`.\n\n**Procedure**\n\n  * Start with `depth = 0`.\n  * Set a clock drift of `depth * no_show_duration`\n  * Take tranches up to `tranche_now - clock_drift` until all needed assignments are met.\n  * Keep track of the `next_no_show` according to the clock drift, as we go.\n  * Keep track of the `last_assignment_tick` as we go.\n  * If running out of tranches before then, return `Pending { considered, next_no_show, maximum_broadcast, clock_drift\n    }`\n  * If there are no no-shows, return `Exact { needed, tolerated_missing, next_no_show, last_assignment_tick }`\n  * `maximum_broadcast` is either `DelayTranche::max_value()` at tranche 0 or otherwise by the last considered tranche +\n    the number of uncovered no-shows at this point.\n  * If there are no-shows, return to the beginning, incrementing `depth` and attempting to cover the number of no-shows.\n    Each no-show must be covered by a non-empty tranche, which are tranches that have at least one assignment. Each\n    non-empty tranche covers exactly one no-show.\n  * If at any point, it seems that all validators are required, do an early return with `RequiredTranches::All` which\n    indicates that everyone should broadcast.\n\n### Check Approval\n  * Check whether a candidate is approved under a particular block.\n  * Requires `(block_entry, candidate_entry, approval_entry, n_tranches)`\n  * If we have `3 * n_approvals > n_validators`, return true. This is because any set with f+1 validators must have at\n    least one honest validator, who has approved the candidate.\n  * If `n_tranches` is `RequiredTranches::Pending`, return false\n  * If `n_tranches` is `RequiredTranches::All`, return false.\n  * If `n_tranches` is `RequiredTranches::Exact { tranche, tolerated_missing, latest_assignment_tick, .. }`, then we\n    return whether all assigned validators up to `tranche` less `tolerated_missing` have approved and\n    `latest_assignment_tick + APPROVAL_DELAY >= tick_now`.\n    * e.g. if we had 5 tranches and 1 tolerated missing, we would accept only if all but 1 of assigned validators in\n      tranches 0..=5 have approved. In that example, we also accept all validators in tranches 0..=5 having approved,\n      but that would indicate that the `RequiredTranches` value was incorrectly constructed, so it is not realistic.\n      `tolerated_missing` actually represents covered no-shows. If there are more missing approvals than there are\n      tolerated missing, that indicates that there are some assignments which are not yet no-shows, but may become\n      no-shows, and we should wait for the validators to either approve or become no-shows.\n    * e.g. If the above passes and the `latest_assignment_tick` was 5 and the current tick was 6, then we'd return\n      false."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain glossary\ninput: "
      },
      {
        "role": "assistant",
        "content": "- **Relay-parent:**\n  - A particular relay-chain block which serves as an anchor and reference point for processes and data which depend on\n    relay-chain state.\n- **Active Leaf:**\n  - A relay chain block which is the head of an active fork of the relay chain.\n  - Block authorship provisioning jobs are spawned per active leaf and concluded for any leaves which become inactive.\n- **Candidate Selection:**\n  - The process by which the provisioner selects backable parachain block candidates to pass to block authoring.\n  - Two versions, prospective parachains candidate selection and legacy candidate selection. See their respective\n    protocol sections for details.\n- **Availability Core:**\n  - Often referred to simply as \"cores\", availability cores are an abstraction used for resource management. For the\n    provisioner, availability cores are most relevant in that core states determine which `para_id`s to provision\n    backable candidates for.\n  - For more on availability cores see Scheduler Module: Availability\n    Cores\n- **Availability Bitfield:**\n  - Often referred to simply as a \"bitfield\", an availability bitfield represents the view of parablock candidate\n    availability from a particular validator's perspective. Each bit in the bitfield corresponds to a single\n    availability core.\n  - For more on availability bitfields see availability\n- **Backable vs. Backed:**\n  - Note that we sometimes use \"backed\" to refer to candidates that are \"backable\", but not yet backed on chain.\n  - Backable means that a quorum of the candidate's assigned backing group have provided signed affirming statements."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain possible attacks / threat model\ninput: "
      },
      {
        "role": "assistant",
        "content": "Webassembly is already sandboxed, but there have already been reported multiple\nCVEs enabling remote code execution. See e.g. these two advisories from\nMar 2023\nand Jul 2022.\n\nSo what are we actually worried about? Things that come to mind:\n\n1. **Consensus faults** - If an attacker can get some source of randomness they\n   could vote against with 50% chance and cause unresolvable disputes.\n2. **Targeted slashes** - An attacker can target certain validators (e.g. some\n   validators running on vulnerable hardware) and make them vote invalid and get\n   them slashed.\n3. **Mass slashes** - With some source of randomness they can do an untargeted\n   attack. I.e. a baddie can do significant economic damage by voting against\n   with 1/3 chance, without even stealing keys or completely replacing the\n   binary.\n4. **Stealing keys** - That would be pretty bad. Should not be possible with\n   sandboxing. We should at least not allow filesystem-access or network access.\n5. **Taking control over the validator.** E.g. replacing the `polkadot` binary\n   with a `polkadot-evil` binary. Should again not be possible with the above\n   sandboxing in place.\n6. **Intercepting and manipulating packages** - Effect very similar to the\n   above, hard to do without also being able to do 4 or 5.\n\nWe do not protect against (1), (2), and (3), because there are too many sources\nof randomness for an attacker to exploit.\n\nWe provide very good protection against (4), (5), and (6)."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain cumulus sdk\ninput: "
      },
      {
        "role": "assistant",
        "content": "A set of tools for writing Substrate-based Polkadot\nparachains. Refer to the included overview\nfor architectural details, and the Connect to a relay chain how-to\nguide for a guided walk-through\nof using these tools.\n\nIt's easy to write blockchains using Substrate, and the overhead of writing parachains' distribution, p2p, database, and\nsynchronization layers should be just as low. This project aims to make it easy to write parachains for Polkadot by\nleveraging the power of Substrate.\n\nCumulus clouds are shaped sort of like dots; together they form a system that is intricate, beautiful and functional."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain consensus\ninput: "
      },
      {
        "role": "assistant",
        "content": "`parachain-consensus`\nis a consensus engine for Substrate that follows a Polkadot relay\nchain. This will run a Polkadot node internally,\nand dictate to the client and synchronization algorithms which chain to follow,\nfinalize, and treat as best."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain relay chain interaction\ninput: "
      },
      {
        "role": "assistant",
        "content": "To operate a parachain node, a connection to the corresponding relay chain is necessary. This can be achieved in one of\nthree ways:\n1. Run a full relay chain node within the parachain node (default)\n2. Connect to an external relay chain node via WebSocket RPC\n3. Run a light client for the relay chain\n\n### In-process Relay Chain Node\nIf an external relay chain node is not specified (default behavior), then a full relay chain node is spawned within the\nsame process.\n\nThis node has all of the typical components of a regular Polkadot node and will have to fully sync with the relay chain\nto work.\n\n### Example command\npolkadot-parachain \\\n\t--chain parachain-chainspec.json \\\n\t--tmp \\\n\t-- \\\n\t--chain relaychain-chainspec.json\n\n### External Relay Chain Node\nAn external relay chain node is connected via WebSocket RPC by using the `--relay-chain-rpc-urls` command line\nargument. This option accepts one or more space-separated WebSocket URLs to a full relay chain node. By default, only\nthe first URL will be used, with the rest as a backup in case the connection to the first node is lost.\n\nParachain nodes using this feature won't have to fully sync with the relay chain to work, so in general they will use\nfewer system resources.\n\n**Note:** At this time, any parachain nodes using this feature will still spawn a significantly cut-down relay chain\nnode in-process. Even though they lack the majority of normal Polkadot subsystems, they will still need to connect\ndirectly to the relay chain network.\n\n### Example command\n\npolkadot-parachain \\\n\t--chain parachain-chainspec.json \\\n\t--tmp \\\n\t--relay-chain-rpc-urls \\\n\t\t\"ws://relaychain-rpc-endpoint:9944\" \\\n\t\t\"ws://relaychain-rpc-endpoint-backup:9944\" \\\n\t-- \\\n\t--chain relaychain-chainspec.json\n\n### Relay Chain Light Client\nAn internal relay chain light client provides a fast and lightweight approach for connecting to the relay chain network.\nIt provides relay chain notifications and facilitates runtime calls.\n\nTo specify which chain the light client should connect to, users need to supply a relay chain chain-spec as part of the\nrelay chain arguments.\n\n**Note:** At this time, any parachain nodes using this feature will still spawn a significantly cut-down relay chain\nnode in-process. Even though they lack the majority of normal Polkadot subsystems, they will still need to connect\ndirectly to the relay chain network.\n\n### Example command\npolkadot-parachain \\\n\t--chain parachain-chainspec.json \\\n\t--tmp \\\n\t--relay-chain-light-client \\\n\t-- \\\n\t--chain relaychain-chainspec.json"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain runtime\ninput: "
      },
      {
        "role": "assistant",
        "content": "Each Substrate blockchain provides a runtime. The runtime is the state transition function of the\nblockchain. Cumulus provides interfaces and extensions to convert a Substrate FRAME runtime into a\nParachain runtime. Polkadot expects each runtime exposes an interface for validating a\nParachain's state transition and also provides interfaces for the Parachain to send and receive\nmessages of other Parachains.\n\nTo convert a Substrate runtime into a Parachain runtime, the following code needs to be added to the\nruntime:\ncumulus_pallet_parachain_system::register_validate_block!(Block, Executive);\n\nThis macro call expects the `Block` and `Executive` type. It generates the `validate_block` function\nthat is expected by Polkadot to validate the state transition.\n\nWhen compiling a runtime that uses Cumulus, a WASM binary is generated that contains the *full* code\nof the Parachain runtime plus the `validate_block` functionality. This binary is required to\nregister a Parachain on the relay chain.\n\nWhen the Parachain validator calls the `validate_block` function, it passes the PoVBlock (See Block\nbuilding for more information) and the parent header of the Parachain that is\nstored on the relay chain. From the PoVBlock witness data, Cumulus reconstructs the partial trie.\nThis partial trie is used as storage while executing the block. Cumulus also redirects all storage\nrelated host functions to use the witness data storage. After the setup is done, Cumulus calls\n`execute_block` with the transactions and the header stored in the PoVBlock. On success, the new\nParachain header is returned as part of the `validate_block` result."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain node\ninput: "
      },
      {
        "role": "assistant",
        "content": "Parachains support light-clients, full nodes, and authority nodes. Authority nodes are called\nCollators in the Polkadot ecosystem. Cumulus provides the consensus implementation for a\nParachain and the block production logic.\n\nThe Parachain consensus will follow the relay chain to get notified about which Parachain blocks are\nincluded in the relay-chain and which are finalized. Each block that is built by a Collator is sent\nto a validator that is assigned to the particular Parachain. Cumulus provides the block production\nlogic that notifies each Collator of the Parachain to build a Parachain block. The\nnotification is triggered on a relay-chain block import by the Collator. This means that every\nCollator of the Parachain can send a block to the Parachain validators. For more sophisticated\nauthoring logic, the Parachain will be able to use Aura, BABE, etc. (Not supported at the moment)\n\nA Parachain Collator will join the Parachain network and the relay-chain network. The Parachain\nnetwork will be used to gossip Parachain blocks and to gossip transactions. Collators will only\ngossip blocks to the Parachain network that have a high chance of being included in the relay\nchain. To prove that a block is probably going to be included, the Collator will send along side\nthe notification the so-called candidate message. This candidate message is issued by a Parachain\nvalidator after approving a block. This proof of possible inclusion prevents spamming other collators\nof the network with useless blocks.\nThe Collator joins the relay-chain network for two reasons. First, the Collator uses it to send the\nParachain blocks to the Parachain validators. Secondly, the Collator participates as a full-node\nof the relay chain to be informed of new relay-chain blocks. This information will be used for the\nconsensus and the block production logic."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain block building\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot requires that a Parachain block is transmitted in a fixed format. These blocks sent by a\nParachain to the Parachain validators are called proof-of-validity blocks (PoVBlock). Such a\nPoVBlock contains the header and the transactions of the Parachain as opaque blobs (`Vec<u8>`). They\nare opaque, because Polkadot can not and should not support all kinds of possible Parachain block\nformats. Besides the header and the transactions, it also contains the witness data and the outgoing\nmessages.\n\nA Parachain validator needs to validate a given PoVBlock, but without requiring the full state of\nthe Parachain. To still make it possible to validate the Parachain block, the PoVBlock contains the\nwitness data. The witness data is a proof that is collected while building the block. The proof will\ncontain all trie nodes that are read during the block production. Cumulus uses the witness data to\nreconstruct a partial trie and uses this as storage when executing the block.\n\nThe outgoing messages are also collected at block production. These are messages from the Parachain\nthe block is built for to other Parachains or to the relay chain itself."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain runtime upgrade\ninput: "
      },
      {
        "role": "assistant",
        "content": "Every Substrate blockchain supports runtime upgrades. Runtime upgrades enable a blockchain to update\nits state transition function without requiring any client update. Such a runtime upgrade is applied\nby a special transaction in a Substrate runtime. Polkadot and Cumulus provide support for these\nruntime upgrades, but updating a Parachain runtime is not as easy as updating a standalone\nblockchain runtime. In a standalone blockchain, the special transaction needs to be included in a\nblock and the runtime is updated.\n\nA Parachain will follow the same paradigm, but the relay chain needs to be informed before\nthe update. Cumulus will provide functionality to notify the relay chain about the runtime update. The\nupdate will not be enacted directly; instead it takes `X` relay blocks (a value that is configured\nby the relay chain) before the relay chain allows the update to be applied. The first Parachain\nblock that will be included after `X` relay chain blocks needs to apply the upgrade.\nIf the update is applied before the waiting period is finished, the relay chain will reject the\nParachain block for inclusion. The Cumulus runtime pallet will provide the functionality to\nregister the runtime upgrade and will also make sure that the update is applied at the correct block.\n\nAfter updating the Parachain runtime, a Parachain needs to wait a certain amount of time `Y`\n(configured by the relay chain) before another update can be applied.\n\nThe WASM blob update not only contains the Parachain runtime, but also the `validate_block`\nfunction provided by Cumulus. So, updating a Parachain runtime on the relay chain involves a\ncomplete update of the validation WASM blob."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain init bridge and run relayer between bridgehubrococo and bridgehubwestend\ninput: "
      },
      {
        "role": "assistant",
        "content": "**Accounts of BridgeHub parachains:**\n- `Bob` is pallet owner of all bridge pallets\n\n### Run with script\ncd <polkadot-sdk-git-repo-dir>\n\n./bridges/testing/environments/rococo-westend/bridges_rococo_westend.sh run-finality-relay\n\n**Check relay-chain headers relaying:**\n- Rococo parachain: - https://polkadot.js.org/apps/?rpc=ws%3A%2F%2F127.0.0.1%3A8943#/chainstate - Pallet:\n  **bridgeWestendGrandpa** - Keys: **bestFinalized()**\n- Westend parachain: - https://polkadot.js.org/apps/?rpc=ws%3A%2F%2F127.0.0.1%3A8945#/chainstate - Pallet:\n  **bridgeRococoGrandpa** - Keys: **bestFinalized()**\n\n**Check parachain headers relaying:**\n- Rococo parachain: - https://polkadot.js.org/apps/?rpc=ws%3A%2F%2F127.0.0.1%3A8943#/chainstate - Pallet:\n  **bridgeWestendParachains** - Keys: **parasInfo(None)**\n- Westend parachain: - https://polkadot.js.org/apps/?rpc=ws%3A%2F%2F127.0.0.1%3A8945#/chainstate - Pallet:\n  **bridgeRococoParachains** - Keys: **parasInfo(None)**"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain the planck unit\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The smallest unit of account balance on Polkadot SDK-based blockchains is Planck, named after the Planck Length. DOT equals 1010 Planck, while Kusama's KSM equals 1012 Planck.\nPolkadotKusama\n\n\n\n\n\nUnit\nDecimal Places\nConversion to Planck\nConversion to DOT\n\n\n\n\nPlanck\n0\n1 Planck\n0.0000000001 DOT\n\n\nMicrodot (uDOT)\n4\n104 Planck\n0.0000010000 DOT\n\n\nMillidot (mDOT)\n7\n107 Planck\n0.0010000000 DOT\n\n\nDot (DOT)\n10\n1010 Planck\n1.0000000000 DOT\n\n\nMillion (MDOT)\n16\n1016 Planck\n1,000,000.00 DOT\n\n\n\n\n\n\n\n\nUnit\nDecimal Places\nConversion to Planck\nConversion to KSM\n\n\n\n\nPlanck\n0\n1 Planck\n0.000000000001 KSM\n\n\nPoint\n3\n103 Planck\n0.000000001000 KSM\n\n\nMicroKSM (uKSM)\n6\n106 Planck\n0.000001000000 KSM\n\n\nMilliKSM (mKSM)\n9\n109 Planck\n0.001000000000 KSM\n\n\nKSM\n12\n1012 Planck\n1.000000000000 KSM"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain dot inflation\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "DOT is an inflationary token, with\nfixed annual expansion of the token supply of 120,000,000 DOT,\nof which 15% goes to the treasury and 85% to\nstakers.\nIt is essential to understand that the primary objective of inflation is to incentivize network\nparticipants through\nNominated Proof of Stake (NPoS) and to grow the\nnetwork through funding the on-chain treasury. The token inflation rate can be updated through\non-chain governance based on thorough tokenomics research.\nBelow is a 25-year prediction of DOT gross annual inflation (red line) and DOT total issuance (blue\nline), assuming the current fixed inflation rate.\nThe total issuance takes into account the gross DOT inflation and thus does not consider tokens that\nare burned.\nNet DOT inflation depends on treasury burns and\ncoretime sales that are variables and\nthus cannot be predicted. Net inflation can be defined as follows:\nNet Inflation = Gross fixed inflation - burned supply (treasury + coretime sales)\nWhere Gross fixed inflation is the annual inflation of 120M DOT and the burned supply is the\nannual burn supply due to treasury burns and coretime sale burns."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain obtaining testnet tokens\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Testnet tokens allow experimentation on Polkadot's features. Obtain testnet tokens on the official faucet. For faucet issues, use the support chat or create an issue.\nPaseoWestend\n\n\nPaseo mirrors Polkadot's runtime. Obtain PAS tokens here or via !drip <PASEO_ADDRESS> in the Matrix chatroom.\n\n\n\nUnit\nDecimal Places\nConversion to Planck\nConversion to PAS\n\n\n\n\nPlanck\n0\n1 Planck\n0.0000000001 PAS\n\n\nMicrodot (uPAS)\n4\n104 Planck\n0.0000010000 PAS\n\n\nMillidot (mPAS)\n7\n107 Planck\n0.0010000000 PAS\n\n\nDot (PAS)\n10\n1010 Planck\n1.0000000000 PAS\n\n\nMillion (MPAS)\n16\n1016 Planck\n1,000,000.00 PAS\n\n\n\n\n\nWestend is Polkadot's testnet. Obtain WND tokens via the faucet or !drip <WESTEND_ADDRESS> in the Matrix chatroom. Validators can also earn WND. Watch the video guide.\n\n\n\nUnit\nDecimal Places\nConversion to Planck\nConversion to WND\n\n\n\n\nPlanck\n0\n1 Planck\n0.000000000001 WND\n\n\nPoint\n3\n103 Planck\n0.000000001000 WND\n\n\nMicroWND (uWND)\n6\n106 Planck\n0.000001000000 WND\n\n\nMilliWND (mWND)\n9\n109 Planck\n0.001000000000 WND\n\n\nWND\n12\n1012 Planck\n1.000000000000 WND"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain proof-of-stake (pos)\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Blockchain networks use consensus mechanisms to\nfinalize blocks on the chain. Consensus is the process of agreeing on something, in this case, the\nprogression of the blockchain or how blocks are added to the chain. Consensus consists of two\nactions:\nBlock production, i.e. the way multiple blocks candidates are produced, and\nBlock finality, i.e. the way only one block out of many candidates is selected and added to\n  the canonical chain (see this article\n  for more information about finality).\nProof-of-Work (PoW) and Proof-of-Stake (PoS) are well-known mechanisms used to reach consensus in a\nsecure and trustless way on public blockchains, where there are many participants who do not know\neach other (and probably never will). In PoW, network security relies on the fact that the miners\nwho are responsible for adding blocks to the chain must compete to solve difficult mathematic\npuzzles to add blocks - a solution that has been criticized for the wastage of energy. For doing\nthis work, miners are typically rewarded with tokens.\nIn PoS networks like Polkadot, the security of the network depends on the amount of capital locked\non the chain: the more the capital locked, the lower the chance of an attack on the network, as the\nattacker needs to incur a heavy loss to orchestrate a successful attack (more on this later on). The\nprocess of locking tokens on the chain is called staking.\nSimilar to the miners in PoW networks, PoS networks have validators, but they do not have to\ncompete with each other to solve mathematical puzzles. They are instead pre-selected to produce the\nblocks based on the stake backing them. Token holders can lock funds on the chain and for doing so,\nthey are getting staking rewards. There is thus an economic incentive for token holders to\nbecome active participants who contribute to the economic security and stability of the network. PoS\nnetworks in general are therefore more inclusive than PoW networks, as participants do not need to\nhave either technical knowledge about blockchain technology or experience in running mining\nequipment.\nPoS ensures that everybody participating in the staking process has \"skin in the game\" and thus can\nbe held accountable. In case of misbehavior, participants in the staking process can be punished or\nslashed, and depending on the gravity of the situation, their stake can\nbe partly or fully confiscated by the network. It is not in a staker's economic interest to\norchestrate an attack and risk losing tokens. Any rational actor staking on the network would want\nto get rewarded, and the PoS network rewards good behavior and punishes bad behavior."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain nominated proof-of-stake (npos)\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot implements\nNominated Proof-of-Stake (NPoS), a relatively novel\nand sophisticated mechanism to select the validators who are allowed to participate in its\nconsensus protocol. NPoS encourages token holders to participate as\nnominators.\nAny potential validators can indicate their intention to be a validator candidate. Their candidacies\nare made public to all nominators, and a nominator, in turn, submits a\ncapped list of candidates that it\nsupports, and the network will automatically distribute the stake among validators in an even manner\nso that the economic security is maximized. In the next era, a certain number of validators having\nthe highest backing get elected and become active. For more information about the election algorithm\ngo to this page on the wiki or\nthis research article. As a\nnominator, a minimum bond\nis required to submit an intention to nominate, which can be thought of as registering to be a\nnominator. Note that in NPoS the stake of both nominators and validators can be\nslashed. For an in-depth review of NPoS see\nthis research article.\nMinimum Nomination to Receive Staking Rewards\nThe minimum nomination intent does not guarantee staking rewards. The nominated amount has to be greater than minimum active nomination, which is a dynamic value that can be much higher than the minimum nomination intent. This dynamic value depends on the amount of tokens being staked, in addition to the selected nominations."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain nominating validators\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Nominating requires 2 actions:\nLocking tokens on-chain.\nSelecting a set of validators, to whom these locked tokens will automatically be allocated to.\nHow many tokens you lock up is completely up to you - as are the validators you wish to select. The\naction of locking tokens is also known as bonding. You can also refer to your locked tokens as\nyour bonded tokens, or staked tokens. Likewise, selecting validators is also known as backing or\nnominating validators. These terms are used interchangeably by the community. From now on locked\ntokens will be referred to as bonded tokens.\nOnce the previous 2 steps are completed and you are nominating, your bonded tokens could be\nallocated to one or more of your selected validators, and this happens every time the active\nvalidator set changes. This validator set is updated every era.\nUnlike other staking systems, Polkadot automatically chooses which of your selected validators will\nbe backed by your bonded tokens. Selecting a group of validators increases your chances of\nconsistently backing at least one who is active. This results in your bonded tokens being allocated\nto validators more often, which means more network security and more rewards. This is in strong\ncontrast to other staking systems that only allow you to back one validator; if that validator is\nnot active, you as a staker will also not be.\nPolkadot's nomination model solves this. It uses tools ranging from election theory to game theory\nto discrete optimization, to develop an efficient validator selection process that offers fair\nrepresentation and security, thus avoiding uneven power and influence among validators. The election\nalgorithms are based on the Proportional Justified Representation (PJR) methods like\nPhragmen. For more information about PJR methods visit\nthis research article."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain eras and sessions\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The stake from nominators is used to increase the number of tokens held by such candidates,\nincreasing their chance of being selected by the election algorithm for block production during a\nspecific era. An era is a period of 24 hours (6 hours on Kusama) during which an active set\nof validators is producing blocks and performing other actions on the chain. This means that not all\nvalidators are in the active set and such set changes between eras. Each era is divided into 6\nepochs or sessions during which validators are assigned as block producers to specific time\nframes or slots. This means that validators know the slots when they will be required to produce\na block within a specific session, but they do not know all the slots within a specific era. Having\nsessions adds a layer of security because it decreases the chance of having multiple validators\nassigned to a slot colluding to harm the network."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain staking rewards\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Validators who produce a block are rewarded with tokens, and they can share rewards with their\nnominators. Both validators and nominators can stake their tokens on chain and receive staking\nrewards at the end of each era. The staking system pays out rewards equally to all validators\nregardless of stake. Thus, having more stake in a validator does not influence the amount of block\nrewards it receives. This avoids the centralization of power to a few validators. There is a\nprobabilistic component in the calculation of rewards, so they may not be exactly equal for all\nvalidators. In fact, during each era validators can earn era points by doing different tasks on\nchain. The more the points, the higher the reward for a specific era. This promotes validators'\nactivity on chain. To know more about era points, and how and on which basis they are distributed\nvisit the dedicated page. Distribution of the\nrewards is pro-rata to all stakers after the validator's commission is deducted."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain skin in the game when staking\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The security of PoS networks depends on the amount of staked tokens. To successfully attack the\nnetwork, a malicious actor would need to accrue a large number of tokens or would need different\nparticipants to collude and act maliciously. If there is an attack in the case of NPoS, both the\nvalidator(s) and nominators will be slashed resulting in their stake being partially or fully\nconfiscated by the network and then deposited to the treasury. There is little interest for a\nrational network participant to act in a harmful way because NPoS ensures that all participants can\nbe held accountable for their bad actions. In NPoS, validators are paid equal rewards regardless of\nthe amount of stake backing them, thus avoiding large payouts to few large validators which might\nlead to centralization."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain tasks and responsibilities of a nominator\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Validators. Since validator slots are limited, most of those who wish to stake their tokens and\ncontribute to the economic security of the network will be nominators, thus here we focus on the\nrole of nominators. However, it is worth mentioning that validators do most of the heavy lifting:\nthey run the validator nodes and manage\nsession keys, produce new block\ncandidates in BABE, vote and come to consensus in\nGRANDPA, validate the state transition function of\nparachains, and possibly some other responsibilities regarding data availability and\nXCM. For more information, you can take a look at the\nvalidator docs to understand what you need to do as a validator. If you want\nto become a validator you can consult\nthis guide.\nNominators. Nominators have far fewer responsibilities than validators. These include selecting\nvalidators and monitoring their performance, keeping an eye on changing commission rates (a\nvalidator can change commission at any time), and general health monitoring of their validators'\naccounts. Thus, while not being completely set-it-and-forget-it, a nominator's experience is\nrelatively hands-off compared to that of a validator, and even more with\nnomination pools. For more information, you can take a look at the\nnominator guide to understanding your responsibilities as a nominator.\nIf you want to become a nominator, see this guide. If you are a\nbeginner and would like to securely stake your tokens using the Polkadot-JS UI, refer to\nthis\nsupport article. The tutorial presented in the support article is demonstrated on Polkadot, but the\nprocedure is the same for Kusama.\nPolkadot Staking Dashboard\nThe Staking Dashboard provides a more user-friendly alternative to staking. See the instructions in this support article to learn how to stake with the dashboard.\nPools. Pools are \"built\" on top of NPoS to provide a very low barrier to entry to staking,\nwithout sacrificing Polkadot's strict security model."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain selection of validators\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The task of choosing validators is not simple, as it should take into account nominator reward and\nrisk preferences. Ideally one aims to maximize the reward-to-risk ratio by maximizing rewards and\nminimizing risks, with sometimes having to compromise between the two, as minimizing risks might\ndecrease rewards as well. Nominators should pay attention, especially to six criteria when\nnominating validators (not in order of importance):\nrecent history of the era points earned across eras\nvalidator's self stake (shows skin in the game)\ntotal stake backing the validator (which is the sum of self stake and the stake coming from\n  nominators)\ncommission fees (i.e. how much validators charge nominators)\nverified identity\nprevious slashes\nThe diagram below shows how the selection of those criteria affects the reward-to-risk ratio.\nValidator Selection Criteria\u00b6\nTo maximize rewards and minimize risk, one could select those validators that:\nhave era points above average (because they will get more rewards for being active),\nhave the total stake backing the validator below the average active validator stake (because they\n  will pay out more rewards per staked token),\nhave high own stake (because if slashed they have something to lose),\nhave low commission fees but not 0% (because it makes sense that for doing the heavy lifting,\n  validators ask for a small commission),\nhave on-chain registered identity (because it adds a layer of trust and possibly provides access\n  to their website and contact details),\nand have not been slashed (meaning that their on-chain behavior is genuine).\nNetwork Providers\u00b6\nFor successful operation, a Validator node should always be ensured to meet the required\nsoftware, hardware, and network bandwidth specifications.\nUnderstandably, most of the validator nodes run on cloud service providers that guarantee high\nhardware specifications and high levels of availability and connectivity. Keep in mind that a\nvalidator in the active set is supposed to be fully online and available for producing blocks. If\nthe active validator node goes offline due to network interruptions or a power outage, that\nvalidator will get fewer rewards.\nChecking Validators using Network Providers\nYou can connect your stash account to the Polkawatch app. The app will show your rewards earned in the past 60 eras divided by network provider and country. You will be able to see networks used by each validator and verify if your validators are using providers who support PoS. This is also a great tool to explore how decentralized your nominations are and act accordingly.\nKeeping Track of Nominated Validators\u00b6\nNominators must periodically check their validators\nNominating is not a \"set and forget\" operation. The whole NPoS system is dynamic and nominators should periodically monitor the performance and reputation of their validators. Failing to do so could result in applied slashes and/or rewards not being paid out, possibly for a prolonged period.\nAlthough the theory can be used as a general guideline, in practice it is more complicated and\nfollowing the theory might not necessarily lead to the desired result. Validators might have the\ntotal stake backing them below average, low commission and above average era points in one era and\nthen have a different profile in the next one. Selection based on the criteria like on-chain\nidentity, slash history and low commission make the staking rewards deterministic. But some criteria\nvary more than others, with era points being the most variable and thus one of the key probabilistic\ncomponents of staking rewards. Part of this probability is directly related to the fact that a\nvalidator can produce blocks for a parachain (i.e. para-validators) or the relay chain, with\npara-validators earning more era points per unit time (see\nthis page for more information). The\nrole can switch between sessions, and you can look at\nthe staking tab on the Polkadot-JS UI to know which\nvalidator is producing blocks for the relay chain or parachains.\nIt is not recommended to change nominations because of the low era points of a validator in a single\nera. Variability in rewards due to the era points should level out over time. If a validator\nconsistently gets era points below average, it makes sense to nominate a better-performing validator\nfor the health of the network and increased staking rewards. See\nthis\nsupport article to understand in detail how to select the set of validators to nominate."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain stash account and staking proxy\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Two different accounts can be used to securely manage your funds while staking.\nStash: This account holds funds bonded for staking, but delegates all staking functions to a\n  staking proxy account. You may actively participate in staking with a stash private key kept in a\n  cold wallet like Ledger, meaning it stays offline all the time. Having a staking proxy will allow\n  you to sign all staking-related transactions with the proxy instead of using your Ledger device.\n  This will allow you:\n\n\nto avoid carrying around your Ledger device just to sign staking-related transactions, and\n\n\nto keep the transaction history of your stash clean\n\n\nStaking Proxy: This account acts on behalf of the stash account, signalling decisions about\n  nominating and validating. It can set preferences like commission (for validators) and the staking\n  rewards payout account. The earned rewards can be bonded (locked) immediately for bonding on your\n  stash account, which would effectively compound the rewards you receive over time. You could also\n  choose to have them deposited to a different account as a free (transferable) balance. If you are\n  a validator, it can also be used to set your session keys. Staking\n  proxies only need sufficient funds to pay for the transaction fees.\nWarning\nNever leave a high balance on a proxy account which are usually \"hot\" as their private key is stored on the device (PC, phone) and it is always exposed to the internet for potential hacks and scams. It is good practice to deposit rewards on the stash account or to send them to another account on a cold wallet.\nThis hierarchy of separate keys for stash and staking accounts was designed to add a layer of\nprotection to nominators and validator operators. The more often one exposes and uses a private key,\nthe higher its vulnerability for hacks or scams. So, if one uses a key for multiple roles on a\nblockchain network, it is likely that the account can get compromised. Note that the damage linked\nto stolen private keys is different depending on the type of account derivation. In the case of soft\nderivation, all derived accounts are compromised. More information about account derivation can be\nfound here.\nInfo\nFor Ledger users staking directly on Ledger Live, currently, there is no option to use separate stash and staking proxy accounts.\nLedger devices are now supported in SubWallet,\nTalisman, and PolkaGate extension. Users can\nimport their Ledger accounts in the extension and use them as a stash in staking. You can find more\ninformation about, SubWallet, Talisman, PolkaGate and other wallets that officially secured funding\nfrom the treasury here."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain claiming staking rewards\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Note that Kusama runs approximately 4x as fast as Polkadot, except for block production times.\nPolkadot will also produce blocks at approximately six-second intervals.\nRewards are calculated per era (approximately six hours on Kusama and twenty-four hours on\nPolkadot). These rewards are calculated based on era points, which have a probabilistic component.\nIn other words, there may be slight differences in your rewards from era to era, and even amongst\nvalidators in the active set at the same time. These variations should cancel out over a long enough\ntimeline. See the page on Validator Payout Guide.\nThe distribution of staking rewards to the nominators is not automatic and needs to be triggered by\nsomeone. Typically the validators take care of this, but anyone can permissionlessly trigger rewards\npayout for all the nominators whose stake has backed a specific validator in the active set of that\nera. Staking rewards are kept available for\na limited amount of time.\nFor more information on why this is so, see the page on simple payouts.\nPayouts\nPayouts are unclaimed rewards waiting to be paid out to both validators and nominators. If you go to the Staking payouts page on Polkadot-JS, you will see a list of all validators that you have nominated in the past 84 eras and for which you have not yet received a payout. The payout page is visible only to stakers.\nEach validator as well as their nominators have the option to trigger the payout for all unclaimed\neras. Note that this will pay everyone who was nominating that validator during those eras.\nTherefore, you may not see anything in this tab, yet still have received a payout if somebody\n(generally, but not necessarily, another nominator or the validator operator) has triggered the\npayout for that validator for that era.\nTime limit to claim staking rewards\nIf nobody claims your staking rewards within 84 eras, then you will not be able to claim them and they will be lost. Additionally, if the validator unbonds all their own stake, any pending payouts will also be lost.\nRewards can be directed to the same account used to sign the payout or to a completely unrelated\naccount. It is also possible to top-up / withdraw some bonded tokens without having to un-stake all\nstaked tokens.\nIf you wish to know if you received a payout, you will have to check via a block explorer. See\nthe relevant Support page\nfor details. For specific details about validator payouts, please see\nthis guide."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain chilling\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Chilling is the act of stepping back from any nominating or validating. It can be done by a\nvalidator or nominator at any time, taking effect in the next era.\nChilling can be validator-initiated, e.g. if there is a planned outage in the validator's\nsurroundings or hosting provider, and the validator wants to exit to protect themselves against\nslashing. Chilling will keep the validator active in the current era, but will move them to the\ninactive set in the next. The validator will not lose their nominators.\nFor more on chilling, see the How to Chill page on the main website."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain fast unstake\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Fast Unstaking feature is live!\nIf you accidentally bonded your tokens or your bonded tokens never backed any active validator, you can now unbond them immediately.\nIf your bonded balance did not back any validators for a\npre-determined period, you are eligible to\nperform fast unstaking. The staking dashboard will\nautomatically check if you qualify. For more information, visit the\n\"Fast Unstake\" section in this support article."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain pros of staking\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Earn rewards for contributing to the network's security through staking.\nLow barrier of entry through Nomination Pools.\nCan choose multiple validators\n  which can help to decentralize the network through the sophisticated\n  NPoS system\n85% of inflation/year of the tokens is primarily intended for staking rewards. Check the\n  inflation section on the Wiki for more information."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain cons of staking\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Tokens will be locked during the\n  unbonding period and no rewards will be\n  earned if you unbond.\nPossible punishment in case of the active validator found to be misbehaving (see\n  slashing).\nLack of liquidity i.e. You would not be able to use the tokens for participating in crowdloans or\n  transfer them to different account etc.\nUnbonding Period Length\u00b6\nThe unbonding period provides a safety net\nfor slashing offenses identified in\npast eras,\nwhich can hold the respective validators and their nominators accountable. The unbonding period is\ncrucial in mitigating ex post facto slashing, particularly in guarding against long-range attacks.\nWhen a client encounters a chain finalized by\nGRANDPA that originates more than one\nunbonding period in the past, it lacks the\nsecurity of slashing protection.\nEssentially, this period establishes a cadence for synchronizing with the chain or acquiring a\ncheckpoint within a timeframe that engenders trust. It's worth noting that while the choice of\nunbonding period length is somewhat\narbitrary, it unquestionably provides a higher level of security compared to a shorter period."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain how many validators?\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The top bound on the number of validators\nhas not been determined yet, but should only be limited by the bandwidth strain of the network due\nto peer-to-peer message passing.\nThe estimate of the number of validators that Polkadot will have at maturity is around 1000, while\nKusama is already operating at this threshold."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain why am i not receiving rewards?\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Nominating is not a set-and-forget action. Nominators need to monitor their nominations and ensure\nthey are eligible to receive staking rewards. Otherwise, they would be risking their funds to secure\nthe chain with no reward. If you are bonding significantly more than the Minimum Active Bond and yet\nnot receiving rewards, your nominations are all waiting, or your active validator has 100%\ncommission. However, if you bond funds close to the Minimum Active Bond, there could be several\npossibilities for not receiving staking rewards. The table below can be used to troubleshoot why you\nmight not be receiving staking rewards using Polkadot-JS UI.\nNomination Status\nWhat's happening?\nCauses\nWhat to do?\n\n\n\n\nNominated validators are all in waiting status.\nYour stake has not been assigned to any of the nominated validators. You cannot earn rewards, nor be slashed in that era.\nWaiting validators are not in the active set in the current era and the stake backing them is not used to secure the network. In simple words, NPoS \"does not see them\".\nChange your nominations. Try to select validators (with reasonable commission) that have high chances to end up in the active set.\n\n\nYou have some inactive, and some waiting nominations.\nValidators shown as \"Inactive\" in your staking dashboard are still in the active set and are producing blocks in the current era, but your stake has not been assigned to any of them. You will not earn rewards if your stake is not backing an active validator. In this case, you cannot be slashed either.\nScenario 1: You have bonded less than the Minimum Active Bond. Scenario 2: You have more than the Minimum Active Bond, but your account is at the tail end of the bags list and within your bag there are accounts with less stake than you, in front of you.\nScenario 1: Try bonding more funds. Scenario 2: Try to put your account in front of the accounts with less stake than you. Instructions available here\nJoin a Nomination Pool\nBy joining a nomination pool that is active and earning rewards, you can start earning staking rewards with as low as 1 DOT. The nomination pools typically have a dedicated pool operator who ensures that the pool's stake is always backing an active validator and is receiving rewards.\nBags List & Minimum Active Bond\nYou can find information about why you might not receive staking rewards on this support page and this video tutorial."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain resources\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "How Nominated Proof of Stake will work in Polkadot -\n  Blog post by Web3 Foundation researcher Alfonso Cevallos covering NPoS in Polkadot.\nValidator setup\nPolkadot validator selector tool - A tool\n  that helps nominators find reliable validators that meet quality-control criteria, including\n  commission rates, verified identity, etc.\nPolkadot-JS Guides\nIf you are an advanced user, see the Polkadot-JS guides about staking."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain data ownership\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In web3, ownership is achieved and validated through cryptography. Each user has a digital identity\nbound to a set of cryptographic keys usually based on the public key cryptographic scheme, i.e., the\nfamous public and private key pair.\nUnlike Web2 which is driven by email IDs, phone numbers, and passwords, users onboarding to Web3\njust need to generate a key pair. The public key can be the identity that can be shared with anybody\nto send you messages or assets, while the private key is used to access your account, sign messages,\ntransfer funds, edit identity details, etc. Keeping your private key secure is\nessential to avoid identity theft or consequent loss of funds. Currently, scams are one of the main\nfactors hindering web3 adoption. No legitimate person or entity will ever ask you to share your\nprivate key, and those who attempt to do so are likely trying to steal your digital identity and\nanything you own related to it.\nTo mitigate risks of key mismanagement (for non-custodial accounts, i.e. when you have custody\nof your keys) there are account abstraction solutions that\nseparate the key management from the user experience. To mitigate key hacks, there are cold wallet\nsolutions where the private key is generated and stored on dedicated devices with secure elements\nthat are not exposed to the internet (see Ledger), or dedicated applications that can\nbe installed on air-gapped devices such as phones (see Polkadot Vault). For\ncustodial accounts, you trust third parties to manage your keys and give you access whenever\nneeded.\nTo summarize, data ownership comes from the fact that any message you sign with your private key\ncomes from your digital identity, and the signature proof can be cryptographically verified. Unless\nsomeone else stole your keys, you and only you are held accountable for signing the messages and are\nresponsible for the information on your account. Transferring an NFT between\ntwo accounts is essentially a transfer of ownership."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain data immutability\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "But what if the data we own can be easily modified or tampered with after they have been signed and\nstored?\nHere is where blockchain technology plays an important role. Blockchain networks comprise of\ndistributed state machines where increments of data are stored within blocks that build on each\nother using hash functions. For example, the hash of block N + 1 contains data of that block\ntogether with the hash of the previous block N. This creates the situation where if you modify the\ncontent of block N you will change the hash of block N + 1, N + 2, etc. essentially breaking\nthe chain. If a blockchain network is not sufficiently decentralized, it can be possible to add an\ninvalid block (a block with invalid transactions) or to censor certain transactions. In\ndecentralized proof-of-stake blockchains like Polkadot however, such attacks are financially\nexpensive and attempting them can get you slashed.\nSo, with blockchain as a means of storing data and transactions permanently without an option to\nmodify them, we can ensure what we cryptographically sign with our digital identity is set in stone\ndigitally."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain data retrievability\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "But what if our data are stored in a blockchain, but that blockchain is run on a centralized server\nor by different computers belonging to the same operator?\nThat server or those computers can be easily shut down, the blockchain can be stopped from running\nand its data wiped out. This can be achieved from the inside by the malicious network participants\nor from the outside by regulatory rules and other forces. Though blockchain offers immutability,\nthere would be little sense in using a centralized blockchain to prove ownership as it can possibly\ncease to exist in the future.\nData retrievability is dependent on how resilient the blockchain is. Resiliency is achieved through\nelements such as decentralization, economic incentives, and on-chain governance to ensure the\nnetwork can sustain on its own.\nData Retrievability vs. Data Availability\nData retrievability is the ability of nodes to retrieve\u00a0historical information\u00a0from the blockchain. Historical data is not needed to verify new blocks; it is only required for synching full nodes from the Genesis block or serving specific historical requests.\nData availability assures full nodes can access and verify the full transactions associated with\na specific block. It does not necessarily imply that the data is accessible forever. For more\ninformation about data availability on Polkadot, see the\ndedicated section on the parachain protocol page."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain decentralization\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Having multiple nodes belonging to numerous independent identities increases network resiliency and\nthus data retrievability.\nBlockchain is a state machine, and consensus must be achieved on every single state transition by\nevery node on the blockchain network. In Proof of Work (PoW) based blockchains, which let any node\nin the network produce a block, consensus is achieved probabilistically by building on the longest\nchain (at the cost of energy-intensive computations). Proof of Stake (PoS) based blockchains like\nPolkadot enable deterministic consensus by allowing only a limited number of privileged nodes to\nproduce blocks. A PoW blockchain can be considered centralized if a single entity can capture 51% of\nnetwork nodes. Similarly, a PoS blockchain can be considered centralized if a single entity controls\nmore than one-third of nodes, as a two-thirds majority is required to arrive at a deterministic\nconsensus. Different blockchains have different levels of decentralization.\nNowadays, most of the nodes cannot be run on consumer-grade hardware. Node running equipment is\ntypically rented through service providers. Resiliency is also achieved by ensuring nodes run on as\nmany different providers as possible and avoiding a significant share of the nodes being run under\nthe same provider in the same geographic region. A legislation change or a natural disaster could\nimpact a considerable fraction of the nodes and potentially stop the network. Polkadot's level of\ndecentralization can be explored through the Polkawatch app.\nThe Decentralized Nodes program aims to incentivize the creation\nof new validator nodes to increase the level of node decentralization."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain decentralized storage\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Blockspace is limited and valuable. Not all data we have can be stored on\nthe blockchain. Large files like pictures, music, movies, etc., typically will never be held on the\nblockchain. But where can we stored those files? To stick to the web3 vision, we need a resilient\nand decentralized storage solution.\nThe most important thing is that the proof of ownership is stored on the blockchain through the\nhashes of data and metadata. The files are uploaded on decentralized storage networks hosting\nprotocols like IPFS."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain stake allocation\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In Proof-of-Stake blockchains, security is dictated by how much stake is locked on-chain (financial\nsecurity). In a decentralized network, you want to ensure that the difficulty level for a financial\nattack to happen is equally difficult across all nodes. Polkadot's\nelection algorithm makes sure that the stake is maximized across all\nactive validators, and the variance in stake across validators is minimized as much as possible."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain economic incentives\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Strong incentives are essential to incentivize network participants to run nodes and secure the\nnetwork. Strong incentives are possible because blockchain is a trustless system where there are no\nintermediaries between who sends a message and who receives it. Such incentives, coupled with\npunishment for bad behavior, ensure that most of the participants make the interest of the network\nand work together to improve it.\nBut from where are those incentives coming from? Polkadot's native token\nDOT is inflationary. Inflation is used to pay validators for running\nnodes and reward nominators for providing the necessary stake to secure the network."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain governance and treasury\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In Polkadot, an on-chain treasury together with an\nopen governance model allow to access funds in a fully\ndecentralized manner without any bank transaction whatsoever. This opens up the possibility to come\nto a decision through on-chain voting mechanism, promoting a sense of community and creating an\nindependent socio-economical environment."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain decentralized access points\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "But what if we have data we own stored on a resilient blockchain, but the only way to access the\nblockchain is through an RPC server? Whoever is behind the server or an attacker could present us\ndata that is not the truth. How can we trustlessly verify that the data is true?\nHere is where light clients play a key role. Light clients are clients that can sit on a web browser\nand can fetch data directly from blockchain. The figure below shows the architectural difference\nbetween web2 and web3 applications.\nIn web2 applications, data are stored on a centralized server, while in web3 applications, data (or\nbetter data proofs) are stored on the blockchain. With light clients, it is possible to access\nblockchain data through a full node and verify the validity of such data. They efficiently\nsynchronize (warp sync in case of Polkadot) with a full node to obtain (Merkle Root) commitment of\nthe latest chain state, and hence can trustlessly verify any response by full node against the\ncommitment. In this way, we can always verify that the data we see is the truth, which is done\nautomatically by the light client. Polkadot has a browser-embedded light client\nSubstrate connect that uses the\nsmoldot codebase. Most web3 applications today access\nblockchain data through a centralized RPC server.\nFor more details about the inner workings of Smoldot, see\nthis blog post and\nthis video."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain interoperability\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The Web3 landscape's expansion into a multi-layered ecosystem highlights the need for\ninteroperability. Blockchains compete and differentiate themselves based on decentralization,\nthroughput, and specific use case focus. Some aim for a single high-performance base-layer\nblockchain, while others focus on decentralization through layer-2 networks. With such diverse\napproaches, it's crucial for distinct on-chain environments to interoperate, especially for\ndevelopers building cross-chain applications and traditional systems interacting with multiple\nblockchains.\nVarious cross-chain interactions are employed to achieve interoperability, including token swaps,\ntoken bridges, native payments, contract calls, and programmable token bridges. Each mechanism\nserves specific functions, such as facilitating the exchange of tokens between different blockchains\nor enabling smart contract interactions across chains. Other interoperability solutions validate the\nstate of a source blockchain and relay transactions to the destination blockchain, which is\nessential for completing cross-chain interactions.\nInteroperability between chains having different consensus has been a challenging task. Most of\nhacks have exploited vulnerabilities in interoperability protocols. Polkadot provides secure\ninteroperability through XCM and XCMP to\nall blockchains attached to it. For more information, see the Polkadot 1.0 page\nand\nthe section about XCM and Accords in Polkadot Direction page."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain data ownership\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In web3, ownership is achieved and validated through cryptography. Each user has a digital identity\nbound to a set of cryptographic keys usually based on the public key cryptographic scheme, i.e., the\nfamous public and private key pair.\nUnlike Web2 which is driven by email IDs, phone numbers, and passwords, users onboarding to Web3\njust need to generate a key pair. The public key can be the identity that can be shared with anybody\nto send you messages or assets, while the private key is used to access your account, sign messages,\ntransfer funds, edit identity details, etc. Keeping your private key secure is\nessential to avoid identity theft or consequent loss of funds. Currently, scams are one of the main\nfactors hindering web3 adoption. No legitimate person or entity will ever ask you to share your\nprivate key, and those who attempt to do so are likely trying to steal your digital identity and\nanything you own related to it.\nTo mitigate risks of key mismanagement (for non-custodial accounts, i.e. when you have custody\nof your keys) there are account abstraction solutions that\nseparate the key management from the user experience. To mitigate key hacks, there are cold wallet\nsolutions where the private key is generated and stored on dedicated devices with secure elements\nthat are not exposed to the internet (see Ledger), or dedicated applications that can\nbe installed on air-gapped devices such as phones (see Polkadot Vault). For\ncustodial accounts, you trust third parties to manage your keys and give you access whenever\nneeded.\nTo summarize, data ownership comes from the fact that any message you sign with your private key\ncomes from your digital identity, and the signature proof can be cryptographically verified. Unless\nsomeone else stole your keys, you and only you are held accountable for signing the messages and are\nresponsible for the information on your account. Transferring an NFT between\ntwo accounts is essentially a transfer of ownership."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain data immutability\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "But what if the data we own can be easily modified or tampered with after they have been signed and\nstored?\nHere is where blockchain technology plays an important role. Blockchain networks comprise of\ndistributed state machines where increments of data are stored within blocks that build on each\nother using hash functions. For example, the hash of block N + 1 contains data of that block\ntogether with the hash of the previous block N. This creates the situation where if you modify the\ncontent of block N you will change the hash of block N + 1, N + 2, etc. essentially breaking\nthe chain. If a blockchain network is not sufficiently decentralized, it can be possible to add an\ninvalid block (a block with invalid transactions) or to censor certain transactions. In\ndecentralized proof-of-stake blockchains like Polkadot however, such attacks are financially\nexpensive and attempting them can get you slashed.\nSo, with blockchain as a means of storing data and transactions permanently without an option to\nmodify them, we can ensure what we cryptographically sign with our digital identity is set in stone\ndigitally."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain data retrievability\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "But what if our data are stored in a blockchain, but that blockchain is run on a centralized server\nor by different computers belonging to the same operator?\nThat server or those computers can be easily shut down, the blockchain can be stopped from running\nand its data wiped out. This can be achieved from the inside by the malicious network participants\nor from the outside by regulatory rules and other forces. Though blockchain offers immutability,\nthere would be little sense in using a centralized blockchain to prove ownership as it can possibly\ncease to exist in the future.\nData retrievability is dependent on how resilient the blockchain is. Resiliency is achieved through\nelements such as decentralization, economic incentives, and on-chain governance to ensure the\nnetwork can sustain on its own.\nData Retrievability vs. Data Availability\nData retrievability is the ability of nodes to retrieve\u00a0historical information\u00a0from the blockchain. Historical data is not needed to verify new blocks; it is only required for synching full nodes from the Genesis block or serving specific historical requests.\nData availability assures full nodes can access and verify the full transactions associated with\na specific block. It does not necessarily imply that the data is accessible forever. For more\ninformation about data availability on Polkadot, see the\ndedicated section on the parachain protocol page."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain decentralization\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Having multiple nodes belonging to numerous independent identities increases network resiliency and\nthus data retrievability.\nBlockchain is a state machine, and consensus must be achieved on every single state transition by\nevery node on the blockchain network. In Proof of Work (PoW) based blockchains, which let any node\nin the network produce a block, consensus is achieved probabilistically by building on the longest\nchain (at the cost of energy-intensive computations). Proof of Stake (PoS) based blockchains like\nPolkadot enable deterministic consensus by allowing only a limited number of privileged nodes to\nproduce blocks. A PoW blockchain can be considered centralized if a single entity can capture 51% of\nnetwork nodes. Similarly, a PoS blockchain can be considered centralized if a single entity controls\nmore than one-third of nodes, as a two-thirds majority is required to arrive at a deterministic\nconsensus. Different blockchains have different levels of decentralization.\nNowadays, most of the nodes cannot be run on consumer-grade hardware. Node running equipment is\ntypically rented through service providers. Resiliency is also achieved by ensuring nodes run on as\nmany different providers as possible and avoiding a significant share of the nodes being run under\nthe same provider in the same geographic region. A legislation change or a natural disaster could\nimpact a considerable fraction of the nodes and potentially stop the network. Polkadot's level of\ndecentralization can be explored through the Polkawatch app.\nThe Decentralized Nodes program aims to incentivize the creation\nof new validator nodes to increase the level of node decentralization."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain decentralized storage\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Blockspace is limited and valuable. Not all data we have can be stored on\nthe blockchain. Large files like pictures, music, movies, etc., typically will never be held on the\nblockchain. But where can we stored those files? To stick to the web3 vision, we need a resilient\nand decentralized storage solution.\nThe most important thing is that the proof of ownership is stored on the blockchain through the\nhashes of data and metadata. The files are uploaded on decentralized storage networks hosting\nprotocols like IPFS."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain stake allocation\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In Proof-of-Stake blockchains, security is dictated by how much stake is locked on-chain (financial\nsecurity). In a decentralized network, you want to ensure that the difficulty level for a financial\nattack to happen is equally difficult across all nodes. Polkadot's\nelection algorithm makes sure that the stake is maximized across all\nactive validators, and the variance in stake across validators is minimized as much as possible."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain economic incentives\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Strong incentives are essential to incentivize network participants to run nodes and secure the\nnetwork. Strong incentives are possible because blockchain is a trustless system where there are no\nintermediaries between who sends a message and who receives it. Such incentives, coupled with\npunishment for bad behavior, ensure that most of the participants make the interest of the network\nand work together to improve it.\nBut from where are those incentives coming from? Polkadot's native token\nDOT is inflationary. Inflation is used to pay validators for running\nnodes and reward nominators for providing the necessary stake to secure the network."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain governance and treasury\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In Polkadot, an on-chain treasury together with an\nopen governance model allow to access funds in a fully\ndecentralized manner without any bank transaction whatsoever. This opens up the possibility to come\nto a decision through on-chain voting mechanism, promoting a sense of community and creating an\nindependent socio-economical environment."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain decentralized access points\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "But what if we have data we own stored on a resilient blockchain, but the only way to access the\nblockchain is through an RPC server? Whoever is behind the server or an attacker could present us\ndata that is not the truth. How can we trustlessly verify that the data is true?\nHere is where light clients play a key role. Light clients are clients that can sit on a web browser\nand can fetch data directly from blockchain. The figure below shows the architectural difference\nbetween web2 and web3 applications.\nIn web2 applications, data are stored on a centralized server, while in web3 applications, data (or\nbetter data proofs) are stored on the blockchain. With light clients, it is possible to access\nblockchain data through a full node and verify the validity of such data. They efficiently\nsynchronize (warp sync in case of Polkadot) with a full node to obtain (Merkle Root) commitment of\nthe latest chain state, and hence can trustlessly verify any response by full node against the\ncommitment. In this way, we can always verify that the data we see is the truth, which is done\nautomatically by the light client. Polkadot has a browser-embedded light client\nSubstrate connect that uses the\nsmoldot codebase. Most web3 applications today access\nblockchain data through a centralized RPC server.\nFor more details about the inner workings of Smoldot, see\nthis blog post and\nthis video."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain interoperability\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The Web3 landscape's expansion into a multi-layered ecosystem highlights the need for\ninteroperability. Blockchains compete and differentiate themselves based on decentralization,\nthroughput, and specific use case focus. Some aim for a single high-performance base-layer\nblockchain, while others focus on decentralization through layer-2 networks. With such diverse\napproaches, it's crucial for distinct on-chain environments to interoperate, especially for\ndevelopers building cross-chain applications and traditional systems interacting with multiple\nblockchains.\nVarious cross-chain interactions are employed to achieve interoperability, including token swaps,\ntoken bridges, native payments, contract calls, and programmable token bridges. Each mechanism\nserves specific functions, such as facilitating the exchange of tokens between different blockchains\nor enabling smart contract interactions across chains. Other interoperability solutions validate the\nstate of a source blockchain and relay transactions to the destination blockchain, which is\nessential for completing cross-chain interactions.\nInteroperability between chains having different consensus has been a challenging task. Most of\nhacks have exploited vulnerabilities in interoperability protocols. Polkadot provides secure\ninteroperability through XCM and XCMP to\nall blockchains attached to it. For more information, see the Polkadot 1.0 page\nand\nthe section about XCM and Accords in Polkadot Direction page."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain definition of a parachain\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "A parachain is an application-specific data structure that is globally coherent and can be validated\nby the validators of the relay chain. They take their name from the concept of parallelized chains\nthat run parallel to the relay chain. Most commonly, a parachain will take the form of a blockchain,\nbut there is no specific need for them to be actual blockchains.\nDue to their parallel nature, they can parallelize transaction processing and achieve scalability of\nthe protocol. They inherit the security of the entire network and can\ncommunicate with other parachains through the XCM format.\nParachains are maintained by a network maintainer known as a collator. The role\nof the collator node is to maintain a full node of the parachain, retain all necessary information\nabout the parachain, and produce new block candidates to pass to the relay chain validators for\nverification and inclusion in the shared state. The incentivization of a collator node is an\nimplementation detail of the parachain. They are not required to be staked on the relay chain or own\nthe native token unless stipulated by the parachain implementation."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain state transitions\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Like other blockchains, parachains are deterministic state machines. Each parachain has a\nstate, executes a batch of transactions grouped into a block, and achieves a new state. Joe\nPetrowski provided in this article a\ngood analogy of a state with a light switch that can be either on or off, which is one of the\nsimplest examples of how a state machine functions. Each parachain has its own state, and the Relay\nChain links all those states into one state, i.e. a state of states. A multi-chain network like\nPolkadot can be viewed like one computer's state with many light switches where a state transition\nfunction is the logic to decide which switches should be toggled. Parachains have their own\ntransition rule, separate economies, governance mechanisms, and users.\nA parachain's state is stored in a Merkle tree. Merkle\ntrees have the convenient property that if some values within the tree change, this will be\nreflected in the Merkle root (in this case, the state root). One can verify the change by only\nlooking at the new values and the paths that are affected within the tree.\nThe Polkadot Host requires that the state transitions performed on parachains be specified as a\nWasm executable. Proofs of new state transitions that occur on a parachain must be\nvalidated against the registered state transition function (STF) that is stored on the relay chain\nby the validators before the relay chain acknowledges a state transition has occurred on a\nparachain. The key constraint regarding the logic of a parachain is that it must be verifiable by\nthe relay chain validators. Verification most commonly takes the form of a bundled proof of a state\ntransition known as a Proof-of-Verification (PoV) block, which is submitted for checking to the\nvalidators from one or more parachain collators."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain why parachains?\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Parachains are a solution to two fundamental problems in blockchains:\nScalability: Having one blockchain for many purposes makes it difficult to scale as future\n  implementations and upgrades will likely advantage some purposes and disadvantage others.\n  Conversely, having different blockchains will allow them to implement features without affecting\n  other chains.\nFlexibility: It is reasonable to state a blockchain will either be really good at solving one\n  problem or not so good at trying to solve many problems. A blockchain specializing in solving a\n  specific problem has more leverage toward itself and its users. Parachains are purpose-built\n  blockchains are highly specialized and can take advantage of each other through cooperation."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain parachain benefits\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Parachains contain their own runtime/STF logic and benefit from the shared security and the\ncross-consensus messaging provided by the relay chain. Parachains permit high flexibility and\ncustomization but require more effort to create and maintain over time. A production-grade parachain\nis typically more involved to create due to the complexity involved in blockchain networks'\ntechnical and economic aspects.\nParachains grant the creators more space to build the monetary system and other chain aspects from\nthe ground up. They will allow for a more concise and efficient execution of complex logic than a\nsmart contract platform could offer. Parachains also provide more flexibility in the form of\ngovernance and can perform complete upgrades in a less controversial way than the current process of\nhard forks.\nSome examples of features you can have on a parachain or parathread:\nCustom fee structure (for example, pay a flat transaction fee or pay per byte).\nShared security and finalization via the relay chain (Polkadot or Kusama).\nCustom monetary policy for the native token and local economy.\nTreasury to be funded through transitions in your state function.\nA governance mechanism that could manage a DAO that is responsible for allocating your on-chain\n  treasury."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain shared security\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Shared security, sometimes referred as pooled security, is one of the unique value propositions\nfor chains considering becoming a parachain and joining the network. On a\nhigh level, shared security means that all parachains that are connected to the relay chain by\naccessing a core will benefit from the economic security provided by the relay chain\nvalidators.\nThe notion of shared security is different from inter-chain protocols that build on an architecture\nof bridges. For bridge protocols, each chain is considered sovereign and must maintain its own\nvalidator set and economic security. One concern in these protocols is the point of scalability of\nsecurity. For example, one suggestion to scale blockchains is that of scale by altcoins, which\nsuggests that transaction volumes will filter down to lower market cap altcoins as the bigger ones\nfill their blocks. A major flaw in this idea is that the lower market cap coins will have less\neconomic security attached and be easier to attack. A real-life example of a 51% attack occurred\nrecently (\nEthereum Classic attack on January 10, 2019\n), in which an unknown attacker double spent 219_500 ETC (~1.1 million USD). This was followed by\ntwo more 51% attacks on ETC.\nPolkadot overcomes security scalability concerns since it gravitates all the economic incentives to\nthe relay chain and allows the parachains to tap into stronger guarantees at genesis. Sovereign\nchains must expend much more effort to grow the value of their coin so that it is sufficiently\nsecure against well-funded attackers."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain pow vs parachain model\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Let's compare the standard sovereign security model that exists on current proof-of-work (PoW)\nchains to Polkadot's shared security model. Bitcoin, Zcash, and their derivatives, must bootstrap\ntheir independent network of miners and maintain a competitive portion of honest hashing power.\nSince mining is becoming a larger industry that increasingly centralizes key players, it is becoming\nmore real that a single actor may control enough hash power to attack a chain.\nThis means that smaller chains that cannot maintain a secure amount of hash power on their networks\ncould potentially be attacked by a large mining cartel at the simple whim of redirecting its hash\npower away from Bitcoin and toward a new and less secure chain.\n51% attacks are viable today with attacks having been reported on\nEthereum Classic (see above),\nVerge,\nBitcoin Gold, and other cryptocurrencies.\nOn Polkadot, this disparity between chain security will not be present. When a parachain connects to\nthe relay chain, validators become the securers of that parachain's state transitions. The parachain\nwill only have the overhead of running a few collator nodes to keep the validators informed with the\nlatest state transitions and proofs/witness. Validators will then check these for the parachains to\nwhich they are assigned. In this way, new parachains instantly benefit from the overall security\nprovided by the relay chain even if they have just been launched."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain parachain economies\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Parachains may have their economies with their native tokens. Schemes such as Proof-of-Stake are\nusually used to select the validator set to handle validation and finalization; parachains will not\nbe required to do either of those things. However, since Polkadot is not overly particular about\nwhat the parachain can implement, it may be the choice of the parachain to implement a staking\ntoken, but it's not generally necessary.\nCollators may be incentivized through the inflation of a native parachain token. There may be other\nways to incentivize the collator nodes that do not involve inflating the native parachain token.\nTransaction fees in a native parachain token can also be an implementation choice of parachains.\nPolkadot makes no hard and fast rules for how the parachains decide on the original validity of\ntransactions. For example, a parachain may be implemented so that transactions must pay a minimum\nfee to collators to be valid. The relay chain will enforce this validity. Similarly, a parachain\ncould not include that in their implementation, and the relay chain would still enforce its\nvalidity.\nParachains are not required to have their token. If they do, it is up to the parachain (and not the\nrelay chain) to make the economic case for their token."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain coretime\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Parachains can access the relay chain via cores.\nThere are two ways to allocate relay chain cores:\nVia Governance only to system chains.\nVia coretime purchase with DOT (KSM on Kusama) for non-system chains.\n  Coretime is used to rent computation time on a relay chain core. This is the only way to access\n  Polkadot's shared security and interoperability.\nSystem parachains are allocated by Polkadot's on-chain\ngovernance and are part of the network's protocol, such as bridges to\nother networks or chains. These typically do not have an economic model and help remove transactions\nfrom the relay chain, allowing for more efficient parachain processing.\nNon-system chains can access the relay chain's cores via bulk or on-demand coretime purchased with\nDOT (or KSM on Kusama)."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain coretime expiration\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The DOT (or KSM on Kusama) used to purchase coretime are burned. Before the coretime expires,\nparachains can renew it at a fixed cost through a bulk coretime purchase. If the parachain does not\npurchase bulk coretime, it has an option to purchase coretime on-demand (at a variable price per\nblock, depending on the demand and other market conditions) when they need to access the relay\nchain. Parachains without coretime to extend time on a relay chain core will be deprecated to the\nstatus of a parathread (i.e., a chain with a registered ParaID but without access to a core)."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain system parachains\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "System parachains are parachains that use execution cores allocated by\nthe network's governance. These chains remove transactions from the relay chain, allowing network\nvalidators to allocate resources to validating parachains. System chains are Polkadot using its\nscaling technology to host itself."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain on-demand parachains\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "On-demand parachains were previously named parathreads\nOn-demand parachains (previously called parathreads) are parachains that acquire on-demand coretime.\nOn-demand parachains temporarily participate (on a block by block basis) in network security without\nneeding to lease a dedicated relay chain core. This is done through economically sharing the scarce\nresource of a core among several competing resources (parachains). Chains that otherwise would not\nbe able to acquire a full core or do not find it economically sensible to do so, can participate in\nshared security, as the on-demand coretime offers a\ngraceful off-ramp to parachains that no longer require a dedicated core, but would like to continue\nusing the relay chain."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain historical context of on-demand parachains\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "According to this talk in Chengdu back in 2019, the\norigin of the idea for on-demand parachains came from similar notions in the limited resource of\nmemory on early personal computers of the late '80s and '90s. Since computers have a limited amount\nof physical memory, when an application needs more, the computer can create virtual memory by using\nswap space on a hard disk. Swap space allows the capacity of a computer's memory to expand and for\nmore processes to run concurrently with the trade-off that some processes will take longer to\nprogress."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain parachains vs. on-demand parachains\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Parachains and on-demand parachains are very similar from a development perspective. One can imagine\nthat a chain developed with Substrate can at different points in its lifetime assume one of three\nstates:\nan independent chain with secured bridge,\na parachain continuously connected to the relay chain,\nor a parachain intermittently connected to the relay chain (i.e. on-demand)\nIt can switch between these states with relatively minimal effort since the difference is more of an\neconomic distinction than a technological one.\nOn-demand parachains have the exact same benefits for connecting to the relay chain that a full\nparachain has. Namely, it is able to send messages to other para-objects through\nXCMP and it is secured under the full economic security of the relay chain\nvalidator set."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain parachains' use cases\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Note that we still have to see the true potential of parachains and what it is listed below are just\na few examples.\nEncrypted Consortium Chains: These are possibly private chains that do not leak any\n  information to the public but still can be interacted with trustlessly due to the nature of the\n  XCMP protocol.\nHigh-Frequency Chains: These chains can compute many transactions in a short amount of time by\n  taking certain trade-offs or making optimizations.\nPrivacy Chains: These chains do not leak any information to the public through novel\n  cryptography.\nSmart Contract Chains: These chains can have additional logic implemented through the\n  deployment of code known as smart contracts."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain parachain host\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "A blockchain is a Directed Acyclic Graph\n(DAG) of state transitions, where every added block can be viewed as the head of the chain or fork\nwith cumulative state. All paths through the DAG terminate at the Genesis Block. A blockchain is a\ntree, as each block can have only one parent.\nA blockchain network is made of nodes that have a view of many forks of the chain and must decide\nwhich fork to follow. To construct the parachain host we need to answer two categories of questions\naddressed by two different components:\nWhat is the state transition function of the blockchain? This is handled by the Runtime, which\n  defines the state transition logic of the chain. The Runtime logic is divided into:\n\n\nModules encapsulate particular behavior of the protocol and consist of:\n\nStorage\nRoutines are invoked by entry points and other modules upon block initialization or closing.\n  Routines can alter the storage of a module.\nThe entry point defines how new information is introduced to a module and can limit the origin\n  from which they are called (user, root, parachain).\n\n\nAPI provides means for the node-side behavior to extract meaningful information from the\n    state of a single fork.\n!!!info The Polkadot Parachain Host Implementers' Guide provides details about\n  Runtime Architecture and\n  Runtime API.\nKnowing various forks of the blockchain, what behaviors should a node take? What information\n  should a node extract from the state of which forks, and how should that information be used? This\n  is handled by the Node-side behavior, which defines all activities a node undertakes given its\n  view of the blockchain. The node-side behavior can be divided into two categories:\n\n\nNetworking behaviors, relate to how information is distributed between nodes but not how the\n    information is used afterward.\n\nCore behaviors, relate to internal work that a specific node does. Such behavior cares about\n    that information is distributed and received, but not how these two are achieved.\nThese two categories often interact, but they can be heavily abstracted from each other. The\n  node-side behavior is split into various subsystems, which perform a particular category of\n  work. Subsystems can communicate with each other through an\n  Overseer that prevents race\n  conditions.\n!!!info\n      The Polkadot Parachain Host Implementers' Guide provides details about node architecture the main subsystems:\n- [Collator subsystem](https://paritytech.github.io/polkadot/book/node/collators/index.html)\n  - [Backing subsystem](https://paritytech.github.io/polkadot/book/node/backing/index.html)\n  - [Availability subsystem](https://paritytech.github.io/polkadot/book/node/availability/index.html)\n  - [Approval subsystem](https://paritytech.github.io/polkadot/book/node/approval/index.html)\n  - [Dispute subsystem](https://paritytech.github.io/polkadot/book/node/disputes/index.html)\n  - [Utility subsystem](https://paritytech.github.io/polkadot/book/node/utility/index.html)\nThe Runtime and Node-side behavior are dependent on each other. The Runtime depends on Node-side\nbehavior to author blocks, and to include extrinsics which trigger the\ncorrect entry points. The Node-side behavior relies on the Runtime APIs to extract information\nnecessary to determine which action to take."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain parachain hubs\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "While the relay chain enables crosschain functionality amongst the parachains, it necessitates that\nthere is some latency between the dispatch of a message from one parachain until the destination\nparachain receives the message. In the optimistic scenario, the latency for this message should be\nat least two blocks - one block for the message to be dispatched and one block for the receiving\nparachain to process and produce a block that acts upon the message. However, in some cases, we may\nsee that the latency for messages is higher if many messages are in queue to be processed or if no\nnodes are running both parachain networks that can quickly gossip the message across the networks.\nDue to the necessary latency in sending crosschain messages, some parachains plan to become hubs\nfor an entire industry (see the Asset Hub and\nBridge Hub). For example, many DeFi applications could take\nadvantage of a property known as composability which means that functions of one application can\nbe synergistically composed with others to create new applications. One example of this includes\nflash loans, which borrow funds to execute some on-chain logic as long as the loan is repaid at the\nend of the transaction.\nAn issue with crosschain latency means that composability property weakens among parachains compared\nto a single blockchain. This implication is common to all sharded blockchain designs, including\nPolkadot, Ethereum, and others. The solution to this is the introduction of parachain hubs, which\nmaintain the stronger property of single block composability."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain resources\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot: The Parachain -\n  Blog post by Polkadot co-founder Rob Habermeier who introduced parachains in 2017 as \"a simpler\n  form of blockchain, which attaches to the security provided by a relay chain rather than providing\n  its own. The relay chain provides security to attached parachains, but also provides a guarantee\n  of secure message-passing between them.\"\nThe Path of a Parachain Block - A\n  technical walk-through of how parachains interact with the relay chain."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain data ownership\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In web3, ownership is achieved and validated through cryptography. Each user has a digital identity\nbound to a set of cryptographic keys usually based on the public key cryptographic scheme, i.e., the\nfamous public and private key pair.\nUnlike Web2 which is driven by email IDs, phone numbers, and passwords, users onboarding to Web3\njust need to generate a key pair. The public key can be the identity that can be shared with anybody\nto send you messages or assets, while the private key is used to access your account, sign messages,\ntransfer funds, edit identity details, etc. Keeping your private key secure is\nessential to avoid identity theft or consequent loss of funds. Currently, scams are one of the main\nfactors hindering web3 adoption. No legitimate person or entity will ever ask you to share your\nprivate key, and those who attempt to do so are likely trying to steal your digital identity and\nanything you own related to it.\nTo mitigate risks of key mismanagement (for non-custodial accounts, i.e. when you have custody\nof your keys) there are account abstraction solutions that\nseparate the key management from the user experience. To mitigate key hacks, there are cold wallet\nsolutions where the private key is generated and stored on dedicated devices with secure elements\nthat are not exposed to the internet (see Ledger), or dedicated applications that can\nbe installed on air-gapped devices such as phones (see Polkadot Vault). For\ncustodial accounts, you trust third parties to manage your keys and give you access whenever\nneeded.\nTo summarize, data ownership comes from the fact that any message you sign with your private key\ncomes from your digital identity, and the signature proof can be cryptographically verified. Unless\nsomeone else stole your keys, you and only you are held accountable for signing the messages and are\nresponsible for the information on your account. Transferring an NFT between\ntwo accounts is essentially a transfer of ownership."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain data immutability\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "But what if the data we own can be easily modified or tampered with after they have been signed and\nstored?\nHere is where blockchain technology plays an important role. Blockchain networks comprise of\ndistributed state machines where increments of data are stored within blocks that build on each\nother using hash functions. For example, the hash of block N + 1 contains data of that block\ntogether with the hash of the previous block N. This creates the situation where if you modify the\ncontent of block N you will change the hash of block N + 1, N + 2, etc. essentially breaking\nthe chain. If a blockchain network is not sufficiently decentralized, it can be possible to add an\ninvalid block (a block with invalid transactions) or to censor certain transactions. In\ndecentralized proof-of-stake blockchains like Polkadot however, such attacks are financially\nexpensive and attempting them can get you slashed.\nSo, with blockchain as a means of storing data and transactions permanently without an option to\nmodify them, we can ensure what we cryptographically sign with our digital identity is set in stone\ndigitally."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain data retrievability\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "But what if our data are stored in a blockchain, but that blockchain is run on a centralized server\nor by different computers belonging to the same operator?\nThat server or those computers can be easily shut down, the blockchain can be stopped from running\nand its data wiped out. This can be achieved from the inside by the malicious network participants\nor from the outside by regulatory rules and other forces. Though blockchain offers immutability,\nthere would be little sense in using a centralized blockchain to prove ownership as it can possibly\ncease to exist in the future.\nData retrievability is dependent on how resilient the blockchain is. Resiliency is achieved through\nelements such as decentralization, economic incentives, and on-chain governance to ensure the\nnetwork can sustain on its own.\nData Retrievability vs. Data Availability\nData retrievability is the ability of nodes to retrieve\u00a0historical information\u00a0from the blockchain. Historical data is not needed to verify new blocks; it is only required for synching full nodes from the Genesis block or serving specific historical requests.\nData availability assures full nodes can access and verify the full transactions associated with\na specific block. It does not necessarily imply that the data is accessible forever. For more\ninformation about data availability on Polkadot, see the\ndedicated section on the parachain protocol page."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain decentralization\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Having multiple nodes belonging to numerous independent identities increases network resiliency and\nthus data retrievability.\nBlockchain is a state machine, and consensus must be achieved on every single state transition by\nevery node on the blockchain network. In Proof of Work (PoW) based blockchains, which let any node\nin the network produce a block, consensus is achieved probabilistically by building on the longest\nchain (at the cost of energy-intensive computations). Proof of Stake (PoS) based blockchains like\nPolkadot enable deterministic consensus by allowing only a limited number of privileged nodes to\nproduce blocks. A PoW blockchain can be considered centralized if a single entity can capture 51% of\nnetwork nodes. Similarly, a PoS blockchain can be considered centralized if a single entity controls\nmore than one-third of nodes, as a two-thirds majority is required to arrive at a deterministic\nconsensus. Different blockchains have different levels of decentralization.\nNowadays, most of the nodes cannot be run on consumer-grade hardware. Node running equipment is\ntypically rented through service providers. Resiliency is also achieved by ensuring nodes run on as\nmany different providers as possible and avoiding a significant share of the nodes being run under\nthe same provider in the same geographic region. A legislation change or a natural disaster could\nimpact a considerable fraction of the nodes and potentially stop the network. Polkadot's level of\ndecentralization can be explored through the Polkawatch app.\nThe Decentralized Nodes program aims to incentivize the creation\nof new validator nodes to increase the level of node decentralization."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain decentralized storage\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Blockspace is limited and valuable. Not all data we have can be stored on\nthe blockchain. Large files like pictures, music, movies, etc., typically will never be held on the\nblockchain. But where can we stored those files? To stick to the web3 vision, we need a resilient\nand decentralized storage solution.\nThe most important thing is that the proof of ownership is stored on the blockchain through the\nhashes of data and metadata. The files are uploaded on decentralized storage networks hosting\nprotocols like IPFS."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain stake allocation\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In Proof-of-Stake blockchains, security is dictated by how much stake is locked on-chain (financial\nsecurity). In a decentralized network, you want to ensure that the difficulty level for a financial\nattack to happen is equally difficult across all nodes. Polkadot's\nelection algorithm makes sure that the stake is maximized across all\nactive validators, and the variance in stake across validators is minimized as much as possible."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain economic incentives\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Strong incentives are essential to incentivize network participants to run nodes and secure the\nnetwork. Strong incentives are possible because blockchain is a trustless system where there are no\nintermediaries between who sends a message and who receives it. Such incentives, coupled with\npunishment for bad behavior, ensure that most of the participants make the interest of the network\nand work together to improve it.\nBut from where are those incentives coming from? Polkadot's native token\nDOT is inflationary. Inflation is used to pay validators for running\nnodes and reward nominators for providing the necessary stake to secure the network."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain governance and treasury\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In Polkadot, an on-chain treasury together with an\nopen governance model allow to access funds in a fully\ndecentralized manner without any bank transaction whatsoever. This opens up the possibility to come\nto a decision through on-chain voting mechanism, promoting a sense of community and creating an\nindependent socio-economical environment."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain decentralized access points\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "But what if we have data we own stored on a resilient blockchain, but the only way to access the\nblockchain is through an RPC server? Whoever is behind the server or an attacker could present us\ndata that is not the truth. How can we trustlessly verify that the data is true?\nHere is where light clients play a key role. Light clients are clients that can sit on a web browser\nand can fetch data directly from blockchain. The figure below shows the architectural difference\nbetween web2 and web3 applications.\nIn web2 applications, data are stored on a centralized server, while in web3 applications, data (or\nbetter data proofs) are stored on the blockchain. With light clients, it is possible to access\nblockchain data through a full node and verify the validity of such data. They efficiently\nsynchronize (warp sync in case of Polkadot) with a full node to obtain (Merkle Root) commitment of\nthe latest chain state, and hence can trustlessly verify any response by full node against the\ncommitment. In this way, we can always verify that the data we see is the truth, which is done\nautomatically by the light client. Polkadot has a browser-embedded light client\nSubstrate connect that uses the\nsmoldot codebase. Most web3 applications today access\nblockchain data through a centralized RPC server.\nFor more details about the inner workings of Smoldot, see\nthis blog post and\nthis video."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain interoperability\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The Web3 landscape's expansion into a multi-layered ecosystem highlights the need for\ninteroperability. Blockchains compete and differentiate themselves based on decentralization,\nthroughput, and specific use case focus. Some aim for a single high-performance base-layer\nblockchain, while others focus on decentralization through layer-2 networks. With such diverse\napproaches, it's crucial for distinct on-chain environments to interoperate, especially for\ndevelopers building cross-chain applications and traditional systems interacting with multiple\nblockchains.\nVarious cross-chain interactions are employed to achieve interoperability, including token swaps,\ntoken bridges, native payments, contract calls, and programmable token bridges. Each mechanism\nserves specific functions, such as facilitating the exchange of tokens between different blockchains\nor enabling smart contract interactions across chains. Other interoperability solutions validate the\nstate of a source blockchain and relay transactions to the destination blockchain, which is\nessential for completing cross-chain interactions.\nInteroperability between chains having different consensus has been a challenging task. Most of\nhacks have exploited vulnerabilities in interoperability protocols. Polkadot provides secure\ninteroperability through XCM and XCMP to\nall blockchains attached to it. For more information, see the Polkadot 1.0 page\nand\nthe section about XCM and Accords in Polkadot Direction page."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain introduction\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot\u2019s unique value lies in its ability to enable interoperability between parachains and other blockchain systems. At the core of this capability is XCM (Cross-Consensus Messaging)\u2014a flexible messaging format that facilitates communication and collaboration between independent consensus systems.\nWith XCM, one chain can send intents to another one, fostering a more interconnected ecosystem. Although it was developed specifically for Polkadot, XCM is a universal format, usable in any blockchain environment. This guide provides an overview of XCM\u2019s core principles, design, and functionality, alongside practical examples of its implementation."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain messaging format\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "XCM is not a protocol but a standardized messaging format. It defines the structure and behavior of messages but does not handle their delivery. This separation allows developers to focus on crafting instructions for target systems without worrying about transmission mechanics.\nXCM messages are intent-driven, outlining desired actions for the receiving blockchain to consider and potentially alter its state. These messages do not directly execute changes; instead, they rely on the host chain's environment to interpret and implement them. By utilizing asynchronous composability, XCM facilitates efficient execution where messages can be processed independently of their original order, similar to how RESTful services handle HTTP requests without requiring sequential processing."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain the four principles of xcm\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "XCM adheres to four guiding principles that ensure robust and reliable communication across consensus systems:\nAsynchronous - XCM messages operate independently of sender acknowledgment, avoiding delays due to blocked processes\nAbsolute - XCM messages are guaranteed to be delivered and interpreted accurately, in order, and timely. Once a message is sent, one can be sure it will be processed as intended\nAsymmetric - XCM messages follow the 'fire and forget' paradigm meaning no automatic feedback is provided to the sender. Any results must be communicated separately to the sender with an additional message back to the origin\nAgnostic - XCM operates independently of the specific consensus mechanisms, making it compatible across diverse systems\nThese principles guarantee that XCM provides a reliable framework for cross-chain communication, even in complex environments."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain core functionalities of xcm\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "XCM enhances cross-consensus communication by introducing several powerful features:\nProgrammability - supports dynamic message handling, allowing for more comprehensive use cases. Includes branching logic, safe dispatches for version checks, and asset operations like NFT management\nFunctional Multichain Decomposition - enables mechanisms such as remote asset locking, asset namespacing, and inter-chain state referencing, with contextual message identification \nBridging - establishes a universal reference framework for multi-hop setups, connecting disparate systems like Ethereum and Bitcoin with the Polkadot relay chain acting as a universal location\nThe standardized format for messages allows parachains to handle tasks like user balances, governance, and staking, freeing the Polkadot relay chain to focus on shared security. These features make XCM indispensable for implementing scalable and interoperable blockchain applications."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain xcm example\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The following is a simplified XCM message demonstrating a token transfer from Alice to Bob on the same chain (ParaA).\nlet message = Xcm(vec![\n    WithdrawAsset((Here, amount).into()),\n    BuyExecution { \n        fees: (Here, amount).into(), \n        weight_limit: WeightLimit::Unlimited \n    },\n    DepositAsset {\n        assets: All.into(),\n        beneficiary: MultiLocation {\n            parents: 0,\n            interior: Junction::AccountId32 {\n                network: None,\n                id: BOB.clone().into()\n            }.into(),\n        }.into()\n    }\n]);\nThe message consists of three instructions described as follows:\nWithdrawAsset - transfers a specified number of tokens from Alice's account to a holding register\nWithdrawAsset((Here, amount).into()),\n\n\nHere - the native parachain token\namount - the number of tokens that are transferred\n\nThe first instruction takes as an input the MultiAsset that should be withdrawn. The MultiAsset describes the native parachain token with the Here keyword. The amount parameter is the number of tokens that are transferred. The withdrawal account depends on the origin of the message. In this example the origin of the message is Alice. The WithdrawAsset instruction moves amount number of native tokens from Alice's account into the holding register.\n\n\nBuyExecution - allocates fees to cover the execution weight of the XCM instructions\nBuyExecution { \n    fees: (Here, amount).into(), \n    weight_limit: WeightLimit::Unlimited \n},\n\n\nfees - describes the asset in the holding register that should be used to pay for the weight \nweight_limit - defines the maximum fees that can be used to buy weight\n\n\n\nDepositAsset - moves the remaining tokens from the holding register to Bob\u2019s account\nDepositAsset {\n    assets: All.into(),\n    beneficiary: MultiLocation {\n        parents: 0,\n        interior: Junction::AccountId32 {\n            network: None,\n            id: BOB.clone().into()\n        }.into(),\n    }.into()\n}\n\n\nAll - the wildcard for the asset(s) to be deposited. In this case, all assets in the holding register should be deposited\nThis step-by-step process showcases how XCM enables precise state changes within a blockchain system. You can find a complete XCM message example in the XCM repository."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain overview\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "XCM revolutionizes cross-chain communication by enabling use cases such as:\nToken transfers between blockchains\nAsset locking for cross-chain smart contract interactions\nRemote execution of functions on other blockchains\nThese functionalities empower developers to build innovative, multi-chain applications, leveraging the strengths of various blockchain networks. To stay updated on XCM\u2019s evolving format or contribute, visit the XCM repository.\nLast update:\nApril 22, 2025\n\n|\nCreated:\nOctober 18, 2024"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain introduction\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot's Proof of Stake consensus model leverages a unique hybrid approach by design to promote decentralized and secure network operations. In traditional Proof of Stake (PoS) systems, a node's ability to validate transactions is tied to its token holdings, which can lead to centralization risks and limited validator participation. Polkadot addresses these concerns through its Nominated Proof of Stake (NPoS) model and a combination of advanced consensus mechanisms to ensure efficient block production and strong finality guarantees. This combination enables the Polkadot network to scale while maintaining security and decentralization."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain nominated proof of stake\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot uses Nominated Proof of Stake (NPoS) to select the validator set and secure the network. This model is designed to maximize decentralization and security by balancing the roles of validators and nominators.\nValidators - play a key role in maintaining the network's integrity. They produce new blocks, validate parachain blocks, and ensure the finality of transactions across the relay chain\nNominators - support the network by selecting validators to back with their stake. This mechanism allows users who don't want to run a validator node to still participate in securing the network and earn rewards based on the validators they support\nIn Polkadot's NPoS system, nominators can delegate their tokens to trusted validators, giving them voting power in selecting validators while spreading security responsibilities across the network."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain hybrid consensus\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot employs a hybrid consensus model that combines two key protocols: a finality gadget called GRANDPA and a block production mechanism known as BABE. This hybrid approach enables the network to benefit from both rapid block production and provable finality, ensuring security and performance.\nThe hybrid consensus model has some key advantages:\nProbabilistic finality - with BABE constantly producing new blocks, Polkadot ensures that the network continues to make progress, even when a final decision has not yet been reached on which chain is the true canonical chain\n\n\nProvable finality - GRANDPA guarantees that once a block is finalized, it can never be reverted, ensuring that all network participants agree on the finalized chain\nBy using separate protocols for block production and finality, Polkadot can achieve rapid block creation and strong guarantees of finality while avoiding the typical trade-offs seen in traditional consensus mechanisms."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain block production - babe\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Blind Assignment for Blockchain Extension (BABE) is Polkadot's block production mechanism, working with GRANDPA to ensure blocks are produced consistently across the network. As validators participate in BABE, they are assigned block production slots through a randomness-based lottery system. This helps determine which validator is responsible for producing a block at a given time. BABE shares similarities with Ouroboros Praos but differs in key aspects like chain selection rules and slot timing.\nKey features of BABE include:\nEpochs and slots - BABE operates in phases called epochs, each of which is divided into slots (around 6 seconds per slot). Validators are assigned slots at the beginning of each epoch based on stake and randomness\n\n\nRandomized block production - validators enter a lottery to determine which will produce a block in a specific slot. This randomness is sourced from the relay chain's randomness cycle\n\n\nMultiple block producers per slot - in some cases, more than one validator might win the lottery for the same slot, resulting in multiple blocks being produced. These blocks are broadcasted, and the network's fork choice rule helps decide which chain to follow\n\n\nHandling empty slots - if no validators win the lottery for a slot, a secondary selection algorithm ensures that a block is still produced. Validators selected through this method always produce a block, ensuring no slots are skipped\nBABE's combination of randomness and slot allocation creates a secure, decentralized system for consistent block production while also allowing for fork resolution when multiple validators produce blocks for the same slot."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain validator participation\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In BABE, validators participate in a lottery for every slot to determine whether they are responsible for producing a block during that slot. This process's randomness ensures a decentralized and unpredictable block production mechanism.\nThere are two lottery outcomes for any given slot that initiate additional processes:\nMultiple validators in a slot - due to the randomness, multiple validators can be selected to produce a block for the same slot. When this happens, each validator produces a block and broadcasts it to the network resulting in a race condition. The network's topology and latency then determine which block reaches the majority of nodes first. BABE allows both chains to continue building until the finalization process resolves which one becomes canonical. The Fork Choice rule is then used to decide which chain the network should follow\n\n\nNo validators in a slot - on occasions when no validator is selected by the lottery, a secondary validator selection algorithm steps in. This backup ensures that a block is still produced, preventing skipped slots. However, if the primary block produced by a verifiable random function (VRF)-selected validator exists for that slot, the secondary block will be ignored. As a result, every slot will have either a primary or a secondary block\nThis design ensures continuous block production, even in cases of multiple competing validators or an absence of selected validators."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain finality gadget - grandpa\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "GRANDPA (GHOST-based Recursive ANcestor Deriving Prefix Agreement) serves as the finality gadget for Polkadot's relay chain. Operating alongside the BABE block production mechanism, it ensures provable finality, giving participants confidence that blocks finalized by GRANDPA cannot be reverted.\nKey features of GRANDPA include:\nIndependent finality service \u2013 GRANDPA runs separately from the block production process, operating in parallel to ensure seamless finalization\nChain-based finalization \u2013 instead of finalizing one block at a time, GRANDPA finalizes entire chains, speeding up the process significantly\nBatch finalization \u2013 can finalize multiple blocks in a single round, enhancing efficiency and minimizing delays in the network\nPartial synchrony tolerance \u2013 GRANDPA works effectively in a partially synchronous network environment, managing both asynchronous and synchronous conditions\nByzantine fault tolerance \u2013 can handle up to 1/5 Byzantine (malicious) nodes, ensuring the system remains secure even when faced with adversarial behavior\nWhat is GHOST?\nGHOST (Greedy Heaviest-Observed Subtree) is a consensus protocol used in blockchain networks to select the heaviest branch in a block tree. Unlike traditional longest-chain rules, GHOST can more efficiently handle high block production rates by considering the weight of subtrees rather than just the chain length."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain probabilistic vs. provable finality\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In traditional Proof of Work (PoW) blockchains, finality is probabilistic. As blocks are added to the chain, the probability that a block is final increases, but it can never be guaranteed. Eventual consensus means that all nodes will agree on a single version of the blockchain over time, but this process can be unpredictable and slow.\nConversely, GRANDPA provides provable finality, which means that once a block is finalized, it is irreversible. By using Byzantine fault-tolerant agreements, GRANDPA finalizes blocks more efficiently and securely than probabilistic mechanisms like Nakamoto consensus. Like Ethereum's Casper the Friendly Finality Gadget (FFG), GRANDPA ensures that finalized blocks cannot be reverted, offering stronger consensus guarantees."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain fork choice\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The fork choice of the relay chain combines BABE and GRANDPA:\nBABE must always build on the chain that GRANDPA has finalized\nWhen there are forks after the finalized head, BABE builds on the chain with the most primary blocks to provide probabilistic finality\nIn the preceding diagram, finalized blocks are black, and non-finalized blocks are yellow. Primary blocks are labeled '1', and secondary blocks are labeled '2.' The topmost chain is the longest chain originating from the last finalized block, but it is not selected because it only has one primary block at the time of evaluation. In comparison, the one below it originates from the last finalized block and has three primary blocks."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain bridging - beefy\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Bridge Efficiency Enabling Finality Yielder (BEEFY) is a specialized protocol that extends the finality guarantees provided by GRANDPA. It is specifically designed to facilitate efficient bridging between Polkadot relay chains (such as Polkadot and Kusama) and external blockchains like Ethereum. While GRANDPA is well-suited for finalizing blocks within Polkadot, it has limitations when bridging external chains that weren't built with Polkadot's interoperability features in mind. BEEFY addresses these limitations by ensuring other networks can efficiently verify finality proofs.\nKey features of BEEFY include:\nEfficient finality proof verification - BEEFY enables external networks to easily verify Polkadot finality proofs, ensuring seamless communication between chains\nMerkle Mountain Ranges (MMR) - this data structure is used to efficiently store and transmit proofs between chains, optimizing data storage and reducing transmission overhead\nECDSA signature schemes - BEEFY uses ECDSA signatures, which are widely supported on Ethereum and other EVM-based chains, making integration with these ecosystems smoother\nLight client optimization - BEEFY reduces the computational burden on light clients by allowing them to check for a super-majority of validator votes rather than needing to process all validator signatures, improving performance"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain nominating vs joining a pool\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Nominating\nJoining a Pool\n\n\n\n\nMinimum 250 DOT to nominate.\nMinimum 1 DOT to be a member.\n\n\nRewards can be compounded automatically or sent to any account.\nRewards can be manually claimed to the pool member's account and be bonded in the pool again to compound them.\n\n\nIf the active validator gets slashed, all active nominators are subjected to slashing.\nIf the active validator gets slashed, all pool members are subjected to slashing.\n\n\nCan bond and stake DOT indefinitely.\nCan bond and stake DOT until the pool exists.\n\n\nMaximum unbonding period of 28 days. Can switch validators without unbonding.\nMaximum unbonding period of 28 days. Need to unbond before switching to a different pool.\n\n\nMaximum uncapped.\nMaximum uncapped.\n\n\nShould bond more than the minimum active nomination in an era to be eligible to earn staking rewards, although it can depend on multiple other factors outlined in the linked document.\nA nomination pool earns rewards in an era if it satisfies all the conditions mentioned for the nominator (as the nomination pool is just a nominator from the NPoS system perspective).\n\n\nStaked tokens can be used for participation in Governance.\nStaked tokens can be used for participation in Governance.\n\n\nRewards payout can be triggered permissionlessly by anyone (typically done by the validator).\nA pool member can self claim the rewards or can grant permission to any other account to claim and compound rewards on your behalf. See Claim Permissions.\n\n\nBonded funds remain in your account.\nBonded funds remain in your account.\n\n\nNominator manages the list of staked validators (up to 16).\nNominations managed by the pool operator."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain join a pool\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Ledger users\nJoining a nomination pool is possible only with the XL version of the Polkadot Ledger App. This should be installed by default on Ledger Nano X and S Plus, but not on the Nano S.\nBefore joining a nomination pool, you must ensure that the\npool is earning rewards and nominating the validators that match your preferences. Participating in\npools is more of a set-and-forget action than nominating by yourself. The pool operator maintains\nthe list of validators nominated by the pool, and so, in a way, you are trusting the pool operator\nto act in your best interests. However, it is advised to check the validators nominated by the pool\nfrom time to time and change the pool if necessary.\nA member delegates funds to a pool with the join extrinsic. The pool then increases its bond with the new funds. A member is afforded the\nability to bond additional funds or re-stake rewards as long as they are already actively bonded.\nNote that a member may only belong to one pool at a time.\nThe current minimum bond to join a pool can be seen\nhere.\nUse Proxy Accounts to join Nomination Pools\nDepending on how much control you want to give your proxy, you might choose between any > non-transfer > staking > nomination pool proxy, with the latter being only able to sign transactions related to the NominationPool pallet.\nCheck the \"How to join a pool\" section in\nthis support article\nfor guidelines."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain claim permissions\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "As a pool member, you can grant permission to any other account to claim and compound rewards on\nyour behalf. There are four permission options:\nPermissioned (default): you need to claim and compound your rewards.\nPermissionlessCompound: you grant permission to any other account to compound (claim and bond)\n  your rewards on your behalf.\nPermissionlessWithdraw: you grant permission to any other account to withdraw (claim and keep as\n  a free balance) your rewards on your behalf.\nPermissionlessAll: you grant permission to any other account to compound or withdraw your\n  rewards on your behalf.\nSee the Staking Dashboard page for more information about how to set your claim permissions.\nSee the advanced guides to\nlearn how to claim rewards for another pool member."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain vote in opengov\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Nomination pool members can vote in Polkadot OpenGov with funds they delegated to the pool. In the past, pool members' funds were transferred to the pool system account. A delegation staking system was introduced to allow keeping ownership of your funds and voting in governance.\nDual Staking\nFor pool members who were dual staking (i.e., pool members and nominators) before the introduction of delegation staking, follow these guides to migrate manually to the new system."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain unbond and withdraw funds\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "At any point in time after joining the pool, a member can start the process of exiting by unbonding.\nunbond will unbond part or all of the member's funds. After unbond has been called and the\nunbonding duration has passed a member may\nwithdraw their funds with withdrawUnbonded. Withdrawing effectively ends a member's relationship\nwith their pool, allowing them to join a different pool if desired. Check the \"Withdraw unbonded\nfunds\" section in\nthis support article\nfor guidelines.\nUnbonding transaction automatically triggers withdrawal of rewards\nWhen there is a change in the bonded balance, the accumulated rewards in the pool thus far are automatically withdrawn to the account. The rewards are then accrued based on the updated bonded balance."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain nomination pools - lazy slashing\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Because pool funds are spread to all its members and each member need to be slashed proportionally, slashes are applied to pool members lazily. The protocol keeps track of how much a pool and its members need to be slashed. There is a permissionless extrinsic to apply any pending slash to the pool member. If successful, the caller gets part of slash as reward (if configured), incentivising free market bots to monitor and apply slashes swiftly.\nThe advantage is, the slashing (computation) cost is spread over multiple blocks. A disadvantage is that a member might have more funds in their account locked than their actual pool contribution, which they can use to vote, until these pending slashes are applied.\nSuppose the staking system slashes a pool\u2019s underlying nomination account. In\nthat case, the slash is distributed evenly across the bonded pool, and the unbonding pools from\nslash era+1 through the slash apply era. Thus, any member who either a) was unbonding or b) was\nactively bonded in the aforementioned range of eras will be affected by the slash. In other words, a\nmember who may have been actively bonded during the offence is slashed pro rata based on its stake\nrelative to the total slash amount.\nUnbonding pools need to be slashed to ensure all nominators who were in the bonded pool while it was\nbacking a validator that committed an offense are punished. Without these measures a nominator could\nunbond right after a validator equivocated with no consequences.\nThis strategy is unfair to members who joined after the slash because they get slashed as well, but\nit spares members who unbond. The latter is much more important for security: if a pool's validators\nattack the network, their members need to unbond fast! Avoiding additional slashes gives them an\nincentive to do that if validators get repeatedly slashed."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain roles\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Depositor: Creates the pool and is the initial member. The depositor can only leave the pool once\n  all other members have left. Once they leave by withdrawing, the pool is fully removed from the\n  system.\nNominator: Can select the validators the pool nominates.\nBouncer: Can change the pool\u2019s state and kick (permissionlessly unbond/withdraw) members if the\n  pool is blocked.\nRoot: Can change the nominator, bouncer, or itself. Further, it can perform any of the actions the\n  nominator or bouncer can."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain pool commissions\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "As the pool root role, you can set pool commissions that will be applied to the staking rewards paid\nout to the pool's system account before rewards are allocated for the pool members. You can set pool\ncommissions through the Polkadot Staking Dashboard.\nThree methods can be used when setting the pool commission:\nCommission Rate (nominationPools.setCommission extrinsic): the start or new commission rate\n  (newCommission parameter) that can be set between 0% and the\n  max commission parameter\n  (decided through governance referendum) via the\n  globalMaxCommission\n  parameter. You will need to specify an Input Payee Account, i.e. the account that will receive the\n  commission.\nMax Commission (nominationPools.setCommissionMax extrinsic): the maximum commission\n  (maxCommission parameter) the pool will apply to its members (between 0% and Max Commission).\n  Note that once set, the pool admin can only lower it.\nChange Rate (nominationPools.setCommissionChangeRate extrinsic): the maximum rate increase\n  (maxIncrease parameter) allowed for a single commission update. Note that once set, the pool\n  admin can only lower it. When setting the Change Rate, it will also be possible to set a\n  minDelay quantified as the number of blocks (since last commission update) after which it is\n  possible to change the commission (i.e. the minimum delay between commission updates). Note that\n  once set, the pool admin can only increase it.\nMax Commission and Change Rate must not be necessarily set. It is the choice of the pool admin to\nset those parameters and provide transparency to the pool members about the pool's commission\npolicy.\nMax Commission and Change Rate are currently permanent\nOnce the Max Commission and the Change Rate are set, the pool admin currently can only decrease those values. The minimum delay between commission updates can only be increased. The situation can change in the future and a forceSetCommissionMax method can be proposed through governance referendum.\nLet's take, for example, Pool A, which sets the Commission Rate to 10%, the Max Commission to 100%,\nand the Change Rate to 1% every 300 blocks (which equates to approximately 30 minutes). The\nfollowing statements are true:\nThe pool commission can be increased by 1% every 30 minutes. Bigger increases are not allowed.\n  Increases of less than or equal to 1% are not allowed sooner than 30 minutes since the last\n  commission update.\nThe Max Commission can only be decreased from 100%. Once decreased, it can be decreased again but\n  it cannot be increased.\nThe Change Rate's maximum increase can only be decreased from 1%. Once decreased, it can be\n  decreased again but it cannot be increased.\nThe Change Rate's minimum delay between updates of 30 min can only be increased. Once increased,\n  it can be increased again but it cannot be decreased."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain sub-identities\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Users can also link accounts by setting \"sub accounts\", each with its own identity, under a primary\naccount. The system reserves a bond for each sub account. An example of how you might use this would\nbe a validation company running multiple validators. A single entity, \"My Staking Company\", could\nregister multiple sub accounts that represent the Stash accounts of each of\ntheir validators.\nAn account can have a maximum of 100 sub-accounts. Note that a\ndeposit is required for every sub-account."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain judgements\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "After a user injects their information on chain, they can request judgement from a registrar. Users\ndeclare a maximum fee that they are willing to pay for judgement, and registrars whose fee is below\nthat amount can provide a judgement.\nWhen a registrar provides judgement, they can select up to six levels of confidence in their\nattestation:\nUnknown: The default value, no judgement made yet.\nReasonable: The data appears reasonable, but no in-depth checks (e.g. formal KYC process) were\n  performed (all the currently verified identities on-chain).\nKnown Good: The registrar has certified that the information is correct (this step involves\n  verification of state issued identity documents, and at the moment no account has known good\n  identity, with the exception of registrars).\nOut of Date: The information used to be good, but is now out of date.\nLow Quality: The information is low quality or imprecise, but can be fixed with an update.\nErroneous: The information is erroneous and may indicate malicious intent.\nA seventh state, \"fee paid\", is for when a user has requested judgement and it is in progress.\nInformation that is in this state or \"erroneous\" is \"sticky\" and cannot be modified; it can only be\nremoved by the complete removal of the identity.\nRegistrars gain trust by performing proper due diligence and would presumably be replaced for\nissuing faulty judgments."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain registrars\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Registrars can set a fee for their services and limit their attestation to certain fields. For\nexample, a registrar could charge 1 DOT to verify one's legal name, email, and GPG key. When a user\nrequests judgement, they will pay this fee to the registrar who provides the judgement on those\nclaims. Users set a maximum fee they are willing to pay and only registrars below this amount would\nprovide judgement.\nThere are multiple registrars on Polkadot and Kusama. Unless no additional information is available\nhere, you must reach out to specific registrars individually if you want to be judged by those.\nDecommissioned Registrar Service\nFrom the 1st of April 2024 onwards, Registrar 0 will still exist on-chain but will not accept any new judgment requests. The registrar fee is set to a substantial amount to dissuade identity judgement requests. Identities judged by the registrar before that date will not be affected. For new identity judgment, please use the other registrars.\nPolkadotKusama\n\n\nRegistrar 0 :  URL: NA  Account:\n12j3Cz8qskCGJxmSJpVL2z2t3Fpmw3KoBaBaRGPnuibFc7o8  Fee: 0 DOT \nRegistrar 1:  URL: https://registrar.d11d.net/  Account:\n1Reg2TYv9rGfrQKpPREmrHRxrNsUDBQKzkYwP1UstD97wpJ  Fee: 20 DOT \nRegistrar 2:  Account: 1EpXirnoTimS1SWq52BeYx7sitsusXNGzMyGx8WPujPd1HB  Fee: 0\nDOT \nRegistrar 3:  Account: 13SceNt2ELz3ti4rnQbY1snpYH4XE4fLFsW8ph9rpwJd6HFC  Fee:\n0.5 DOT  Polkassembly (Registrar 3) provides setting on-chain ID as a service on their\nwebsite.\nRegistrar 4:  URL: https://polkaidentity.com/  Account:\n16LYBUcQKWZjAYE4oAPWx9XFaEYnCAffwpPuPWrUvU1mqBZT  Fee: 0.5 DOT  PolkaIdentity\n(Registrar 4) provides setting on-chain ID as a service on their\nwebsite.\n\n\nRegistrar 0 :  URL: NA  Account:\nH4XieK3r3dq3VEvRtqZR7wN7a1UEkXxf14orRsEfdFjmgkF  Fee: 0.04 KSM \nRegistrar 1:  URL: https://registrar.d11d.net/  Account:\nFom9M5W6Kck1hNAiE2mDcZ67auUCiNTzLBUdQy4QnxHSxdn  Fee: 4.5 KSM \nRegistrar 2: is no longer offering registrar services on Kusama.  Account:\nEK8veMNH6sVtvhSRo4q1ZRh6huCDm69gxK4eN5MFoZzo3G7  Fee: 1 KSM \nRegistrar 3:  Account: GLiebiQp5f6G5vNcc7BgRE9T3hrZSYDwP6evERn3hEczdaM  Fee: 1\nKSM  Polkassembly (Registrar 3) provides setting on-chain ID as a service on their\nwebsite.\nRegistrar 4:  Account: GhmpzxUyTVsFJhV7s2wNvD8v3Bgikb6WvYjj4QSuSScAUw6  Fee:\n0.04 KSM \nRegistrar 5:  Account: F1wAMxpzvjWCpsnbUMamgKfqFM7LRvNdkcQ44STkeVbemEZ  Fee:\n0.04 KSM  Polkassembly (Registrar 5) provides setting on-chain ID as a service on their\nwebsite.\nRegistrar 6:  URL: https://polkaidentity.com/  Account:\nHurhThD66KBUf2zcE9Zhx46sCqNJXviKhWAct95rBCkPuix  Fee: 0.04 KSM  PolkaIdentity\n(Registrar 6) provides setting on-chain ID as a service on their\nwebsite.\nSee this page to learn how to become a Registrar.\nPolkadot-JS Guides\nIf you are an advanced user, see the Polkadot-JS guides about account identity.\nSee also these Polkadot-JS support guides."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain premise\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot's first governance system Governance V1 included three\nmain components: the Technical Committee, the Council, the Public (i.e. all token holders).\nOver the first few years of operation, Governance V1 ensured the appropriate usage of treasury funds\nand enabled timely upgrades and fixes. Like most early technologies, protocols must evolve as they\nmature to improve their shortcomings and keep up with modern advancements. In Governance V1, all\nreferenda carried the same weight as only one referendum could be voted on at a time (except for\nemergency proposals), and the voting period could last multiple weeks. Also, an\nalternating voting timetable allowed to vote either for a public referendum or a council motion every 28 days (7 days on Kusama). This\nresulted in the system favoring careful consideration of very few proposals instead of broad\nconsideration of many.\nPolkadot OpenGov changes how the practical means of day-to-day decisions are made, making the\nrepercussions of referenda better scoped and agile to increase the number of collective decisions\nthe system can make at any given time.\nThe following content is focused on Polkadot OpenGov, and on the main differences with previous\ngovernance versions."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain summary\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In Governance v1, active token holders (public) and the Council administrated the network's upgrade\ndecisions. Whether the public or the council initiated the proposal, it would eventually have to go\nthrough a referendum to let all holders (weighted by stake and conviction) make the decision.\nThe Council fulfilled its role as the representative of the public, guardian of the treasury and\ninitiator of legislation, but it was often seen as a centralized entity. To further decentralize the\nnetwork, Polkadot OpenGov proposes the following main changes:\nMigrating all responsibilities of the Council to the public via a direct democracy voting system.\nDissolving the Council collective\nAllowing users to delegate voting power in more ways to community members\nDissolving the Technical Committee and establishing the broader Polkadot Technical Fellowship\nThe figure below shows an overview of Polkadot OpenGov's structure.\nIn Polkadot OpenGov, all the proposals are initiated by the public. The proposal will enter a\nLead-in period (for more information, see Referenda Timeline), after which it\nwill follow a specific Track which has a dedicated Origin. There are\n15 Origins, each with a different\ntrack. The origins and tracks parameters are preset values that set the duration of a referendum as\nwell as how many referenda can be voted on simultaneously. For example, a treasury proposal can now\nbe submitted in different tracks depending on the amount requested. A proposal for a small tip will\nneed to be submitted to the Small Tipper track, while a proposal requiring substantial funds will\nneed to be submitted to the Medium or Big Spender track.\nThe Polkadot Technical Fellowship can decide to\nwhitelist a proposal that will be enacted through the Whitelist Caller origin.\nThose proposals will have a shorter Lead-in, Confirmation, and Enactment period when compared to the\nRoot Origin track.\nEach track has its own preset Approval and Support curves based on the\norigin's privileges. When both the approval and support criteria are satisfied for a specific period\n(called the confirmation period), the referendum passes and will be executed after the enactment\nperiod.\nAll referenda within each track and across tracks can be voted on simultaneously (assuming the\ntrack's maximum capacity is not reached).\nPolkadot OpenGov also comes with multi-role delegations where the token holder can assign voting\npower on different tracks to different entities who are experts in judging the referenda submitted\nto those tracks. For example, suppose a token holder does not have the technical background to\nconsider the merits and vote on the referenda submitted to the Root track. In that case, they can\ndelegate their voting power just for the Root track to a trusted expert who (according to them) acts\nin the best interest of the network protocol. In this way, token holders do not need to be\nup-to-date with governance matters and can still make their votes count through delegates."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain gov1 vs. polkadot opengov\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Governance V1\nPolkadot OpenGov\nPolkadot OpenGov Benefit\n\n\n\n\nIncludes the Council, the Technical Committee, and the Public (i.e. token holders).\nIncludes the Public and the Technical Fellowship.\nSimpler and more decentralized structure.\n\n\nReferenda executed only from one origin (Root). Referenda in this origin must be carefully scrutinized. Therefore, there is only one track (i.e., only one referendum at a time can be executed).\nReferenda executed from multiple origins, each with a different track that shapes proposals\u2019 timelines. Depending on the origin, multiple referenda within the same track are possible.\nPossibility to categorize proposals (based on importance and urgency) and execute them simultaneously within and between origin tracks.\n\n\nProposals can be submitted by either the Council or the Public.\nThe public submits proposals.\nMore democratic.\n\n\nUses Adaptive Quorum Biasing to define the approval threshold based on turnout. Given the same turnout, council-initiated referenda require fewer Aye votes to pass compared to public referenda.\nUses origin-specific approval and support curves defining the amount of approval and support (i.e. turnout) needed as a function of time. The same curves are applied to all referenda within the same origin track.\nReferenda timeline depends on the origin and not on who submitted the proposal (i.e. Council or Public). This is a more democratic and equalitarian system.\n\n\nUses alternating voting timetable allowing voters to cast votes for either council or public referenda every 28 eras.\nMultiple referenda can be voted at the same time.\nMore flexible and agile governance system.\n\n\nExcept for emergency proposals, all referenda have fixed voting and enactment periods of 28 eras.\nPeriods' length is customizable and has pre-defined limits for each origin. The same limits apply to all tracks with the same origin. For example, the track in the origin Root will be longer than the track within the Small Tipper origin.\nReferenda\u2019s timeline is tailored to their importance and urgency. Flexible enactment period based on origin.\n\n\nEmergency proposals turned referenda can be simultaneously voted on and executed with other referenda and have shorter enactment periods. They must be proposed by the Technical Committee and approved by the Council.\nNo emergency proposals. The Technical Fellowship can whitelist proposals that will have their origin with shorter lead-in, confirmation, and enactment periods.\nThe Technical Fellowship is a more decentralized entity than the Technical Committee. Whitelisting a proposal requires a majority of approval from the fellowship.\n\n\nOnly the most endorsed proposal is able to transit from Launch to Voting period. The time for the transition is indeterminate, and (with no possibility of canceling endorsements) proposers and endorsers might wait a long time before a referendum is tabled, and getting their deposits back.\nAll proposals will eventually be voted on (given track capacity and deposit are met and the Lead-in period has ended).\nIt allows all proposals to get a chance to be voted on in a timely, predictive manner.\n\n\nOnly aye or nay votes possible.\nVoters can have the additional voting options of abstaining or splitting votes.\nMore ways to engage in voting and increase turnout.\n\n\nVoters can decide to delegate votes to another account.\nVoters can use multirole delegations and delegate votes to different accounts depending on origins.\nMore agile delegations tailored by expertise."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain referenda timeline\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The figure above provides a summary view of the referenda timeline for Polkadot OpenGov.\nIn (1), when a referendum is initially created, the community can immediately vote on it. However,\nit is not immediately in a state where it can end or otherwise have its votes counted, approved, and\nultimately enacted. Instead, the proposal will stay within a Lead-in Period until it fulfills\nthree criteria:\nProposals must stay within the lead-in period for a pre-defined minimum amount of time. This helps\n  mitigate against the possibility of \"decision sniping\" where an attacker controlling a substantial\n  amount of voting power might seek to have a proposal passed immediately after proposing, not\n  allowing the overall voting population adequate time to consider and participate.\nThere must be enough room for the decision within the origin. Different origins have their limit\n  on the number of proposals that can be decided simultaneously. Tracks that have more potent\n  abilities will have lower limits. For example, the Root level Origin has a limit of one, implying\n  that only a single proposal may be decided on at once.\nA decision deposit must be submitted. Creating a referendum is cheap as the deposit value consists\n  of only the value required for the on-chain storage needed to track it. But, having a referendum\n  reviewed and decided upon carries the risk of using up the limited spots available in the\n  referenda queue. Having a more significant but refundable deposit requirement makes sense to help\n  mitigate spam. Failing to submit the decision deposit will lead to a referendum timeout.\nDecision Deposit Amounts\nIn Polkadot OpenGov, someone must submit the Decision Deposit for a referendum to enter its Decision Period. The number of tokens required for the Decision Deposit depends on the track\u2019s privilege level. The higher the privilege, the higher the deposit. For example, malicious referenda posted on the Small Tipper track inflict low economic damage to the network. In contrast, malicious referenda on the Root track can inflict more significant harm, such as changing the entire network's runtime.\nUntil they are in the lead-in period, proposals remain undecided. Once the criteria above are met,\nthe referendum moves to the deciding state. The votes of the referendum are now counted towards\nthe outcome.\nIn (2), the proposal enters the Decision Period, where voting can continue. For a proposal to be\napproved, votes must satisfy the approval and support criteria for at least the Confirmation\nPeriod; otherwise, the proposal is automatically rejected. A rejected proposal can be resubmitted\nanytime and as many times as needed.\nIn (3), approved proposals will enter the Enactment Period, after which proposed changes will be\nexecuted.\nNote how the length of the lead-in, decision, confirmation, and enactment periods vary depending on\nthe track. Root origin track has more extended periods than the other tracks. Also, the number of\nreferenda within each track differs, with the Root origin track only accepting one proposal at a\ntime (see below).\nThis directly affects the number of proposals that can be voted on and executed simultaneously.\nContinuing the comparison between Root and Small Tipper, Small Tipper will allow many proposals on\nits track to be executed simultaneously. In contrast, Root will allow only one proposal to be on its\ntrack. Once the track capacity is filled, additional proposals in the lead-in period will queue\nuntil place is available to enter the decision period.\nFor examples of collectives, see the Polkadot Alliance and the Polkadot Technical Fellowship."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain origins and tracks\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "An Origin is a specific level of privilege that will determine the Track of all referenda\nexecuted with that origin. The track is a pipeline in which the proposal lives and proceeds,\nindependent of other origins' tracks. The proposer of the referenda now selects an appropriate\nOrigin for their request based on the proposal\u2019s requirements.\nAlthough the track structure is the same for all origins, track parameters are not. Such parameters\ninclude:\nMaximum Deciding or Capacity: the limit for the number of referenda that can be decided at\n  once (i.e., the number of tracks within each origin).\nDecision deposit: the amount of funds that must be placed on deposit to enter the Decision\n  Period (note that more requirements must be met to enter the Decision Period).\nPreparation Period: the minimum amount of voting time needed before entering the Decision\n  Period (given capacity and deposit are met).\nDecision Period: the time interval during which a proposal's outcome can be decided.\nConfirmation Period: the minimum amount of time the approval and support criteria must hold\n  before the proposal is approved and moved to the enactment period. The confirmation period should\n  start before the end of the decision period.\nExample Scenario of an Edge Case\nA referendum may enter the confirmation period just one block before the decision period ends. In this scenario, the referendum will pass if it satisfies approval and support thresholds for the minimum confirmation period (track-dependent).\nVoting Period: The period in which voting is allowed on a referendum, which includes\n  preparation, decision, and confirmation periods.\nMinimum Enactment Period: the minimum amount of waiting time before the proposed changes are\n  applied\nApproval Curve: the curve describing the minimum % of aye votes as a function of time within\n  the Decision Period. The approval % is the portion of aye votes (adjusted for conviction) over\n  the total votes (aye, nay, and abstained).\nSupport Curve: the curve describing the minimum % of all votes in support of a proposal as a\n  function of time within the Decision Period. The support % is defined as the portion of all votes\n  (aye and abstained) without conviction over the total possible amount of votes in the system\n  (i.e., the total active issuance).\nFor example, a runtime upgrade (requiring a set_code call, if approved) does not have the same\nimplications for the ecosystem as the approval of a treasury tip (reportAwesome call) and\ntherefore, different Origins for these two actions are needed in which different deposits, support,\napproval, and a minimum enactment periods will be predetermined on the pallet.\nFor detailed information about origin and tracks, and parameter values in Kusama, see\nthis page."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain voluntary locking (conviction voting)\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Conviction Voting Locks created during Gov 1\nConviction voting locks in Governance v1 will not be carried over to OpenGov. Voting with conviction in OpenGov will create a new lock (as this will use the convictionVoting pallet), while any existing lock under Governance v1 (using the deprecated democracy pallet) will be left to expire. Delegations under Governance v1 will need to be re-issued under OpenGov.\nPolkadot utilizes an idea called voluntary locking that allows token holders to increase their\nvoting power by declaring how long they are willing to lock up their tokens; hence, the number of\nvotes for each token holder will be calculated by the following formula:\nvotes = tokens * conviction_multiplier\nThe conviction multiplier increases the vote multiplier by one every time the number of lock periods\ndouble.\nLock Periods\nVote Multiplier\nLength in Days\n\n\n\n\n0\n0.1\n0\n\n\n1\n1\n7\n\n\n2\n2\n14\n\n\n4\n3\n28\n\n\n8\n4\n56\n\n\n16\n5\n112\n\n\n32\n6\n224\nThe maximum number of \"doublings\" of the\nlock period is set to 6 (and thus\n32 lock periods in total). For additional information regarding the timeline of governance events, see the origins and tracks information.\nVotes are always \"counted\" at the same time (at the end of the voting period), no matter how long\nthe tokens are locked.\nSee below an example that shows how voluntary locking works.\nPeter: Votes No with 10 DOT for a 32-week lock period => 10 x 6 = 60 Votes\nLogan: Votes Yes with 20 DOT for one week lock period => 20 x 1 = 20 Votes\nKevin: Votes Yes with 15 DOT for a 2-week lock period => 15 x 2 = 30 Votes\nEven though both Logan and Kevin vote with more DOT than Peter, the lock period for both of them is\nless than Peter\u2019s, leading to their voting power counting as less.\nStaked tokens can be used in governance\nWhile the tokens are locked, you can still use them for voting and staking. You are only prohibited from transferring these tokens to another account. See the section about OpenGov locks, and learn more about locks on the Balances page."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain approval and support\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The figure above provides a summary view of how the approval and support system works during the\nDecision Period.\nOnce the proposal exits the Lead-in Period and enters the Voting Period, to be approved, it must\nsatisfy the approval and support criteria for the Confirmation Period.\nApproval is defined as the share of conviction-weighted aye votes\n  against the conviction-weighted total of aye and nay votes. The code implementation can be\n  viewed\n  here\nSupport is the total number of aye and abstain votes (ignoring any adjustment for\n  conviction) compared to the total possible votes (active issuance)\n  that could be made in the system. In case of split votes, only aye and abstain will count.\nFor example, let us consider a hypothetical example where the total active issuance is 100 DOT.\nAn account A votes \"Aye\" with 10 DOT with 4x conviction\nAn account B votes \"Nay\" with 5 DOT with 2x conviction\nAn account C votes \"Abstain\" with 20 DOT. (no conviction can be applied to \"Abstain\" votes)\nIn this scenario, only 35 DOT from the total active issuance participated in voting on the\nreferendum. Now, let us calculate the Approval and Support values for that referendum.\nApproval is calculated as (Aye') / (Aye' + Nay\u2019), where Aye' and Nay' are the votes after applying\n  the conviction multiplier. Hence, Approval = (10 x 4) / (10 x 4 + 5 x 2) = 40/50 which is 80%.\nSupport is calculated as (Aye + Abstain) / (total active issuance), where \"Aye\" and \"Abstain\" are\n  the votes without the conviction multiplier. Hence, Support = (10 + 20) / 100 which is 30%.\nNay votes are not counted towards Support\nSupport is a measure of voters who turned out either in favor of the referenda or consciously abstained from it. Support does not include nay votes. This avoids edge situations where nay votes could push a referendum into a confirming state. For example, imagine current approval is high (near 100%, way above the approval curve), and current support is just below the support curve. A nay could bump support above the support curve but not reduce approval below the approval curve. Therefore, someone voting against a proposal would make it pass. Hence, a decrease in % of current approval through new votes does not directly translate into increasing support because Support needs to consider nay votes.\nThe figure above shows the following:\nEven if the approval threshold is reached (i.e., % of current approval is greater than the\n  approval curve), the proposal only enters the confirmation period once the support threshold is\n  also reached (i.e., % current support is greater than the underlying support curve).\nIf the referendum meets the approval and support thresholds for the duration of the confirmation\n  period, the proposal will be approved and will be scheduled for enactment. Each track has a\n  default minimum Enactment Period, and the approved referendum needs to wait till the end of it to\n  be executed. Powerful Tracks like Root enforce a larger Enactment Period to ensure the network\n  has ample time to prepare for any changes the proposal may bring. The referendum proposers can\n  also set the enactment period higher than its default value.\nA referendum may exit the confirmation period when the thresholds are no longer met due to new\n  Nay votes or a change of existing Aye or Abstain votes to Nay . Each time it exits, the\n  confirmation period clock is reset. For example, suppose the confirmation period is 20 minutes,\n  and a referendum enters it just for 5 min before exiting. The next time it enters, it must be\n  confirmed for 20 minutes (not 15 minutes).\nIt is possible that a referendum meets the approval and support thresholds almost at the end of\n  the decision period. In this case, even though the decision period elapses, the referendum can\n  pass if it stays confirming for the duration of the track-specific confirmation period. It is\n  rejected immediately if it exits the confirmation period after the decision period elapses.\nThe approval curve starts at 100% and gradually decreases to 50%, but never below 50%. Assuming\n  all the active token supply has voted on a proposal, the conviction vote-weighted support should\n  always be above 50% to pass.\nNote that support may not increase monotonically, as shown in the figure, as people might switch\nvotes.\nDifferent Origins' tracks have different Confirmation Periods and requirements for approval and\nsupport. For additional details on the various origins and tracks, check out\nthis table. With proposals that use\nless privileged origins, it is far more reasonable to drop the required support to a more realistic\namount earlier than those which use highly privileged classes such as Root."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain cancelling, killing & blacklisting\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot OpenGov has two origins dedicated to rejecting ongoing referenda:\nReferendum Canceller and\nReferendum Killer.\nReferendum Canceller aims to cancel an already ongoing referendum. When this origin cancels a\nreferendum, the Submission and Decision Deposit are refunded to their originators. An example of\nwhen a referendum might be considered to be canceled is if the originator has made some errors in\ncreating the preimage and did not necessarily do anything malicious. Cancellation has a lower\nDecision Period, and Approval and Support criteria are much easier to meet over time than most other\nOrigins. This is because the cancellation of a referendum usually comes with a sense of urgency.\nReferendum Killer aims to instantly kill an ongoing referendum, slashing submission and decision\ndeposit (the account(s) that posted these deposits will lose those funds). This origin can be\nengaged if, for example, a malicious actor submits a referendum on the Root Track to set the code of\nthe chains' runtime to stop block production.\nThe Decision Deposit for the Referendum Killer track itself is high to prevent malicious actors from\nattempting to slash deposits of good referenda. A subsequent Referendum Killer can kill an existing\nReferendum Killer.\nFor more information about how to cancel or kill a referendum, see the\nadvanced how-to guides.\nA proposal can be blacklisted by Root Origin. A blacklisted proposal and its related referendum (if any) are immediately canceled. Additionally, a blacklisted proposal's hash cannot re-appear in the proposal queue. Blacklisting is useful when removing erroneous proposals that could be submitted with the same hash."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain voting on a referendum\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "If you are a voter, it means that you will vote with your tokens on each single referendum.\nIn Governance V1, voters could cast only an aye or nay vote. In Polkadot OpenGov, voters can\nadditionally cast a abstain and split votes.\nVote splitting allows voters to allocate\ndifferent votes for aye, nay, and abstain. Voting with conviction is not possible when\nabstaining or splitting the votes.\nOnly the last vote counts\nVoting a second time replaces your original vote, e.g. voting with 10 DOT, then a second extrinsic to vote with 5 DOT, means that you are voting with 5 DOT, not 10 DOT.\nNote that to successfully cast votes you need to have the\nexistential deposit and some additional funds\nto pay for transaction fees.\nIn general, you can remove your vote:\nWhile a referendum is ongoing (your vote does not count)\nAfter a referendum ended (your vote counts)\nIf you voted without conviction, there's no conviction lock in either case. If you voted with\nconviction, you only get a conviction lock if the referendum ended and you voted with the winning\nside.\nRevoke your delegation on a track if you like to vote on your own\nIf you want to vote on a referendum on a specific track on your own, you will need to revoke any existing delegation on that track (i.e. undelegate). You can have a conviction lock on the track, but you cannot have an active delegation."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain voting without conviction\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "If you vote without conviction, the referendum is ongoing, and you remove the vote, you can unlock\nyour tokens immediately. If the referendum ended, you can remove your vote and unlock your tokens\nimmediately, regardless of whether you are on the winning or losing side of the referendum. The\ngovernance app or interface you used for participating in Polkadot OpenGov should show an option to\nunlock your tokens."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain voting with conviction\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "If you voted with conviction, the referendum is ongoing, and you removed the vote, you can unlock\nyour tokens immediately. If the referendum ended and you are on the losing side, you can remove your\nvote and unlock the tokens immediately. However, if you are on the winning side of the referendum,\nyou will get a conviction lock.\nConviction locks are calculated from the time the referendum ended but are applied when you remove\nthe vote.\nFor example, if you voted with conviction 1x with 10 DOT, those 10 DOT will be locked for 7 days\nafter the referendum ends (assuming you are on the winning side). If you remove the vote 3 days\nafter the referendum ended, your tokens will be locked for 4 more days. If you remove it on the 8th\nday after the end of the referendum, the tokens can be unlocked right away (after you remove the\nvote). When you remove the vote, the lock expiration block is calculated and added to the chain\nstate.\nIf you voted on multiple referenda, and you are on the winning side of all those referenda, you will\nget multiple conviction voting locks for all those referenda. Locks do not stack; the length and\nsize of the lock decides. This means that - assuming you used the same conviction on the same number\nof tokens - when the conviction lock on the latest referendum (see below, Ref 4) expires, you will\nbe able to unlock your tokens. In the meantime, the previous locks (1 to 3) might have expired, and\nyou can remove those locks (after removing the votes).\nWhen you delegate your votes, the locking mechanism differs slightly. Please check the next section\non Multirole Delegation for more information."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain multirole delegation\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot OpenGov builds on the vote delegation feature from Governance v1 where a\nvoter can delegate their voting power to another voter. It does so by introducing a feature known as\nmultirole delegation, where voters can specify a different delegate for every class of\nreferendum in the system. Delegation can be done per track, and accounts can choose to select\ndifferent delegates (or no delegation) for each track.\nFor example, a voter could delegate one entity for managing a less potent referenda class, choose a\ndifferent delegate for another class with more powerful consequences and still retain full voting\npower over any remaining classes.\nContrary to solo voting, with delegations, any conviction locks are applied as soon as you\nundelegate, regardless of whether your delegated votes were used for voting during that time. If\nyour delegated votes were used in any ongoing referenda, they would be removed from those referenda\nwhen you undelegate. Alternatively, after undelegating, you can delegate to another person or modify\nyour delegation. The only way to modify the delegation is to undelegate and delegate again. You do\nnot have to do this yourself; wallets and extensions should have implemented UI to modify delegation\nwithout you knowing this.\nIf you delegate without conviction and you undelegate, you can unlock your tokens immediately.\nAlternatively, after undelegating, you can always delegate to another person or modify your\ndelegation.\nIn the case you delegated with 1x conviction, you undelegate and re-delegate with 2x conviction; the\ntime you undelegate again, you will have created two conviction locks: one for the 1x and one for\nthe 2x conviction. If you re-delegate immediately with 1x conviction and undelegate, you will get a\nsecond 1x conviction lock, but the 2x conviction lock will be the one deciding when your token can\nbe unlocked.\nInfo\nIf the account delegated votes to different delegates using different convictions, then after undelegating those delegates, there will be different unlocking periods with lengths dependent on the conviction multipliers.\nBefore delegating a specific track, you must remove any vote on that\ntrack.\nIt is worth noting that a user delegating their voting power does not imply that the delegate will\nhave control over the funds of the delegating user's account. That delegate's account can vote with\na user's voting power but won't be able to transfer balances, nominate a different set of\nvalidators, or execute any call other than voting on the tracks defined by the user.\nThe goal of delegations is to ensure the required support for proposals to be enacted is reached\nwhile keeping the overall design censorship-free. Also, voters might not have the technical\nknowledge to judge some referenda or might not have the time to read all referenda. Delegations\nallow voters to participate in OpenGov hands-free by delegating their voting power to trusted\nentities."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: What is the economic security model of Polkadot?\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot's economic security model is based on shared security where all parachains benefit from the collective economic security of the relay chain. Validators stake DOT tokens and are randomly assigned to validate parachain blocks, with their stake at risk if they behave maliciously. This creates a security model where the cost of attacking any parachain is proportional to the total value staked on the relay chain."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: How does Polkadot's auction mechanism work for parachain slots?\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot uses a candle auction mechanism for parachain slot allocation. Projects bid DOT tokens for lease periods, with auctions having a random ending time within a specified range. The highest bidder at the random end time wins the slot. This mechanism prevents auction sniping and ensures fair price discovery while creating long-term DOT demand through the bonding mechanism."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain the role of DOT token in Polkadot's governance system\ninput: "
      },
      {
        "role": "assistant",
        "content": "DOT tokens serve as the primary governance mechanism in Polkadot through OpenGov. Token holders can propose referenda, vote on proposals, and delegate their voting power. The system uses conviction voting where users can increase their voting power by locking tokens for longer periods. This creates a time-weighted voting system that balances immediate participation with long-term commitment to the network."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: What are the inflation dynamics of DOT tokens?\ninput: "
      },
      {
        "role": "assistant",
        "content": "DOT has a fixed inflation rate of approximately 10% annually, designed to incentivize staking and fund the treasury. The inflation is distributed between staking rewards (about 8-9%) and treasury funding (1-2%). When staking participation is optimal (around 75% of supply), validators and nominators receive the highest rewards. Lower staking participation results in higher individual returns but reduced overall security."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: How does slashing work in Polkadot's NPoS system?\ninput: "
      },
      {
        "role": "assistant",
        "content": "Slashing in Polkadot penalizes validators and their nominators for malicious behavior or protocol violations. The severity depends on the offense: equivocation (double-signing) can result in 0.1% slash, while coordinated attacks can trigger up to 100% slashing. The punishment affects both the validator's own stake and all nominator stakes backing that validator, creating strong incentives for nominators to choose reliable validators."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Analyze the validator selection game in Polkadot's NPoS system\ninput: "
      },
      {
        "role": "assistant",
        "content": "The validator selection in Polkadot creates a multi-player game where nominators choose validators to maximize returns while minimizing slashing risk. The Nash equilibrium involves nominators distributing stake across reliable validators with lower commission rates. Validators compete by offering competitive commission rates and demonstrating reliability. The algorithm optimizes for both security (avoiding concentration) and fairness (proportional representation), creating incentives for decentralization."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: What are the game-theoretic implications of Polkadot's slashing mechanism?\ninput: "
      },
      {
        "role": "assistant",
        "content": "Slashing creates a coordination game between validators and nominators. Validators have incentives to maintain high uptime and avoid equivocation, as slashing affects both their own stake and nominator stake. Nominators must evaluate validator behavior and past performance. The mechanism creates a deterrent effect where the cost of misbehavior exceeds potential gains, establishing a stable equilibrium where honest behavior is dominant strategy."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: How does the parachain auction mechanism prevent strategic manipulation?\ninput: "
      },
      {
        "role": "assistant",
        "content": "The candle auction format prevents last-second bidding strategies by having a random, unknown end time. This eliminates the advantage of waiting until the last moment to bid, as bidders cannot know when the auction actually ends. The mechanism incentivizes truthful bidding early in the auction period, as strategic waiting may result in missing the actual end time. This creates a more fair price discovery process."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain the Nash equilibrium in Polkadot's nomination pools\ninput: "
      },
      {
        "role": "assistant",
        "content": "Nomination pools create a coordination game where pool operators compete for delegators while delegators seek optimal returns. The Nash equilibrium emerges when pool operators set commission rates that balance profitability with competitiveness, while delegators distribute stake across pools based on historical performance and commission rates. This creates market efficiency where poorly performing pools lose delegation and high-performing pools attract more stake."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: How does conviction voting in Polkadot governance solve collective action problems?\ninput: "
      },
      {
        "role": "assistant",
        "content": "Conviction voting addresses the collective action problem in governance by allowing token holders to multiply their voting power by locking tokens for longer periods. This mechanism ensures that those with long-term interests in the network have proportionally more influence, while preventing short-term actors from manipulating governance. The time-locking requirement creates a credible commitment mechanism that aligns voting incentives with network health."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain auto generation\ninput: "
      },
      {
        "role": "assistant",
        "content": "You can create a PrDoc by using the `/cmd prdoc` command (see args with `/cmd prdoc --help`) in a\ncomment on your PR.\n\nOptions:\n\n- `audience` The audience of whom the changes may concern.\n  - `runtime_dev`: Anyone building a runtime themselves. For example parachain teams, or people\n    providing template runtimes. Also devs using pallets, FRAME etc directly. These are people who\n    care about the protocol (WASM), not the meta-protocol (client).\n  - `runtime_user`: Anyone using the runtime. Can be front-end devs reading the state, exchanges\n    listening for events, libraries that have hard-coded pallet indices etc. Anything that would\n    result in an observable change to the runtime behaviour must be marked with this.\n  - `node_dev`: Those who build around the client side code. Alternative client builders, SMOLDOT,\n  those who consume RPCs. These are people who are oblivious to the runtime changes. They only care\n  about the meta-protocol, not the protocol itself.\n  - `node_operator`: People who run the node. Think of validators, exchanges, indexer services, CI\n    actions. Anything that modifies how the binary behaves (its arguments, default arguments, error\n    messags, etc) must be marked with this.\n- `bump:`: The default bump level for all crates. The PrDoc will likely need to be edited to reflect\n  the actual changes after generation. More details in the section below.\n  - `none`: There is no observable change. So to say: if someone were handed the old and the new\n    version of our software, it would be impossible to figure out what version is which.\n  - `patch`: Fixes that will never cause compilation errors if someone updates to this version. No\n    functionality has been changed. Should be limited to fixing bugs or No-OP implementation\n    changes.\n  - `minor`: Additions that will never cause compilation errors if someone updates to this version.\n    No functionality has been changed. Should be limited to adding new features.\n  - `major`: Anything goes.\n- `force: true|false`: Whether to overwrite any existing PrDoc file."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain how to document?\ninput: "
      },
      {
        "role": "assistant",
        "content": "There are good sources to look into:\n\n- Rust Documentation Guide\n- Documentation in Rust\n  Book\n- Guide on Writing Documentation for a Rust\n  Crate\n\nAs mentioned\nhere\nand here,\nalways start with a **single sentence** demonstrating what is documented. All additional documentation should be added\n*after a newline*. Strive to make the first sentence succinct and short.The reason for this is the first paragraph of\ndocs about an item (everything before the first newline) is used as the excerpt that rust doc displays about this item\nwhen it appears in tables, such as the table listing all functions in a module. If this excerpt is too long, the module\ndocs will be very difficult to read.\n\nAbout special\nsections,\nwe will most likely not need to think about panic and safety in any runtime related code. Our code is never `unsafe`,\nand will (almost) never panic.\n\nUse `# Examples` as much as possible. These are great ways to further demonstrate what your APIs are doing, and add free\ntest coverage. As an additional benefit, any code in rust-docs is treated as an \"integration test\",\nwhich tests your crate in a different way than unit tests. So, it is both a win for \"more documentation\" and a win for\n\"more test coverage\".\n\nYou can also consider having an `# Error` section optionally. Of course, this only applies if there is a `Result` being\nreturned, and if the `Error` variants are overly complicated.\n\nStrive to include correct links to other items in your written docs as much as possible.\nRead more about how to correctly use links in your rust-docs\nhere and\nhere.\nIn other words, avoid `` `some_func` `` and instead use ``[`some_func`]``.\n\n> While you are linking, you might become conscious of the fact that you are in need of linking to (too many) foreign\nitems in order to explain your API. This is leaning more towards API-Design rather than documentation, but it is a\nwarning that the subject API might be slightly wrong. For example, most \"glue\" traits[^1] in `frame/support` should be\ndesigned and documented without making hard assumptions about particular pallets that implement them.\n\n---\n\n### TLDR\n\n0. Have the goal of enforcing `#![deny(missing_docs)]` mentally, even if it is not enforced by the compiler \ud83d\ude48.\n1. Start with a single, clear and concise sentence. Follow up with more context, after a newline, if needed.\n2. Use examples as much as reasonably possible.\n3. Use links as much as possible.\n4. Think about context. If you are explaining a lot of foreign topics while documenting a trait that should not\nexplicitly depend on them, you have likely not designed it properly.\n\n---\n\n### Proc-Macros\n\nNote that there are special considerations when documenting proc macros. Doc links will appear to function *within* your\nproc macro crate, but often will no longer function when these proc macros are re-exported elsewhere in your project.\nThe exception is doc links to *other proc macros* which will function just fine if they are also being re-exported. It\nis also often necessary to disambiguate between a proc macro and a function of the same name, which can be done using\nthe `macro@my_macro_name` syntax in your link. Read more about how to correctly use links in your rust-docs\nhere and\nhere.\n\n---"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain other guidelines\ninput: "
      },
      {
        "role": "assistant",
        "content": "The above five guidelines must always be reasonably respected in the documentation.\n\nThe following is a set of notes that may not necessarily hold in all circumstances:\n\n---\n\n### Document Through Code\n\nYou should make sure that your code is properly-named and well-organized so that your code functions as a form of\ndocumentation. However, within the complexity of our projects in Polkadot/Substrate that is not enough. Particularly,\nthings like examples, errors and panics cannot be documented only through properly-named and well-organized code.\n\n> Our north star is self-documenting code that also happens to be well-documented and littered with examples.\n\n- Your written documents should *complement* the code, not *repeat* it. As an example, a documentation on top of a code\nexample should never look like the following:\n\n /// Sends request and handles the response.\n trait SendRequestAndHandleResponse {\n\n }\n ```\n\nIn the above example, the documentation has added no useful information not already contained within the properly-named\ntrait and is redundant.\n\n---\n\n### Formatting Matters\n\nThe way you format your documents (newlines, heading and so on) makes a difference. Consider the below examples:\nrust\n/// This function works with input u32 x and multiplies it by two. If\n/// we optimize the other variant of it, we would be able to achieve more\n/// efficiency but I have to think about it. Probably can panic if the input\n/// overflows u32.\nfn multiply_by_2(x: u32) -> u32 { .. }\nrust\n/// Multiplies an input of type [`u32`] by two.\n///\n/// # Panics\n///\n/// Panics if the input overflows.\n///\n/// # Complexity\n///\n/// Is implemented using some algorithm that yields complexity of O(1).\n// More efficiency can be achieved if we improve this via such and such.\nfn multiply_by_2(x: u32) -> u32 { .. }\n```\n\nThey are both roughly conveying the same set of facts, but one is easier to follow because it was formatted cleanly.\nEspecially for traits and types that you can foresee will be seen and used a lot, try and write a well formatted\nversion.\n\nSimilarly, make sure your comments are wrapped at 100 characters line-width (as defined by our\n`rustfmt.toml`), no **more and no less**! The more is fixed by `rustfmt` and our CI, but if you (for\nsome unknown reason) wrap your lines at 59 characters, it will pass the CI, and it will not look good \ud83e\udee3. Consider using\na plugin like rewrap (for Visual Studio Code) to\nproperly do this.\n\n[^1]: Those that help two pallets talk to each other.\n\n---"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain top level pallet docs (`lib.rs`)\ninput: "
      },
      {
        "role": "assistant",
        "content": "For the top-level pallet docs, consider the following template:\n\n//! # <Pallet Name>\n//!\n//! <single-liner about the pallet>.\n//!\n//! ## Pallet API\n//!\n//! <Reminder: inside the [`pallet`] module, a template that leads the reader to the relevant items is auto-generated. There is no need to repeat\n//! things like \"See Config trait for ...\", which are generated inside [`pallet`] here anyways. You can use the line below as-is:>\n//!\n//! See the [`pallet`] module for more information about the interfaces this pallet exposes, including its\n//! configuration trait, dispatchables, storage items, events and errors.\n//!\n//! ## Overview\n//!\n//! <should be high-level details that are relevant to the most broad audience>\n//!\n//! <The audience here is potentially non-coders who just want to know what this pallet does, not how it does it>\n//!\n//! <potentially a few paragraphs, focus on what external folks should know about the pallet>\n//!\n//! ### Example\n//!\n//! <Your pallet must have a few tests that cover important user journeys. Use https://crates.io/crates/docify to\n//! reuse these as examples.>\n//!\n//! <The audience of this is those who want to know how this pallet works, to the extent of being able to build\n//! something on top of it, like a DApp or another pallet. In some cases, you might want to add an example of how to\n//! use this pallet in other pallets.>\n//!\n//! This section can most often be left as-is.\n//!\n//! ## Low Level / Implementation Details\n//!\n//! <The format of this section is up to you, but we suggest the Design-oriented approach that follows>\n//!\n//! <The audience of this would be your future self, or anyone who wants to gain a deep understanding of how the pallet\n//! works so that they can eventually propose optimizations to it>\n//!\n//! ### Design Goals (optional)\n//!\n//! <Describe your goals with the pallet design.>\n//!\n//! ### Design (optional)\n//!\n//! <Describe how you've reached those goals. This should describe the storage layout of your pallet and what was your\n//! approach in designing it that way.>\n//!\n//! ### Terminology (optional)\n//!\n//! <Optionally, explain any non-obvious terminology here. You can link to it if you want to use the terminology further\n//! up>\n\nThis template's details (Heading 3s and beyond) are left flexible, and at the discretion of the developer to make the\nbest final choice about. For example, you might want to include `### Terminology` or not. Moreover, you might find it\nmore useful to include it in `## Overview`.\n\nNonetheless, the high level flow of going from the most high level explanation to the most low level explanation is\nimportant to follow.\n\nAs a rule of thumb, the Heading 2s (`##`) in this template can be considered a strict rule, while the Heading 3s (`###`)\nand beyond are flexible.\n\n---\n\n### Polkadot and Substrate\n\nOptionally, in order to demonstrate the relation between the two, you can start the pallet documentation with:\n\n//! > Made with *Substrate*, for *Polkadot*.\n//!\n//! [![github]](https://github.com/paritytech/polkadot-sdk/tree/master/substrate/frame/fast-unstake) -\n//! [![polkadot]](https://polkadot.com)\n//!\n//! [polkadot]: https://img.shields.io/badge/polkadot-E6007A?style=for-the-badge&logo=polkadot&logoColor=white\n//! [github]: https://img.shields.io/badge/github-8da0cb?style=for-the-badge&labelColor=555555&logo=github\n\n---"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain or\ninput: "
      },
      {
        "role": "assistant",
        "content": "/cmd --help # to see all available commands\n\nTo regenerate all weights (however it will take long,\nso don't do it unless you really need it), run the following command:\nsh\n/cmd bench\n\nTo generate weights for all pallets in a particular runtime(s), run the following command:\nsh\n/cmd bench --runtime kusama polkadot\n\nFor Substrate pallets (supports sub-modules too):\nsh\n/cmd bench --runtime dev --pallet pallet_asset_conversion_ops\n\n> **\ud83d\udcdd Note**: The action is not being run right-away, it will be queued and run in the next available runner.\n> So might be quick, but might also take up to 10 mins (That's in control of Github).  \n> Once the action is run, you'll see reaction \ud83d\udc40 on original comment, and if you didn't pass `--quiet` -\n> it will also send a link to a pipeline when started, and link to whole workflow when finished.\n>\n> **\ud83d\udcdd Note**: It will try keep benchmarking even if some pallets failed, with the result of failed/successful pallets.\n>\n> If you want to fail fast on first failed benchmark, add `--fail-fast` flag to the command.\n\n---\n\nThis way it runs all possible runtimes for the specified pallets, if it finds them in the runtime\nsh\n/cmd bench --pallet pallet_balances pallet_xcm_benchmarks::generic pallet_xcm_benchmarks::fungible\n\nIf you want to run all specific pallet(s) for specific runtime(s), you can do it like this:\nsh\n/cmd bench --runtime bridge-hub-polkadot --pallet pallet_xcm_benchmarks::generic pallet_xcm_benchmarks::fungible\n\n> **\ud83d\udca1Hint #1** : Sometimes when you run too many commands, or they keep failing and you're rerunning them again,\n> it's handy to add `--clean` flag to the command. This will clean up all yours and bot's comments in PR relevant to\n> /cmd commands.\nsh\n/cmd bench --runtime kusama polkadot --pallet=pallet_balances --clean\n```\n\n> **\ud83d\udca1Hint #2** : If you have questions or need help, feel free to tag @paritytech/opstooling (in github comments)\n> or ping in matrix channel."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain using docker compose\ninput: "
      },
      {
        "role": "assistant",
        "content": "You can use the following docker-compose.yml file:\n\nversion: '2'\n\nservices:\n  polkadot:\n    container_name: polkadot\n    image: parity/polkadot\n    ports:\n      - 30333:30333 # p2p port\n      - 9933:9933 # rpc port\n      - 9944:9944 # ws port\n      - 9615:9615 # Prometheus port\n    volumes:\n      - /my/local/folder:/polkadot\n    command: [\n      \"--name\", \"PolkaDocker\",\n      \"--ws-external\",\n      \"--rpc-external\",\n      \"--prometheus-external\",\n      \"--rpc-cors\", \"all\"\n    ]\n\nWith following `docker-compose.yml` you can set up a node and use `polkadot-js-apps` as the front end on port 80. After\nstarting the node use a browser and enter your Docker host IP in the URL field: _<http://[YOUR_DOCKER_HOST_IP]>_\n\nversion: '2'\n\nservices:\n  polkadot:\n    container_name: polkadot\n    image: parity/polkadot\n    ports:\n      - 30333:30333 # p2p port\n      - 9933:9933 # rpc port\n      - 9944:9944 # ws port\n      - 9615:9615 # Prometheus port\n    command: [\n      \"--name\", \"PolkaDocker\",\n      \"--ws-external\",\n      \"--rpc-external\",\n      \"--prometheus-external\",\n      \"--rpc-cors\", \"all\"\n    ]\n\n  polkadotui:\n    container_name: polkadotui\n    image: jacogr/polkadot-js-apps\n    environment:\n      - WS_URL=ws://[YOUR_DOCKER_HOST_IP]:9944\n    ports:\n      - 80:80"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain upgrade instructions\ninput: "
      },
      {
        "role": "assistant",
        "content": "Not too much has changed on the top and API level for developing Substrate between 2.0 and 3.0. The easiest and quickest\npath for upgrading is just to take the latest node-template and try applying your changes to it:\n1. take a diff between 2.0 and your changes\n2. store that diff\n3. remove everything, copy over the 3.0 node-template\n4. try re-applying your diff, manually, a hunk at a time.\n\nIf that doesn't work for you, we are working on an in-depth-guide for all major changes that took place and how you need\nto adapt your code for it. You can find the upgrade guide under `docs/` in the\nrepo, if you have further questions\nor problem, please feel free to ask in the github discussion\nboard.\n\n### Runtime\n\n* contracts: Charge rent for code storage (#7935)\n* contracts: Emit event on contract termination (#8014)\n* Fix elections-phragmen and proxy issue (#7040)\n* Allow validators to block and kick their nominator set. (#7930)\n* Decouple Staking and Election - Part1: Support traits (#7908)\n* Introduces account existence providers reference counting (#7363)\n* contracts: Cap the surcharge reward by the amount of rent that way paid by a contract (#7870)\n* Use checked math when calculating storage size (#7885)\n* Fix clear prefix check to avoid erasing child trie roots. (#7848)\n* contracts: Collect rent for the first block during deployment (#7847)\n* contracts: Add configurable per-storage item cost (#7819)\n* babe: expose next epoch data (#7829)\n* fix : remove `_{ }` syntax from benchmark macro (#7822)\n* Define ss58 prefix inside the runtime (#7810)\n* Allow council to slash treasury tip (#7753)\n* Don't allow self proxies (#7803)\n* add a `current_epoch` to BabeApi (#7789)\n* Add `pallet` attribute macro to declare pallets (#6877)\n* Make it possible to calculate the storage root as often as you want (#7714)\n* Issue 7143 | Refactor Treasury Pallet into Bounties, Tips, and Proposals (#7536)\n* Participating in Council Governance is Free for First Time Voters and Successful Closing (#7661)\n* Streamline frame_system weight parametrization (#6629)\n* Features needed for reserve-backed stablecoins (#7152)\n* `sudo_as` should return a result (#7620)\n* More Extensible Multiaddress Format (#7380)\n* Fix `on_runtime_upgrade` weight recording (#7480)\n* Implement batch_all and update Utility pallet for weight refunds (#7188)\n* Fix wrong outgoing calculation in election (#7384)\n* Implements pallet versioning (#7208)\n* Runtime worker threads (#7089)\n* Allow `schedule_after(0, ...)` to work (#7284)\n* Fix offchain election to respect the weight (#7215)\n* Fix weight for inner call with new origin (#7196)\n* Move proxies migration (#7205)\n* Introduce `cancel_proposal` to rid us of those pesky proposals (#7111)\n\n### Client\n\n* Remove backwards-compatibility networking hack (#8068)\n* Extend SS58 network identifiers (#8039)\n* Update dependencies ahead of next release (#8015)\n* Storage chains: serve transactions over IPFS/bitswap (#7963)\n* Add a send_request function to NetworkService (#8008)\n* Rename system_networkState to system_unstable_networkState (#8001)\n* Allow transaction for offchain indexing (#7290)\n* Grandpa warp sync request-response protocol (#7711)\n* Add explicit limits to notifications sizes and adjust yamux buffer size (#7925)\n* Rework priority groups, take 2 (#7700)\n* Define ss58 prefix inside the runtime (#7810)\n* Expand remote keystore interface to allow for hybrid mode (#7628)\n* Allow capping the amount of work performed when deleting a child trie (#7671)\n* RPC to allow setting the log filter (#7474)\n* Remove sc_network::NetworkService::register_notifications_protocol and partially refactor Grandpa tests (#7646)\n* minor fix and improvements on localkeystore (#7626)\n* contracts: Add `salt` argument to contract instantiation (#7482)\n* contracts: Rework contracts_call RPC (#7468)\n* Make sure to use the optimized method instead of reading the storage. (#7445)\n* WASM Local-blob override (#7317)\n* client/network: Allow configuring Kademlia's disjoint query paths (#7356)\n* client/network: Remove option to disable yamux flow control (#7358)\n* Make `queryStorage` and `storagePairs` unsafe RPC functions (#7342)\n* No longer actively open legacy substreams (#7076)\n* Make `run_node_until_exit` take a future (#7318)\n* Add an system_syncState RPC method (#7315)\n* Async keystore + Authority-Discovery async/await (#7000)\n* Fixes logging of target names with dashes (#7281)\n* Refactor CurrencyToVote (#6896)\n* client/network: Stop sending noise legacy handshake (#7211)\n\n### API\n\n* pallet macro: easier syntax for `#[pallet::pallet]` with `struct Pallet<T>(_)` (#8091)\n* WasmExecutor takes a cache directory (#8057)\n* Remove PalletInfo impl for () (#8090)\n* Migrate assets pallet to new macros (#7984)\n* contracts: Make ChainExtension trait generic over the runtime (#8003)\n* Decouple the session validators from im-online (#7127)\n* Update `parity-scale-codec` to 2.0 (#7994)\n* Merkle Mountain Range pallet improvements (#7891)\n* Cleaner GRANDPA RPC API for proving finality (#7339)\n* Migrate frame-system to pallet attribute macro (#7898)\n* Introduces account existence providers reference counting (#7363)\n* contracts: Lazy storage removal (#7740)\n* contracts: Allow runtime authors to define a chain extension (#7548)\n* Define ss58 prefix inside the runtime (#7810)\n* Add `pallet` attribute macro to declare pallets (#6877)\n* Add keccak-512 to host functions. (#7531)\n* Merkle Mountain Range pallet (#7312)\n* Allow capping the amount of work performed when deleting a child trie (#7671)\n* add an upgrade_keys method for pallet-session (#7688)\n* Streamline frame_system weight parametrization (#6629)\n* Rename pallet trait `Trait` to `Config` (#7599)\n* contracts: Add `salt` argument to contract instantiation (#7482)\n* pallet-evm: move to Frontier (Part IV) (#7573)\n* refactor subtrait/elevated trait as not needed (#7497)\n* Allow BabeConsensusDataProvider fork existing chain (#7078)\n* decouple transaction payment and currency (#6912)\n* contracts: Refactor the runtime API in order to simplify node integration (#7409)\n* client/authority-discovery: Remove sentry node logic (#7368)\n* client/network: Make NetworkService::set_priority_group async (#7352)\n* *: Bump async-std to v1.6.5 (#7306)\n* babe: make secondary slot randomness available on-chain (#7053)\n* allow where clause in decl_error (#7324)\n* reschedule (#6860)\n* SystemOrigin trait (#7226)\n* permit setting treasury pallet initial funding through genesis (#7214)\n\n### Runtime Migrations\n\n* Migrate assets pallet to new macros (#7984)\n* Fix elections-phragmen and proxy issue (#7040)\n* Allow validators to block and kick their nominator set. (#7930)\n* Migrate frame-system to pallet attribute macro (#7898)\n* Implements pallet versioning (#7208)\n* Move proxies migration (#7205)"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain runtime\ninput: "
      },
      {
        "role": "assistant",
        "content": "* Custom Codec Implementation for NPoS Election (#6720)\n* Successful `note_imminent_preimage` is free (#6793)\n* pallet-democracy use of weightinfo (#6783)\n* Update Balances Pallet to use `WeightInfo` (#6610)\n* pallet-evm: add builtin support for the four basic Ethereum precompiles (#6743)\n* Allow `PostDispatchInfo` to disable fees (#6749)\n* pallet-evm: add support for tuple-based precompile declarations (#6681)\n* grandpa: allow noting that the set has stalled (#6725)\n\n### Client\n\n* Merge Subkey into sc-cli (#4954)\n* RpcHandlers Refactorings (#6846)\n* client/authority-discovery: Introduce AuthorityDiscoveryService (#6760)\n* Implement tracing::Event handling & parent_id for spans and events (#6672)\n* Move to upstream wasmtime, refactor globals snapshot  (#6759)\n* Revalidate transactions only on latest best block (#6824)\n* Allow task manager to have children (#6771)\n* client/network: Expose DHT query duration to Prometheus (#6784)\n* client/network: Add peers to DHT only if protocols match (#6549)\n* Name all the tasks! (#6726)\n* Child nodes can be handled by adding a child `TaskManager` to the parent's `TaskManager` (#6771)"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain runtime\ninput: "
      },
      {
        "role": "assistant",
        "content": "* Support using system storage directly for EVM balance and nonce (#6659)\n* Properly filter out duplicate voters in elections. (#6693)\n* Treasury burning can be directed (#6671)\n* identity: Don't let subs be re-registered (#6667)\n* Regression test to ensure we don't break deterministic builds in wasm (#6597)\n* allow to specify schedule time as a relative value (#6578)\n* Make signature batching use specialized methods (#6616)\n* Rename `CheckEra` to `CheckMortality` (#6619)\n* Add `WeightInfo` to all pallets with benchmarks. (#6575)\n* Don't require module name in inherents (#6576)\n* pallet-evm: return Ok(()) when EVM execution fails (#6493)\n* Make the encoded-Call Vec<u8> explicitly so in metadata (#6566)\n* Allow specify schedule dispatch origin (#6387)\n* pallet-evm: customizable chain id (#6537)\n* Refactor as_sub to make things clearer. (#6503)"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain client\ninput: "
      },
      {
        "role": "assistant",
        "content": "* Update wasmtime to (almost) latest master (#6662)\n* Update to latest sysinfo prevents leaking fd-handlers (#6708)\n* Tracing values (#6679)\n* Graceful shutdown for the task manager (#6654)\n* Update `substrate-networking` Grafana dashboard (#6649)\n* *: Update to libp2p v0.21.1 (#6559)\n* Send Status message on all newly-opened legacy substreams (#6593)\n* babe: report equivocations (#6362)\n* Support synching of blocks that are not `new_best` (#6508)\n* Remove the service, replacing it with a struct of individual chain components (#6352)\n* Fix tx-pool returning the same transaction multiple times (#6535)"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain runtime\ninput: "
      },
      {
        "role": "assistant",
        "content": "* Staking Payout Creates Controller (#6496)\n* `pallet-scheduler`: Check that `when` is not in the past (#6480)\n* Fix `sp-api` handling of multiple arguments (#6484)\n* Fix issues with `Operational` transactions validity and prioritization. (#6435)\n* pallet-atomic-swap: generalized swap action (#6421)\n* Avoid multisig reentrancy (#6445)\n* Root origin use no filter by default. Scheduler and Democracy dispatch without asserting BaseCallFilter (#6408)\n* Scale and increase validator count (#6417)\n* Pallet: Atomic Swap (#6349)\n* Restrict remove_proxies (#6383)\n* Stored call in multisig (#6319)\n* Allow Sudo to do anything (#6375)\n* vesting: Force Vested Transfer (#6368)\n* Add events for balance reserve and unreserve functions (#6330)\n* Introduce frozen indices. (#6307)"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain client\ninput: "
      },
      {
        "role": "assistant",
        "content": "* client/network/service: Add primary dimension to connection metrics (#6472)\n* Fix Babe secondary plain slots claiming (#6451)\n* add network propagated metrics (#6438)\n* client/authority-discovery: Compare PeerIds and not Multihashes (#6414)\n* Update sync chain info on own block import (#6424)\n* Remove --legacy-network-protocol CLI flag (#6411)\n* Runtime interface to add support for tracing from wasm (#6381)\n* Remove penalty on duplicate Status message (#6377)\n* Fix the broken weight multiplier update function (#6334)\n* client/authority-discovery: Don't add own address to priority group (#6370)\n* Split the service initialisation up into separate functions (#6332)\n* Fix transaction pool event sending (#6341)\n* Add a [prefix]_process_start_time_seconds metric (#6315)\n* new crate sc-light (#6235)\n* Allow adding a prefix to the informant (#6174)"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain client\ninput: "
      },
      {
        "role": "assistant",
        "content": "* Make transaction pool prune transactions only of canonical blocks (#6123)\n* Rename all the election operations (#6245)\n* Sentry nodes and validator nodes also imply reserved (#6251)\n* Fix peerset not filtering incoming connections in reserved-only (#6249)\n* Use Subscription Manager from `jsonrpc-pubsub` (#6208)\n* Add a Substrate networking Grafana dashboard template (#6171)\n* Add subkey inspect-node-key (#6153)"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain client\ninput: "
      },
      {
        "role": "assistant",
        "content": "* Adds `export-state` subcommand (#5842)\n* Drop ClientProvider (#5823)\n* Move spawning tasks from thread pools to Service's TaskManager for block importing (#5647)\n* Reputation penalty for sending empty block response (#5814)\n* Move sc-client into sc-service (#5502)\n* Use new block requests protocol (#5760)\n* Fix leak in stream notifications (#5739)\n* network: Only insert global addresses into the DHT. (#5735)\n* enum Pays for PaysFee (#5733)\n* Migrate away from `SimpleDispatchInfo` (#5686)\n* Child trie api changes BREAKING (#4857)\n* subkey: compute and inspect a moduleid (#5676)\n* Listen on ipv6 by default as well (#5677)\n* Adjustments to Kademlia-related metrics (#5660)\n* client/authority-discovery: Allow to be run by sentry node (#5568)\n* Add alternative RPC methods to system_networkState (#5643)\n* Several tweaks to networking Prometheus metrics (#5636)\n* Use a Kademlia instance per `ProtocolId`. (#5045)\n* Report tasks metrics to Prometheus (#5619)"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain client\ninput: "
      },
      {
        "role": "assistant",
        "content": "* Add new RPC method to get the chain type (#5576)\n* Reuse wasmtime instances, the PR (#5567)\n* Prometheus Metrics: Turn notifications_total counter into notifications_sizes histogram (#5535)\n* Make verbosity level mandatory with telemetry opt (#5057)\n* Additional Metrics collected and exposed via prometheus (#5414)\n* Switch to new light client protocol (#5472)\n* client/finality-grandpa: Instrument until-imported queue (#5438)\n* Batch benchmarks together with `*` notation. (#5436)\n* src/service/src/builder: Fix memory metric exposed in bytes not KiB (#5459)\n* Make transactions and block announces use notifications substre\u2026 (#5360)\n* Adds state_queryStorageAt (#5362)\n* Offchain Phragm\u00e9n BREAKING. (#4517)\n* `sc_rpc::system::SystemInfo.impl_version` now returns the full version (2.0.0-alpha.2-b950f731c-x86_64-linux-gnu)\n  instead of the short version (1.0.0) (#5271)"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain client\ninput: "
      },
      {
        "role": "assistant",
        "content": "* client/finality-grandpa: Add Prometheus metrics to GossipValidator (#5237)\n* removes use of sc_client::Client from node-transaction-factory (#5158)\n* removes use of sc_client::Client from sc_network (#5147)\n* Use CLI to configure max instances cache (#5177)\n* client/service/src/builder.rs: Add build_info metric (#5192)\n* Remove `substrate-ui.parity.io` from CORS whitelist (#5142)\n* removes use of sc_client::Client from sc-rpc (#5063)\n* Use 128mb for db cache default (#5134)\n* Drop db-cache default from 1gig to 32mb (#5128)\n* Add more metrics to prometheus (#5034)"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain runtime\ninput: "
      },
      {
        "role": "assistant",
        "content": "### FRAME 2.0\n\nThe new FRAME 2.0 macros are a lot nicer to use and easier to read. While we were on that change though, we also cleaned\nup some mainly internal names and traits. The old `macro`'s still work and also produce the new structure, however, when\nplugging all that together as a Runtime, there's some things we have to adapt now:\n\n### `::Trait for Runtime` becomes `::Config for Runtime`\n\nThe most visible and significant change is that the macros no longer generate the `$pallet::Trait` but now a much more\naptly named `$pallet::Config`. Thus, we need to rename all `::Trait for Runtime` into`::Config for Runtime`, e.g. for\nthe `sudo` pallet we must do:\n\n-impl pallet_sudo::Trait for Runtime {\n+impl pallet_sudo::Config for Runtime {\n\nThe same goes for all `<Self as frame_system::Trait>` and alike, which simply becomes `<Self as frame_system::Config>`.\n\n### SS58 Prefix is now a runtime param\n\nSince #7810 we don't define the ss58 prefix in the chainspec\nanymore but moved it into the runtime. Namely, `frame_system` now needs a new `SS58Prefix`, which in Substrate node we\nhave defined for ourselves as: `pub const SS58Prefix: u8 = 42;`. Use your own chain-specific value there.\n\n### Weight Definition\n\n`type WeightInfo` has changed and instead on `weights::pallet_$name::WeightInfo` is now bound to the Runtime as\n`pallet_$name::weights::SubstrateWeight<Runtime>`. As a result we have to the change the type definitions everywhere in\nour Runtime accordingly:\n\n-\ttype WeightInfo = weights::pallet_$name::WeightInfo;\n+\ttype WeightInfo = pallet_$name::weights::SubstrateWeight<Runtime>;\n\ne.g.\n-\ttype WeightInfo = weights::pallet_collective::WeightInfo;\n+\ttype WeightInfo = pallet_collective::weights::SubstrateWeight<Runtime>;\nand\n\n-\ttype WeightInfo = weights::pallet_proxy::WeightInfo;\n+\ttype WeightInfo = pallet_proxy::weights::SubstrateWeight<Runtime>;\n\nAnd update the overall definition for weights on frame and a few related types and runtime parameters:\n\n```diff=\n\n-const AVERAGE_ON_INITIALIZE_WEIGHT: Perbill = Perbill::from_percent(10);\n+/// We assume that ~10% of the block weight is consumed by `on_initialize` handlers.\n+/// This is used to limit the maximal weight of a single extrinsic.\n+const AVERAGE_ON_INITIALIZE_RATIO: Perbill = Perbill::from_percent(10);\n+/// We allow `Normal` extrinsics to fill up the block up to 75%, the rest can be used\n+/// by  Operational  extrinsics.\n+const NORMAL_DISPATCH_RATIO: Perbill = Perbill::from_percent(75);\n+/// We allow for 2 seconds of compute with a 6 second average block time.\n+const MAXIMUM_BLOCK_WEIGHT: Weight = Weight::from_parts(2u64 * WEIGHT_REF_TIME_PER_SECOND, u64::MAX);\n+\n parameter_types! {\n \tpub const BlockHashCount: BlockNumber = 2400;\n-\t/// We allow for 2 seconds of compute with a 6 second average block time.\n-\tpub const MaximumBlockWeight: Weight = Weight::from_parts(2u64 * WEIGHT_REF_TIME_PER_SECOND, u64::MAX);\n-\tpub const AvailableBlockRatio: Perbill = Perbill::from_percent(75);\n-\t/// Assume 10% of weight for average on_initialize calls.\n-\tpub MaximumExtrinsicWeight: Weight =\n-\t\tAvailableBlockRatio::get().saturating_sub(AVERAGE_ON_INITIALIZE_WEIGHT)\n-\t\t* MaximumBlockWeight::get();\n-\tpub const MaximumBlockLength: u32 = 5 * 1024 * 1024;\n \tpub const Version: RuntimeVersion = VERSION;\n-}\n-\n-const_assert!(AvailableBlockRatio::get().deconstruct() >= AVERAGE_ON_INITIALIZE_WEIGHT.deconstruct());\n-\n-impl frame_system::Trait for Runtime {\n+\tpub RuntimeBlockLength: BlockLength =\n+\t\tBlockLength::max_with_normal_ratio(5 * 1024 * 1024, NORMAL_DISPATCH_RATIO);\n+\tpub RuntimeBlockWeights: BlockWeights = BlockWeights::builder()\n+\t\t.base_block(BlockExecutionWeight::get())\n+\t\t.for_class(DispatchClass::all(), |weights| {\n+\t\t\tweights.base_extrinsic = ExtrinsicBaseWeight::get();\n+\t\t})\n+\t\t.for_class(DispatchClass::Normal, |weights| {\n+\t\t\tweights.max_total = Some(NORMAL_DISPATCH_RATIO * MAXIMUM_BLOCK_WEIGHT);\n+\t\t})\n+\t\t.for_class(DispatchClass::Operational, |weights| {\n+\t\t\tweights.max_total = Some(MAXIMUM_BLOCK_WEIGHT);\n+\t\t\t// Operational transactions have some extra reserved space, so that they\n+\t\t\t// are included even if block reached `MAXIMUM_BLOCK_WEIGHT`.\n+\t\t\tweights.reserved = Some(\n+\t\t\t\tMAXIMUM_BLOCK_WEIGHT - NORMAL_DISPATCH_RATIO * MAXIMUM_BLOCK_WEIGHT\n+\t\t\t);\n+\t\t})\n+\t\t.avg_block_initialization(AVERAGE_ON_INITIALIZE_RATIO)\n+\t\t.build_or_panic();\n+}\n+\n+const_assert!(NORMAL_DISPATCH_RATIO.deconstruct() >= AVERAGE_ON_INITIALIZE_RATIO.deconstruct());\n+\n+impl frame_system::Config for Runtime {\n \ttype BaseCallFilter = frame_support::traits::AllowAll;\n+\ttype BlockWeights = RuntimeBlockWeights;\n+\ttype BlockLength = RuntimeBlockLength;\n+\ttype DbWeight = RocksDbWeight;\n \ttype RuntimeOrigin = RuntimeOrigin;\n \ttype RuntimeCall = RuntimeCall;\n \ttype Index = Index;\n@@ -171,25 +198,19 @@ impl frame_system::Trait for Runtime {\n \ttype Header = generic::Header<BlockNumber, BlakeTwo256>;\n \ttype Event = Event;\n \ttype BlockHashCount = BlockHashCount;\n-\ttype MaximumBlockWeight = MaximumBlockWeight;\n-\ttype DbWeight = RocksDbWeight;\n-\ttype BlockExecutionWeight = BlockExecutionWeight;\n-\ttype ExtrinsicBaseWeight = ExtrinsicBaseWeight;\n-\ttype MaximumExtrinsicWeight = MaximumExtrinsicWeight;\n-\ttype MaximumBlockLength = MaximumBlockLength;\n-\ttype AvailableBlockRatio = AvailableBlockRatio;\n \ttype Version = Version;\n \ttype PalletInfo = PalletInfo;\n \ttype AccountData = pallet_balances::AccountData<Balance>;\n \ttype OnNewAccount = ();\n \ttype OnKilledAccount = ();\n-\ttype SystemWeightInfo = weights::frame_system::WeightInfo;\n+\ttype SystemWeightInfo = frame_system::weights::SubstrateWeight<Runtime>;\n\n### Pallets\n\n### Assets\n\nThe assets pallet has seen a variety of changes:\n- Features needed for reserve-backed stablecoins #7152\n- Freeze Assets and Asset Metadata #7346\n- Introduces account existence providers reference counting #7363)\n\nhave all altered the feature set and changed the concepts. However, it has some of the best documentation and explains\nthe current state very well. If you are using the assets pallet and need to upgrade from an earlier version, we\nrecommend you use the current docs to guide your way!\n\n### Contracts\n\nAs noted in the changelog, the `contracts`-pallet is still undergoing massive changes and is not yet part of this\nrelease. We are expecting for it to be released a few weeks after. If your chain is dependent on this pallet, we\nrecommend to wait until it has been released as the currently released version is not compatible with FRAME 2.0.\n\n### (changes) Treasury\n\nAs mentioned above, Bounties, Tips and Lottery have been extracted out of treasury into their own pallets - removing\nthese options here. Secondly we must now specify the `BurnDestination`  and `SpendFunds`, which now go the `Bounties`.\ndiff\n-\ttype Tippers = Elections;\n-\ttype TipCountdown = TipCountdown;\n-\ttype TipFindersFee = TipFindersFee;\n-\ttype TipReportDepositBase = TipReportDepositBase;\n-\ttype DataDepositPerByte = DataDepositPerByte;\n \ttype Event = Event;\n \ttype OnSlash = ();\n \ttype ProposalBond = ProposalBond;\n \ttype ProposalBondMinimum = ProposalBondMinimum;\n\ttype ProposalBondMaximum = ();\n \ttype SpendPeriod = SpendPeriod;\n \ttype Burn = Burn;\n+\ttype BurnDestination = ();\n+\ttype SpendFunds = Bounties;\n\nFactoring out Bounties and Tips means most of these definitions have now moved there, while the parameter types can be\nleft as they were:\n\n### \ud83c\udd95 Bounties\nrust=\nimpl pallet_bounties::Config for Runtime {\n\ttype Event = Event;\n \ttype BountyDepositBase = BountyDepositBase;\n \ttype BountyDepositPayoutDelay = BountyDepositPayoutDelay;\n \ttype BountyUpdatePeriod = BountyUpdatePeriod;\n \ttype BountyCuratorDeposit = BountyCuratorDeposit;\n \ttype BountyValueMinimum = BountyValueMinimum;\n\ttype DataDepositPerByte = DataDepositPerByte;\n \ttype MaximumReasonLength = MaximumReasonLength;\n\ttype WeightInfo = pallet_bounties::weights::SubstrateWeight<Runtime>;\n }\n\n### \ud83c\udd95 Tips\nrust=\nimpl pallet_tips::Config for Runtime {\n\ttype Event = Event;\n\ttype DataDepositPerByte = DataDepositPerByte;\n\ttype MaximumReasonLength = MaximumReasonLength;\n\ttype Tippers = Elections;\n\ttype TipCountdown = TipCountdown;\n\ttype TipFindersFee = TipFindersFee;\n\ttype TipReportDepositBase = TipReportDepositBase;\n\ttype MaxTipAmount = MaxTipAmount;\n\ttype WeightInfo = pallet_tips::weights::SubstrateWeight<Runtime>;\n }\n\n### `FinalityTracker` removed\n\nFinality Tracker has been removed in favor of a different approach to handle the issue in GRANDPA, see #7228 for\ndetails. With latest GRANDPA this is not needed anymore and can be\nremoved without worry.\n\n### (changes) Elections Phragmen\n\nThe pallet has been moved to a new system in which the exact amount of deposit for each voter, candidate, member, or\nrunner-up is now deposited on-chain. Moreover, the concept of a `defunct_voter` is removed, since votes now have\nadequate deposit associated with them. A number of configuration parameters has changed to reflect this, as shown below:\ndiff=\n parameter_types! {\n \tpub const CandidacyBond: Balance = 10 * DOLLARS;\n-\tpub const VotingBond: Balance = 1 * DOLLARS;\n+\t// 1 storage item created, key size is 32 bytes, value size is 16+16.\n+\tpub const VotingBondBase: Balance = deposit(1, 64);\n+\t// additional data per vote is 32 bytes (account id).\n+\tpub const VotingBondFactor: Balance = deposit(0, 32);\n \tpub const TermDuration: BlockNumber = 7 * DAYS;\n \tpub const DesiredMembers: u32 = 13;\n \tpub const DesiredRunnersUp: u32 = 7;\n\n@@ -559,16 +600,16 @@ impl pallet_elections_phragmen::Trait for Runtime {\n \t// NOTE: this implies that council's genesis members cannot be set directly and must come from\n \t// this module.\n \ttype InitializeMembers = Council;\n-\ttype CurrencyToVote = CurrencyToVoteHandler;\n+\ttype CurrencyToVote = U128CurrencyToVote;\n \ttype CandidacyBond = CandidacyBond;\n-\ttype VotingBond = VotingBond;\n+\ttype VotingBondBase = VotingBondBase;\n+\ttype VotingBondFactor = VotingBondFactor;\n \ttype LoserCandidate = ();\n-\ttype BadReport = ();\n \ttype KickedMember = ();\n \ttype DesiredMembers = DesiredMembers;\n \ttype DesiredRunnersUp = DesiredRunnersUp;\n \ttype TermDuration = TermDuration;\n \n **This upgrade requires storage\n migration**.\n Further details can be found in the pallet-specific\n changelog.\n\n### (changes) Democracy\n\nDemocracy brings three new settings with this release, all to allow for better influx- and spam-control. Namely these\nallow to specify the maximum number of proposals at a time, who can blacklist and who can cancel proposals. This diff\nacts as a good starting point:\ndiff=\n@@ -508,6 +537,14 @@ impl pallet_democracy::Trait for Runtime {\n \ttype FastTrackVotingPeriod = FastTrackVotingPeriod;\n \t// To cancel a proposal which has been passed, 2/3 of the council must agree to it.\n \ttype CancellationOrigin = pallet_collective::EnsureProportionAtLeast<_2, _3, AccountId, CouncilCollective>;\n+\t// To cancel a proposal before it has been passed, the technical committee must be unanimous or\n+\t// Root must agree.\n+\ttype CancelProposalOrigin = EitherOfDiverse<\n+\t\tAccountId,\n+\t\tEnsureRoot<AccountId>,\n+\t\tpallet_collective::EnsureProportionAtLeast<_1, _1, AccountId, TechnicalCollective>,\n+\t>;\n+\ttype BlacklistOrigin = EnsureRoot<AccountId>;\n \t// Any single technical committee member may veto a coming council proposal, however they can\n \t// only do it once and it lasts only for the cooloff period.\n \ttype VetoOrigin = pallet_collective::EnsureMember<AccountId, TechnicalCollective>;\n@@ -518,7 +555,8 @@ impl pallet_democracy::Trait for Runtime {\n \ttype Scheduler = Scheduler;\n \ttype PalletsOrigin = OriginCaller;\n \ttype MaxVotes = MaxVotes;\n+\ttype MaxProposals = MaxProposals;\n }\n```\n\n----"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain client\ninput: "
      },
      {
        "role": "assistant",
        "content": "### CLI\n\nA few minor things have changed in the `cli` (compared to 2.0.1):\n\n1. we've replaced the newly added `BuildSyncSpec` subcommand with an RPC\n   API\n   in an on-going effort to make light-client-support smoother, see below\n2. we've removed double accounts from our\n   chainspec-builder\n3. we don't fallback to `--chain flaming-fir`\n   anymore, if no chain is\n   given our `substrate-node` will error.\n4. the `subkey`-integration has seen a fix to the\n   `insert`-command that\n   requires you to now add the `&cli` as a param.\n    ```diff=\n    --- a/bin/node/cli/src/command.rs\n    +++ b/bin/node/cli/src/command.rs\n    @@ -92,7 +97,7 @@ pub fn run() -> Result<()> {\n                    You can enable it with `--features runtime-benchmarks`.\".into())\n                }\n            }\n    -\t\tSome(Subcommand::Key(cmd)) => cmd.run(),\n    +\t\tSome(Subcommand::Key(cmd)) => cmd.run(&cli),\n            Some(Subcommand::Sign(cmd)) => cmd.run(),\n            Some(Subcommand::Verify(cmd)) => cmd.run(),\n            Some(Subcommand::Vanity(cmd)) => cmd.run(),\n    \n### Service Builder Upgrades\n\n### Light client support\n\nAs said, we've added a new optional RPC service for improved light client support. For that to work, we need to pass the\n`chain_spec` and give access  to the `AuxStore` to our `rpc`:\ndiff=\n\n--- a/bin/node/rpc/src/lib.rs\n+++ b/bin/node/rpc/src/lib.rs\n@@ -49,6 +49,7 @@ use sp_consensus::SelectChain;\n use sp_consensus_babe::BabeApi;\n use sc_rpc::SubscriptionTaskExecutor;\n use sp_transaction_pool::TransactionPool;\n+use sc_client_api::AuxStore;\n\n /// Light client extra dependencies.\n pub struct LightDeps<C, F, P> {\n@@ -94,6 +95,8 @@ pub struct FullDeps<C, P, SC, B> {\n \tpub pool: Arc<P>,\n \t/// The SelectChain Strategy\n \tpub select_chain: SC,\n+\t/// A copy of the chain spec.\n+\tpub chain_spec: Box<dyn sc_chain_spec::ChainSpec>,\n \t/// Whether to deny unsafe calls\n \tpub deny_unsafe: DenyUnsafe,\n \t/// BABE specific dependencies.\n@@ -109,9 +112,8 @@ pub type IoHandler = jsonrpc_core::IoHandler<sc_rpc::Metadata>;\n pub fn create_full<C, P, SC, B>(\n \tdeps: FullDeps<C, P, SC, B>,\n ) -> jsonrpc_core::IoHandler<sc_rpc_api::Metadata> where\n-\tC: ProvideRuntimeApi<Block>,\n-\tC: HeaderBackend<Block> + HeaderMetadata<Block, Error=BlockChainError> + 'static,\n-\tC: Send + Sync + 'static,\n+\tC: ProvideRuntimeApi<Block> + HeaderBackend<Block> + AuxStore +\n+\t\tHeaderMetadata<Block, Error=BlockChainError> + Sync + Send + 'static,\n \tC::Api: substrate_frame_rpc_system::AccountNonceApi<Block, AccountId, Index>,\n \tC::Api: pallet_contracts_rpc::ContractsRuntimeApi<Block, AccountId, Balance, BlockNumber>,\n \tC::Api: pallet_transaction_payment_rpc::TransactionPaymentRuntimeApi<Block, Balance>,\n@@ -131,6 +133,7 @@ pub fn create_full<C, P, SC, B>(\n \t\tclient,\n \t\tpool,\n \t\tselect_chain,\n+\t\tchain_spec,\n \t\tdeny_unsafe,\n \t\tbabe,\n \t\tgrandpa,\n@@ -164,8 +167,8 @@ pub fn create_full<C, P, SC, B>(\n \tio.extend_with(\n \t\tsc_consensus_babe_rpc::BabeApi::to_delegate(\n \t\t\tBabeRpcHandler::new(\n-\t\t\t\tclient,\n-\t\t\t\tshared_epoch_changes,\n+\t\t\t\tclient.clone(),\n+\t\t\t\tshared_epoch_changes.clone(),\n \t\t\t\tkeystore,\n \t\t\t\tbabe_config,\n \t\t\t\tselect_chain,\n@@ -176,7 +179,7 @@ pub fn create_full<C, P, SC, B>(\n \tio.extend_with(\n \t\tsc_finality_grandpa_rpc::GrandpaApi::to_delegate(\n \t\t\tGrandpaRpcHandler::new(\n-\t\t\t\tshared_authority_set,\n+\t\t\t\tshared_authority_set.clone(),\n \t\t\t\tshared_voter_state,\n \t\t\t\tjustification_stream,\n \t\t\t\tsubscription_executor,\n\n\nand add the new service:\ndiff=\n--- a/bin/node/rpc/src/lib.rs\n+++ b/bin/node/rpc/src/lib.rs\n@@ -185,6 +188,18 @@ pub fn create_full<C, P, SC, B>(\n \t\t)\n \t);\n\n+\tio.extend_with(\n+\t\tsc_sync_state_rpc::SyncStateRpcApi::to_delegate(\n+\t\t\tsc_sync_state_rpc::SyncStateRpcHandler::new(\n+\t\t\t\tchain_spec,\n+\t\t\t\tclient,\n+\t\t\t\tshared_authority_set,\n+\t\t\t\tshared_epoch_changes,\n+\t\t\t\tdeny_unsafe,\n+\t\t\t)\n+\t\t)\n+\t);\n+\n \tio\n }\n\n### Telemetry\n\nThe telemetry subsystem has seen a few fixes and refactorings to allow for a more flexible handling, in particular in\nregards to parachains. Most notably `sc_service::spawn_tasks` now returns the `telemetry_connection_notifier` as the\nsecond member of the tuple, (`let (_rpc_handlers, telemetry_connection_notifier) = sc_service::spawn_tasks(`), which\nshould be passed to `telemetry_on_connect` of `new_full_base` now: `telemetry_on_connect:\ntelemetry_connection_notifier.map(|x| x.on_connect_stream()),` (see the service-section below for a full diff).\n\n### Async & Remote Keystore support\n\nIn order to allow for remote-keystores, the keystore-subsystem has been reworked to support async operations and\ngenerally refactored to not provide the keys itself but only sign on request. This allows for remote-keystore to never\nhand out keys and thus to operate any Substrate-based node in a manner without ever having the private keys in the local\nsystem memory.\n\nThere are some operations, however, that the keystore must be local for performance reasons and for which a remote\nkeystore won't work (in particular around parachains). As such, the keystore has both a slot for remote but also always\na local instance, where some operations hard bind to the local variant, while most subsystems just ask the generic\nkeystore which prefers a remote signer if given. To reflect this change, `sc_service::new_full_parts` now returns a\n`KeystoreContainer` rather than the keystore, and the other subsystems (e.g. `sc_service::PartialComponents`) expect to\nbe given that.\n\n### on RPC\n\nThis has most visible changes for the rpc, where we are switching from the previous `KeyStorePtr` to the new\n`SyncCryptoStorePtr`:\ndiff\n\n--- a/bin/node/rpc/src/lib.rs\n+++ b/bin/node/rpc/src/lib.rs\n@@ -32,6 +32,7 @@\n\n use std::sync::Arc;\n\n+use sp_keystore::SyncCryptoStorePtr;\n use node_primitives::{Block, BlockNumber, AccountId, Index, Balance, Hash};\n use sc_consensus_babe::{Config, Epoch};\n use sc_consensus_babe_rpc::BabeRpcHandler;\n@@ -40,7 +41,6 @@ use sc_finality_grandpa::{\n \tSharedVoterState, SharedAuthoritySet, FinalityProofProvider, GrandpaJustificationStream\n };\n use sc_finality_grandpa_rpc::GrandpaRpcHandler;\n-use sc_keystore::KeyStorePtr;\n pub use sc_rpc_api::DenyUnsafe;\n use sp_api::ProvideRuntimeApi;\n use sp_block_builder::BlockBuilder;\n pub struct LightDeps<C, F, P> {\n@@ -69,7 +70,7 @@ pub struct BabeDeps {\n \t/// BABE pending epoch changes.\n \tpub shared_epoch_changes: SharedEpochChanges<Block, Epoch>,\n \t/// The keystore that manages the keys of the node.\n-\tpub keystore: KeyStorePtr,\n+\tpub keystore: SyncCryptoStorePtr,\n }\n\n\n### GRANDPA\n\nAs already in the changelog, a few things significant things have changed in regards to GRANDPA: the finality tracker\nhas been replaced, an RPC command has been added and WARP-sync-support for faster light client startup has been\nimplemented. All this means we have to do a few changes to our GRANDPA setup procedures in the client.\n\nFirst and foremost, grandpa internalised a few aspects, and thus `new_partial` doesn't expect a tuple but only the\n`grandpa::SharedVoterState` as input now, and unpacking that again later is not needed anymore either. On the opposite\nside `grandpa::FinalityProofProvider::new_for_service` now requires the `Some(shared_authority_set)` to be passed as a\nnew third parameter. This set also becomes relevant when adding warp-sync-support, which is added as an\nextra-protocol-layer to the networking as:diff=\n\n+\tconfig.network.extra_sets.push(grandpa::grandpa_peers_set_config());\n+\n+\t#[cfg(feature = \"cli\")]\n+\tconfig.network.request_response_protocols.push(sc_finality_grandpa_warp_sync::request_response_config_for_chain(\n+\t\t&config, task_manager.spawn_handle(), backend.clone(),\n+\t));\n\nAs these changes pull through the entirety of `cli/src/service.rs`, we recommend looking at the final diff below for\nguidance.\n\n### In a nutshell\n\nAltogether this accumulates to the following diff for `node/cli/src/service.rs`. If you want these features and have\nmodified your chain you should probably try to apply these patches:\ndiff=\n--- a/bin/node/cli/src/service.rs\n+++ b/bin/node/cli/src/service.rs\n@@ -22,11 +22,10 @@\n\n use std::sync::Arc;\n use sc_consensus_babe;\n-use grandpa::{self, FinalityProofProvider as GrandpaFinalityProofProvider};\n use node_primitives::Block;\n use node_runtime::RuntimeApi;\n use sc_service::{\n-\tconfig::{Role, Configuration}, error::{Error as ServiceError},\n+\tconfig::{Configuration}, error::{Error as ServiceError},\n \tRpcHandlers, TaskManager,\n };\n use sp_inherents::InherentDataProviders;\n@@ -34,8 +33,8 @@ use sc_network::{Event, NetworkService};\n use sp_runtime::traits::Block as BlockT;\n use futures::prelude::*;\n use sc_client_api::{ExecutorProvider, RemoteBackend};\n-use sp_core::traits::BareCryptoStorePtr;\n use node_executor::Executor;\n+use sc_telemetry::TelemetryConnectionNotifier;\n\n type FullClient = sc_service::TFullClient<Block, RuntimeApi, Executor>;\n type FullBackend = sc_service::TFullBackend<Block>;\n@@ -58,13 +57,10 @@ pub fn new_partial(config: &Configuration) -> Result<sc_service::PartialComponen\n \t\t\tgrandpa::LinkHalf<Block, FullClient, FullSelectChain>,\n \t\t\tsc_consensus_babe::BabeLink<Block>,\n \t\t),\n-\t\t(\n-\t\t\tgrandpa::SharedVoterState,\n-\t\t\tArc<GrandpaFinalityProofProvider<FullBackend, Block>>,\n-\t\t),\n+\t\tgrandpa::SharedVoterState,\n \t)\n >, ServiceError> {\n-\tlet (client, backend, keystore, task_manager) =\n+\tlet (client, backend, keystore_container, task_manager) =\n \t\tsc_service::new_full_parts::<Block, RuntimeApi, Executor>(&config)?;\n \tlet client = Arc::new(client);\n\n@@ -94,7 +90,6 @@ pub fn new_partial(config: &Configuration) -> Result<sc_service::PartialComponen\n \t\tbabe_link.clone(),\n \t\tblock_import.clone(),\n \t\tSome(Box::new(justification_import)),\n-\t\tNone,\n \t\tclient.clone(),\n \t\tselect_chain.clone(),\n \t\tinherent_data_providers.clone(),\n@@ -111,10 +106,12 @@ pub fn new_partial(config: &Configuration) -> Result<sc_service::PartialComponen\n \t\tlet justification_stream = grandpa_link.justification_stream();\n \t\tlet shared_authority_set = grandpa_link.shared_authority_set().clone();\n \t\tlet shared_voter_state = grandpa::SharedVoterState::empty();\n-\t\tlet finality_proof_provider =\n-\t\t\tGrandpaFinalityProofProvider::new_for_service(backend.clone(), client.clone());\n+\t\tlet rpc_setup = shared_voter_state.clone();\n\n-\t\tlet rpc_setup = (shared_voter_state.clone(), finality_proof_provider.clone());\n+\t\tlet finality_proof_provider = grandpa::FinalityProofProvider::new_for_service(\n+\t\t\tbackend.clone(),\n+\t\t\tSome(shared_authority_set.clone()),\n+\t\t);\n\n \t\tlet babe_config = babe_link.config().clone();\n \t\tlet shared_epoch_changes = babe_link.epoch_changes().clone();\n@@ -122,13 +119,15 @@ pub fn new_partial(config: &Configuration) -> Result<sc_service::PartialComponen\n \t\tlet client = client.clone();\n \t\tlet pool = transaction_pool.clone();\n \t\tlet select_chain = select_chain.clone();\n-\t\tlet keystore = keystore.clone();\n+\t\tlet keystore = keystore_container.sync_keystore();\n+\t\tlet chain_spec = config.chain_spec.cloned_box();\n\n \t\tlet rpc_extensions_builder = move |deny_unsafe, subscription_executor| {\n \t\t\tlet deps = node_rpc::FullDeps {\n \t\t\t\tclient: client.clone(),\n \t\t\t\tpool: pool.clone(),\n \t\t\t\tselect_chain: select_chain.clone(),\n+\t\t\t\tchain_spec: chain_spec.cloned_box(),\n \t\t\t\tdeny_unsafe,\n \t\t\t\tbabe: node_rpc::BabeDeps {\n \t\t\t\t\tbabe_config: babe_config.clone(),\n@@ -151,9 +150,15 @@ pub fn new_partial(config: &Configuration) -> Result<sc_service::PartialComponen\n \t};\n\n \tOk(sc_service::PartialComponents {\n-\t\tclient, backend, task_manager, keystore, select_chain, import_queue, transaction_pool,\n+\t\tclient,\n+\t\tbackend,\n+\t\ttask_manager,\n+\t\tkeystore_container,\n+\t\tselect_chain,\n+\t\timport_queue,\n+\t\ttransaction_pool,\n \t\tinherent_data_providers,\n-\t\tother: (rpc_extensions_builder, import_setup, rpc_setup)\n+\t\tother: (rpc_extensions_builder, import_setup, rpc_setup),\n \t})\n }\n\n@@ -168,19 +173,32 @@ pub struct NewFullBase {\n\n /// Creates a full service from the configuration.\n pub fn new_full_base(\n-\tconfig: Configuration,\n+\tmut config: Configuration,\n \twith_startup_data: impl FnOnce(\n \t\t&sc_consensus_babe::BabeBlockImport<Block, FullClient, FullGrandpaBlockImport>,\n \t\t&sc_consensus_babe::BabeLink<Block>,\n \t)\n ) -> Result<NewFullBase, ServiceError> {\n \tlet sc_service::PartialComponents {\n-\t\tclient, backend, mut task_manager, import_queue, keystore, select_chain, transaction_pool,\n+\t\tclient,\n+\t\tbackend,\n+\t\tmut task_manager,\n+\t\timport_queue,\n+\t\tkeystore_container,\n+\t\tselect_chain,\n+\t\ttransaction_pool,\n \t\tinherent_data_providers,\n \t\tother: (rpc_extensions_builder, import_setup, rpc_setup),\n \t} = new_partial(&config)?;\n\n-\tlet (shared_voter_state, finality_proof_provider) = rpc_setup;\n+\tlet shared_voter_state = rpc_setup;\n+\n+\tconfig.network.extra_sets.push(grandpa::grandpa_peers_set_config());\n+\n+\t#[cfg(feature = \"cli\")]\n+\tconfig.network.request_response_protocols.push(sc_finality_grandpa_warp_sync::request_response_config_for_chain(\n+\t\t&config, task_manager.spawn_handle(), backend.clone(),\n+\t));\n\n \tlet (network, network_status_sinks, system_rpc_tx, network_starter) =\n \t\tsc_service::build_network(sc_service::BuildNetworkParams {\n@@ -191,8 +209,6 @@ pub fn new_full_base(\n \t\t\timport_queue,\n \t\t\ton_demand: None,\n \t\t\tblock_announce_validator_builder: None,\n-\t\t\tfinality_proof_request_builder: None,\n-\t\t\tfinality_proof_provider: Some(finality_proof_provider.clone()),\n \t\t})?;\n\n \tif config.offchain_worker.enabled {\n@@ -203,26 +219,28 @@ pub fn new_full_base(\n\n \tlet role = config.role.clone();\n \tlet force_authoring = config.force_authoring;\n+\tlet backoff_authoring_blocks =\n+\t\tSome(sc_consensus_slots::BackoffAuthoringOnFinalizedHeadLagging::default());\n \tlet name = config.network.node_name.clone();\n \tlet enable_grandpa = !config.disable_grandpa;\n \tlet prometheus_registry = config.prometheus_registry().cloned();\n-\tlet telemetry_connection_sinks = sc_service::TelemetryConnectionSinks::default();\n\n-\tsc_service::spawn_tasks(sc_service::SpawnTasksParams {\n-\t\tconfig,\n-\t\tbackend: backend.clone(),\n-\t\tclient: client.clone(),\n-\t\tkeystore: keystore.clone(),\n-\t\tnetwork: network.clone(),\n-\t\trpc_extensions_builder: Box::new(rpc_extensions_builder),\n-\t\ttransaction_pool: transaction_pool.clone(),\n-\t\ttask_manager: &mut task_manager,\n-\t\ton_demand: None,\n-\t\tremote_blockchain: None,\n-\t\ttelemetry_connection_sinks: telemetry_connection_sinks.clone(),\n-\t\tnetwork_status_sinks: network_status_sinks.clone(),\n-\t\tsystem_rpc_tx,\n-\t})?;\n+\tlet (_rpc_handlers, telemetry_connection_notifier) = sc_service::spawn_tasks(\n+\t\tsc_service::SpawnTasksParams {\n+\t\t\tconfig,\n+\t\t\tbackend: backend.clone(),\n+\t\t\tclient: client.clone(),\n+\t\t\tkeystore: keystore_container.sync_keystore(),\n+\t\t\tnetwork: network.clone(),\n+\t\t\trpc_extensions_builder: Box::new(rpc_extensions_builder),\n+\t\t\ttransaction_pool: transaction_pool.clone(),\n+\t\t\ttask_manager: &mut task_manager,\n+\t\t\ton_demand: None,\n+\t\t\tremote_blockchain: None,\n+\t\t\tnetwork_status_sinks: network_status_sinks.clone(),\n+\t\t\tsystem_rpc_tx,\n+\t\t},\n+\t)?;\n\n \tlet (block_import, grandpa_link, babe_link) = import_setup;\n\n@@ -230,6 +248,7 @@ pub fn new_full_base(\n\n \tif let sc_service::config::Role::Authority { .. } = &role {\n \t\tlet proposer = sc_basic_authorship::ProposerFactory::new(\n+\t\t\ttask_manager.spawn_handle(),\n \t\t\tclient.clone(),\n \t\t\ttransaction_pool.clone(),\n \t\t\tprometheus_registry.as_ref(),\n@@ -239,7 +258,7 @@ pub fn new_full_base(\n \t\t\tsp_consensus::CanAuthorWithNativeVersion::new(client.executor().clone());\n\n \t\tlet babe_config = sc_consensus_babe::BabeParams {\n-\t\t\tkeystore: keystore.clone(),\n+\t\t\tkeystore: keystore_container.sync_keystore(),\n \t\t\tclient: client.clone(),\n \t\t\tselect_chain,\n \t\t\tenv: proposer,\n@@ -247,6 +266,7 @@ pub fn new_full_base(\n \t\t\tsync_oracle: network.clone(),\n \t\t\tinherent_data_providers: inherent_data_providers.clone(),\n \t\t\tforce_authoring,\n+\t\t\tbackoff_authoring_blocks,\n \t\t\tbabe_link,\n \t\t\tcan_author_with,\n \t\t};\n@@ -256,42 +276,30 @@ pub fn new_full_base(\n \t}\n\n \t// Spawn authority discovery module.\n-\tif matches!(role, Role::Authority{..} | Role::Sentry {..}) {\n-\t\tlet (sentries, authority_discovery_role) = match role {\n-\t\t\tsc_service::config::Role::Authority { ref sentry_nodes } => (\n-\t\t\t\tsentry_nodes.clone(),\n-\t\t\t\tsc_authority_discovery::Role::Authority (\n-\t\t\t\t\tkeystore.clone(),\n-\t\t\t\t),\n-\t\t\t),\n-\t\t\tsc_service::config::Role::Sentry {..} => (\n-\t\t\t\tvec![],\n-\t\t\t\tsc_authority_discovery::Role::Sentry,\n-\t\t\t),\n-\t\t\t_ => unreachable!(\"Due to outer matches! constraint; qed.\")\n-\t\t};\n-\n+\tif role.is_authority() {\n+\t\tlet authority_discovery_role = sc_authority_discovery::Role::PublishAndDiscover(\n+\t\t\tkeystore_container.keystore(),\n+\t\t);\n \t\tlet dht_event_stream = network.event_stream(\"authority-discovery\")\n \t\t\t.filter_map(|e| async move { match e {\n \t\t\t\tEvent::Dht(e) => Some(e),\n \t\t\t\t_ => None,\n-\t\t\t}}).boxed();\n+\t\t\t}});\n \t\tlet (authority_discovery_worker, _service) = sc_authority_discovery::new_worker_and_service(\n \t\t\tclient.clone(),\n \t\t\tnetwork.clone(),\n-\t\t\tsentries,\n-\t\t\tdht_event_stream,\n+\t\t\tBox::pin(dht_event_stream),\n \t\t\tauthority_discovery_role,\n \t\t\tprometheus_registry.clone(),\n \t\t);\n\n-\t\ttask_manager.spawn_handle().spawn(\"authority-discovery-worker\", authority_discovery_worker);\n+\t\ttask_manager.spawn_handle().spawn(\"authority-discovery-worker\", authority_discovery_worker.run());\n \t}\n\n \t// if the node isn't actively participating in consensus then it doesn't\n \t// need a keystore, regardless of which protocol we use below.\n \tlet keystore = if role.is_authority() {\n-\t\tSome(keystore as BareCryptoStorePtr)\n+\t\tSome(keystore_container.sync_keystore())\n \t} else {\n \t\tNone\n \t};\n@@ -317,8 +325,7 @@ pub fn new_full_base(\n \t\t\tconfig,\n \t\t\tlink: grandpa_link,\n \t\t\tnetwork: network.clone(),\n-\t\t\tinherent_data_providers: inherent_data_providers.clone(),\n-\t\t\ttelemetry_on_connect: Some(telemetry_connection_sinks.on_connect_stream()),\n+\t\t\ttelemetry_on_connect: telemetry_connection_notifier.map(|x| x.on_connect_stream()),\n \t\t\tvoting_rule: grandpa::VotingRulesBuilder::default().build(),\n \t\t\tprometheus_registry,\n \t\t\tshared_voter_state,\n@@ -330,17 +337,15 @@ pub fn new_full_base(\n \t\t\t\"grandpa-voter\",\n \t\t\tgrandpa::run_grandpa_voter(grandpa_config)?\n \t\t);\n-\t} else {\n-\t\tgrandpa::setup_disabled_grandpa(\n-\t\t\tclient.clone(),\n-\t\t\t&inherent_data_providers,\n-\t\t\tnetwork.clone(),\n-\t\t)?;\n \t}\n\n \tnetwork_starter.start_network();\n \tOk(NewFullBase {\n-\t\ttask_manager, inherent_data_providers, client, network, network_status_sinks,\n+\t\ttask_manager,\n+\t\tinherent_data_providers,\n+\t\tclient,\n+\t\tnetwork,\n+\t\tnetwork_status_sinks,\n \t\ttransaction_pool,\n \t})\n }\n@@ -353,14 +358,16 @@ pub fn new_full(config: Configuration)\n \t})\n }\n\n-pub fn new_light_base(config: Configuration) -> Result<(\n-\tTaskManager, RpcHandlers, Arc<LightClient>,\n+pub fn new_light_base(mut config: Configuration) -> Result<(\n+\tTaskManager, RpcHandlers, Option<TelemetryConnectionNotifier>, Arc<LightClient>,\n \tArc<NetworkService<Block, <Block as BlockT>::Hash>>,\n \tArc<sc_transaction_pool::LightPool<Block, LightClient, sc_network::config::OnDemand<Block>>>\n ), ServiceError> {\n-\tlet (client, backend, keystore, mut task_manager, on_demand) =\n+\tlet (client, backend, keystore_container, mut task_manager, on_demand) =\n \t\tsc_service::new_light_parts::<Block, RuntimeApi, Executor>(&config)?;\n\n+\tconfig.network.extra_sets.push(grandpa::grandpa_peers_set_config());\n+\n \tlet select_chain = sc_consensus::LongestChain::new(backend.clone());\n\n \tlet transaction_pool = Arc::new(sc_transaction_pool::BasicPool::new_light(\n@@ -371,14 +378,12 @@ pub fn new_light_base(config: Configuration) -> Result<(\n \t\ton_demand.clone(),\n \t));\n\n-\tlet grandpa_block_import = grandpa::light_block_import(\n-\t\tclient.clone(), backend.clone(), &(client.clone() as Arc<_>),\n-\t\tArc::new(on_demand.checker().clone()),\n+\tlet (grandpa_block_import, _) = grandpa::block_import(\n+\t\tclient.clone(),\n+\t\t&(client.clone() as Arc<_>),\n+\t\tselect_chain.clone(),\n \t)?;\n-\n-\tlet finality_proof_import = grandpa_block_import.clone();\n-\tlet finality_proof_request_builder =\n-\t\tfinality_proof_import.create_finality_proof_request_builder();\n+\tlet justification_import = grandpa_block_import.clone();\n\n \tlet (babe_block_import, babe_link) = sc_consensus_babe::block_import(\n \t\tsc_consensus_babe::Config::get_or_compute(&*client)?,\n@@ -391,8 +396,7 @@ pub fn new_light_base(config: Configuration) -> Result<(\n \tlet import_queue = sc_consensus_babe::import_queue(\n \t\tbabe_link,\n \t\tbabe_block_import,\n-\t\tNone,\n-\t\tSome(Box::new(finality_proof_import)),\n+\t\tSome(Box::new(justification_import)),\n \t\tclient.clone(),\n \t\tselect_chain.clone(),\n \t\tinherent_data_providers.clone(),\n@@ -401,9 +405,6 @@ pub fn new_light_base(config: Configuration) -> Result<(\n \t\tsp_consensus::NeverCanAuthor,\n \t)?;\n\n-\tlet finality_proof_provider =\n-\t\tGrandpaFinalityProofProvider::new_for_service(backend.clone(), client.clone());\n-\n \tlet (network, network_status_sinks, system_rpc_tx, network_starter) =\n \t\tsc_service::build_network(sc_service::BuildNetworkParams {\n \t\t\tconfig: &config,\n@@ -413,8 +414,6 @@ pub fn new_light_base(config: Configuration) -> Result<(\n \t\t\timport_queue,\n \t\t\ton_demand: Some(on_demand.clone()),\n \t\t\tblock_announce_validator_builder: None,\n-\t\t\tfinality_proof_request_builder: Some(finality_proof_request_builder),\n-\t\t\tfinality_proof_provider: Some(finality_proof_provider),\n \t\t})?;\n \tnetwork_starter.start_network();\n\n@@ -433,32 +432,39 @@ pub fn new_light_base(config: Configuration) -> Result<(\n\n \tlet rpc_extensions = node_rpc::create_light(light_deps);\n\n-\tlet rpc_handlers =\n+\tlet (rpc_handlers, telemetry_connection_notifier) =\n \t\tsc_service::spawn_tasks(sc_service::SpawnTasksParams {\n \t\t\ton_demand: Some(on_demand),\n \t\t\tremote_blockchain: Some(backend.remote_blockchain()),\n \t\t\trpc_extensions_builder: Box::new(sc_service::NoopRpcExtensionBuilder(rpc_extensions)),\n \t\t\tclient: client.clone(),\n \t\t\ttransaction_pool: transaction_pool.clone(),\n-\t\t\tconfig, keystore, backend, network_status_sinks, system_rpc_tx,\n+\t\t\tkeystore: keystore_container.sync_keystore(),\n+\t\t\tconfig, backend, network_status_sinks, system_rpc_tx,\n \t\t\tnetwork: network.clone(),\n-\t\t\ttelemetry_connection_sinks: sc_service::TelemetryConnectionSinks::default(),\n \t\t\ttask_manager: &mut task_manager,\n \t\t})?;\n\n-\tOk((task_manager, rpc_handlers, client, network, transaction_pool))\n+\tOk((\n+\t\ttask_manager,\n+\t\trpc_handlers,\n+\t\ttelemetry_connection_notifier,\n+\t\tclient,\n+\t\tnetwork,\n+\t\ttransaction_pool,\n+\t))\n }\n\n /// Builds a new service for a light client.\n pub fn new_light(config: Configuration) -> Result<TaskManager, ServiceError> {\n-\tnew_light_base(config).map(|(task_manager, _, _, _, _)| {\n+\tnew_light_base(config).map(|(task_manager, _, _, _, _, _)| {\n \t\ttask_manager\n \t})\n }\n\n #[cfg(test)]\n mod tests {\n-\tuse std::{sync::Arc, borrow::Cow, any::Any};\n+\tuse std::{sync::Arc, borrow::Cow, any::Any, convert::TryInto};\n \tuse sc_consensus_babe::{CompatibleDigestItem, BabeIntermediate, INTERMEDIATE_KEY};\n \tuse sc_consensus_epochs::descendent_query;\n \tuse sp_consensus::{\n@@ -469,20 +475,25 @@ mod tests {\n \tuse node_runtime::{BalancesCall, Call, UncheckedExtrinsic, Address};\n \tuse node_runtime::constants::{currency::CENTS, time::SLOT_DURATION};\n \tuse codec::Encode;\n-\tuse sp_core::{crypto::Pair as CryptoPair, H256};\n+\tuse sp_core::{\n+\t\tcrypto::Pair as CryptoPair,\n+\t\tH256,\n+\t\tPublic\n+\t};\n+\tuse sp_keystore::{SyncCryptoStorePtr, SyncCryptoStore};\n \tuse sp_runtime::{\n \t\tgeneric::{BlockId, Era, Digest, SignedPayload},\n \t\ttraits::{Block as BlockT, Header as HeaderT},\n \t\ttraits::Verify,\n \t};\n \tuse sp_timestamp;\n-\tuse sp_finality_tracker;\n \tuse sp_keyring::Sr25519Keyring;\n \tuse sc_service_test::TestNetNode;\n \tuse crate::service::{new_full_base, new_light_base, NewFullBase};\n-\tuse sp_runtime::traits::IdentifyAccount;\n+\tuse sp_runtime::{key_types::BABE, traits::IdentifyAccount, RuntimeAppPublic};\n \tuse sp_transaction_pool::{MaintainedTransactionPool, ChainEvent};\n \tuse sc_client_api::BlockBackend;\n+\tuse sc_keystore::LocalKeystore;\n\n \ttype AccountPublic = <Signature as Verify>::Signer;\n\n@@ -492,15 +503,15 @@ mod tests {\n \t#[ignore]\n \tfn test_sync() {\n \t\tlet keystore_path = tempfile::tempdir().expect(\"Creates keystore path\");\n-\t\tlet keystore = sc_keystore::Store::open(keystore_path.path(), None)\n-\t\t\t.expect(\"Creates keystore\");\n-\t\tlet alice = keystore.write().insert_ephemeral_from_seed::<sc_consensus_babe::AuthorityPair>(\"//Alice\")\n-\t\t\t.expect(\"Creates authority pair\");\n+\t\tlet keystore: SyncCryptoStorePtr = Arc::new(LocalKeystore::open(keystore_path.path(), None)\n+\t\t\t.expect(\"Creates keystore\"));\n+\t\tlet alice: sp_consensus_babe::AuthorityId = SyncCryptoStore::sr25519_generate_new(&*keystore, BABE, Some(\"//Alice\"))\n+\t\t\t.expect(\"Creates authority pair\").into();\n\n \t\tlet chain_spec = crate::chain_spec::tests::integration_test_config_with_single_authority();\n\n \t\t// For the block factory\n-\t\tlet mut slot_num = 1u64;\n+\t\tlet mut slot = 1u64;\n\n \t\t// For the extrinsics factory\n \t\tlet bob = Arc::new(Sr25519Keyring::Bob.pair());\n@@ -528,14 +539,13 @@ mod tests {\n \t\t\t\tOk((node, (inherent_data_providers, setup_handles.unwrap())))\n \t\t\t},\n \t\t\t|config| {\n-\t\t\t\tlet (keep_alive, _, client, network, transaction_pool) = new_light_base(config)?;\n+\t\t\t\tlet (keep_alive, _, _, client, network, transaction_pool) = new_light_base(config)?;\n \t\t\t\tOk(sc_service_test::TestNetComponents::new(keep_alive, client, network, transaction_pool))\n \t\t\t},\n \t\t\t|service, &mut (ref inherent_data_providers, (ref mut block_import, ref babe_link))| {\n \t\t\t\tlet mut inherent_data = inherent_data_providers\n \t\t\t\t\t.create_inherent_data()\n \t\t\t\t\t.expect(\"Creates inherent data.\");\n-\t\t\t\tinherent_data.replace_data(sp_finality_tracker::INHERENT_IDENTIFIER, &1u64);\n\n \t\t\t\tlet parent_id = BlockId::number(service.client().chain_info().best_number);\n \t\t\t\tlet parent_header = service.client().header(&parent_id).unwrap().unwrap();\n@@ -552,6 +562,7 @@ mod tests {\n \t\t\t\t);\n\n \t\t\t\tlet mut proposer_factory = sc_basic_authorship::ProposerFactory::new(\n+\t\t\t\t\tservice.spawn_handle(),\n \t\t\t\t\tservice.client(),\n \t\t\t\t\tservice.transaction_pool(),\n \t\t\t\t\tNone,\n@@ -561,7 +572,7 @@ mod tests {\n \t\t\t\t\tdescendent_query(&*service.client()),\n \t\t\t\t\t&parent_hash,\n \t\t\t\t\tparent_number,\n-\t\t\t\t\tslot_num,\n+\t\t\t\t\tslot.into(),\n \t\t\t\t).unwrap().unwrap();\n\n \t\t\t\tlet mut digest = Digest::<H256>::default();\n@@ -569,18 +580,18 @@ mod tests {\n \t\t\t\t// even though there's only one authority some slots might be empty,\n \t\t\t\t// so we must keep trying the next slots until we can claim one.\n \t\t\t\tlet babe_pre_digest = loop {\n-\t\t\t\t\tinherent_data.replace_data(sp_timestamp::INHERENT_IDENTIFIER, &(slot_num * SLOT_DURATION));\n+\t\t\t\t\tinherent_data.replace_data(sp_timestamp::INHERENT_IDENTIFIER, &(slot * SLOT_DURATION));\n \t\t\t\t\tif let Some(babe_pre_digest) = sc_consensus_babe::test_helpers::claim_slot(\n-\t\t\t\t\t\tslot_num,\n+\t\t\t\t\t\tslot.into(),\n \t\t\t\t\t\t&parent_header,\n \t\t\t\t\t\t&*service.client(),\n-\t\t\t\t\t\t&keystore,\n+\t\t\t\t\t\tkeystore.clone(),\n \t\t\t\t\t\t&babe_link,\n \t\t\t\t\t) {\n \t\t\t\t\t\tbreak babe_pre_digest;\n \t\t\t\t\t}\n\n-\t\t\t\t\tslot_num += 1;\n+\t\t\t\t\tslot += 1;\n \t\t\t\t};\n\n \t\t\t\tdigest.push(<DigestItem as CompatibleDigestItem>::babe_pre_digest(babe_pre_digest));\n@@ -600,11 +611,18 @@ mod tests {\n \t\t\t\t// sign the pre-sealed hash of the block and then\n \t\t\t\t// add it to a digest item.\n \t\t\t\tlet to_sign = pre_hash.encode();\n-\t\t\t\tlet signature = alice.sign(&to_sign[..]);\n+\t\t\t\tlet signature = SyncCryptoStore::sign_with(\n+\t\t\t\t\t&*keystore,\n+\t\t\t\t\tsp_consensus_babe::AuthorityId::ID,\n+\t\t\t\t\t&alice.to_public_crypto_pair(),\n+\t\t\t\t\t&to_sign,\n+\t\t\t\t).unwrap()\n+\t\t\t\t .try_into()\n+\t\t\t\t .unwrap();\n \t\t\t\tlet item = <DigestItem as CompatibleDigestItem>::babe_seal(\n-\t\t\t\t\tsignature.into(),\n+\t\t\t\t\tsignature,\n \t\t\t\t);\n-\t\t\t\tslot_num += 1;\n+\t\t\t\tslot += 1;\n\n \t\t\t\tlet mut params = BlockImportParams::new(BlockOrigin::File, new_header);\n \t\t\t\tparams.post_digests.push(item);\n@@ -679,7 +697,7 @@ mod tests {\n \t\t\t\tOk(sc_service_test::TestNetComponents::new(task_manager, client, network, transaction_pool))\n \t\t\t},\n \t\t\t|config| {\n-\t\t\t\tlet (keep_alive, _, client, network, transaction_pool) = new_light_base(config)?;\n+\t\t\t\tlet (keep_alive, _, _, client, network, transaction_pool) = new_light_base(config)?;\n \t\t\t\tOk(sc_service_test::TestNetComponents::new(keep_alive, client, network, transaction_pool))\n \t\t\t},\n \t\t\tvec![\n```"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain substreams\ninput: "
      },
      {
        "role": "assistant",
        "content": "Once a connection has been established and uses multiplexing, substreams can be opened. When\na substream is open, the **multistream-select** protocol is used to negotiate which protocol\nto use on that given substream.\n\nProtocols that are specific to a certain chain have a `<protocol-id>` in their name. This\n\"protocol ID\" is defined in the chain specifications. For example, the protocol ID of Polkadot\nis \"dot\". In the protocol names below, `<protocol-id>` must be replaced with the corresponding\nprotocol ID.\n\n> **Note**: It is possible for the same connection to be used for multiple chains. For example,\n> one can use both the `/dot/sync/2` and `/sub/sync/2` protocols on the same\n> connection, provided that the remote supports them.\n\nSubstrate uses the following standard libp2p protocols:\n\n- **`/ipfs/ping/1.0.0`**. We periodically open an ephemeral substream in order to ping the\nremote and check whether the connection is still alive. Failure for the remote to reply leads\nto a disconnection.\n- **`/ipfs/id/1.0.0`**. We\nperiodically open an ephemeral substream in order to ask information from the remote.\n- **`/<protocol_id>/kad`**. We periodically open\nephemeral substreams for Kademlia random walk queries. Each Kademlia query is done in a\nseparate substream.\n\nAdditionally, Substrate uses the following non-libp2p-standard protocols:\n\n- **`/substrate/<protocol-id>/<version>`** (where `<protocol-id>` must be replaced with the\nprotocol ID of the targeted chain, and `<version>` is a number between 2 and 6). For each\nconnection we optionally keep an additional substream for all Substrate-based communications alive.\nThis protocol is considered legacy, and is progressively being replaced with alternatives.\nThis is designated as \"The legacy Substrate substream\" in this documentation. See below for\nmore details.\n- **`/<protocol-id>/sync/2`** is a request-response protocol (see below) that lets one perform\nrequests for information about blocks. Each request is the encoding of a `BlockRequest` and\neach response is the encoding of a `BlockResponse`, as defined in the `api.v1.proto` file in\nthis source tree.\n- **`/<protocol-id>/light/2`** is a request-response protocol (see below) that lets one perform\nlight-client-related requests for information about the state. Each request is the encoding of\na `light::Request` and each response is the encoding of a `light::Response`, as defined in the\n`light.v1.proto` file in this source tree.\n- **`/<protocol-id>/transactions/1`** is a notifications protocol (see below) where\ntransactions are pushed to other nodes. The handshake is empty on both sides. The message\nformat is a SCALE-encoded list of transactions, where each transaction is an opaque list of\nbytes.\n- **`/<protocol-id>/block-announces/1`** is a notifications protocol (see below) where\nblock announces are pushed to other nodes. The handshake is empty on both sides. The message\nformat is a SCALE-encoded tuple containing a block header followed with an opaque list of\nbytes containing some data associated with this block announcement, e.g. a candidate message.\n- Notifications protocols that are registered using `NetworkConfiguration::notifications_protocols`.\nFor example: `/paritytech/grandpa/1`. See below for more information."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain details\ninput: "
      },
      {
        "role": "assistant",
        "content": "Before we jump into describing how BEEFY works in details, let's agree on the terms we are going\nto use and actors in the system. All nodes in the network need to participate in the BEEFY\nnetworking protocol, but we can identify two distinct actors though: **regular nodes** and\n**BEEFY validators**.\nValidators are expected to actively participate in the protocol, by producing and broadcasting\n**votes**. Votes are simply their signatures over a **Commitment**. A Commitment consists of a\n**payload** (an opaque blob of bytes extracted from a block or state at that block, expected to\nbe some form of crypto accumulator (like Merkle Tree Hash or Merkle Mountain Range Root Hash))\nand **block number** from which this payload originates. Additionally, Commitment contains BEEFY\n**validator set id** at that particular block. Note the block is finalized, so there is no\nambiguity despite using block number instead of a hash. A collection of **votes**, or rather\na Commitment and a collection of signatures is going to be called **Signed Commitment**. A valid\n(see later for the rules) Signed Commitment is also called a **BEEFY Justification** or\n**BEEFY Finality Proof**. For more details on the actual data structures please see\nBEEFY primitives definitions.\n\nA **round** is an attempt by BEEFY validators to produce a BEEFY Justification. **Round number**\nis simply defined as a block number the validators are voting for, or to be more precise, the\nCommitment for that block number. Round ends when the next round is started, which may happen\nwhen one of the events occur:\n1. Either the node collects `2/3rd + 1` valid votes for that round.\n2. Or the node receives a BEEFY Justification for a block greater than the current best BEEFY block.\n\nIn both cases the node proceeds to determining the new round number using \"Round Selection\"\nprocedure.\n\nRegular nodes are expected to:\n1. Receive & validate votes for the current round and broadcast them to their peers.\n1. Receive & validate BEEFY Justifications and broadcast them to their peers.\n1. Return BEEFY Justifications for **Mandatory Blocks** on demand.\n1. Optionally return BEEFY Justifications for non-mandatory blocks on demand.\n\nValidators are expected to additionally:\n1. Produce & broadcast vote for the current round.\n\nBoth kinds of actors are expected to fully participate in the protocol ONLY IF they believe they\nare up-to-date with the rest of the network, i.e. they are fully synced. Before this happens,\nthe node should continue processing imported BEEFY Justifications and votes without actively\nvoting themselves."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain round selection\ninput: "
      },
      {
        "role": "assistant",
        "content": "Every node (both regular nodes and validators) need to determine locally what they believe\ncurrent round number is. The choice is based on their knowledge of:\n\n1. Best GRANDPA finalized block number (`best_grandpa`).\n1. Best BEEFY finalized block number (`best_beefy`).\n1. Starting block of current session (`session_start`).\n\n**Session** means a period of time (or rather number of blocks) where validator set (keys) do not change.\nSee `pallet_session` for implementation details in `FRAME` context. Since we piggy-back on\nGRANDPA, session boundaries for BEEFY are exactly the same as the ones for GRANDPA.\n\nWe define two kinds of blocks from the perspective of BEEFY protocol:\n1. **Mandatory Blocks**\n2. **Non-mandatory Blocks**\n\nMandatory blocks are the ones that MUST have BEEFY justification. That means that the validators\nwill always start and conclude a round at mandatory blocks. For non-mandatory blocks, there may\nor may not be a justification and validators may never choose these blocks to start a round.\n\nEvery **first block in** each **session** is considered a **mandatory block**. All other blocks\nin the session are non-mandatory, however validators are encouraged to finalize as many blocks as\npossible to enable lower latency for light clients and hence end users. Since GRANDPA is\nconsidering session boundary blocks as mandatory as well, `session_start` block will always have\nboth GRANDPA and BEEFY Justification.\n\nTherefore, to determine current round number nodes use a formula:\n\nround_number =\n      (1 - M) * session_start\n   +        M * (best_beefy + NEXT_POWER_OF_TWO((best_grandpa - best_beefy + 1) / 2))\n\nwhere:\n\n- `M` is `1` if mandatory block in current session is already finalized and `0` otherwise.\n- `NEXT_POWER_OF_TWO(x)` returns the smallest number greater or equal to `x` that is a power of two.\n\nIn other words, the next round number should be the oldest mandatory block without a justification,\nor the highest GRANDPA-finalized block, whose block number difference with `best_beefy` block is\na power of two. The mental model for round selection is to first finalize the mandatory block and\nthen to attempt to pick a block taking into account how fast BEEFY catches up with GRANDPA.\nIn case GRANDPA makes progress, but BEEFY seems to be lagging behind, validators are changing\nrounds less often to increase the chance of concluding them.\n\nAs mentioned earlier, every time the node picks a new `round_number` (and validator casts a vote)\nit ends the previous one, no matter if finality was reached (i.e. the round concluded) or not.\nVotes for an inactive round should not be propagated.\n\nNote that since BEEFY only votes for GRANDPA-finalized blocks, `session_start` here actually means:\n\"the latest session for which the start of is GRANDPA-finalized\", i.e. block production might\nhave already progressed, but BEEFY needs to first finalize the mandatory block of the older\nsession.\n\nIn good networking conditions BEEFY may end up finalizing each and every block (if GRANDPA does\nthe same). Practically, with short block times, it's going to be rare and might be excessive, so\nit's suggested for implementations to introduce a `min_delta` parameter which will limit the\nfrequency with which new rounds are started. The affected component of the formula would be:\n`best_beefy + MAX(min_delta, NEXT_POWER_OF_TWO(...))`, so we start a new round only if the\npower-of-two component is greater than the min delta. Note that if `round_number > best_grandpa`\nthe validators are not expected to start any round."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain output\ninput: "
      },
      {
        "role": "assistant",
        "content": "The output on reference hardware:\n\n+----------+----------------+---------------+--------------+-------------------+\n| Category | Function       | Score         | Minimum      | Result            |\n+----------+----------------+---------------+--------------+-------------------+\n| CPU      | BLAKE2-256     | 1023.00 MiB/s | 1.00 GiB/s   | \u2705 Pass ( 99.4 %) |\n+----------+----------------+---------------+--------------+-------------------+\n| CPU      | SR25519-Verify | 665.13 KiB/s  | 666.00 KiB/s | \u2705 Pass ( 99.9 %) |\n+----------+----------------+---------------+--------------+-------------------+\n| Memory   | Copy           | 14.39 GiB/s   | 14.32 GiB/s  | \u2705 Pass (100.4 %) |\n+----------+----------------+---------------+--------------+-------------------+\n| Disk     | Seq Write      | 457.00 MiB/s  | 450.00 MiB/s | \u2705 Pass (101.6 %) |\n+----------+----------------+---------------+--------------+-------------------+\n| Disk     | Rnd Write      | 190.00 MiB/s  | 200.00 MiB/s | \u2705 Pass ( 95.0 %) |\n+----------+----------------+---------------+--------------+-------------------+\n\nThe *score* is the average result of each benchmark. It always adheres to \"higher is better\".\n\nThe *category* indicate which part of the hardware was benchmarked:\n- **CPU** Processor intensive task\n- **Memory** RAM intensive task\n- **Disk** Hard drive intensive task\n\nThe *function* is the concrete benchmark that was run:\n- **BLAKE2-256** The throughput of the [Blake2-256] cryptographic hashing function with 32 KiB input. The [blake2_256\n  function] is used in many places in Substrate. The throughput of a hash function strongly depends on the input size,\n  therefore we settled to use a fixed input size for comparable results.\n- **SR25519 Verify** Sr25519 is an optimized version of the [Curve25519] signature scheme. Signature verification is\n  used by Substrate when verifying extrinsics and blocks.\n- **Copy** The throughput of copying memory from one place in the RAM to another.\n- **Seq Write** The throughput of writing data to the storage location sequentially. It is important that the same disk\n  is used that will later-on be used to store the chain data.\n- **Rnd Write** The throughput of writing data to the storage location in a random order. This is normally much slower\n  than the sequential write.\n\nThe *score* needs to reach the *minimum* in order to pass the benchmark. This can be reduced with the `--tolerance`\nflag.\n\nThe *result* indicated if a specific benchmark was passed by the machine or not. The percent number is the relative\nscore reached to the *minimum* that is needed. The `--tolerance` flag is taken into account for this decision. For\nexample a benchmark that passes even with 95% since the *tolerance* was set to 10% would look like this: `\u2705 Pass ( 95.0\n%)`."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain output interpretation\ninput: "
      },
      {
        "role": "assistant",
        "content": "<sup>(Only results from reference hardware are relevant)</sup>\n\nEach block is executed multiple times and the results are averaged. The percent number is the interesting part and\nindicates how much weight was used as compared to how much was predicted. The closer to 100% this is without exceeding\n100%, the better. If it exceeds 100%, the block is marked with \"**OVER WEIGHT!**\" to easier spot them. This is not good\nsince then the benchmarking under-estimated the weight. This would mean that an honest validator would possibly not be\nable to keep up with importing blocks since users did not pay for enough weight. If that happens the validator could lag\nbehind the chain and get slashed for missing deadlines. It is therefore important to investigate any overweight blocks.\n\nIn this example you can see an unexpected result; only < 5% of the weight was used! The measured blocks can be executed\nmuch faster than predicted. This means that the benchmarking process massively over-estimated the execution time. Since\nthey are off by so much, it is an issue [`polkadot#5192`].\n\nThe ideal range for these results would be 85-100%."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain polkadot # 2\ninput: "
      },
      {
        "role": "assistant",
        "content": "Let's take a more interesting example where the blocks use more of their predicted weight. Every day when validators pay\nout rewards, the blocks are nearly full. Using an archive node here is the easiest.\n\nThe Polkadot blocks TODO-TODO for example contain large batch transactions for staking payout.\n\ncargo run --profile=production -- benchmark block --from TODO --to TODO --db paritydb\n\nTODO"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain interface\ninput: "
      },
      {
        "role": "assistant",
        "content": "### Dispatchable Functions\n\n### For General Users\n- `set_identity` - Set the associated identity of an account; a small deposit is reserved if not\n  already taken.\n- `clear_identity` - Remove an account's associated identity; the deposit is returned.\n- `request_judgement` - Request a judgement from a registrar, paying a fee.\n- `cancel_request` - Cancel the previous request for a judgement.\n- `accept_username` - Accept a username issued by a username authority.\n- `remove_expired_approval` - Remove a username that was issued but never accepted.\n- `set_primary_username` - Set a given username as an account's primary.\n- `remove_username` - Remove a username after its grace period has ended.\n\n### For General Users with Sub-Identities\n- `set_subs` - Set the sub-accounts of an identity.\n- `add_sub` - Add a sub-identity to an identity.\n- `remove_sub` - Remove a sub-identity of an identity.\n- `rename_sub` - Rename a sub-identity of an identity.\n- `quit_sub` - Remove a sub-identity of an identity (called by the sub-identity).\n\n### For Registrars\n- `set_fee` - Set the fee required to be paid for a judgement to be given by the registrar.\n- `set_fields` - Set the fields that a registrar cares about in their judgements.\n- `provide_judgement` - Provide a judgement to an identity.\n\n### For Username Authorities\n- `set_username_for` - Set a username for a given account. The account must approve it.\n- `unbind_username` - Start the grace period for a username.\n\n### For Superusers\n- `add_registrar` - Add a new registrar to the system.\n- `kill_identity` - Forcibly remove the associated identity; the deposit is lost.\n- `add_username_authority` - Add an account with the ability to issue usernames.\n- `remove_username_authority` - Remove an account with the ability to issue usernames.\n- `kill_username` - Forcibly remove a username.\n\n[`Call`]: ./enum.Call.html\n[`Config`]: ./trait.Config.html\n\nLicense: Apache-2.0"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain dispatchable functions\ninput: "
      },
      {
        "role": "assistant",
        "content": "### For General Users\n\n- `create_recovery` - Create a recovery configuration for your account and make it recoverable.\n- `initiate_recovery` - Start the recovery process for a recoverable account.\n\n### For Friends of a Recoverable Account\n- `vouch_recovery` - As a `friend` of a recoverable account, vouch for a recovery attempt on the account.\n\n### For a User Who Successfully Recovered an Account\n\n- `claim_recovery` - Claim access to the account that you have successfully completed the recovery process for.\n- `as_recovered` - Send a transaction as an account that you have recovered. See other functions below.\n\n### For the Recoverable Account\n\n- `close_recovery` - Close an active recovery process for your account and reclaim the recovery deposit.\n- `remove_recovery` - Remove the recovery configuration from the account, making it un-recoverable.\n\n### For Super Users\n\n- `set_recovered` - The ROOT origin is able to skip the recovery process and directly allow\n  one account to access another.\n\nLicense: Apache-2.0"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain mechanics\ninput: "
      },
      {
        "role": "assistant",
        "content": "### Rewards\n\nMembers are incentivized to participate in the society through rewards paid\nby the Society treasury. These payments have a maturity period that the user\nmust wait before they are able to access the funds.\n\n### Punishments\n\nMembers can be punished by slashing the reward payouts that have not been\ncollected. Additionally, members can accumulate \"strikes\", and when they\nreach a max strike limit, they become suspended.\n\n### Skeptics\n\nDuring the voting period, a random set of members are selected as \"skeptics\".\nThese skeptics are expected to vote on the current candidates. If they do not vote,\ntheir skeptic status is treated as a rejection vote, the member is deemed\n\"lazy\", and are given a strike per missing vote.\n\n### Membership Challenges\n\nEvery challenge rotation period, an existing member will be randomly selected\nto defend their membership into society. Then, other members can vote whether\nthis defender should stay in society. A simple majority wins vote will determine\nthe outcome of the user. Ties are treated as a failure of the challenge, but\nassuming no one else votes, the defender always get a free vote on their\nown challenge keeping them in the society. The Head member is exempt from the\nnegative outcome of a membership challenge.\n\n### Society Treasury\n\nThe membership society is independently funded by a treasury managed by this\nmodule. Some subset of this treasury is placed in a Society Pot, which is used\nto determine the number of accepted bids.\n\n### Rate of Growth\n\nThe membership society can grow at a rate of 10 accepted candidates per rotation period up\nto the max membership threshold. Once this threshold is met, candidate selections\nare stalled until there is space for new members to join. This can be resolved by\nvoting out existing members through the random challenges or by using governance\nto increase the maximum membership count."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain user life cycle\ninput: "
      },
      {
        "role": "assistant",
        "content": "A user can go through the following phases:\n\n          +------->  User  <----------+\n          |           +               |\n          |           |               |\n+----------------------------------------------+\n|         |           |               |        |\n|         |           v               |        |\n|         |        Bidder <-----------+        |\n|         |           +               |        |\n|         |           |               +        |\n|         |           v            Suspended   |\n|         |       Candidate +----> Candidate   |\n|         |           +               +        |\n|         |           |               |        |\n|         +           |               |        |\n|   Suspended +------>|               |        |\n|      Member         |               |        |\n|         ^           |               |        |\n|         |           v               |        |\n|         +-------+ Member <----------+        |\n|                                              |\n|                                              |\n+------------------Society---------------------+\n\n### Initialization\n\nThe society is initialized with a single member who is automatically chosen as the Head.\n\n### Bid Phase\n\nNew users must have a bid to join the society.\n\nA user can make a bid by reserving a deposit. Alternatively, an already existing member\ncan create a bid on a user's behalf by \"vouching\" for them.\n\nA bid includes reward information that the user would like to receive for joining\nthe society. A vouching bid can additionally request some portion of that reward as a tip\nto the voucher for vouching for the prospective candidate.\n\nEvery rotation period, Bids are ordered by reward amount, and the module\nselects as many bids the Society Pot can support for that period.\n\nThese selected bids become candidates and move on to the Candidate phase.\nBids that were not selected stay in the bidder pool until they are selected or\na user chooses to \"unbid\".\n\n### Candidate Phase\n\nOnce a bidder becomes a candidate, members vote whether to approve or reject\nthat candidate into society. This voting process also happens during a rotation period.\n\nThe approval and rejection criteria for candidates are not set on chain,\nand may change for different societies.\n\nAt the end of the rotation period, we collect the votes for a candidate\nand randomly select a vote as the final outcome.\n\n [ a-accept, r-reject, s-skeptic ]\n+----------------------------------+\n|                                  |\n|  Member   |0|1|2|3|4|5|6|7|8|9|  |\n|  -----------------------------   |\n|  Vote     |a|a|a|r|s|r|a|a|s|a|  |\n|  -----------------------------   |\n|  Selected | | | |x| | | | | | |  |\n|                                  |\n+----------------------------------+\n\nResult: Rejected\n\nEach member that voted opposite to this randomly selected vote is punished by\nslashing their unclaimed payouts and increasing the number of strikes they have.\n\nThese slashed funds are given to a random user who voted the same as the\nselected vote as a reward for participating in the vote.\n\nIf the candidate wins the vote, they receive their bid reward as a future payout.\nIf the bid was placed by a voucher, they will receive their portion of the reward,\nbefore the rest is paid to the winning candidate.\n\nOne winning candidate is selected as the Head of the members. This is randomly\nchosen, weighted by the number of approvals the winning candidates accumulated.\n\nIf the candidate loses the vote, they are suspended and it is up to the Suspension\nJudgement origin to determine if the candidate should go through the bidding process\nagain, should be accepted into the membership society, or rejected and their deposit\nslashed.\n\n### Member Phase\n\nOnce a candidate becomes a member, their role is to participate in society.\n\nRegular participation involves voting on candidates who want to join the membership\nsociety, and by voting in the right way, a member will accumulate future payouts.\nWhen a payout matures, members are able to claim those payouts.\n\nMembers can also vouch for users to join the society, and request a \"tip\" from\nthe fees the new member would collect by joining the society. This vouching\nprocess is useful in situations where a user may not have enough balance to\nsatisfy the bid deposit. A member can only vouch one user at a time.\n\nDuring rotation periods, a random group of members are selected as \"skeptics\".\nThese skeptics are expected to vote on the current candidates. If they do not vote,\ntheir skeptic status is treated as a rejection vote, the member is deemed\n\"lazy\", and are given a strike per missing vote.\n\nThere is a challenge period in parallel to the rotation period. During a challenge period,\na random member is selected to defend their membership to the society. Other members\nmake a traditional majority-wins vote to determine if the member should stay in the society.\nTies are treated as a failure of the challenge.\n\nIf a member accumulates too many strikes or fails their membership challenge,\nthey will become suspended. While a member is suspended, they are unable to\nclaim matured payouts. It is up to the Suspension Judgement origin to determine\nif the member should re-enter society or be removed from society with all their\nfuture payouts slashed."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain scenarios\ninput: "
      },
      {
        "role": "assistant",
        "content": "### Staking\n\nAlmost any interaction with the Staking module requires a process of _**bonding**_ (also known as being a _staker_). To\nbecome *bonded*, a fund-holding account known as the _stash account_, which holds some or all of the funds that become\nfrozen in place as part of the staking process. The controller account, which this pallet now assigns the stash account to,\nissues instructions on how funds shall be used.\n\nAn account can become a bonded stash account using the\n`bond` call.\n\nStash accounts can update their associated controller back to their stash account using the\n`set_controller` call.\n\nNote: Controller accounts are being deprecated in favor of proxy accounts, so it is no longer possible to set a unique\naddress for a stash's controller.\n\nThere are three possible roles that any staked account pair can be in: `Validator`, `Nominator` and `Idle` (defined in\n`StakerStatus`). There are three\ncorresponding instructions to change between roles, namely:\n`validate`,\n`nominate`, and\n`chill`.\n\n### Validating\n\nA **validator** takes the role of either validating blocks or ensuring their finality, maintaining the veracity of the\nnetwork. A validator should avoid both any sort of malicious misbehavior and going offline. Bonded accounts that state\ninterest in being a validator do NOT get immediately chosen as a validator. Instead, they are declared as a _candidate_\nand they _might_ get elected at the _next era_ as a validator. The result of the election is determined by nominators\nand their votes.\n\nAn account can become a validator candidate via the\n`validate` call.\n\n### Nomination\n\nA **nominator** does not take any _direct_ role in maintaining the network, instead, it votes on a set of validators to\nbe elected. Once interest in nomination is stated by an account, it takes effect at the next election round. The funds\nin the nominator's stash account indicate the _weight_ of its vote. Both the rewards and any punishment that a validator\nearns are shared between the validator and its nominators. This rule incentivizes the nominators to NOT vote for the\nmisbehaving/offline validators as much as possible, simply because the nominators will also lose funds if they vote\npoorly.\n\nAn account can become a nominator via the\n`nominate` call.\n\n### Rewards and Slash\n\nThe **reward and slashing** procedure is the core of the Staking module, attempting to _embrace valid behavior_ while\n_punishing any misbehavior or lack of availability_.\n\nRewards must be claimed for each era before it gets too old by `$HISTORY_DEPTH` using the `payout_stakers` call. When a\nvalidator has more than [`Config::MaxExposurePageSize`] nominators, nominators are divided into pages with each call to\n`payout_stakers` paying rewards to one page of nominators in a sequential and ascending manner. Any account can also\ncall `payout_stakers_by_page` to explicitly pay reward for a given page. As evident, this means only the\n[`Config::MaxExposurePageSize`] nominators are rewarded per call. This is to limit the i/o cost to mutate storage for\neach nominator's account.\n\nSlashing can occur at any point in time, once misbehavior is reported. Once slashing is determined, a value is deducted\nfrom the balance of the validator and all the nominators who voted for this validator (values are deducted from the\n_stash_ account of the slashed entity).\n\nSlashing logic is further described in the documentation of the `slashing` module.\n\nSimilar to slashing, rewards are also shared among a validator and its associated nominators. Yet, the reward funds are\nnot always transferred to the stash account and can be configured. See Reward\nCalculation for more details.\n\n### Chilling\n\nFinally, any of the roles above can choose to step back temporarily and just chill for a while. This means that if they\nare a nominator, they will not be considered as voters anymore and if they are validators, they will no longer be a\ncandidate for the next election.\n\nAn account can step back via the\n`chill` call."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain running benchmarks\ninput: "
      },
      {
        "role": "assistant",
        "content": "Finally, once you have a node binary with benchmarks enabled, you need to execute your various benchmarks.\n\nYou can get a list of the available benchmarks by running:\n\n./target/production/substrate benchmark pallet --chain dev --pallet \"*\" --extrinsic \"*\" --repeat 0\n\nThen you can run a benchmark like so:\n\n./target/production/substrate benchmark pallet \\\n    --chain dev \\                  # Configurable Chain Spec\n    --wasm-execution=compiled \\    # Always used `wasm-time`\n    --pallet pallet_balances \\     # Select the pallet\n    --extrinsic transfer \\         # Select the extrinsic\n    --steps 50 \\                   # Number of samples across component ranges\n    --repeat 20 \\                  # Number of times we repeat a benchmark\n    --output <path> \\              # Output benchmark results into a folder or file\n\nThis will output a file `pallet_name.rs` which implements the `WeightInfo` trait you should include in your pallet.\nDouble colons `::` will be replaced with a `_` in the output name if you specify a directory. Each blockchain should\ngenerate their own benchmark file with their custom implementation of the `WeightInfo` trait. This means that you will\nbe able to use these modular Substrate pallets while still keeping your network safe for your specific configuration and\nrequirements.\n\nThe benchmarking CLI uses a Handlebars template to format the final output file. You can optionally pass the flag\n`--template` pointing to a custom template that can be used instead. Within the template, you have access to all the\ndata provided by the `TemplateData` struct in the benchmarking CLI\nwriter. You can find the default template used\nhere.\n\nThere are some custom Handlebars helpers included with our output generation:\n\n* `underscore`: Add an underscore to every 3rd character from the right of a string. Primarily to be used for delimiting\nlarge numbers.\n* `join`: Join an array of strings into a space-separated string for the template. Primarily to be used for joining all\nthe arguments passed to the CLI.\n\nTo get a full list of available options when running benchmarks, run:\n\n./target/production/substrate benchmark --help\n\nLicense: Apache-2.0"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain dispatchable functions\ninput: "
      },
      {
        "role": "assistant",
        "content": "### Public\n\nThese calls can be made from any externally held account capable of creating\na signed extrinsic.\n\nBasic actions:\n- `propose` - Submits a sensitive action, represented as a hash. Requires a deposit.\n- `second` - Signals agreement with a proposal, moves it higher on the proposal queue, and\n  requires a matching deposit to the original.\n- `vote` - Votes in a referendum, either the vote is \"Aye\" to enact the proposal or \"Nay\" to\n  keep the status quo.\n- `unvote` - Cancel a previous vote, this must be done by the voter before the vote ends.\n- `delegate` - Delegates the voting power (tokens * conviction) to another account.\n- `undelegate` - Stops the delegation of voting power to another account.\n\nAdministration actions that can be done to any account:\n- `reap_vote` - Remove some account's expired votes.\n- `unlock` - Redetermine the account's balance lock, potentially making tokens available.\n\nPreimage actions:\n- `note_preimage` - Registers the preimage for an upcoming proposal, requires\n  a deposit that is returned once the proposal is enacted.\n- `note_preimage_operational` - same but provided by `T::OperationalPreimageOrigin`.\n- `note_imminent_preimage` - Registers the preimage for an upcoming proposal.\n  Does not require a deposit, but the proposal must be in the dispatch queue.\n- `note_imminent_preimage_operational` - same but provided by `T::OperationalPreimageOrigin`.\n- `reap_preimage` - Removes the preimage for an expired proposal. Will only\n  work under the condition that it's the same account that noted it and\n  after the voting period, OR it's a different account after the enactment period.\n\n### Cancellation Origin\n\nThis call can only be made by the `CancellationOrigin`.\n\n- `emergency_cancel` - Schedules an emergency cancellation of a referendum.\n  Can only happen once to a specific referendum.\n\n### ExternalOrigin\n\nThis call can only be made by the `ExternalOrigin`.\n\n- `external_propose` - Schedules a proposal to become a referendum once it is legal\n  for an externally proposed referendum.\n\n### External Majority Origin\n\nThis call can only be made by the `ExternalMajorityOrigin`.\n\n- `external_propose_majority` - Schedules a proposal to become a majority-carries\n\t referendum once it is legal for an externally proposed referendum.\n\n### External Default Origin\n\nThis call can only be made by the `ExternalDefaultOrigin`.\n\n- `external_propose_default` - Schedules a proposal to become a negative-turnout-bias\n  referendum once it is legal for an externally proposed referendum.\n\n### Fast Track Origin\n\nThis call can only be made by the `FastTrackOrigin`.\n\n- `fast_track` - Schedules the current externally proposed proposal that\n  is \"majority-carries\" to become a referendum immediately.\n\n### Veto Origin\n\nThis call can only be made by the `VetoOrigin`.\n\n- `veto_external` - Vetoes and blacklists the external proposal hash.\n\n### Root\n\n- `cancel_referendum` - Removes a referendum.\n- `cancel_queued` - Cancels a proposal that is queued for enactment.\n- `clear_public_proposal` - Removes all public proposals.\n\nLicense: Apache-2.0"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain terminology\ninput: "
      },
      {
        "role": "assistant",
        "content": "<!-- Original author of paragraph: @gavofyork -->\n\n- **Session:** A session is a period of time that has a constant set of validators. Validators can only join or exit the\nvalidator set at a session change. It is measured in block numbers. The block where a session is ended is determined by\nthe `ShouldEndSession` trait. When the session is ending, a new validator set can be chosen by `OnSessionEnding`\nimplementations.\n- **Session key:** A session key is actually several keys kept together that provide the various signing functions\nrequired by network authorities/validators in pursuit of their duties.\n- **Validator ID:** Every account has an associated validator ID. For some simple staking systems, this may just be the\nsame as the account ID. For staking systems using a stash/controller model, the validator ID would be the stash account\nID of the controller.\n- **Session key configuration process:** Session keys are set using `set_keys` for use not in the next session, but the\nsession after next. They are stored in `NextKeys`, a mapping between the caller's `ValidatorId` and the session keys\nprovided. `set_keys` allows users to set their session key prior to being selected as validator. It is a public call\nsince it uses `ensure_signed`, which checks that the origin is a signed account. As such, the account ID of the origin\nstored in `NextKeys` may not necessarily be associated with a block author or a validator. The session keys of accounts\nare removed once their account balance is zero.\n- **Session length:** This pallet does not assume anything about the length of each session. Rather, it relies on an\nimplementation of `ShouldEndSession` to dictate a new session's start. This pallet provides the `PeriodicSessions`\nstruct for simple periodic sessions.\n- **Session rotation configuration:** Configure as either a 'normal' (rewardable session where rewards are applied) or\n'exceptional' (slashable) session rotation.\n- **Session rotation process:** At the beginning of each block, the `on_initialize` function queries the provided\nimplementation of `ShouldEndSession`. If the session is to end the newly activated validator IDs and session keys are\ntaken from storage and passed to the `SessionHandler`. The validator set supplied by `SessionManager::new_session` and\nthe corresponding session keys, which may have been registered via `set_keys` during the previous session, are written\nto storage where they will wait one session before being passed to the `SessionHandler` themselves."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain documentation template:<br>\ninput: "
      },
      {
        "role": "assistant",
        "content": "Copy and paste this template from frame/examples/basic/src/lib.rs into file\n`frame/<INSERT_CUSTOM_PALLET_NAME>/src/lib.rs` of your own custom pallet and complete it.\n<details><p><pre>\n// Add heading with custom pallet name\n\n\\# <INSERT_CUSTOM_PALLET_NAME> Pallet\n\n// Add simple description\n\n// Include the following links that shows what trait needs to be implemented to use the pallet\n// and the supported dispatchables that are documented in the Call enum.\n\n- \\`<INSERT_CUSTOM_PALLET_NAME>::Config`\n- \\`Call`\n- \\`Module`\n\n\\## Overview\n\n<!-- Original author of paragraph: Various. See https://github.com/paritytech/substrate-developer-hub/issues/44 -->\n// Short description of pallet's purpose.\n// Links to Traits that should be implemented.\n// What this pallet is for.\n// What functionality the pallet provides.\n// When to use the pallet (use case examples).\n// How it is used.\n// Inputs it uses and the source of each input.\n// Outputs it produces.\n\n<!-- Original author of paragraph: @Kianenigma in PR https://github.com/paritytech/substrate/pull/1951 -->\n<!-- and comment https://github.com/paritytech/substrate-developer-hub/issues/44#issuecomment-471982710 -->\n\n\\## Terminology\n\n// Add terminology used in the custom pallet. Include concepts, storage items, or actions that you think\n// deserve to be noted to give context to the rest of the documentation or pallet usage. The author needs to\n// use some judgment about what is included. We don't want a list of every storage item nor types - the user\n// can go to the code for that. For example, \"transfer fee\" is obvious and should not be included, but\n// \"free balance\" and \"reserved balance\" should be noted to give context to the pallet.\n// Please do not link to outside resources. The reference docs should be the ultimate source of truth.\n\n<!-- Original author of heading: @Kianenigma in PR https://github.com/paritytech/substrate/pull/1951 -->\n\n\\## Goals\n\n// Add goals that the custom pallet is designed to achieve.\n\n<!-- Original author of heading: @Kianenigma in PR https://github.com/paritytech/substrate/pull/1951 -->\n\n\\### Scenarios\n\n<!-- Original author of paragraph: @Kianenigma. Based on PR https://github.com/paritytech/substrate/pull/1951 -->\n\n\\### <INSERT_SCENARIO_NAME>\n\n// Describe requirements prior to interacting with the custom pallet.\n// Describe the process of interacting with the custom pallet for this scenario and public API functions used.\n\n\\## Interface\n\n\\### Supported Origins\n\n// What origins are used and supported in this pallet (root, signed, none)\n// i.e. root when <code>\\`ensure_root\\`</code> used\n// i.e. none when <code>\\`ensure_none\\`</code> used\n// i.e. signed when <code>\\`ensure_signed\\`</code> used\n\n<code>\\`inherent\\`</code> <INSERT_DESCRIPTION>\n\n<!-- Original author of paragraph: @Kianenigma in comment -->\n<!-- https://github.com/paritytech/substrate-developer-hub/issues/44#issuecomment-471982710 -->\n\n\\### Types\n\n// Type aliases. Include any associated types and where the user would typically define them.\n\n<code>\\`ExampleType\\`</code> <INSERT_DESCRIPTION>\n\n<!-- Original author of paragraph: ??? -->\n\n// Reference documentation of aspects such as `storageItems` and `dispatchable` functions should only be\n// included in the https://docs.rs Rustdocs for Substrate and not repeated in the README file.\n\n\\### Dispatchable Functions\n\n<!-- Original author of paragraph: @AmarRSingh & @joepetrowski -->\n\n// A brief description of dispatchable functions and a link to the rustdoc with their actual documentation.\n\n// <b>MUST</b> have link to Call enum\n// <b>MUST</b> have origin information included in function doc\n// <b>CAN</b> have more info up to the user\n\n\\### Public Functions\n\n<!-- Original author of paragraph: @joepetrowski -->\n\n// A link to the rustdoc and any notes about usage in the pallet, not for specific functions.\n// For example, in the Balances Pallet: \"Note that when using the publicly exposed functions,\n// you (the runtime developer) are responsible for implementing any necessary checks\n// (e.g. that the sender is the signer) before calling a function that will affect storage.\"\n\n<!-- Original author of paragraph: @AmarRSingh -->\n\n// It is up to the writer of the respective pallet (with respect to how much information to provide).\n\n\\### Public Inspection functions - Immutable (getters)\n\n// Insert a subheading for each getter function signature\n\n\\### <code>\\`example_getter_name()\\`</code>\n\n// What it returns\n// Why, when, and how often to call it\n// When it could panic or error\n// When safety issues to consider\n\n\\### Public Mutable functions (changing state)\n\n// Insert a subheading for each setter function signature\n\n\\### <code>\\`example_setter_name(origin, parameter_name: T::ExampleType)\\`</code>\n\n// What state it changes\n// Why, when, and how often to call it\n// When it could panic or error\n// When safety issues to consider\n// What parameter values are valid and why\n\n\\### Storage Items\n\n// Explain any storage items included in this pallet\n\n\\### Digest Items\n\n// Explain any digest items included in this pallet\n\n\\### Inherent Data\n\n// Explain what inherent data (if any) is defined in the pallet and any other related types\n\n\\### Events:\n\n// Insert events for this pallet if any\n\n\\### Errors:\n\n// Explain what generates errors\n\n\\## Usage\n\n// Insert 2-3 examples of usage and code snippets that show how to\n// use <INSERT_CUSTOM_PALLET_NAME> Pallet in a custom pallet.\n\n\\### Prerequisites\n\n// Show how to include necessary imports for <INSERT_CUSTOM_PALLET_NAME> and derive\n// your pallet configuration trait with the `INSERT_CUSTOM_PALLET_NAME` trait.\n\n\\```rust\nuse <INSERT_CUSTOM_PALLET_NAME>;\n\npub trait Config: <INSERT_CUSTOM_PALLET_NAME>::Config { }\n\\```\n\n\\### Simple Code Snippet\n\n// Show a simple example (e.g. how to query a public getter function of <INSERT_CUSTOM_PALLET_NAME>)\n\n\\### Example from FRAME\n\n// Show a usage example in an actual runtime\n\n// See:\n// - Substrate TCR https://github.com/parity-samples/substrate-tcr\n// - Substrate Kitties https://shawntabrizi.github.io/substrate-collectables-workshop/#/\n\n\\## Genesis Config\n\n<!-- Original author of paragraph: @joepetrowski -->\n\n\\## Dependencies\n\n// Dependencies on other FRAME pallets and the genesis config should be mentioned,\n// but not the Rust Standard Library.\n// Genesis configuration modifications that may be made to incorporate this pallet\n// Interaction with other pallets\n\n<!-- Original author of heading: @AmarRSingh -->\n\n\\## Related Pallets\n\n// Interaction with other pallets in the form of a bullet point list\n\n\\## References\n\n<!-- Original author of paragraph: @joepetrowski -->\n\n// Links to reference material, if applicable. For example, Phragmen, W3F research, etc.\n// that the implementation is based on.\n</pre></p></details>\n\nLicense: MIT-0"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain generate a random account\ninput: "
      },
      {
        "role": "assistant",
        "content": "Generating a new key is as simple as running:\n\nsubkey generate\n\nThe output looks similar to:\n\nSecret phrase `hotel forest jar hover kite book view eight stuff angle legend defense` is account:\n  Secret seed:      0xa05c75731970cc7868a2fb7cb577353cd5b31f62dccced92c441acd8fee0c92d\n  Public key (hex): 0xfec70cfbf1977c6965b5af10a4534a6a35d548eb14580594d0bc543286892515\n  Account ID:       0xfec70cfbf1977c6965b5af10a4534a6a35d548eb14580594d0bc543286892515\n  SS58 Address:     5Hpm9fq3W3dQgwWpAwDS2ZHKAdnk86QRCu7iX4GnmDxycrte\n\n---\n\u2620\ufe0f DO NT RE-USE ANY OF THE SEEDS AND SECRETS FROM THIS PAGE \u2620\ufe0f.\n\nYou can read more about security and risks in SECURITY.md and in the Polkadot\nWiki.\n\n---\n\nThe output above shows a **secret phrase** (also called **mnemonic phrase**) and the **secret seed** (also called\n**Private Key**). Those 2 secrets are the pieces of information you MUST keep safe and secret. All the other information\nbelow can be derived from those secrets.\n\nThe output above also shows the **public key** and the **Account ID**. Those are the independent from the network where\nyou will use the key.\n\nThe **SS58 address** (or **Public Address**) of a new account is a representation of the public keys of an account for\na given network (for instance Kusama or Polkadot).\n\nYou can read more about the SS58 format in the Substrate Docs\nand see the list of reserved prefixes in the SS58 Registry.\n\nFor instance, considering the previous seed `0xa05c75731970cc7868a2fb7cb577353cd5b31f62dccced92c441acd8fee0c92d` the\nSS58 addresses are:\n\n- Polkadot: `16m4J167Mptt8UXL8aGSAi7U2FnPpPxZHPrCgMG9KJzVoFqM`\n- Kusama: `JLNozAv8QeLSbLFwe2UvWeKKE4yvmDbfGxTuiYkF2BUMx4M`"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain infrastructure/api\ninput: "
      },
      {
        "role": "assistant",
        "content": "### *Peer Set Management*\n\nCategory: Networking\n\nValidators assigned to a parachain need a way to discover and connect to collators in order to get fresh parachain\nblocks to validate.\n\nCollators need to discover and connect to validators in order to submit parachain blocks.\n\nFishermen need to talk to validators and collators to fetch available data and circulate reports.\n\nSome connections are long-lived, some are just for a single request.\n\n### Custom libp2p sub-protocols\n\nPolkadot parachains involve many distinct networking protocols. Ideally, we'd be able to spawn each of these as a\nseparate futures task which communicates via channel with other protocols or node code as necessary. This requires\nchanges in Substrate and libp2p.\n\n---"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain assignment\ninput: "
      },
      {
        "role": "assistant",
        "content": "### *Auctions*\n\nCategory: Runtime\n\nAuctioning and registration of parachains. This is already implemented and follows the Parachain Allocation \u2014 Research\nat W3F document.\n\n### *On-demand Blockspace Purchase*\n\nCategory: Runtime\n\nThe blockspace purchasing system for on-demand parachains consists of an on-chain mechanism for resolving block space\npurchases by collators and ensuring that they author a block.\n\nThe node-side portion of on-demand parachains is for collators to actually purchase blockspace and to configure the\nconditions in which purchases are made.\n\n### *Validator Assignment*\n\nCategory: Runtime\n\nAssignment of validators to parachains. Validators are only assigned to parachains for a short period of time. Tweakable\nparameters include length of time assigned to each parachain and length of time in advance that the network is aware of\nvalidators' assignments.\n\n---"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain agreement\ninput: "
      },
      {
        "role": "assistant",
        "content": "### *Attestation Circulation*\n\nCategory: Networking\n\nA black-box networking component for circulating attestation messages (`Candidate`, `Valid`, `Invalid`) between\nvalidators of any given parachain to create a quorum on which blocks can be included.\n\n### *Availability Erasure-coding*\n\nCategory: Node, Networking\n\nFor each potential, considered parachain block, perform an erasure-coding of the PoV and outgoing messages of the block.\nCall the number of validators on the relay chain for the Relay-chain block this parachain block is being considered for\ninclusion in `n`. Erasure-code into `n` pieces, where any `f + 1` can recover (`f` being the maximum number of tolerated\nfaulty nodes = ~ `n / 3`). The `i'th` validator stores the `i'th` piece of the coding and provides it to any who ask.\n\n### *PoV block fetching*\n\nCategory: Networking\n\nA black-box networking component for validators or fishermen on a parachain to obtain the PoV block referenced by hash\nin an attestation, for the purpose of validating. When fetching \"current\" PoV blocks (close to the head of the chain, or\nrelating to the block currently being built), this should be fast. When fetching \"old\" PoV blocks, it should be possible\nand fall back on recovering from the availability erasure-coding.\n\n### *On-demand Blockspace Purchase*\n\nCategory: Node, Networking\n\nHow and when collators are configured to purchase on-demand blockspace.\n\n### *Collation Loop*\n\nCategory: Node, Networking\n\nThe main event loop of a collator node:\n 1. new relay chain block B\n 2. sync new parachain head P w.r.t. B\n 3. build new child of P\n 4. submit to validators\n\n---"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain cross-chain messaging\ninput: "
      },
      {
        "role": "assistant",
        "content": "https://hackmd.io/ILoQltEISP697oMYe4HbrA?view https://github.com/paritytech/polkadot/issues/597\n\nThe biggest sub-project of the parachains roadmap - how messages are sent between parachains. This involves the\nstate-machine ordering of incoming messages, protocols for fetching those messages, and node logic for persisting the\nmessages.\n\nThis is designed around a concept of unidirectional _channels_ between paras, which consist of a sender and receiver. At\neach relay chain block, each para has an opportunity to send a message on each channel for which it controls the sending\nhalf. It will also attempt to process messages on each receiving half of the channel which it controls _in order_:\nmessages sent at block height `b` must be processed before those sent at block height `b+1`. For messages on different\nchannels sent at the same block height, there will be some well-defined order in which they should be processed.\n\nThis means that a receiving para will have a maximum height differential of `1` in terms of the most recently processed\nmessage's send-height across all of the channels it is receiving on. The minimum processed send-height of a receiving\npara is known as its _watermark_. All messages on all channels sending to this para before or at the watermark have been\nprocessed.\n\n### *Finalize CandidateReceipt format*\n\nCategory: Runtime / Node\n\nThe `CandidateReceipt` is the wrapper around a parablock header which is submitted to the runtime. It contains\ncryptographic commitments to data which is important for validation or interpretation of the parablock, including the\nhash of the witness data and outgoing message data.\n\nThe `CandidateReceipt` format should be finalized in accordance to the XCMP writeups linked above - most importantly, to\nbe altered to hold `bitfield` and `message_root` fields which cryptographically commit to the state of each open\nchannel.\n\n### *Finalize PovBlock format*\n\nCategory: Runtime / Node\n\nThe `PovBlock` or `Proof-of-Validity` block contains all the data you need to validate a parablock. It will need to\ncontain incoming message queues and potentially outgoing ones as well.\n\n### *CST Update Procedure*\n\nCategory: Runtime\n\nStorage definitions and update logic of the Channel State Table (CST) based on the supplied `CandidateReceipt`s in a\nrelay chain block.\n\n### *CST Entry Proof Generation and Checking*\n\nCategory: Node\n\nMeans for full nodes of the relay chain to generate proofs of items in the CST and for light clients or pruned nodes to\ncheck those proofs.\n\n### *MQC Storage and Distribution Protocol*\n\nCategory: Node\n\nEvery channel's state is described by a Message Queue Chain (MQC) which is a hash-chain, where the links are defined by\n`(M, b, H)`: the message most recently sent, the block height at which the prior message was sent, and the hash of the\nprior link.\n\nIt is the responsibility of the full nodes of the _sending_ para to maintain all links of the MQC up to and including\nthe link where `b` is less than the watermark of the _receiving_ para.\n\nFull nodes of the para will be aware of the head of all MQCs for its channels because they are produced by execution of\nthe block. This will take collaboration with the Cumulus team (https://github.com/paritytech/polkadot-sdk) on APIs.\n\nWe will need a network where collators of paras can discover and fetch the relevant portion of the MQC incoming from all\nchannels.\n\n### *Channel Registrar and Economics*\n\nCategory: Runtime\n\nRuntime logic for paras to open and close channels by putting down a deposit. The amount of channels an on-demand\nparachain can open will be limited. Channels that are pending close should remain open until the watermark of the\nrecipient has reached the block height of the close request.\n\n---"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain fishing/slashing\ninput: "
      },
      {
        "role": "assistant",
        "content": "### *Validity/Availability Report Handler*\n\nCategory: Runtime\n\nIn Polkadot, a bad parachain group can force inclusion of an invalid or unavailable parachain block. It is the job of\nfishermen to detect those blocks and report them to the runtime. This item is about the report handler\n\nThe W3F-research writeup on availability/validity provides a high-level view of the dispute resolution process:\nAvailability and Validity \u2014 Research at\nW3F\n\nOne of the main behaviors that is unimplemented and needs to be is the _rollback_ that occurs when the dispute\nresolution process concludes that an error has been made. When we mark a parachain block as having been invalid or\nunavailable, we need to roll back all parachains to a point from just before this state.  We would also need to roll\nback relay chain state, because there may have been messages from a parachain to a relay chain that now need to be\nrolled back. The easiest thing to do would be to side-step that by putting a delay on upwards messages, but this would\nimpact the UX of parachain participation in slot auctions, council votes, etc. considerably. Assuming we can't side-step\nthis, we will have to find a way to roll back selected state of the relay chain.\n\n### *Double-vote Slash Handler*\n\nCategory: Runtime\n\nIn the attestation process, validators may submit only one `Candidate` message for a given relay chain block. If issuing\na `Candidate` message on a parachain block, neither a `Valid` or `Invalid` vote cannot be issued on that parachain\nblock, as the `Candidate` message is an implicit validity vote. Otherwise, it is illegal to cast both a `Valid` and\n`Invalid` vote on a given parachain block.\n\nRuntime handlers that take two conflicting votes as arguments and slash the offender are needed.\n\n### *Validity/Availability Fishing*\n\nCategory: Node\n\nThis code-path is also taken by validators who self-select based on VRF Availability and Validity \u2014 Research at\nW3F. Validators and fishermen will\nselect parachain blocks to re-validate. In these steps:\n- Attempt to recover the PoV block, falling back on the erasure-coding. If not available, issue report.\n- Attempt to validate the PoV block. If invalid, issue report.\n\n### *Double-vote Fishing*\n\nCategory: Node\n\nNodes that observe a double-vote in the attestation process should submit a report to the chain to trigger slashing.\n\n---"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain parachain status\ninput: "
      },
      {
        "role": "assistant",
        "content": "This dashboard allows you to see at a glance how fast are candidates approved, disputed and\nfinalized. It was originally designed for observing liveliness after parachain deployment in\n Kusama/Polkadot, but can be useful generally in production or testing.\n\nIt includes panels covering key subsystems of the parachain node side implementation:\n- Backing\n- PVF execution\n- Approval voting\n- Disputes coordinator\n- Chain selection\n\nIt is important to note that this dashboard applies only for validator nodes. The prometheus\nqueries assume the `instance` label value contains the string `validator` only for validator nodes.\n\nDashboard JSON"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain key liveliness indicators\ninput: "
      },
      {
        "role": "assistant",
        "content": "- **Relay chain finality lag**. How far behind finality is compared to the current best block. By design,\n GRANDPA never finalizes past last 2 blocks, so this value is always >=2 blocks.\n- **Approval checking finality lag**. The distance (in blocks) between the chain head and the last block\non which Approval voting is happening. The block is generally the highest approved ancestor of the head\nblock and the metric is computed during relay chain selection.\n- **Disputes finality lag**. How far behind the chain head is the last approved and non disputed block.\nThis value is always higher than approval checking lag as it further restricts finality to only undisputed\nchains.\n- **PVF preparation and execution time**. Each parachain has it's own PVF (parachain validation function):\na wasm blob that is executed by validators during backing, approval checking and disputing. The PVF\npreparation time refers to the time it takes for the PVF wasm to be compiled. This step is done once and\nthen result cached. PVF execution will use the resulting artifact to execute the PVF for a given candidate.\nPVFs are expected to have a limited execution time to ensure there is enough time left for the parachain\nblock to be included in the relay block.\n- **Time to recover and check candidate**. This is part of approval voting and covers the time it takes\nto recover the candidate block available data from other validators, check it (includes PVF execution time)\nand issue statement or initiate dispute.\n- **Assignment delay tranches**. Approval voting is designed such that validators assigned to check a specific\ncandidate are split up into equal delay tranches (0.5 seconds each). All validators checks are ordered by the delay\ntranche index. Early tranches of validators have the opportunity to check the candidate first before later tranches\nthat act as backups in case of no shows."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain example run\ninput: "
      },
      {
        "role": "assistant",
        "content": "Let's run an availability read test which will recover availability for 200 cores with max PoV size on a 1000\nnode validator network.\n\n<!-- markdownlint-disable line-length -->\n\ntarget/testnet/subsystem-bench polkadot/node/subsystem-bench/examples/availability_write.yaml\n[2024-02-19T14:10:32.981Z INFO  subsystem_bench] Sequence contains 1 step(s)\n[2024-02-19T14:10:32.981Z INFO  subsystem-bench::cli] Step 1/1\n[2024-02-19T14:10:32.981Z INFO  subsystem-bench::cli] [objective = DataAvailabilityWrite] n_validators = 1000, n_cores = 200, pov_size = 5120 - 5120, connectivity = 75, latency = Some(PeerLatency { mean_latency_ms: 30, std_dev: 2.0 })\n[2024-02-19T14:10:32.982Z INFO  subsystem-bench::availability] Generating template candidate index=0 pov_size=5242880\n[2024-02-19T14:10:33.106Z INFO  subsystem-bench::availability] Created test environment.\n[2024-02-19T14:10:33.106Z INFO  subsystem-bench::availability] Pre-generating 600 candidates.\n[2024-02-19T14:10:34.096Z INFO  subsystem-bench::network] Initializing emulation for a 1000 peer network.\n[2024-02-19T14:10:34.096Z INFO  subsystem-bench::network] connectivity 75%, latency Some(PeerLatency { mean_latency_ms: 30, std_dev: 2.0 })\n[2024-02-19T14:10:34.098Z INFO  subsystem-bench::network] Network created, connected validator count 749\n[2024-02-19T14:10:34.099Z INFO  subsystem-bench::availability] Seeding availability store with candidates ...\n[2024-02-19T14:10:34.100Z INFO  substrate_prometheus_endpoint] \u303d\ufe0f Prometheus exporter started at 127.0.0.1:9999\n[2024-02-19T14:10:34.387Z INFO  subsystem-bench::availability] Done\n[2024-02-19T14:10:34.387Z INFO  subsystem-bench::availability] Current block #1\n[2024-02-19T14:10:34.389Z INFO  subsystem-bench::availability] Waiting for all emulated peers to receive their chunk from us ...\n[2024-02-19T14:10:34.625Z INFO  subsystem-bench::availability] All chunks received in 237ms\n[2024-02-19T14:10:34.626Z INFO  polkadot_subsystem_bench::availability] Waiting for 749 bitfields to be received and processed\n[2024-02-19T14:10:35.710Z INFO  subsystem-bench::availability] All bitfields processed\n[2024-02-19T14:10:35.710Z INFO  subsystem-bench::availability] All work for block completed in 1322ms\n[2024-02-19T14:10:35.710Z INFO  subsystem-bench::availability] Current block #2\n[2024-02-19T14:10:35.712Z INFO  subsystem-bench::availability] Waiting for all emulated peers to receive their chunk from us ...\n[2024-02-19T14:10:35.947Z INFO  subsystem-bench::availability] All chunks received in 236ms\n[2024-02-19T14:10:35.947Z INFO  polkadot_subsystem_bench::availability] Waiting for 749 bitfields to be received and processed\n[2024-02-19T14:10:37.038Z INFO  subsystem-bench::availability] All bitfields processed\n[2024-02-19T14:10:37.038Z INFO  subsystem-bench::availability] All work for block completed in 1328ms\n[2024-02-19T14:10:37.039Z INFO  subsystem-bench::availability] Current block #3\n[2024-02-19T14:10:37.040Z INFO  subsystem-bench::availability] Waiting for all emulated peers to receive their chunk from us ...\n[2024-02-19T14:10:37.276Z INFO  subsystem-bench::availability] All chunks received in 237ms\n[2024-02-19T14:10:37.276Z INFO  polkadot_subsystem_bench::availability] Waiting for 749 bitfields to be received and processed\n[2024-02-19T14:10:38.362Z INFO  subsystem-bench::availability] All bitfields processed\n[2024-02-19T14:10:38.362Z INFO  subsystem-bench::availability] All work for block completed in 1323ms\n[2024-02-19T14:10:38.362Z INFO  subsystem-bench::availability] All blocks processed in 3974ms\n[2024-02-19T14:10:38.362Z INFO  subsystem-bench::availability] Avg block time: 1324 ms\n[2024-02-19T14:10:38.362Z INFO  parachain::availability-store] received `Conclude` signal, exiting\n[2024-02-19T14:10:38.362Z INFO  parachain::bitfield-distribution] Conclude\n[2024-02-19T14:10:38.362Z INFO  subsystem-bench::network] Downlink channel closed, network interface task exiting\n\npolkadot/node/subsystem-bench/examples/availability_write.yaml #1 DataAvailabilityWrite\n\nNetwork usage, KiB                     total   per block\nReceived from peers                12922.000    4307.333\nSent to peers                      47705.000   15901.667\n\nCPU usage, seconds                     total   per block\navailability-distribution              0.045       0.015\nbitfield-distribution                  0.104       0.035\navailability-store                     0.304       0.101\nTest environment                       3.213       1.071\n\n<!-- markdownlint-enable line-length -->\n\n`Block time` in the current context has a different meaning. It measures the amount of time it\ntook the subsystem to finish processing all of the messages sent in the context of the current test block."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain profile memory usage using jemalloc\ninput: "
      },
      {
        "role": "assistant",
        "content": "Bellow you can find instructions how to setup and run profiling with jemalloc, this is complementary\nwith using other memory profiling tools like: <https://github.com/koute/bytehound?tab=readme-ov-file#basic-usage>.\n\n### Prerequisites\n\nInstall tooling with:\n\nsudo apt install libjemalloc-dev graphviz\n\n### Generate memory usage snapshots\n\nMemory usage can be profiled by running any subsystem benchmark with `--features memprofile`, e.g:\n\nRUSTFLAGS=-g cargo run -p polkadot-subsystem-bench --release --features memprofile -- polkadot/node/subsystem-bench/examples/approvals_throughput.yaml\n\n### Interpret the results\n\nAfter the benchmark ran the memory usage snapshots can be found in `/tmp/subsystem-bench*`, to extract the information\nfrom a snapshot you can use `jeprof` like this:\n\njeprof --text PATH_TO_EXECUTABLE_WITH_DEBUG_SYMBOLS /tmp/subsystem-bench.1222895.199.i199.heap > statistics.txt\n\nUseful links:\n\n- Tutorial: <https://www.magiroux.com/rust-jemalloc-profiling/>\n- Jemalloc configuration options: <https://jemalloc.net/jemalloc.3.html>"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain issue 1: scalability\ninput: "
      },
      {
        "role": "assistant",
        "content": "It became clear a few years ago that the transaction throughput of simple Proof-of-Work (PoW) blockchains such as\nBitcoin, Ethereum, and myriad others was simply too low.\n\n> TODO: what if there were more blockchains, etc.\n\nProof-of-Stake (PoS) systems can accomplish higher throughput than PoW blockchains. PoS systems are secured by bonded\ncapital as opposed to spent effort - liquidity opportunity cost vs. burning electricity. The way they work is by\nselecting a set of validators with known economic identity who lock up tokens in exchange for earning the right to\n\"validate\" or participate in the consensus process. If they are found to carry out that process wrongly, they will be\nslashed, meaning some or all of the locked tokens will be burned. This provides a strong disincentive in the direction\nof misbehavior.\n\nSince the consensus protocol doesn't revolve around wasting effort, block times and agreement can occur much faster.\nSolutions to PoW challenges don't have to be found before a block can be authored, so the overhead of authoring a block\nis reduced to only the costs of creating and distributing the block.\n\nHowever, consensus on a PoS chain requires full agreement of 2/3+ of the validator set for everything that occurs at\nLayer 1: all logic which is carried out as part of the blockchain's state machine. This means that everybody still needs\nto check everything. Furthermore, validators may have different views of the system based on the information that they\nreceive over an asynchronous network, making agreement on the latest state more difficult.\n\nParachains are an example of a **sharded** protocol. Sharding is a concept borrowed from traditional database\narchitecture. Rather than requiring every participant to check every transaction, we require each participant to check\nsome subset of transactions, with enough redundancy baked in that byzantine (arbitrarily malicious) participants can't\nsneak in invalid transactions - at least not without being detected and getting slashed, with those transactions\nreverted.\n\nSharding and Proof-of-Stake in coordination with each other allow a parachain host to provide full security on many\nparachains, even without all participants checking all state transitions.\n\n> TODO: note about network effects & bridging"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain assignment criteria\ninput: "
      },
      {
        "role": "assistant",
        "content": "Assignment criteria compute actual assignments using stories and the validators' secret approval assignment key.\nAssignment criteria output a `Position` consisting of both a `ParaId` to be checked, as well as a precedence\n`DelayTranche` for when the assignment becomes valid.\n\nAssignment criteria come in four flavors, `RelayVRFModuloCompact`, `RelayVRFDelay`, `RelayEquivocation` and the\ndeprecated `RelayVRFModulo`.  Among these, `RelayVRFModulo`, `RelayVRFModuloCompact` and `RelayVRFDelay` run a\nVRF whose input is the output of a `RelayVRFStory`, while `RelayEquivocation` runs a VRF whose input is the\noutput of a `RelayEquivocationStory`.\n\nAmong these, we have two distinct VRF output computations:\n\n`RelayVRFModulo` runs several distinct samples whose VRF input is the `RelayVRFStory` and the sample number.  It\ncomputes the VRF output with `schnorrkel::vrf::VRFInOut::make_bytes` using the context \"A&V Core\", reduces this number\nmodulo the number of availability cores, and outputs the candidate just declared available by, and included by aka\nleaving, that availability core.  We drop any samples that return no candidate because no candidate was leaving the\nsampled availability core in this relay chain block.  We choose three samples initially, but we could make Polkadot more\nsecure and efficient by increasing this to four or five, and reducing the backing checks accordingly.  All successful\n`RelayVRFModulo` samples are assigned delay tranche zero.\n\n`RelayVRFModuloCompact` runs a single samples whose VRF input is the `RelayVRFStory` and the sample count. Similar\nto `RelayVRFModulo` introduces multiple core assignments for tranche zero. It computes the VRF output with\n`schnorrkel::vrf::VRFInOut::make_bytes` using the context \"A&V Core v2\" and samples up to 160 bytes of the output\nas an array of `u32`. Then reduces each `u32` modulo the number of availability cores, and outputs up\nto `relay_vrf_modulo_samples` availability core indices.\n\nThere is no sampling process for `RelayVRFDelay` and `RelayEquivocation`.  We instead run them on specific candidates\nand they compute a delay from their VRF output.  `RelayVRFDelay` runs for all candidates included under, aka declared\navailable by, a relay chain block, and inputs the associated VRF output via `RelayVRFStory`.  `RelayEquivocation` runs\nonly on candidate block equivocations, and inputs their block hashes via the `RelayEquivocation` story.\n\n`RelayVRFDelay` and `RelayEquivocation` both compute their output with `schnorrkel::vrf::VRFInOut::make_bytes` using the\ncontext \"A&V Tranche\" and reduce the result modulo `num_delay_tranches + zeroth_delay_tranche_width`, and consolidate\nresults 0 through `zeroth_delay_tranche_width` to be 0.  In this way, they ensure the zeroth delay tranche has\n`zeroth_delay_tranche_width+1` times as many assignments as any other tranche.\n\nAs future work (or TODO?), we should merge assignment notices with the same delay and story using `vrf_merge`.  We\ncannot merge those with the same delay and different stories because `RelayEquivocationStory`s could change but\n`RelayVRFStory` never changes."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain vertical message passing\ninput: "
      },
      {
        "role": "assistant",
        "content": "```dot process\ndigraph {\n    rc [shape=Mdiamond label=\"Relay Chain\"];\n    p1 [shape=box label = \"Parachain\"];\n\n    rc -> p1 [label=\"DMP\"];\n    p1 -> rc [label=\"UMP\"];\n}\n```\n\nDownward Message Passing (DMP) is a mechanism for delivering messages to parachains from the relay chain.\n\nEach parachain has its own queue that stores all pending inbound downward messages. A parachain doesn't have to process\nall messages at once, however, there are rules as to how the downward message queue should be processed. Currently, at\nleast one message must be consumed per candidate if the queue is not empty. The downward message queue doesn't have a\ncap on its size and it is up to the relay-chain to put mechanisms that prevent spamming in place.\n\nUpward Message Passing (UMP) is a mechanism responsible for delivering messages in the opposite direction: from a\nparachain up to the relay chain. Upward messages are essentially byte blobs. However, they are interpreted by the\nrelay-chain according to the XCM standard.\n\nThe XCM standard is a common vocabulary of messages. The XCM standard doesn't require a particular interpretation of a\nmessage. However, the parachains host (e.g. Polkadot) guarantees certain semantics for those.\n\nMoreover, while most XCM messages are handled by the on-chain XCM interpreter, some of the messages are special cased.\nSpecifically, those messages can be checked during the acceptance criteria and thus invalid messages would lead to\nrejecting the candidate itself.\n\nOne kind of such a message is `Xcm::Transact`. This upward message can be seen as a way for a parachain to execute\narbitrary entrypoints on the relay-chain. `Xcm::Transact` messages resemble regular extrinsics with the exception that\nthey originate from a parachain.\n\nThe payload of `Xcm::Transact` messages is referred as to `Dispatchable`. When a candidate with such a message is\nenacted the dispatchables are put into a queue corresponding to the parachain. There can be only so many dispatchables\nin that queue at once. The weight that processing of the dispatchables can consume is limited by a preconfigured value.\nTherefore, it is possible that some dispatchables will be left for later blocks. To make the dispatching more fair, the\nqueues are processed turn-by-turn in a round robin fashion.\n\nThe second category of special cased XCM messages are for horizontal messaging channel management, namely messages meant\nto request opening and closing HRMP channels (HRMP will be described below)."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain background\ninput: "
      },
      {
        "role": "assistant",
        "content": "As established in the approval process dealing with bad parablocks is a three step process:\n\n1. Detection\n1. Escalation\n1. Consequences\n\nThe main system responsible for dispensing **consequences** for malicious actors is the dispute\nsystem which eventually dispenses slash events. The slashes itself can be dispensed quickly (a\nmatter of blocks) but for an extra layer of auditing all slashes are deferred for 27 days (in Polkadot/Kusama) which\ngives time for Governance to investigate and potentially alter the punishment. Dispute concluding by itself does not\nimmediately remove the validator from the active validator set.\n\n> **Note:** \\\n> There was an additional mechanism of automatically chilling the validator which removed their intent to participate in\n> the next election, but the removed validator could simply re-register his intent to validate.\n\nThere is a need to have a more immediate way to deal with malicious validators. This is where the validator disabling\ncomes in. It is focused on dispensing **low latency** consequences for malicious actors. It is important to note that\nthe validator disabling is not a replacement for the dispute or slashing systems. It is a complementary system that is\nfocused on lighter but immediate consequences usually in the form of restricted validator privileges.\n\nThe primary goals are:\n- Eliminate or minimize cases where attackers can get free attempts at attacking the network\n- Eliminate or minimize the risks of honest nodes being pushed out of consensus when getting unjustly slashed (defense\n  in depth)\n\nThe above two goals are generally at odds so a careful balance has to be struck between them. We will achieve them by\nsacrificing some **liveness** in favor of **soundness** when the network is under stress. Maintaining some liveness but\nabsolute soundness is paramount.\n\n> **Note:** \\\n> Liveness = Valid candidates can go through (at a decent pace) \\\n> Security = Invalid candidates cannot go through (or are statistically very improbable)\n\nSide goals are:\n- Reduce the damages to honest nodes that had a fault which might cause repeated slashes\n- Reduce liveness impact of individual malicious attackers"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain design\ninput: "
      },
      {
        "role": "assistant",
        "content": "A few options for the duration of disablement were considered:\n- 1 epoch (4h in Polkadot)\n- 1 era (24h in Polkadot)\n- 2-26 eras\n- 27 eras\n\n1 epoch is a short period and between a few epochs the validator will most likely be exactly the same. It is also very\ndifficult to fix any local node issues for honest validator in such a short time so the chance for a repeated offense is\nhigh.\n\n1 era gives a bit more time to fix any minor issues. Additionally, it guarantees a validator set change at so many of\nthe currently disabled validator might no longer be present anyway. It also gives the time for the validator to chill\nthemselves if they have identified a cause and want to spend more time fixing it. (**Point 4.**)\n\nHigher values could be considered and the main arguments for those are based around the fact that it reduces the number\nof repeated attacks that will be allowed before the slash execution. Generally 1 attack per era for 27 eras resulting in\n27 attacks at most should not compromise our safety assumptions. Although this direction could be further explored and\nmight be parametrized for governance to decide.\n\n</br></br></br>"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain enabling approval voter slashes\ninput: "
      },
      {
        "role": "assistant",
        "content": "The original Polkadot 1.0 design describes that all validators on the loosing side of the dispute are slashed. In the\ncurrent system only the backers are slashed and any approval voters on the wrong side will not be slashed. This creates\nsome undesirable incentives:\n\n- Lazy approval checkers (approvals yay`ing everything)\n- Spammy approval checkers (approval voters nay`ing everything)\n\nInitially those slashes were disabled to reduce the complexity and to minimize the risk surface in case the system\nmalfunctioned. This is especially risky in case any nondeterministic bugs are present in the system. Once validator\nre-enabling is launched approval voter slashes can be re-instated. Numbers need to be further explored but slashes\nbetween 0-2% are reasonable. 0% would still disable which with the opportunity cost consideration should be enough.\n\n > **Note:** \\\n> Spammy approval checkers are in fact not a big issue as a side effect of the offchain-disabling introduced by the\n> Defense Against Past-Era Dispute Spam (**Node**) #2225. It\n> makes it so all validators loosing a dispute are locally disabled and ignored for dispute initiation so it effectively\n> silences spammers. They can still no-show but the damage is minimized."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain core features\ninput: "
      },
      {
        "role": "assistant",
        "content": "1. Disabled Validators Tracking (**Runtime**) #2950\n    - Expose a ``disabled_validators`` map through a Runtime API\n1. Enforce Backing Disabling (**Runtime**) #1592\n    - Filter out votes from ``disabled_validators`` in ``BackedCandidates`` in ``process_inherent_data``\n1. Substrate Byzantine Threshold (BZT) as Limit for Disabling\n   #1963\n    - Can be parametrized but default to BZT\n    - Disable only up to 1/3 of validators\n1. Respect Disabling in Backing Statement Distribution (**Node**)\n   #1591\n    - This is an optimization as in the end it would get filtered in the runtime anyway\n    - Filter out backing statements coming from ``disabled_validators``\n1. Respect Disablement in Backing (**Node**) #2951\n    - This is an optimization as in the end it would get filtered in the runtime anyway\n    - Don't start backing new candidates when disabled\n    - Don't react to backing requests when disabled\n1. Stop Automatic Chilling of Offenders #1962\n    - Chilling still persists as a state but is no longer automatically applied on offenses\n1. Respect Disabling in Dispute Participation (**Node**) #2225\n    - Receive dispute statements from ``disabled_validators`` but do not release own statements\n    - Ensure dispute confirmation when BZT statements from disabled\n1. Remove Liveness Slashes #1964\n    - Remove liveness slashes from the system\n    - The are other incentives to be online and they could be abused to attack the system\n1. Defense Against Past-Era Dispute Spam (**Node**) #2225\n    - This is needed because runtime cannot disable validators which it no longer knows about\n    - Add a node-side parallel store of ``disabled_validators``\n    - Add new disabled validators to node-side store when they loose a dispute in any leaf in scope\n    - Runtime ``disabled_validators`` always have priority over node-side ``disabled_validators``\n    - Respect the BZT threshold\n    > **Note:** \\\n    > An alternative design here was considered where instead of tracking new incoming leaves a relay parent is used.\n    > This would guarantee determinism as different nodes can see different leaves, but this approach was leaving too\n    > wide of a window because of Async-Backing. Relay Parent could have been significantly in the past and it would\n    > give a lot of time for past session disputes to be spammed.\n1. Do not block finality for \"disabled\" disputes #3358\n    - Emergency fix to not block finality for disputes initiated only by disabled validators\n1. Re-enable small offender when approaching BZT (**Runtime**) #TODO\n    - When BZT limit is reached and there are more offenders to be disabled re-enable the smallest offenders to disable\n      the biggest ones"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain motivation and background\ninput: "
      },
      {
        "role": "assistant",
        "content": "All parachain blocks that end up in the finalized relay chain should be valid. This does not apply to blocks that are\nonly backed, but not included.\n\nWe have two primary components for ensuring that nothing invalid ends up in the finalized relay chain:\n  * Approval Checking, as described here and implemented accordingly in the Approval\nVoting subsystem. This protocol can be shown to prevent invalid parachain blocks\nfrom making their way into the finalized relay chain as long as the amount of attempts are limited.\n  * Disputes, this protocol, which ensures that each attempt to include something bad is caught, and the offending\nvalidators are punished. Disputes differ from backing and approval process (and can not be part of those) in that a\ndispute is independent of a particular fork, while both backing and approval operate on particular forks. This\ndistinction is important! Approval voting stops, if an alternative fork which might not contain the currently approved\ncandidate gets finalized. This is totally fine from the perspective of approval voting as its sole purpose is to make\nsure invalid blocks won't get finalized. For disputes on the other hand we have different requirements: Even though the\n\"danger\" is past and the adversaries were not able to get their invalid block approved, we still want them to get\nslashed for the attempt. Otherwise they just have been able to get a free try, but this is something we need to avoid in\nour security model, as it is based on the assumption that the probability of getting an invalid block finalized is very\nlow and an attacker would get bankrupt before it could have tried often enough.\n\nEvery dispute stems from a disagreement among two or more validators. If a bad actor creates a bad block, but the bad\nactor never distributes it to honest validators, then nobody will dispute it. Of course, such a situation is not even an\nattack on the network, so we don't need to worry about defending against it.\n\nWe are interested in identifying and deterring the following attack scenario:\n  * A parablock included on a branch of the relay chain is bad\n\nWe are also interested in identifying these additional scenarios:\n  * A parablock backed on a branch of the relay chain is bad\n  * A parablock seconded, but not backed on any branch of the relay chain, is bad.\n\nPunishing misbehavior in the latter two scenarios doesn't effect our security guarantees and introduces substantial\ntechnical challenges as described in the `No Disputes for Non Included Candidates` section of Dispute\nCoordinator. We therefore choose to punt on disputes in these cases, instead\nfavoring the protocol simplicity resulting from only punishing in the first scenario.\n\nAs covered in the protocol overview, checking a parachain block requires 3 pieces of data: the\nparachain validation code, the `AvailableData`, and the\n`CandidateReceipt`. The validation code is available on-chain, and published ahead of time, so\nthat no two branches of the relay chain have diverging views of the validation code for a given parachain. Note that\nonly for the first scenario, where the parablock has been included on a branch of the relay chain, is the data\nnecessarily available. Thus, dispute processes should begin with an availability process to ensure availability of the\n`AvailableData`. This availability process will conclude quickly if the data is already available. If the data is not\nalready available, then the initiator of the dispute must make it available.\n\nDisputes have both an on-chain and an off-chain component. Slashing and punishment is handled on-chain, so votes by\nvalidators on either side of the dispute must be placed on-chain. Furthermore, a dispute on one branch of the relay\nchain should be transposed to all other active branches of the relay chain. The fact that slashing occurs _in all\nhistories_ is crucial for deterring attempts to attack the network. The attacker should not be able to escape with their\nfunds because the network has moved on to another branch of the relay chain where no attack was attempted.\n\nIn fact, this is why we introduce a distinction between _local_ and _remote_ disputes. We categorize disputes as either\nlocal or remote relative to any particular branch of the relay chain. Local disputes are about dealing with our first\nscenario, where a parablock has been included on the specific branch we are looking at. In these cases, the chain is\ncorrupted all the way back to the point where the parablock was backed and must be discarded. However, as mentioned\nbefore, the dispute must propagate to all other branches of the relay chain. All other disputes are considered _remote_.\nFor the on-chain component, when handling a dispute for a block which was not included in the current fork of the relay\nchain, it is impossible to discern between our attack scenarios. It is possible that the parablock was included\nsomewhere, or backed somewhere, or wasn't backed anywhere. The on-chain component for handling these cases will be the\nsame."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain collation generation message\ninput: "
      },
      {
        "role": "assistant",
        "content": "Messages received by the Collation Generation subsystem\n\nThis is the core interface by which collators built on top of a Polkadot node submit collations to validators. As such,\nthese messages are not sent by any subsystem but are instead sent from outside of the overseer.\n\n/// A function provided to the subsystem which it uses to pull new collations.\n///\n/// This mode of querying collations is obsoleted by `CollationGenerationMessages::SubmitCollation`\n///\n/// The response channel, if present, is meant to receive a `Seconded` statement as a\n/// form of authentication, for collation mechanisms which rely on this for anti-spam.\ntype CollatorFn = Fn(Hash, PersistedValidationData) -> Future<Output = (Collation, Option<ResponseChannel<SignedStatement>>)>;\n\n/// Configuration for the collation generator\nstruct CollationGenerationConfig {\n    /// Collator's authentication key, so it can sign things.\n    key: CollatorPair,\n    /// Collation function. See [`CollatorFn`] for more details.\n    collator: CollatorFn,\n    /// The parachain that this collator collates for\n    para_id: ParaId,\n}\n\n/// Parameters for submitting a collation\nstruct SubmitCollationParams {\n    /// The relay-parent the collation is built against.\n    relay_parent: Hash,\n    /// The collation itself (PoV and commitments)\n    collation: Collation,\n    /// The parent block's head-data.\n    parent_head: HeadData,\n    /// The hash of the validation code the collation was created against.\n    validation_code_hash: ValidationCodeHash,\n    /// A response channel for receiving a `Seconded` message about the candidate\n    /// once produced by a validator. This is not guaranteed to provide anything.\n    result_sender: Option<ResponseChannel<SignedStatement>>,\n}\n\nenum CollationGenerationMessage {\n    /// Initialize the collation generation subsystem\n\tInitialize(CollationGenerationConfig),\n    /// Submit a collation to the subsystem. This will package it into a signed\n    /// [`CommittedCandidateReceipt`] and distribute along the network to validators.\n    ///\n    /// If sent before `Initialize`, this will be ignored.\n    SubmitCollation(SubmitCollationParams),\n}"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain v1 overview\ninput: "
      },
      {
        "role": "assistant",
        "content": "Diagrams are rendered in high resolution; open them in a separate tab to see full scale.\n\nThese data types are defined in `polkadot/primitives/src/v1.rs`:\n\n```dot process\ndigraph {\n    rankdir = LR;\n    node [shape = plain]\n\n    CandidateDescriptor [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">CandidateDescriptor&lt;H = Hash&gt;</td></tr>\n            <tr><td>para_id</td><td port=\"para_id\">Id</td></tr>\n            <tr><td>relay_parent</td><td port=\"relay_parent\">H</td></tr>\n            <tr><td>collator</td><td port=\"collator\">CollatorId</td></tr>\n            <tr><td>persisted_validation_data_hash</td><td port=\"persisted_validation_data_hash\">Hash</td></tr>\n            <tr><td>pov_hash</td><td port=\"pov_hash\">Hash</td></tr>\n            <tr><td>erasure_root</td><td port=\"erasure_root\">Hash</td></tr>\n            <tr><td>signature</td><td port=\"signature\">CollatorSignature</td></tr>\n        </table>\n    >]\n\n    CandidateDescriptor:para_id -> Id:w\n    CandidateDescriptor:pov_hash -> PoVHash\n    CandidateDescriptor:collator -> CollatorId:w\n    CandidateDescriptor:persisted_validation_data_hash -> PersistedValidationDataHash\n\n    Id [label=\"polkadot_parachain_primitives::primitives::Id\"]\n    CollatorId [label=\"polkadot_primitives::v2::CollatorId\"]\n\n    PoVHash [label = \"Hash\", shape=\"doublecircle\", fill=\"gray90\"]\n\n    PoVHash -> PoV:name\n\n    CandidateReceipt [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">CandidateReceipt&lt;H = Hash&gt;</td></tr>\n            <tr><td>descriptor</td><td port=\"descriptor\">CandidateDescriptor&lt;H&gt;</td></tr>\n            <tr><td>commitments_hash</td><td port=\"commitments_hash\">Hash</td></tr>\n        </table>\n    >]\n\n    CandidateReceipt:descriptor -> CandidateDescriptor:name\n    CandidateReceipt:commitments_hash -> CandidateCommitmentsHash\n\n    CandidateHash [label = \"Hash\", shape=\"doublecircle\", fill=\"gray90\"]\n    CandidateHash -> CandidateReceipt:name\n\n    CandidateCommitmentsHash [label = \"Hash\", shape=\"doublecircle\", fill=\"gray90\"]\n    CandidateCommitmentsHash -> CandidateCommitments:name\n\n    CommittedCandidateReceipt [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">CommittedCandidateReceipt&lt;H = Hash&gt;</td></tr>\n            <tr><td>descriptor</td><td port=\"descriptor\">CandidateDescriptor&lt;H&gt;</td></tr>\n            <tr><td>commitments</td><td port=\"commitments\">CandidateCommitments</td></tr>\n        </table>\n    >]\n\n    CommittedCandidateReceipt:descriptor -> CandidateDescriptor:name\n    CommittedCandidateReceipt:commitments -> CandidateCommitments:name\n\n    ValidationData [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">ValidationData&lt;N = BlockNumber&gt;</td></tr>\n            <tr><td>persisted</td><td port=\"persisted\">PersistedValidationData&lt;N&gt;</td></tr>\n            <tr><td>transient</td><td port=\"transient\">TransientValidationData&lt;N&gt;</td></tr>\n        </table>\n    >]\n\n    ValidationData:persisted -> PersistedValidationData:name\n    ValidationData:transient -> TransientValidationData:name\n\n    PersistedValidationData [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">PersistedValidationData&lt;N = BlockNumber&gt;</td></tr>\n            <tr><td>parent_head</td><td port=\"parent_head\">HeadData</td></tr>\n            <tr><td>block_number</td><td port=\"block_number\">N</td></tr>\n            <tr><td>relay_parent_storage_root</td><td port=\"relay_parent_storage_root\">Hash</td></tr>\n            <tr><td>max_pov_size</td><td port=\"max_pov_size\">u32</td></tr>\n        </table>\n    >]\n\n    PersistedValidationData:parent_head -> HeadData:w\n\n    PersistedValidationDataHash [label = \"Hash\", shape=\"doublecircle\", fill=\"gray90\"]\n    PersistedValidationDataHash -> PersistedValidationData:name\n\n    TransientValidationData [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">TransientValidationData&lt;N = BlockNumber&gt;</td></tr>\n            <tr><td>max_code_size</td><td port=\"max_code_size\">u32</td></tr>\n            <tr><td>max_head_data_size</td><td port=\"max_head_data_size\">u32</td></tr>\n            <tr><td>balance</td><td port=\"balance\">Balance</td></tr>\n            <tr><td>code_upgrade_allowed</td><td port=\"code_upgrade_allowed\">Option&lt;N&gt;</td></tr>\n            <tr><td>dmq_length</td><td port=\"dmq_length\">u32</td></tr>\n        </table>\n    >]\n\n    TransientValidationData:balance -> \"polkadot_core_primitives::v2::Balance\":w\n\n    CandidateCommitments [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">CandidateCommitments&lt;N = BlockNumber&gt;</td></tr>\n            <tr><td>upward_messages</td><td port=\"upward_messages\">Vec&lt;UpwardMessage&gt;</td></tr>\n            <tr><td>horizontal_messages</td><td port=\"horizontal_messages\">Vec&lt;OutboundHrmpMessage&lt;Id&gt;&gt;</td></tr>\n            <tr><td>new_validation_code</td><td port=\"new_validation_code\">Option&lt;ValidationCode&gt;</td></tr>\n            <tr><td>head_data</td><td port=\"head_data\">HeadData</td></tr>\n            <tr><td>processed_downward_messages</td><td port=\"processed_downward_messages\">u32</td></tr>\n            <tr><td>hrmp_watermark</td><td port=\"hrmp_watermark\">N</td></tr>\n        </table>\n    >]\n\n    CandidateCommitments:upward_messages -> \"polkadot_parachain_primitives::primitives::UpwardMessage\":w\n    CandidateCommitments:horizontal_messages -> \"polkadot_core_primitives::v2::OutboundHrmpMessage\":w\n    CandidateCommitments:head_data -> HeadData:w\n    CandidateCommitments:horizontal_messages -> \"polkadot_parachain_primitives::primitives::Id\":w\n    CandidateCommitments:new_validation_code -> \"polkadot_parachain_primitives::primitives::ValidationCode\":w\n\n    PoV [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">PoV</td></tr>\n            <tr><td>block_data</td><td port=\"block_data\">BlockData</td></tr>\n        </table>\n    >]\n\n    PoV:block_data -> \"polkadot_parachain_primitives::primitives::BlockData\":w\n\n    BackedCandidate [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">BackedCandidate&lt;H = Hash&gt;</td></tr>\n            <tr><td>candidate</td><td port=\"candidate\">CommittedCandidateReceipt&lt;H&gt;</td></tr>\n            <tr><td>validity_votes</td><td port=\"validity_votes\">Vec&lt;ValidityAttestation&gt;</td></tr>\n            <tr><td>validator_indices</td><td port=\"validator_indices\">BitVec</td></tr>\n        </table>\n    >]\n\n    BackedCandidate:candidate -> CommittedCandidateReceipt:name\n    BackedCandidate:validity_votes  -> \"polkadot_primitives:v0:ValidityAttestation\":w\n\n    HeadData [label = \"polkadot_parachain_primitives::primitives::HeadData\"]\n\n    CoreIndex [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">CoreIndex</td></tr>\n            <tr><td>0</td><td port=\"0\">u32</td></tr>\n        </table>\n    >]\n\n    GroupIndex [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">GroupIndex</td></tr>\n            <tr><td>0</td><td port=\"0\">u32</td></tr>\n        </table>\n    >]\n\n    ParathreadClaim [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">ParathreadClaim</td></tr>\n            <tr><td>0</td><td port=\"0\">Id</td></tr>\n            <tr><td>1</td><td port=\"1\">CollatorId</td></tr>\n        </table>\n    >]\n\n    ParathreadClaim:0 -> Id:w\n    ParathreadClaim:1 -> CollatorId:w\n\n    MessageQueueChainLink [label = \"(prev_head, B, H(M))\\nSee doc of AbridgedHrmpChannel::mqc_head\"]\n    MQCHash [label = \"Hash\", shape=\"doublecircle\", fill=\"gray90\"]\n\n    MQCHash -> MessageQueueChainLink\n\n    ParathreadEntry [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">ParathreadEntry</td></tr>\n            <tr><td>claim</td><td port=\"claim\">ParathreadClaim</td></tr>\n            <tr><td>retries</td><td port=\"retries\">u32</td></tr>\n        </table>\n    >]\n\n    ParathreadEntry:claim -> ParathreadClaim:name\n\n    CoreOccupied [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\"><i>enum</i> CoreOccupied</td></tr>\n            <tr><td></td><td port=\"parathread\">Parathread(ParathreadEntry)</td></tr>\n            <tr><td></td><td port=\"parachain\">Parachain</td></tr>\n        </table>\n    >]\n\n    CoreOccupied:parathread -> ParathreadEntry:name\n\n    AvailableData [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">AvailableData</td></tr>\n            <tr><td>pov</td><td port=\"pov\">Arc&lt;PoV&gt;</td></tr>\n            <tr><td>validation_data</td><td port=\"validation_data\">PersistedValidationData</td></tr>\n        </table>\n    >]\n\n    AvailableData:pov -> PoV:name\n    AvailableData:validation_data -> PersistedValidationData:name\n\n    GroupRotationInfo [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">GroupRotationInfo&lt;N = BlockNumber&gt;</td></tr>\n            <tr><td>session_start_block</td><td port=\"session_start_block\">N</td></tr>\n            <tr><td>group_rotation_frequency</td><td port=\"group_rotation_frequency\">N</td></tr>\n            <tr><td>now</td><td port=\"now\">N</td></tr>\n        </table>\n    >]\n\n    OccupiedCore [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">OccupiedCore&lt;H = Hash, N = BlockNumber&gt;</td></tr>\n            <tr><td>next_up_on_available</td><td port=\"next_up_on_available\">Option&lt;ScheduledCore&gt;</td></tr>\n            <tr><td>occupied_since</td><td port=\"occupied_since\">N</td></tr>\n            <tr><td>time_out_at</td><td port=\"time_out_at\">N</td></tr>\n            <tr><td>next_up_on_time_out</td><td port=\"next_up_on_time_out\">Option&lt;ScheduledCore&gt;</td></tr>\n            <tr><td>availability</td><td port=\"availability\">BitVec</td></tr>\n            <tr><td>group_responsible</td><td port=\"group_responsible\">GroupIndex</td></tr>\n            <tr><td>candidate_hash</td><td port=\"candidate_hash\">CandidateHash</td></tr>\n            <tr><td>candidate_descriptor</td><td port=\"candidate_descriptor\">CandidateDescriptor</td></tr>\n        </table>\n    >]\n\n    OccupiedCore:next_up_on_available -> ScheduledCore:name\n    OccupiedCore:next_up_on_time_out -> ScheduledCore:name\n    OccupiedCore:group_responsible -> GroupIndex\n    OccupiedCore:candidate_hash -> CandidateHash\n    OccupiedCore:candidate_descriptor -> CandidateDescriptor:name\n\n    ScheduledCore [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">ScheduledCore</td></tr>\n            <tr><td>para_id</td><td port=\"para_id\">Id</td></tr>\n            <tr><td>collator</td><td port=\"collator\">Option&lt;CollatorId&gt;</td></tr>\n        </table>\n    >]\n\n    ScheduledCore:para_id -> Id:w\n    ScheduledCore:collator -> CollatorId:w\n\n    CoreState [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\"><i>enum</i> CoreState&lt;H = Hash, N = BlockNumber&gt;</td></tr>\n            <tr><td></td><td port=\"occupied\">Occupied(OccupiedCore&lt;H, N&gt;)</td></tr>\n            <tr><td></td><td port=\"scheduled\">Scheduled(ScheduledCore)</td></tr>\n            <tr><td></td><td port=\"free\">Free</td></tr>\n        </table>\n    >]\n\n    CoreState:occupied -> OccupiedCore:name\n    CoreState:scheduled -> ScheduledCore:name\n\n    CandidateEvent [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\"><i>enum</i> CandidateEvent&lt;H = Hash&gt;</td></tr>\n            <tr><td></td><td port=\"CandidateBacked\">CandidateBacked(CandidateReceipt&lt;H&gt;, HeadData)</td></tr>\n            <tr><td></td><td port=\"CandidateIncluded\">CandidateIncluded(CandidateReceipt&lt;H&gt;, HeadData)</td></tr>\n            <tr><td></td><td port=\"CandidateTimedOut\">CandidateTimedOut(CandidateReceipt&lt;H&gt;, HeadData)</td></tr>\n        </table>\n    >]\n\n    CandidateEvent:e -> CandidateReceipt:name\n    CandidateEvent:e -> HeadData:w\n\n    SessionInfo [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">SessionInfo</td></tr>\n            <tr><td>validators</td><td port=\"validators\">Vec&lt;ValidatorId&gt;</td></tr>\n            <tr><td>discovery_keys</td><td port=\"discovery_keys\">Vec&lt;AuthorityDiscoveryId&gt;</td></tr>\n            <tr><td>assignment_keys</td><td port=\"assignment_keys\">Vec&lt;AssignmentId&gt;</td></tr>\n            <tr><td>validator_groups</td><td port=\"validator_groups\">Vec&lt;Vec&lt;ValidatorIndex&gt;&gt;</td></tr>\n            <tr><td>n_cores</td><td port=\"n_cores\">u32</td></tr>\n            <tr><td>zeroth_delay_tranche_width</td><td port=\"zeroth_delay_tranch_width\">u32</td></tr>\n            <tr><td>relay_vrf_modulo_samples</td><td port=\"relay_vrf_modulo_samples\">u32</td></tr>\n            <tr><td>n_delay_tranches</td><td port=\"n_delay_tranches\">u32</td></tr>\n            <tr><td>no_show_slots</td><td port=\"no_show_slots\">u32</td></tr>\n            <tr><td>needed_approvals</td><td port=\"needed_approvals\">u32</td></tr>\n        </table>\n    >]\n\n    SessionInfo:validators -> ValidatorId:w\n    SessionInfo:discovery_keys -> AuthorityDiscoveryId:w\n    SessionInfo:validator_groups -> ValidatorIndex:w\n\n    ValidatorId [label = \"polkadot_primitives::v2::ValidatorId\"]\n    AuthorityDiscoveryId [label = \"sp_authority_discovery::AuthorityId\"]\n    ValidatorIndex [label = \"polkadot_primitives::v2::ValidatorIndex\"]\n\n    AbridgedHostConfiguration [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">AbridgedHostConfiguration</td></tr>\n            <tr><td>max_code_size</td><td port=\"max_code_size\">u32</td></tr>\n            <tr><td>max_head_data_size</td><td port=\"max_head_data_size\">u32</td></tr>\n            <tr><td>max_upward_queue_count</td><td port=\"max_upward_queue_count\">u32</td></tr>\n            <tr><td>max_upward_queue_size</td><td port=\"max_upward_queue_size\">u32</td></tr>\n            <tr><td>max_upward_message_size</td><td port=\"max_upward_message_size\">u32</td></tr>\n            <tr><td>max_upward_messages_num_per_candidate</td><td port=\"max_upward_messages_num_per_candidate\">u32</td></tr>\n            <tr><td>hrmp_max_message_num_per_candidate</td><td port=\"hrmp_max_message_num_per_candidate\">u32</td></tr>\n            <tr><td>validation_upgrade_cooldown</td><td port=\"validation_upgrade_cooldown\">BlockNumber</td></tr>\n            <tr><td>validation_upgrade_delay</td><td port=\"validation_upgrade_delay\">BlockNumber</td></tr>\n        </table>\n    >]\n\n    AbridgedHrmpChannel [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">AbridgedHrmpChannel</td></tr>\n            <tr><td>max_capacity</td><td port=\"max_capacity\">u32</td></tr>\n            <tr><td>max_total_size</td><td port=\"max_total_size\">u32</td></tr>\n            <tr><td>max_message_size</td><td port=\"max_message_size\">u32</td></tr>\n            <tr><td>msg_count</td><td port=\"msg_count\">u32</td></tr>\n            <tr><td>total_size</td><td port=\"total_size\">u32</td></tr>\n            <tr><td>mqc_head</td><td port=\"mqc_head\">Option&lt;Hash&gt;</td></tr>\n        </table>\n    >]\n\n    AbridgedHrmpChannel:mqc_head -> MQCHash\n}\n\nThese data types are defined in `polkadot/parachain/src/primitives.rs`:\ndot process\ndigraph {\n    rankdir = LR;\n    node [shape = plain]\n\n    HeadData [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">HeadData</td></tr>\n            <tr><td>0</td><td port=\"0\">Vec&lt;u8&gt;</td></tr>\n        </table>\n    >]\n\n    ValidationCode [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">ValidationCode</td></tr>\n            <tr><td>0</td><td port=\"0\">Vec&lt;u8&gt;</td></tr>\n        </table>\n    >]\n\n    BlockData [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">BlockData</td></tr>\n            <tr><td>0</td><td port=\"0\">Vec&lt;u8&gt;</td></tr>\n        </table>\n    >]\n\n    Id [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">Id</td></tr>\n            <tr><td>0</td><td port=\"0\">u32</td></tr>\n        </table>\n    >]\n\n    Sibling [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">Sibling</td></tr>\n            <tr><td>0</td><td port=\"0\">Id</td></tr>\n        </table>\n    >]\n\n    Sibling:0 -> Id:name\n\n    HrmpChannelId [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">HrmpChannelId</td></tr>\n            <tr><td>sender</td><td port=\"sender\">Id</td></tr>\n            <tr><td>recipient</td><td port=\"recipient\">Id</td></tr>\n        </table>\n    >]\n\n    HrmpChannelId:e -> Id:name\n\n    ValidationParams [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">ValidationParams</td></tr>\n            <tr><td>parent_head</td><td port=\"parent_head\">HeadData</td></tr>\n            <tr><td>block_data</td><td port=\"block_data\">BlockData</td></tr>\n            <tr><td>relay_parent_number</td><td port=\"relay_parent_number\">RelayChainBlockNumber</td></tr>\n            <tr><td>relay_parent_storage_root</td><td port=\"relay_parent_storage_root\">Hash</td></tr>\n        </table>\n    >]\n\n    ValidationParams:parent_head -> HeadData:name\n    ValidationParams:block_data -> BlockData:name\n    ValidationParams:relay_parent_number -> RelayChainBlockNumber:w\n\n    RelayChainBlockNumber [label = \"polkadot_core_primitives::BlockNumber\"]\n\n    ValidationResult [label = <\n        <table>\n            <tr><td border=\"0\" colspan=\"2\" port=\"name\">ValidationResult</td></tr>\n            <tr><td>head_data</td><td port=\"head_data\">HeadData</td></tr>\n            <tr><td>new_validation_code</td><td port=\"new_validation_code\">Option&lt;ValidationCode&gt;</td></tr>\n            <tr><td>upward_messages</td><td port=\"upward_messages\">Vec&lt;UpwardMessage&gt;</td></tr>\n            <tr><td>horizontal_messages</td><td port=\"horizontal_messages\">Vec&lt;OutboundHrmpMessage&lt;Id&gt;&gt;</td></tr>\n            <tr><td>processed_downward_messages</td><td port=\"processed_downward_messages\">u32</td></tr>\n            <tr><td>hrmp_watermark</td><td port=\"hrmp_watermark\">RelayChainBlockNumber</td></tr>\n        </table>\n    >]\n\n    ValidationResult:head_data -> HeadData:name\n    ValidationResult:new_validation_code -> ValidationCode:name\n    ValidationResult:upward_messages -> UpwardMessage:w\n    ValidationResult:horizontal_messages -> OutboundHrmpMessage:w\n    ValidationResult:horizontal_messages -> Id:name\n    ValidationResult:hrmp_watermark -> RelayChainBlockNumber:w\n\n    UpwardMessage [label = \"Vec<u8>\"]\n    OutboundHrmpMessage [label = \"polkadot_core_primitives::OutboundHrmpMessage\"]\n}\n```"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain host configuration\ninput: "
      },
      {
        "role": "assistant",
        "content": "The internal-to-runtime configuration of the parachain host is kept in `struct HostConfiguration`. This is expected to\nbe altered only by governance procedures or via migrations from the Polkadot-SDK codebase. The latest definition of\n`HostConfiguration` can be found in the project repo\nhere. Each\nparameter has got a doc comment so for any details please refer to the code.\n\nSome related parameters in `HostConfiguration` are grouped together so that they can be managed easily. These are:\n* `async_backing_params` in `struct AsyncBackingParams`\n* `executor_params` in `struct ExecutorParams`\n* `approval_voting_params` in `struct ApprovalVotingParams`\n* `scheduler_params` in `struct SchedulerParams`\n\nCheck the definitions of these structs for further details."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain utility structs\ninput: "
      },
      {
        "role": "assistant",
        "content": "// the two key times necessary to track for every code replacement.\npub struct ReplacementTimes {\n /// The relay-chain block number that the code upgrade was expected to be activated.\n /// This is when the code change occurs from the para's perspective - after the\n /// first parablock included with a relay-parent with number >= this value.\n expected_at: BlockNumber,\n /// The relay-chain block number at which the parablock activating the code upgrade was\n /// actually included. This means considered included and available, so this is the time at which\n /// that parablock enters the acceptance period in this fork of the relay-chain.\n activated_at: BlockNumber,\n}\n\n/// Metadata used to track previous parachain validation code that we keep in\n/// the state.\npub struct ParaPastCodeMeta {\n // Block numbers where the code was expected to be replaced and where the code\n // was actually replaced, respectively. The first is used to do accurate lookups\n // of historic code in historic contexts, whereas the second is used to do\n // pruning on an accurate timeframe. These can be used as indices\n // into the `PastCode` map along with the `ParaId` to fetch the code itself.\n upgrade_times: Vec<ReplacementTimes>,\n // This tracks the highest pruned code-replacement, if any.\n last_pruned: Option<BlockNumber>,\n}\n\nstruct ParaGenesisArgs {\n  /// The initial head-data to use.\n  genesis_head: HeadData,\n  /// The validation code to start with.\n  validation_code: ValidationCode,\n  /// True if parachain, false if parathread.\n  parachain: bool,\n}\n\n/// The possible states of a para, to take into account delayed lifecycle changes.\npub enum ParaLifecycle {\n  /// A Para is new and is onboarding.\n  Onboarding,\n  /// Para is a Parathread (on-demand parachain).\n  Parathread,\n  /// Para is a lease holding Parachain.\n  Parachain,\n  /// Para is a Parathread (on-demand Parachain) which is upgrading to a lease holding Parachain.\n  UpgradingParathread,\n  /// Para is a lease holding Parachain which is downgrading to an on-demand parachain.\n  DowngradingParachain,\n  /// Parathread (on-demand parachain) is being offboarded.\n  OutgoingParathread,\n  /// Parachain is being offboarded.\n  OutgoingParachain,\n}\n\nenum PvfCheckCause {\n  /// PVF vote was initiated by the initial onboarding process of the given para.\n  Onboarding(ParaId),\n  /// PVF vote was initiated by signalling of an upgrade by the given para.\n  Upgrade {\n    /// The ID of the parachain that initiated or is waiting for the conclusion of pre-checking.\n    id: ParaId,\n    /// The relay-chain block number that was used as the relay-parent for the parablock that\n    /// initiated the upgrade.\n    relay_parent_number: BlockNumber,\n  },\n}\n\nstruct PvfCheckActiveVoteState {\n  // The two following vectors have their length equal to the number of validators in the active\n  // set. They start with all zeroes. A 1 is set at an index when the validator at the that index\n  // makes a vote. Once a 1 is set for either of the vectors, that validator cannot vote anymore.\n  // Since the active validator set changes each session, the bit vectors are reinitialized as\n  // well: zeroed and resized so that each validator gets its own bit.\n  votes_accept: BitVec,\n  votes_reject: BitVec,\n\n  /// The number of session changes this PVF vote has observed. Therefore, this number is\n  /// increased at each session boundary. When created, it is initialized with 0.\n  age: SessionIndex,\n  /// The block number at which this PVF vote was created.\n  created_at: BlockNumber,\n  /// A list of causes for this PVF pre-checking. Has at least one.\n  causes: Vec<PvfCheckCause>,\n}\n\n### Para Lifecycle\n\nBecause the state changes of parachains are delayed, we track the specific state of the para using the `ParaLifecycle`\nenum.\n\nNone         Parathread (on-demand parachain)    Parachain\n +                        +                          +\n |                        |                          |\n |   (\u22482 Session Delay)   |                          |\n |                        |                          |\n +----------------------->+                          |\n |       Onboarding       |                          |\n |                        |                          |\n +-------------------------------------------------->+\n |       Onboarding       |                          |\n |                        |                          |\n |                        +------------------------->+\n |                        |   UpgradingParathread    |\n |                        |                          |\n |                        +<-------------------------+\n |                        |   DowngradingParachain   |\n |                        |                          |\n |<-----------------------+                          |\n |   OutgoingParathread   |                          |\n |                        |                          |\n +<--------------------------------------------------+\n |                        |    OutgoingParachain     |\n |                        |                          |\n +                        +                          +\n\nNote that if PVF pre-checking is enabled, onboarding of a para may potentially be delayed. This can happen due to PVF\npre-checking voting concluding late.\n\nDuring the transition period, the para object is still considered in its existing state."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain routines\ninput: "
      },
      {
        "role": "assistant",
        "content": "All failed checks should lead to an unrecoverable error making the block invalid.\n\n* `process_bitfields(expected_bits, Bitfields, core_lookup: Fn(CoreIndex) -> Option<ParaId>)`:\n  1. Call `sanitize_bitfields<true>` and use the sanitized `signed_bitfields` from now on.\n  1. Call `sanitize_backed_candidates<true>` and use the sanitized `backed_candidates` from now on.\n  1. Apply each bit of bitfield to the corresponding pending candidate, looking up on-demand parachain cores using the\n     `core_lookup`. Disregard bitfields that have a `1` bit for any free cores.\n  1. For each applied bit of each availability-bitfield, set the bit for the validator in the\n     `CandidatePendingAvailability`'s `availability_votes` bitfield. Track all candidates that now have >2/3 of bits set\n     in their `availability_votes`. These candidates are now available and can be enacted.\n  1. For all now-available candidates, invoke the `enact_candidate` routine with the candidate and relay-parent number.\n  1. Return a list of `(CoreIndex, CandidateHash)` from freed cores consisting of the cores where candidates have become\n     available.\n* `sanitize_bitfields<T: crate::inclusion::Config>( unchecked_bitfields: UncheckedSignedAvailabilityBitfields,\n    disputed_bitfield: DisputedBitfield, expected_bits: usize, parent_hash: T::Hash, session_index: SessionIndex,\n    validators: &[ValidatorId], full_check: FullCheck, )`:\n  1. check that `disputed_bitfield` has the same number of bits as the `expected_bits`, iff not return early with an\n     empty vec.\n  1. each of the below checks is for each bitfield. If a check does not pass the bitfield will be skipped.\n  1. check that there are no bits set that reference a disputed candidate.\n  1. check that the number of bits is equal to `expected_bits`.\n  1. check that the validator index is strictly increasing (and thus also unique).\n  1. check that the validator bit index is not out of bounds.\n  1. check the validators signature, iff `full_check=FullCheck::Yes`.\n\n* `sanitize_backed_candidates<T: crate::inclusion::Config, F: FnMut(usize, &BackedCandidate<T::Hash>) -> bool>( mut\n  backed_candidates: Vec<BackedCandidate<T::Hash>>, candidate_has_concluded_invalid_dispute: F, scheduled:\n  &[CoreAssignment], )`\n  1. filter out any backed candidates that have concluded invalid.\n  1. filters backed candidates whom's paraid was scheduled by means of the provided `scheduled` parameter.\n  1. sorts remaining candidates with respect to the core index assigned to them.\n\n* `process_candidates(allowed_relay_parents, BackedCandidates, scheduled: Vec<CoreAssignment>, group_validators:\n  Fn(GroupIndex) -> Option<Vec<ValidatorIndex>>)`:\n    > For details on `AllowedRelayParentsTracker` see documentation for Shared module.\n  1. check that each candidate corresponds to a scheduled core and that they are ordered in the same order the cores\n     appear in assignments in `scheduled`.\n  1. check that `scheduled` is sorted ascending by `CoreIndex`, without duplicates.\n  1. check that the relay-parent from each candidate receipt is one of the allowed relay-parents.\n  1. check that there is no candidate pending availability for any scheduled `ParaId`.\n  1. check that each candidate's `validation_data_hash` corresponds to a `PersistedValidationData` computed from the\n     state of the context block.\n  1. If the core assignment includes a specific collator, ensure the backed candidate is issued by that collator.\n  1. Ensure that any code upgrade scheduled by the candidate does not happen within `config.validation_upgrade_cooldown`\n     of `Paras::last_code_upgrade(para_id, true)`, if any, comparing against the value of `Paras::FutureCodeUpgrades`\n     for the given para ID.\n  1. Check the collator's signature on the candidate data (only if `CandidateDescriptor` is version 1)\n  1. check the backing of the candidate using the signatures and the bitfields, comparing against the validators\n     assigned to the groups, fetched with the `group_validators` lookup, while group indices are computed by `Scheduler`\n     according to group rotation info.\n  1. call `check_upward_messages(config, para, commitments.upward_messages)` to check that the upward messages are\n     valid.\n  1. call `Dmp::check_processed_downward_messages(para, commitments.processed_downward_messages)` to check that the DMQ\n     is properly drained.\n  1. call `Hrmp::check_hrmp_watermark(para, commitments.hrmp_watermark)` for each candidate to check rules of processing\n     the HRMP watermark.\n  1. using `Hrmp::check_outbound_hrmp(sender, commitments.horizontal_messages)` ensure that the each candidate sent a\n     valid set of horizontal messages\n  1. create an entry in the `PendingAvailability` map for each backed candidate with a blank `availability_votes`\n     bitfield.\n  1. create a corresponding entry in the `PendingAvailabilityCommitments` with the commitments.\n  1. Return a `Vec<CoreIndex>` of all scheduled cores of the list of passed assignments that a candidate was\n     successfully backed for, sorted ascending by CoreIndex.\n* `enact_candidate(relay_parent_number: BlockNumber, CommittedCandidateReceipt)`:\n  1. If the receipt contains a code upgrade, Call `Paras::schedule_code_upgrade(para_id, code, relay_parent_number,\n     config)`.\n    > TODO: Note that this is safe as long as we never enact candidates where the relay parent is across a session\n    > boundary. In that case, which we should be careful to avoid with contextual execution, the configuration might\n    > have changed and the para may de-sync from the host's understanding of it.\n  1. Reward all backing validators of each candidate, contained within the `backers` field.\n  1. call `receive_upward_messages` for each backed candidate, using the\n     `UpwardMessage`s from the\n     `CandidateCommitments`.\n  1. call `Dmp::prune_dmq` with the para id of the candidate and the candidate's `processed_downward_messages`.\n  1. call `Hrmp::prune_hrmp` with the para id of the candidate and the candidate's `hrmp_watermark`.\n  1. call `Hrmp::queue_outbound_hrmp` with the para id of the candidate and the list of horizontal messages taken from\n     the commitment,\n  1. Call `Paras::note_new_head` using the `HeadData` from the receipt and `relay_parent_number`.\n\n* `collect_pending`:\n\n  ```rust\n    fn collect_pending(f: impl Fn(CoreIndex, BlockNumber) -> bool) -> Vec<CoreIndex> {\n      // sweep through all paras pending availability. if the predicate returns true, when given the core index and\n      // the block number the candidate has been pending availability since, then clean up the corresponding storage for that candidate and the commitments.\n      // return a vector of cleaned-up core IDs.\n    }\n  ```\n* `force_enact(ParaId)`: Forcibly enact the pending candidates of the given paraid as though they had been deemed\n  available by bitfields. Is a no-op if there is no candidate pending availability for this para-id.\n  If there are multiple candidates pending availability for this para-id, it will enact all of\n  them. This should generally not be used but it is useful during execution of Runtime APIs,\n  where the changes to the state are expected to be discarded directly after.\n* `candidate_pending_availability(ParaId) -> Option<CommittedCandidateReceipt>`: returns the `CommittedCandidateReceipt`\n  pending availability for the para provided, if any.\n* `candidates_pending_availability(ParaId) -> Vec<CommittedCandidateReceipt>`: returns the `CommittedCandidateReceipt`s\n  pending availability for the para provided, if any.\n* `pending_availability(ParaId) -> Option<CandidatePendingAvailability>`: returns the metadata around the candidate\n  pending availability for the para, if any.\n* `free_disputed(disputed: Vec<CandidateHash>) -> Vec<CoreIndex>`: Sweeps through all paras pending availability. If\n  the candidate hash is one of the disputed candidates, then clean up the corresponding storage for that candidate and\n  the commitments. Return a vector of cleaned-up core IDs.\n\nThese functions were formerly part of the UMP pallet:\n\n* `check_upward_messages(P: ParaId, Vec<UpwardMessage>)`:\n    1. Checks that the parachain is not currently offboarding and error otherwise.\n    2. Checks that there are at most `config.max_upward_message_num_per_candidate` messages to be enqueued.\n    3. Checks that no message exceeds `config.max_upward_message_size`.\n    4. Checks that the total resulting queue size would not exceed `co`.\n    5. Verify that queuing up the messages could not result in exceeding the queue's footprint according to the config\n    items `config.max_upward_queue_count` and `config.max_upward_queue_size`. The queue's current footprint is provided\n    in `well_known_keys` in order to facilitate oraclisation on to the para.\n\nCandidate Enactment:\n\n* `receive_upward_messages(P: ParaId, Vec<UpwardMessage>)`:\n    1. Process each upward message `M` in order:\n        1. Place in the dispatch queue according to its para ID (or handle it immediately)."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain availability cores\ninput: "
      },
      {
        "role": "assistant",
        "content": "The Scheduler manages resource allocation using the concept of \"Availability Cores\". There will be one availability core\nfor each lease holding parachain, and a fixed number of cores used for multiplexing on-demand parachains. Validators\nwill be partitioned into groups, with the same number of groups as availability cores. Validator groups will be assigned\nto different availability cores over time.\n\nAn availability core can exist in either one of two states at the beginning or end of a block: free or occupied. A free\navailability core can have a lease holding or on-demand parachain assigned to it for the potential to have a backed\ncandidate included. After backing, the core enters the occupied state as the backed candidate is pending availability.\nThere is an important distinction: a core is not considered occupied until it is in charge of a block pending\navailability, although the implementation may treat scheduled cores the same as occupied ones for brevity. A core exits\nthe occupied state when the candidate is no longer pending availability - either on timeout or on availability. A core\nstarting in the occupied state can move to the free state and back to occupied all within a single block, as\navailability bitfields are processed before backed candidates. At the end of the block, there is a possible timeout on\navailability which can move the core back to the free state if occupied.\n\nCores are treated as an ordered list and are typically referred to by their index in that list.\n\n```dot process\ndigraph {\n  label = \"Availability Core State Machine\\n\\n\\n\";\n  labelloc = \"t\";\n\n  { rank=same vg1 vg2 }\n\n  vg1 [label = \"Free\" shape=rectangle]\n  vg2 [label = \"Occupied\" shape=rectangle]\n\n  vg1 -> vg2 [label = \"Assignment & Backing\" ]\n  vg2 -> vg1 [label = \"Availability or Timeout\" ]\n}\ndot process\ndigraph {\n  label = \"Availability Core Transitions within Block\\n\\n\\n\";\n  labelloc = \"t\";\n  splines=\"line\";\n\n  subgraph cluster_left {\n    label = \"\";\n    labelloc = \"t\";\n\n    fr1 [label = \"Free\" shape=rectangle]\n    fr2 [label = \"Free\" shape=rectangle]\n    occ [label = \"Occupied\" shape=rectangle]\n\n    fr1 -> fr2 [label = \"No Backing\"]\n    fr1 -> occ [label = \"Backing\"]\n\n    { rank=same fr2 occ }\n  }\n\n  subgraph cluster_right {\n    label = \"\";\n    labelloc = \"t\";\n\n    occ2 [label = \"Occupied\" shape=rectangle]\n    fr3 [label = \"Free\" shape=rectangle]\n    fr4 [label = \"Free\" shape=rectangle]\n    occ3 [label = \"Occupied\" shape=rectangle]\n    occ4 [label = \"Occupied\" shape=rectangle]\n\n    occ2 -> fr3 [label = \"Availability\"]\n    occ2 -> occ3 [label = \"No availability\"]\n    fr3 -> fr4 [label = \"No backing\"]\n    fr3 -> occ4 [label = \"Backing\"]\n    occ3 -> occ4 [label = \"(no change)\"]\n    occ3 -> fr3 [label = \"Availability Timeout\"]\n\n    { rank=same; fr3[group=g1]; occ3[group=g2] }\n    { rank=same; fr4[group=g1]; occ4[group=g2] }\n  }\n}\n```"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain routines\ninput: "
      },
      {
        "role": "assistant",
        "content": "- `add_parathread_claim(ParathreadClaim)`: Add a parathread (on-demand parachain) claim to the queue.\n  - Fails if any on-demand claim on the same parachain is currently indexed.\n  - Fails if the queue length is >= `config.scheduling_lookahead * config.parathread_cores`.\n  - The core used for the on-demand claim is the `next_core` field of the `ParathreadQueue` (on-demand queue) and adding\n    `paras::Parachains::<T>::get().len()` to it.\n  - `next_core` is then updated by adding 1 and taking it modulo `config.parathread_cores`.\n  - The claim is then added to the claim index.\n- `free_cores(Vec<(CoreIndex, FreedReason)>)`: indicate previously-occupied cores which are to be considered returned\n  and why they are being returned.\n  - All freed lease holding parachain cores should be assigned to their respective parachain\n  - All freed on-demand parachain cores whose reason for freeing was `FreedReason::Concluded` should have the claim\n    removed from the claim index.\n  - All freed on-demand cores whose reason for freeing was `FreedReason::TimedOut` should have the claim added to the\n    parathread queue (on-demand queue) again without retries incremented\n  - All freed on-demand cores should take the next on-demand parachain entry from the queue.\n- `schedule(Vec<(CoreIndex, FreedReason)>, now: BlockNumber)`: schedule new core assignments, with a parameter\n  indicating previously-occupied cores which are to be considered returned and why they are being returned.\n  - Invoke `free_cores(freed_cores)`\n  - The i'th validator group will be assigned to the `(i+k)%n`'th core at any point in time, where `k` is the number of\n    rotations that have occurred in the session, and `n` is the total number of cores. This makes upcoming rotations\n    within the same session predictable. Rotations are based off of `now`.\n- `scheduled() -> Vec<CoreAssignment>`: Get currently scheduled core assignments.\n- `occupied(Vec<CoreIndex>)`. Note that the given cores have become occupied.\n  - Behavior undefined if any given cores were not scheduled.\n  - Behavior undefined if the given cores are not sorted ascending by core index\n  - This clears them from `Scheduled` and marks each corresponding `core` in the `AvailabilityCores` as occupied.\n  - Since both the availability cores and the newly-occupied cores lists are sorted ascending, this method can be\n    implemented efficiently.\n- `group_validators(GroupIndex) -> Option<Vec<ValidatorIndex>>`: return all validators in a given group, if the group\n  index is valid for this session.\n- `availability_timeout_predicate() -> Option<impl Fn(CoreIndex, BlockNumber) -> bool>`: returns an optional predicate\n  that should be used for timing out occupied cores. if `None`, no timing-out should be done. The predicate accepts the\n  index of the core, and the block number since which it has been occupied. The predicate should be implemented based on\n  the time since the last validator group rotation, and the respective parachain timeouts, i.e. only within\n  `max(config.chain_availability_period, config.thread_availability_period)` of the last rotation would this return\n  `Some`.\n- `group_rotation_info(now: BlockNumber) -> GroupRotationInfo`: Returns a helper for determining group rotation.\n- `next_up_on_available(CoreIndex) -> Option<ScheduledCore>`: Return the next thing that will be scheduled on this core\n  assuming it is currently occupied and the candidate occupying it became available. Returns in `ScheduledCore` format\n  (todo: link to Runtime APIs page; linkcheck doesn't allow this right now). For lease holding parachains, this is\n  always the ID of the parachain and no specified collator. For on-demand parachains, this is based on the next item in\n  the `ParathreadQueue` (on-demand queue) assigned to that core, and is `None` if there isn't one.\n- `next_up_on_time_out(CoreIndex) -> Option<ScheduledCore>`: Return the next thing that will be scheduled on this core\n  assuming it is currently occupied and the candidate occupying it timed out. Returns in `ScheduledCore` format (todo:\n  link to Runtime APIs page; linkcheck doesn't allow this right now). For parachains, this is always the ID of the\n  parachain and no specified collator. For on-demand parachains, this is based on the next item in the `ParathreadQueue`\n  (on-demand queue) assigned to that core, or if there isn't one, the claim that is currently occupying the core.\n  Otherwise `None`.\n- `clear()`:\n  - Free all scheduled cores and return on-demand claims to queue, with retries incremented. Skip on-demand parachains\n    which no longer exist under paras."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain disputes filtering\ninput: "
      },
      {
        "role": "assistant",
        "content": "All disputes delivered to the runtime by the client are filtered before the actual import. In this context actual import\nmeans persisted in the runtime storage. The filtering has got two purposes:\n* Limit the amount of data saved onchain.\n* Prevent persisting malicious dispute data onchain.\n\n*Implementation note*: Filtering is performed in function `filter_dispute_data` from `Disputes` pallet.\n\nThe filtering is performed on the whole statement set which is about to be imported onchain. The following filters are\napplied:\n1. Remove ancient disputes - if a dispute is concluded before the block number indicated in `OLDEST_ACCEPTED` parameter\n   it is removed from the set. `OLDEST_ACCEPTED` is a runtime configuration option. *Implementation note*:\n   `dispute_post_conclusion_acceptance_period` from `HostConfiguration` is used in the current Polkadot/Kusama\n   implementation.\n2. Remove votes from unknown validators. If there is a vote from a validator which wasn't an authority in the session\n   where the dispute was raised - they are removed. Please note that this step removes only single votes instead of\n   removing the whole dispute.\n3. Remove one sided disputes - if a dispute doesn't contain two opposing votes it is not imported onchain. This serves\n   as a measure not to import one sided disputes. A dispute is raised only if there are two opposing votes so if the\n   client is not sending them the dispute is a potential spam.\n4. Remove unconfirmed disputes - if a dispute contains less votes than the byzantine threshold it is removed. This is\n   also a spam precaution. A legitimate client will send only confirmed disputes to the runtime."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain entry-points\ninput: "
      },
      {
        "role": "assistant",
        "content": "The following entry-points are meant to be used for HRMP channel management.\n\nThose entry-points are meant to be called from a parachain. `origin` is defined as the `ParaId` of the parachain\nexecuted the message.\n\n* `hrmp_init_open_channel(recipient, proposed_max_capacity, proposed_max_message_size)`:\n    1. Check that the `origin` is not `recipient`.\n    1. Check that `proposed_max_capacity` is less or equal to `config.hrmp_channel_max_capacity` and greater than zero.\n    1. Check that `proposed_max_message_size` is less or equal to `config.hrmp_channel_max_message_size` and greater\n       than zero.\n    1. Check that `recipient` is a valid para.\n    1. Check that there is no existing channel for `(origin, recipient)` in `HrmpChannels`.\n    1. Check that there is no existing open channel request (`origin`, `recipient`) in `HrmpOpenChannelRequests`.\n    1. Check that the sum of the number of already opened HRMP channels by the `origin` (the size of the set found\n    `HrmpEgressChannelsIndex` for `origin`) and the number of open requests by the `origin` (the value from\n    `HrmpOpenChannelRequestCount` for `origin`) doesn't exceed the limit of channels\n    (`config.hrmp_max_parachain_outbound_channels` or `config.hrmp_max_parathread_outbound_channels`) minus 1.\n    1. Check that `origin`'s balance is more or equal to `config.hrmp_sender_deposit`\n    1. Reserve the deposit for the `origin` according to `config.hrmp_sender_deposit`\n    1. Increase `HrmpOpenChannelRequestCount` by 1 for `origin`.\n    1. Append `(origin, recipient)` to `HrmpOpenChannelRequestsList`.\n    1. Add a new entry to `HrmpOpenChannelRequests` for `(origin, recipient)`\n        1. Set `sender_deposit` to `config.hrmp_sender_deposit`\n        1. Set `max_capacity` to `proposed_max_capacity`\n        1. Set `max_message_size` to `proposed_max_message_size`\n        1. Set `max_total_size` to `config.hrmp_channel_max_total_size`\n    1. Send a downward message to `recipient` notifying about an inbound HRMP channel request.\n        * The DM is sent using `queue_downward_message`.\n        * The DM is represented by the `HrmpNewChannelOpenRequest`  XCM message.\n            * `sender` is set to `origin`,\n            * `max_message_size` is set to `proposed_max_message_size`,\n            * `max_capacity` is set to `proposed_max_capacity`.\n* `hrmp_accept_open_channel(sender)`:\n    1. Check that there is an existing request between (`sender`, `origin`) in `HrmpOpenChannelRequests`\n        1. Check that it is not confirmed.\n    1. Check that the sum of the number of inbound HRMP channels opened to `origin` (the size of the set found in\n    `HrmpIngressChannelsIndex` for `origin`) and the number of accepted open requests by the `origin` (the value from\n    `HrmpAcceptedChannelRequestCount` for `origin`) doesn't exceed the limit of channels\n    (`config.hrmp_max_parachain_inbound_channels` or `config.hrmp_max_parathread_inbound_channels`) minus 1.\n    1. Check that `origin`'s balance is more or equal to `config.hrmp_recipient_deposit`.\n    1. Reserve the deposit for the `origin` according to `config.hrmp_recipient_deposit`\n    1. For the request in `HrmpOpenChannelRequests` identified by `(sender, P)`, set `confirmed` flag to `true`.\n    1. Increase `HrmpAcceptedChannelRequestCount` by 1 for `origin`.\n    1. Send a downward message to `sender` notifying that the channel request was accepted.\n        * The DM is sent using `queue_downward_message`.\n        * The DM is represented by the `HrmpChannelAccepted` XCM message.\n            * `recipient` is set to `origin`.\n* `hrmp_cancel_open_request(ch)`:\n    1. Check that `origin` is either `ch.sender` or `ch.recipient`\n    1. Check that the open channel request `ch` exists.\n    1. Check that the open channel request for `ch` is not confirmed.\n    1. Remove `ch` from `HrmpOpenChannelRequests` and `HrmpOpenChannelRequestsList`\n    1. Decrement `HrmpAcceptedChannelRequestCount` for `ch.recipient` by 1.\n    1. Unreserve the deposit of `ch.sender`.\n* `hrmp_close_channel(ch)`:\n    1. Check that `origin` is either `ch.sender` or `ch.recipient`\n    1. Check that `HrmpChannels` for `ch` exists.\n    1. Check that `ch` is not in the `HrmpCloseChannelRequests` set.\n    1. If not already there, insert a new entry `Some(())` to `HrmpCloseChannelRequests` for `ch` and append `ch` to\n    `HrmpCloseChannelRequestsList`.\n    1. Send a downward message to the opposite party notifying about the channel closing.\n        * The DM is sent using `queue_downward_message`.\n        * The DM is represented by the `HrmpChannelClosing` XCM message with:\n            * `initiator` is set to `origin`,\n            * `sender` is set to `ch.sender`,\n            * `recipient` is set to `ch.recipient`.\n        * The opposite party is `ch.sender` if `origin` is `ch.recipient` and `ch.recipient` if `origin` is `ch.sender`."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain subsystem message traffic\ninput: "
      },
      {
        "role": "assistant",
        "content": "Which subsystems send messages to which other subsystems.\n\n**Note**: This diagram omits the overseer for simplicity. In fact, all messages\nare relayed via the overseer.\n\n**Note**: Messages with a filled diamond arrowhead (\"\u2666\") include a\n`oneshot::Sender` which communicates a response from the recipient. Messages\nwith an open triangle arrowhead (\"\u0394\") do not include a return sender.\n\n```dot process\ndigraph {\n    rankdir=LR;\n    node [shape = oval];\n    concentrate = true;\n\n    av_store    [label = \"Availability Store\"]\n    avail_dist  [label = \"Availability Distribution\"]\n    avail_rcov  [label = \"Availability Recovery\"]\n    bitf_dist   [label = \"Bitfield Distribution\"]\n    bitf_sign   [label = \"Bitfield Signing\"]\n    cand_back   [label = \"Candidate Backing\"]\n    cand_sel    [label = \"Candidate Selection\"]\n    cand_val    [label = \"Candidate Validation\"]\n    chn_api     [label = \"Chain API\"]\n    coll_gen    [label = \"Collation Generation\"]\n    coll_prot   [label = \"Collator Protocol\"]\n    net_brdg    [label = \"Network Bridge\"]\n    pov_dist    [label = \"PoV Distribution\"]\n    provisioner [label = \"Provisioner\"]\n    runt_api    [label = \"Runtime API\"]\n    stmt_dist   [label = \"Statement Distribution\"]\n\n    av_store    -> runt_api     [arrowhead = \"diamond\", label = \"Request::CandidateEvents\"]\n    av_store    -> chn_api      [arrowhead = \"diamond\", label = \"BlockNumber\"]\n    av_store    -> chn_api      [arrowhead = \"diamond\", label = \"BlockHeader\"]\n    av_store    -> runt_api     [arrowhead = \"diamond\", label = \"Request::Validators\"]\n    av_store    -> chn_api      [arrowhead = \"diamond\", label = \"FinalizedBlockHash\"]\n\n    avail_dist  -> net_brdg     [arrowhead = \"onormal\", label = \"Request::SendValidationMessages\"]\n    avail_dist  -> runt_api     [arrowhead = \"diamond\", label = \"Request::AvailabilityCores\"]\n    avail_dist  -> net_brdg     [arrowhead = \"onormal\", label = \"ReportPeer\"]\n    avail_dist  -> av_store     [arrowhead = \"diamond\", label = \"QueryDataAvailability\"]\n    avail_dist  -> av_store     [arrowhead = \"diamond\", label = \"QueryChunk\"]\n    avail_dist  -> av_store     [arrowhead = \"diamond\", label = \"StoreChunk\"]\n    avail_dist  -> runt_api     [arrowhead = \"diamond\", label = \"Request::Validators\"]\n    avail_dist  -> chn_api      [arrowhead = \"diamond\", label = \"Ancestors\"]\n    avail_dist  -> runt_api     [arrowhead = \"diamond\", label = \"Request::SessionIndexForChild\"]\n\n    avail_rcov  -> net_brdg     [arrowhead = \"onormal\", label = \"ReportPeer\"]\n    avail_rcov  -> av_store     [arrowhead = \"diamond\", label = \"QueryChunk\"]\n    avail_rcov  -> net_brdg     [arrowhead = \"diamond\", label = \"ConnectToValidators\"]\n    avail_rcov  -> net_brdg     [arrowhead = \"onormal\", label = \"SendValidationMessage::Chunk\"]\n    avail_rcov  -> net_brdg     [arrowhead = \"onormal\", label = \"SendValidationMessage::RequestChunk\"]\n\n    bitf_dist   -> net_brdg     [arrowhead = \"onormal\", label = \"ReportPeer\"]\n    bitf_dist   -> provisioner  [arrowhead = \"onormal\", label = \"ProvisionableData::Bitfield\"]\n    bitf_dist   -> net_brdg     [arrowhead = \"onormal\", label = \"SendValidationMessage\"]\n    bitf_dist   -> net_brdg     [arrowhead = \"onormal\", label = \"SendValidationMessage\"]\n    bitf_dist   -> runt_api     [arrowhead = \"diamond\", label = \"Request::Validatiors\"]\n    bitf_dist   -> runt_api     [arrowhead = \"diamond\", label = \"Request::SessionIndexForChild\"]\n\n    bitf_sign   -> av_store     [arrowhead = \"diamond\", label = \"QueryChunkAvailability\"]\n    bitf_sign   -> runt_api     [arrowhead = \"diamond\", label = \"Request::AvailabilityCores\"]\n    bitf_sign   -> bitf_dist    [arrowhead = \"onormal\", label = \"DistributeBitfield\"]\n\n    cand_back   -> av_store     [arrowhead = \"diamond\", label = \"StoreAvailableData\"]\n    cand_back   -> pov_dist     [arrowhead = \"diamond\", label = \"FetchPoV\"]\n    cand_back   -> cand_val     [arrowhead = \"diamond\", label = \"ValidateFromChainState\"]\n    cand_back   -> cand_sel     [arrowhead = \"onormal\", label = \"Invalid\"]\n    cand_back   -> provisioner  [arrowhead = \"onormal\", label = \"ProvisionableData::MisbehaviorReport\"]\n    cand_back   -> provisioner  [arrowhead = \"onormal\", label = \"ProvisionableData::BackedCandidate\"]\n    cand_back   -> pov_dist     [arrowhead = \"onormal\", label = \"DistributePoV\"]\n    cand_back   -> stmt_dist    [arrowhead = \"onormal\", label = \"Share\"]\n\n    cand_sel    -> coll_prot    [arrowhead = \"diamond\", label = \"FetchCollation\"]\n    cand_sel    -> cand_back    [arrowhead = \"onormal\", label = \"Second\"]\n\n    cand_val    -> runt_api     [arrowhead = \"diamond\", label = \"Request::PersistedValidationData\"]\n    cand_val    -> runt_api     [arrowhead = \"diamond\", label = \"Request::ValidationCode\"]\n    cand_val    -> runt_api     [arrowhead = \"diamond\", label = \"Request::CheckValidationOutputs\"]\n\n    coll_gen    -> coll_prot    [arrowhead = \"onormal\", label = \"DistributeCollation\"]\n\n    coll_prot   -> net_brdg     [arrowhead = \"onormal\", label = \"ReportPeer\"]\n    coll_prot   -> net_brdg     [arrowhead = \"onormal\", label = \"Declare\"]\n    coll_prot   -> net_brdg     [arrowhead = \"onormal\", label = \"AdvertiseCollation\"]\n    coll_prot   -> net_brdg     [arrowhead = \"onormal\", label = \"Collation\"]\n    coll_prot   -> net_brdg     [arrowhead = \"onormal\", label = \"RequestCollation\"]\n    coll_prot   -> cand_sel     [arrowhead = \"onormal\", label = \"Collation\"]\n\n    net_brdg    -> avail_dist   [arrowhead = \"onormal\", label = \"NetworkBridgeUpdate\"]\n    net_brdg    -> bitf_dist    [arrowhead = \"onormal\", label = \"NetworkBridgeUpdate\"]\n    net_brdg    -> pov_dist     [arrowhead = \"onormal\", label = \"NetworkBridgeUpdate\"]\n    net_brdg    -> stmt_dist    [arrowhead = \"onormal\", label = \"NetworkBridgeUpdate\"]\n    net_brdg    -> coll_prot    [arrowhead = \"onormal\", label = \"NetworkBridgeUpdate\"]\n\n    pov_dist    -> net_brdg     [arrowhead = \"onormal\", label = \"SendValidationMessage\"]\n    pov_dist    -> net_brdg     [arrowhead = \"onormal\", label = \"ReportPeer\"]\n\n    provisioner -> cand_back    [arrowhead = \"diamond\", label = \"GetBackedCandidates\"]\n    provisioner -> chn_api      [arrowhead = \"diamond\", label = \"BlockNumber\"]\n\n    stmt_dist   -> net_brdg     [arrowhead = \"onormal\", label = \"SendValidationMessage\"]\n    stmt_dist   -> net_brdg     [arrowhead = \"onormal\", label = \"ReportPeer\"]\n    stmt_dist   -> cand_back    [arrowhead = \"onormal\", label = \"Statement\"]\n    stmt_dist   -> runt_api     [arrowhead = \"onormal\", label = \"Request::Validators\"]\n    stmt_dist   -> runt_api     [arrowhead = \"onormal\", label = \"Request::SessionIndexForChild\"]\n}\n```"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain the path to inclusion (node side)\ninput: "
      },
      {
        "role": "assistant",
        "content": "Let's contextualize that diagram a bit by following a parachain block from its\ncreation through finalization. Parachains can use completely arbitrary processes\nto generate blocks. The relay chain doesn't know or care about the details; each\nparachain just needs to provide a collator.\n\n**Note**: Inter-subsystem communications are relayed via the overseer, but that\nstep is omitted here for brevity.\n\n**Note**: Dashed lines indicate a request/response cycle, where the response is\ncommunicated asynchronously via a oneshot channel. Adjacent dashed lines may be\nprocessed in parallel.\n\nsequenceDiagram\n    participant Overseer\n    participant CollationGeneration\n    participant RuntimeApi\n    participant CollatorProtocol\n\n    Overseer ->> CollationGeneration: ActiveLeavesUpdate\n    loop for each activated head\n        CollationGeneration -->> RuntimeApi: Request availability cores\n        CollationGeneration -->> RuntimeApi: Request validators\n\n        Note over CollationGeneration: Determine an appropriate ScheduledCore <br/>and OccupiedCoreAssumption\n\n        CollationGeneration -->> RuntimeApi: Request full validation data\n\n        Note over CollationGeneration: Build the collation\n\n        CollationGeneration ->> CollatorProtocol: DistributeCollation\n    end\n\nThe `DistributeCollation` messages that `CollationGeneration` sends to the\n`CollatorProtocol` contains two items: a `CandidateReceipt` and `PoV`. The\n`CollatorProtocol` is then responsible for distributing that collation to\ninterested validators. However, not all potential collations are of interest.\nThe `CandidateSelection` subsystem is responsible for determining which\ncollations are interesting, before `CollatorProtocol` actually fetches the\ncollation.\n\nsequenceDiagram\n    participant CollationGeneration\n    participant CS as CollatorProtocol::CollatorSide\n    participant NB as NetworkBridge\n    participant VS as CollatorProtocol::ValidatorSide\n    participant CandidateSelection\n\n    CollationGeneration ->> CS: DistributeCollation\n    CS -->> NB: ConnectToValidators\n\n    Note over CS,NB: This connects to multiple validators.\n\n    CS ->> NB: Declare\n    NB ->> VS: Declare\n\n    Note over CS: Ensure that the connected validator is among<br/>the para's validator set. Otherwise, skip it.\n\n    CS ->> NB: AdvertiseCollation\n    NB ->> VS: AdvertiseCollation\n\n    VS ->> CandidateSelection: Collation\n\n    Note over CandidateSelection: Lots of other machinery in play here,<br/>but there are only two outcomes from the<br/>perspective of the `CollatorProtocol`:\n\n    alt happy path\n        CandidateSelection -->> VS: FetchCollation\n        Activate VS\n        VS ->> NB: RequestCollation\n        NB ->> CS: RequestCollation\n        CS ->> NB: Collation\n        NB ->> VS: Collation\n        Deactivate VS\n\n    else CandidateSelection already selected a different candidate\n        Note over CandidateSelection: silently drop\n    end\n\nAssuming we hit the happy path, flow continues with `CandidateSelection`\nreceiving a `(candidate_receipt, pov)` as the return value from its\n`FetchCollation` request. The only time `CandidateSelection` actively requests a\ncollation is when it hasn't yet seconded one for some `relay_parent`, and is\nready to second.\n\nsequenceDiagram\n    participant CS as CandidateSelection\n    participant CB as CandidateBacking\n    participant CV as CandidateValidation\n    participant PV as Provisioner\n    participant SD as StatementDistribution\n    participant PD as PoVDistribution\n\n    CS ->> CB: Second\n    % fn validate_and_make_available\n    CB -->> CV: ValidateFromChainState\n\n    Note over CB,CV: There's some complication in the source, as<br/>candidates are actually validated in a separate task.\n\n    alt valid\n        Note over CB: This is where we transform the CandidateReceipt into a CommittedCandidateReceipt\n        % CandidateBackingJob::sign_import_and_distribute_statement\n        % CandidateBackingJob::import_statement\n        CB ->> PV: ProvisionableData::BackedCandidate\n        % CandidateBackingJob::issue_new_misbehaviors\n        opt if there is misbehavior to report\n            CB ->> PV: ProvisionableData::MisbehaviorReport\n        end\n        % CandidateBackingJob::distribute_signed_statement\n        CB ->> SD: Share\n        % CandidateBackingJob::distribute_pov\n        CB ->> PD: DistributePoV\n    else invalid\n        CB ->> CS: Invalid\n    end\n\nAt this point, you'll see that control flows in two directions: to\n`StatementDistribution` to distribute the `SignedStatement`, and to\n`PoVDistribution` to distribute the `PoV`. However, that's largely a mirage:\nwhile the initial implementation distributes `PoV`s by gossip, that's\ninefficient, and will be replaced with a system which fetches `PoV`s only when\nactually necessary.\n\n> TODO: figure out more precisely the current status and plans; write them up\n\nTherefore, we'll follow the `SignedStatement`. The `StatementDistribution`\nsubsystem is largely concerned with implementing a gossip protocol:\n\nsequenceDiagram\n    participant SD as StatementDistribution\n    participant NB as NetworkBridge\n\n    alt On receipt of a<br/>SignedStatement from CandidateBacking\n        % fn circulate_statement_and_dependents\n        SD ->> NB: SendValidationMessage\n\n        Note right of NB: Bridge sends validation message to all appropriate peers\n    else On receipt of peer validation message\n        NB ->> SD: NetworkBridgeUpdate\n\n        % fn handle_incoming_message\n        alt if we aren't already aware of the relay parent for this statement\n            SD ->> NB: ReportPeer\n        end\n\n        % fn circulate_statement\n        opt if we know of peers who haven't seen this message, gossip it\n            SD ->> NB: SendValidationMessage\n        end\n    end\n\nBut who are these `Listener`s who've asked to be notified about incoming\n`SignedStatement`s? Nobody, as yet.\n\nLet's pick back up with the PoV Distribution subsystem.\n\nsequenceDiagram\n    participant CB as CandidateBacking\n    participant PD as PoVDistribution\n    participant Listener\n    participant NB as NetworkBridge\n\n    CB ->> PD: DistributePoV\n\n    Note over PD,Listener: Various subsystems can register listeners for when PoVs arrive\n\n    loop for each Listener\n        PD ->> Listener: Arc<PoV>\n    end\n\n    Note over PD: Gossip to connected peers\n\n    PD ->> NB: SendPoV\n\n    Note over PD,NB: On receipt of a network PoV, PovDistribution forwards it to each Listener.<br/>It also penalizes bad gossipers.\n\nUnlike in the case of `StatementDistribution`, there is another subsystem which\nin various circumstances already registers a listener to be notified when a new\n`PoV` arrives: `CandidateBacking`. Note that this is the second time that\n`CandidateBacking` has gotten involved. The first instance was from the\nperspective of the validator choosing to second a candidate via its\n`CandidateSelection` subsystem. This time, it's from the perspective of some\nother validator, being informed that this foreign `PoV` has been received.\n\nsequenceDiagram\n    participant SD as StatementDistribution\n    participant CB as CandidateBacking\n    participant PD as PoVDistribution\n    participant AS as AvailabilityStore\n\n    SD ->> CB: Statement\n    % CB::maybe_validate_and_import => CB::kick_off_validation_work\n    CB -->> PD: FetchPoV\n    Note over CB,PD: This call creates the Listener from the previous diagram\n\n    CB ->> AS: StoreAvailableData\n\nAt this point, things have gone a bit nonlinear. Let's pick up the thread again\nwith `BitfieldSigning`. As the `Overseer` activates each relay parent, it starts\na `BitfieldSigningJob` which operates on an extremely simple metric: after\ncreation, it immediately goes to sleep for 1.5 seconds. On waking, it records\nthe state of the world pertaining to availability at that moment.\n\nsequenceDiagram\n    participant OS as Overseer\n    participant BS as BitfieldSigning\n    participant RA as RuntimeApi\n    participant AS as AvailabilityStore\n    participant BD as BitfieldDistribution\n\n    OS ->> BS: ActiveLeavesUpdate\n    loop for each activated relay parent\n        Note over BS: Wait 1.5 seconds\n        BS -->> RA: Request::AvailabilityCores\n        loop for each availability core\n            BS -->> AS: QueryChunkAvailability\n        end\n        BS ->> BD: DistributeBitfield\n    end\n\n`BitfieldDistribution` is, like the other `*Distribution` subsystems, primarily\ninterested in implementing a peer-to-peer gossip network propagating its\nparticular messages. However, it also serves as an essential relay passing the\nmessage along.\n\nsequenceDiagram\n    participant BS as BitfieldSigning\n    participant BD as BitfieldDistribution\n    participant NB as NetworkBridge\n    participant PV as Provisioner\n\n    BS ->> BD: DistributeBitfield\n    BD ->> PV: ProvisionableData::Bitfield\n    BD ->> NB: SendValidationMessage::BitfieldDistribution::Bitfield\n\nWe've now seen the message flow to the `Provisioner`: both `CandidateBacking`\nand `BitfieldDistribution` contribute provisionable data. Now, let's look at\nthat subsystem.\n\nMuch like the `BitfieldSigning` subsystem, the `Provisioner` creates a new job\nfor each newly-activated leaf, and starts a timer. Unlike `BitfieldSigning`, we\nwon't depict that part of the process, because the `Provisioner` also has other\nthings going on.\n\nsequenceDiagram\n    participant A as Arbitrary\n    participant PV as Provisioner\n    participant CB as CandidateBacking\n    participant BD as BitfieldDistribution\n    participant RA as RuntimeApi\n    participant PI as ParachainsInherentDataProvider\n\n    alt receive provisionable data\n        alt\n            CB ->> PV: ProvisionableData\n        else\n            BD ->> PV: ProvisionableData\n        end\n\n        loop over stored Senders\n            PV ->> A: ProvisionableData\n        end\n\n        Note over PV: store bitfields and backed candidates\n    else receive request for inherent data\n        PI ->> PV: RequestInherentData\n        alt we have already constructed the inherent data\n            PV ->> PI: send the inherent data\n        else we have not yet constructed the inherent data\n            Note over PV,PI: Store the return sender without sending immediately\n        end\n    else timer times out\n        note over PV: Waited 2 seconds\n        PV -->> RA: RuntimeApiRequest::AvailabilityCores\n        Note over PV: construct and store the inherent data\n        loop over stored inherent data requests\n            PV ->> PI: (SignedAvailabilityBitfields, BackedCandidates)\n        end\n    end\n\nIn principle, any arbitrary subsystem could send a `RequestInherentData` to the\n`Provisioner`. In practice, only the `ParachainsInherentDataProvider` does so.\n\nThe tuple `(SignedAvailabilityBitfields, BackedCandidates, ParentHeader)` is\ninjected by the `ParachainsInherentDataProvider` into the inherent data. From\nthat point on, control passes from the node to the runtime."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain ensuring recording\ninput: "
      },
      {
        "role": "assistant",
        "content": "Only votes recorded by the dispute coordinator will be considered for slashing.\n\nWhile there is no need to record approval votes in the dispute coordinator preemptively, we make some effort to have any\nin approval-voting received approval votes recorded when a dispute actually happens:\n\nThis is not required for concluding the dispute, as nodes send their own vote anyway (either explicit valid or their\nexisting approval-vote). What nodes can do though, is participating in approval-voting, casting a vote, but later when a\ndispute is raised reconsider their vote and send an explicit invalid vote. If they managed to only have that one\nrecorded, then they could avoid a slash.\n\nThis is not a problem for our basic security assumptions: The backers are the ones to be supposed to have skin in the\ngame, so we are not too worried about colluding approval voters getting away slash free as the gambler's ruin property is\nmaintained anyway. There is however a separate problem, from colluding approval-voters, that is \"lazy\" approval voters.\nIf it were easy and reliable for approval-voters to reconsider their vote, in case of an actual dispute, then they don't\nhave a direct incentive (apart from playing a part in securing the network) to properly run the validation function at\nall - they could just always vote \"valid\" totally risk free. (While they would always risk a slash by voting invalid.)\n\nSo we do want to fetch approval votes from approval-voting. Importing votes is most efficient when batched. At the same\ntime approval voting and disputes are running concurrently so approval votes are expected to trickle in still, when a\ndispute is already ongoing.\n\nHence, we have the following requirements for importing approval votes:\n\n1. Only import them when there is a dispute, because otherwise we are wasting lots of resources _always_ for the\n   exceptional case of a dispute.\n2. Import votes batched when possible, to avoid quadratic import complexity.\n3. Take into account that approval voting is still ongoing, while a dispute is already running.\n\nWith a design where approval voting sends votes to the dispute-coordinator by itself, we would need to make approval\nvoting aware of ongoing disputes and once it is aware it could start sending all already existing votes batched and\ntrickling in votes as they come. The problem with this is, that it adds some unnecessary complexity to approval-voting\nand also we might still import most of the votes unbatched one-by-one, depending on what point in time the dispute was\nraised.\n\nInstead of the dispute coordinator informing approval-voting of an ongoing dispute for it to begin forwarding votes to\nthe dispute coordinator, it makes more sense for the dispute-coordinator to just ask approval-voting for votes of\ncandidates in dispute. This way, the dispute coordinator can also pick the best time for maximizing the number of votes\nin the batch.\n\nNow the question remains, when should the dispute coordinator ask approval-voting for votes?\n\nIn fact for slashing it is only relevant to have them once the dispute concluded, so we can query approval voting the\nmoment the dispute concludes! Two concerns that come to mind, are easily addressed:\n\n1. Timing: We would like to rely as little as possible on implementation details of approval voting. In particular, if\n   the dispute is ongoing for a long time, do we have any guarantees that approval votes are kept around long enough by\n   approval voting? Will approval votes still be present by the time the dispute concludes in all cases? The answer is\n   nuanced, but in general we cannot rely on it. The problem is first, that finalization and approval-voting is an\n   off-chain process so there is no global consensus: As soon as at least f+1 honest (f=n/3, where n is the number of\n   validators/nodes) nodes have seen the dispute conclude, finalization will take place and approval votes will be\n   cleared. This would still be fine, if we had some guarantees that those honest nodes will be able to include those\n   votes in a block. This guarantee does not exist unfortunately, we will discuss the problem and solutions in more\n   detail [below][#Ensuring Chain Import].\n\n   The second problem is that approval-voting will abandon votes as soon as a chain can no longer be finalized (some\n   other/better fork already has been). This second problem can somehow be mitigated by also importing votes as soon as\n   a dispute is detected, but not fully resolved. It is still inherently racy. The good thing is, this should be good\n   enough: We are worried about lazy approval checkers, the system does not need to be perfect. It should be enough if\n   there is some risk of getting caught.\n2. We are not worried about the dispute not concluding, as nodes will always send their own vote, regardless of it being\n   an explicit or an already existing approval-vote.\n\nConclusion: As long as we make sure, if our own approval vote gets imported (which would prevent dispute participation)\nto also distribute it via dispute-distribution, disputes can conclude. To mitigate raciness with approval-voting\ndeleting votes we will import approval votes twice during a dispute: Once when it is raised, to make as sure as possible\nto see approval votes also for abandoned forks and second when the dispute concludes, to maximize the amount of\npotentially malicious approval votes to be recorded. The raciness obviously is not fully resolved by this, but this is\nfine as argued above.\n\nEnsuring vote import on chain is covered in the next section.\n\nWhat we don't care about is that honest approval-voters will likely validate twice, once in approval voting and once via\ndispute-participation. Avoiding that does not really seem worthwhile though, as disputes are for one exceptional, so a\nlittle wasted effort won't affect everyday performance - second, even with eager importing of approval votes, those\ndoubled work is still present as disputes and approvals are racing. Every time participation is faster than approval, a\nnode would do double work."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain spam considerations\ninput: "
      },
      {
        "role": "assistant",
        "content": "In Polkadot's security model, it is important that attempts to attack the system result in a slash of the offenders.\nTherefore we need to make sure that this slash is actually happening. Attackers could try to prevent the slashing from\ntaking place, by overwhelming validators with disputes in such a way that no single dispute ever concludes, because\nnodes are busy processing newly incoming ones. Other attacks are imaginable as well, like raising disputes for\ncandidates that don't exist, just filling up everyone's disk slowly or worse making nodes try to participate, which will\nresult in lots of network requests for recovering availability.\n\nThe last point brings up a significant consideration in general: Disputes are about escalation: Every node will suddenly\nwant to check, instead of only a few. A single message will trigger the whole network to start significant amount of\nwork and will cause lots of network traffic and messages. Hence the dispute system is very susceptible to being a brutal\namplifier for DoS attacks, resulting in DoS attacks to become very easy and cheap, if we are not careful.\n\nOne counter measure we are taking is making raising of disputes a costly thing: If you raise a dispute, because you\nclaim a candidate is invalid, although it is in fact valid - you will get slashed, hence you pay for consuming those\nresources. The issue is: This only works if the dispute concerns a candidate that actually exists!\n\nIf a node raises a dispute for a candidate that never got included (became available) on any chain, then the dispute can\nnever conclude, hence nobody gets slashed. It makes sense to point out that this is less bad than it might sound at\nfirst, as trying to participate in a dispute for a non existing candidate is \"relatively\" cheap. Each node will send out\na few hundred tiny request messages for availability chunks, which all will end up in a tiny response \"NoSuchChunk\" and\nthen no participation will actually happen as there is nothing to participate. Malicious nodes could provide chunks,\nwhich would make things more costly, but at the full expense of the attackers bandwidth - no amplification here. I am\nbringing that up for completeness only: Triggering a thousand nodes to send out a thousand tiny network messages by just\nsending out a single garbage message, is still a significant amplification and is nothing to ignore - this could\nabsolutely be used to cause harm!"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain reception\ninput: "
      },
      {
        "role": "assistant",
        "content": "As we shall see the receiving side is mostly about handling spam and ensuring\nthe dispute-coordinator learns about disputes as fast as possible.\n\nGoals for the receiving side:\n\n1. Get new disputes to the dispute-coordinator as fast as possible, so\n  prioritization can happen properly.\n2. Batch votes per disputes as much as possible for good import performance.\n3. Prevent malicious nodes exhausting node resources by sending lots of messages.\n4. Prevent malicious nodes from sending so many messages/(fake) disputes,\n  preventing us from concluding good ones.\n5. Limit ability of malicious nodes of delaying the vote import due to batching\n   logic.\n\nGoal 1 and 2 seem to be conflicting, but an easy compromise is possible: When\nlearning about a new dispute, we will import the vote immediately, making the\ndispute coordinator aware and also getting immediate feedback on the validity.\nThen if valid we can batch further incoming votes, with less time constraints as\nthe dispute-coordinator already knows about the dispute.\n\nGoal 3 and 4 are obviously very related and both can easily be solved via rate\nlimiting as we shall see below. Rate limits should already be implemented at the\nSubstrate level, but are not\nat the time of writing. But even if they were, the enforced Substrate limits would\nlikely not be configurable and thus would still be to high for our needs as we can\nrely on the following observations:\n\n1. Each honest validator will only send one message (apart from duplicates on\n  timeout) per candidate/dispute.\n2. An honest validator needs to fully recover availability and validate the\n  candidate for casting a vote.\n\nWith these two observations, we can conclude that honest validators will usually\nnot send messages at a high rate. We can therefore enforce conservative rate\nlimits and thus minimize harm spamming malicious nodes can have.\n\nBefore we dive into how rate limiting solves all spam issues elegantly, let's\ndiscuss that honest behaviour further:\n\nWhat about session changes? Here we might have to inform a new validator set of\nlots of already existing disputes at once.\n\nWith observation 1) and a rate limit that is per peer, we are still good:\n\nLet's assume a rate limit of one message per 200ms per sender. This means 5\nmessages from each validator per second. 5 messages means 5 disputes!\nConclusively, we will be able to conclude 5 disputes per second - no matter what\nmalicious actors are doing. This is assuming dispute messages are sent ordered,\nbut even if not perfectly ordered: On average it will be 5 disputes per second.\n\nThis is good enough! All those disputes are valid ones and will result in\nslashing and disabling of validators. Let's assume all of them conclude `valid`,\nand we disable validators only after 100 raised concluding valid disputes, we\nwould still start disabling misbehaving validators in only 20 seconds.\n\nOne could also think that in addition participation is expected to take longer,\nwhich means on average we can import/conclude disputes faster than they are\ngenerated - regardless of dispute spam. Unfortunately this is not necessarily\ntrue: There might be parachains with very light load where recovery and\nvalidation can be accomplished very quickly - maybe faster than we can import\nthose disputes.\n\nThis is probably an argument for not imposing a too low rate limit, although the\nissue is more general: Even without any rate limit, if an attacker generates\ndisputes at a very high rate, nodes will be having trouble keeping participation\nup, hence the problem should be mitigated at a more fundamental\nlayer.\n\nFor nodes that have been offline for a while, the same argument as for session\nchanges holds, but matters even less: We assume 2/3 of nodes to be online, so\neven if the worst case 1/3 offline happens and they could not import votes fast\nenough (as argued above, they in fact can) it would not matter for consensus."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain glossary\ninput: "
      },
      {
        "role": "assistant",
        "content": "- **Acknowledgement:** A partial manifest sent to a validator that already has the candidate to inform them that the\n  sending node also knows the candidate. Concludes a manifest exchange.\n- **Announcement:** A full manifest indicating that a backed candidate is known by the sending node. Initiates a\n  manifest exchange.\n- **Attestation:** See \"Statement\".\n- **Backable vs. Backed:**\n  - Note that we sometimes use \"backed\" to refer to candidates that are \"backable\", but not yet backed on chain.\n  - **Backed** should technically mean that the parablock candidate and its backing statements have been added to a\n    relay chain block.\n  - **Backable** is when the necessary backing statements have been acquired but those statements and the parablock\n    candidate haven't been backed in a relay chain block yet.\n- **Fragment tree:** A parachain fragment not referenced by the relay-chain. It is a tree of prospective parachain\n  blocks.\n- **Manifest:** A message about a known backed candidate, along with a description of the statements backing it. There\n  are two kinds of manifest, `Acknowledgement` and `Announcement`. See \"Manifests\" section.\n- **Peer:** Another validator that a validator is connected to.\n- **Request/response:** A protocol used to lazily request and receive heavy candidate data when needed.\n- **Reputation:** Tracks reputation of peers. Applies annoyance cost and good behavior benefits.\n- **Statement:** Signed statements that can be made about parachain candidates.\n  - **Seconded:** Proposal of a parachain candidate. Implicit validity vote.\n  - **Valid:** States that a parachain candidate is valid.\n- **Target:** Target validator to send a statement to.\n- **View:** Current knowledge of the chain state.\n  - **Explicit view** / **immediate view**\n    - The view a peer has of the relay chain heads and highest finalized block.\n  - **Implicit view**\n    - Derived from the immediate view. Composed of active leaves and minimum relay-parents allowed for candidates of\n      various parachains at those leaves."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain default recovery strategy configuration\ninput: "
      },
      {
        "role": "assistant",
        "content": "### For validators\n\nIf the estimated available data size is smaller than a configured constant (currently 1Mib for Polkadot or 4Mib for\nother networks), try doing `FetchFull` first.\nNext, if the preconditions described in `FetchSystematicChunks` above are met, try systematic recovery.\nAs a last resort, do `FetchChunks`.\n\n### For collators\n\nCollators currently only use `FetchChunks`, as they only attempt recoveries in rare scenarios.\n\nMoreover, the recovery task is specially configured to not attempt requesting data from the local availability-store\n(because it doesn't exist) and to not reencode the data after a succcessful recovery (because it's an expensive check\nthat is not needed; checking the pov_hash is enough for collators)."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain functionality\ninput: "
      },
      {
        "role": "assistant",
        "content": "The process of generating a collation for a parachain is very parachain-specific. As such, the details of how to do so\nare left beyond the scope of this description. The subsystem should be implemented as an abstract wrapper, which is\naware of this configuration:\n\n/// The output of a collator.\n///\n/// This differs from `CandidateCommitments` in two ways:\n///\n/// - does not contain the erasure root; that's computed at the Polkadot level, not at Cumulus\n/// - contains a proof of validity.\npub struct Collation {\n  /// Messages destined to be interpreted by the Relay chain itself.\n  pub upward_messages: Vec<UpwardMessage>,\n  /// The horizontal messages sent by the parachain.\n  pub horizontal_messages: Vec<OutboundHrmpMessage<ParaId>>,\n  /// New validation code.\n  pub new_validation_code: Option<ValidationCode>,\n  /// The head-data produced as a result of execution.\n  pub head_data: HeadData,\n  /// Proof to verify the state transition of the parachain.\n  pub proof_of_validity: PoV,\n  /// The number of messages processed from the DMQ.\n  pub processed_downward_messages: u32,\n  /// The mark which specifies the block number up to which all inbound HRMP messages are processed.\n  pub hrmp_watermark: BlockNumber,\n}\n\n/// Result of the [`CollatorFn`] invocation.\npub struct CollationResult {\n  /// The collation that was build.\n  pub collation: Collation,\n  /// An optional result sender that should be informed about a successfully seconded collation.\n  ///\n  /// There is no guarantee that this sender is informed ever about any result, it is completely okay to just drop it.\n  /// However, if it is called, it should be called with the signed statement of a parachain validator seconding the\n  /// collation.\n  pub result_sender: Option<oneshot::Sender<CollationSecondedSignal>>,\n}\n\n/// Signal that is being returned when a collation was seconded by a validator.\npub struct CollationSecondedSignal {\n  /// The hash of the relay chain block that was used as context to sign [`Self::statement`].\n  pub relay_parent: Hash,\n  /// The statement about seconding the collation.\n  ///\n  /// Anything else than `Statement::Seconded` is forbidden here.\n  pub statement: SignedFullStatement,\n}\n\n/// Collation function.\n///\n/// Will be called with the hash of the relay chain block the parachain block should be build on and the\n/// [`ValidationData`] that provides information about the state of the parachain on the relay chain.\n///\n/// Returns an optional [`CollationResult`].\npub type CollatorFn = Box<\n  dyn Fn(\n      Hash,\n      &PersistedValidationData,\n    ) -> Pin<Box<dyn Future<Output = Option<CollationResult>> + Send>>\n    + Send\n    + Sync,\n>;\n\n/// Configuration for the collation generator\npub struct CollationGenerationConfig {\n  /// Collator's authentication key, so it can sign things.\n  pub key: CollatorPair,\n  /// Collation function. See [`CollatorFn`] for more details.\n  pub collator: Option<CollatorFn>,\n  /// The parachain that this collator collates for\n  pub para_id: ParaId,\n}\n\nThe configuration should be optional, to allow for the case where the node is not run with the capability to collate."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain network updates\ninput: "
      },
      {
        "role": "assistant",
        "content": "### `NetworkBridgeEvent::PeerConnected`\n\nAdd a blank view to the `peer_views` state.\n\n### `NetworkBridgeEvent::PeerDisconnected`\n\nRemove the view under the associated `PeerId` from `State::peer_views`.\n\nIterate over every `BlockEntry` and remove `PeerId` from it.\n\n### `NetworkBridgeEvent::OurViewChange`\n\nRemove entries in `pending_known` for all hashes not present in the view. Ensure a vector is present in `pending_known`\nfor each hash in the view that does not have an entry in `blocks`.\n\n### `NetworkBridgeEvent::PeerViewChange`\n\nInvoke `unify_with_peer(peer, view)` to catch them up to messages we have.\n\nWe also need to use the `view.finalized_number` to remove the `PeerId` from any blocks that it won't be wanting\ninformation about anymore. Note that we have to be on guard for peers doing crazy stuff like jumping their\n`finalized_number` forward 10 trillion blocks to try and get us stuck in a loop for ages.\n\nOne of the safeguards we can implement is to reject view updates from peers where the new `finalized_number` is less\nthan the previous.\n\nWe augment that by defining `constrain(x)` to output the x bounded by the first and last numbers in\n`state.blocks_by_number`.\n\nFrom there, we can loop backwards from `constrain(view.finalized_number)` until `constrain(last_view.finalized_number)`\nis reached, removing the `PeerId` from all `BlockEntry`s referenced at that height. We can break the loop early if we\never exit the bound supplied by the first block in `state.blocks_by_number`.\n\n### `NetworkBridgeEvent::PeerMessage`\n\nIf the block hash referenced by the message exists in `pending_known`, add it to the vector of pending messages and\nreturn.\n\nIf the message is of type `ApprovalDistributionV1Message::Assignment(assignment_cert, claimed_index)`, then call\n`import_and_circulate_assignment(MessageSource::Peer(sender), assignment_cert, claimed_index)`\n\nIf the message is of type `ApprovalDistributionV1Message::Approval(approval_vote)`, then call\n`import_and_circulate_approval(MessageSource::Peer(sender), approval_vote)`"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain utility\ninput: "
      },
      {
        "role": "assistant",
        "content": "enum MessageSource {\n  Peer(PeerId),\n  Local,\n}\n\n### `import_and_circulate_assignment(...)`\n\n`import_and_circulate_assignment(source: MessageSource, assignment: IndirectAssignmentCert, claimed_candidate_index:\nCandidateIndex)`\n\nImports an assignment cert referenced by block hash and candidate index. As a postcondition, if the cert is valid, it\nwill have distributed the cert to all peers who have the block in their view, with the exclusion of the peer referenced\nby the `MessageSource`.\n\nWe maintain a few invariants:\n  * we only send an assignment to a peer after we add its fingerprint to our knowledge\n  * we add a fingerprint of an assignment to our knowledge only if it's valid and hasn't been added before\n\nThe algorithm is the following:\n\n  * Load the `BlockEntry` using `assignment.block_hash`. If it does not exist, report the source if it is\n    `MessageSource::Peer` and return.\n  * Compute a fingerprint for the `assignment` using `claimed_candidate_index`.\n  * If the source is `MessageSource::Peer(sender)`:\n    * check if `peer` appears under `known_by` and whether the fingerprint is in the knowledge of the peer. If the peer\n      does not know the block, report for providing data out-of-view and proceed. If the peer does know the block and\n      the `sent` knowledge contains the fingerprint, report for providing replicate data and return, otherwise, insert\n      into the `received` knowledge and return.\n    * If the message fingerprint appears under the `BlockEntry`'s `Knowledge`, give the peer a small positive reputation\n    boost, add the fingerprint to the peer's knowledge only if it knows about the block and return. Note that we must do\n    this after checking for out-of-view and if the peers knows about the block to avoid being spammed. If we did this\n    check earlier, a peer could provide data out-of-view repeatedly and be rewarded for it.\n    * Check the assignment certificate is valid.\n      * If the cert kind is `RelayVRFModulo`, then the certificate is valid as long as `sample <\n        session_info.relay_vrf_samples` and the VRF is valid for the validator's key with the input\n        `block_entry.relay_vrf_story ++ sample.encode()` as described with\n        the approvals protocol section. We set\n        `core_index = vrf.make_bytes().to_u32() % session_info.n_cores`. If the `BlockEntry` causes\n        inclusion of a candidate at `core_index`, then this is a valid assignment for the candidate\n        at `core_index` and has delay tranche 0. Otherwise, it can be ignored.\n      * If the cert kind is `RelayVRFModuloCompact`, then the certificate is valid as long as the VRF\n        is valid for the validator's key with the input `block_entry.relay_vrf_story ++ relay_vrf_samples.encode()`\n        as described with the approvals protocol section.\n        We enforce that all `core_bitfield` indices are included in the set of the core indices sampled from the\n        VRF Output. The assignment is considered a valid tranche0 assignment for all claimed candidates if all\n        `core_bitfield` indices match the core indices where the claimed candidates were included at.\n      * If the cert kind is `RelayVRFDelay`, then we check if the VRF is valid for the validator's key with the\n        input `block_entry.relay_vrf_story ++ cert.core_index.encode()` as described in the approvals protocol\n        section. The cert can be ignored if the block did not\n        cause inclusion of a candidate on that core index. Otherwise, this is a valid assignment for the included\n        candidate. The delay tranche for the assignment is determined by reducing\n        `(vrf.make_bytes().to_u64() % (session_info.n_delay_tranches + session_info.zeroth_delay_tranche_width)).saturating_sub(session_info.zeroth_delay_tranche_width)`.\n      * We also check that the core index derived by the output is covered by the `VRFProof` by means of an auxiliary signature.\n      * If the delay tranche is too far in the future, return `AssignmentCheckResult::TooFarInFuture`.\n    * If the result is `AssignmentCheckResult::Accepted`\n      * Dispatch `ApprovalVotingMessage::ImportAssignment(assignment)` to approval-voting to import the assignment.\n      * If the vote was accepted but not duplicate, give the peer a positive reputation boost\n      * add the fingerprint to both our and the peer's knowledge in the `BlockEntry`. Note that we only doing this after\n        making sure we have the right fingerprint.\n    * If the result is `AssignmentCheckResult::AcceptedDuplicate`, add the fingerprint to the peer's knowledge if it\n      knows about the block and return.\n    * If the result is `AssignmentCheckResult::TooFarInFuture`, mildly punish the peer and return.\n    * If the result is `AssignmentCheckResult::Bad`, punish the peer and return.\n  * If the source is `MessageSource::Local(CandidateIndex)`\n    * check if the fingerprint appears under the `BlockEntry's` knowledge. If not, add it.\n  * Load the candidate entry for the given candidate index. It should exist unless there is a logic error in the\n    approval voting subsystem.\n  * Set the approval state for the validator index to `ApprovalState::Assigned` unless the approval state is set\n    already. This should not happen as long as the approval voting subsystem instructs us to ignore duplicate\n    assignments.\n  * Dispatch a `ApprovalDistributionV1Message::Assignment(assignment, candidate_index)` to all peers in the\n    `BlockEntry`'s `known_by` set, excluding the peer in the `source`, if `source` has kind `MessageSource::Peer`. Add\n    the fingerprint of the assignment to the knowledge of each peer.\n\n### `import_and_circulate_approval(source: MessageSource, approval: IndirectSignedApprovalVote)`\n\nImports an approval signature referenced by block hash and candidate index:\n\n  * Load the `BlockEntry` using `approval.block_hash` and the candidate entry using `approval.candidate_entry`. If\n    either does not exist, report the source if it is `MessageSource::Peer` and return.\n  * Compute a fingerprint for the approval.\n  * Compute a fingerprint for the corresponding assignment. If the `BlockEntry`'s knowledge does not contain that\n    fingerprint, then report the source if it is `MessageSource::Peer` and return. All references to a fingerprint after\n    this refer to the approval's, not the assignment's.\n  * If the source is `MessageSource::Peer(sender)`:\n    * check if `peer` appears under `known_by` and whether the fingerprint is in the knowledge of the peer. If the peer\n      does not know the block, report for providing data out-of-view and proceed. If the peer does know the block and\n      the `sent` knowledge contains the fingerprint, report for providing replicate data and return, otherwise, insert\n      into the `received` knowledge and return.\n    * If the message fingerprint appears under the `BlockEntry`'s `Knowledge`, give the peer a small positive reputation\n    boost, add the fingerprint to the peer's knowledge only if it knows about the block and return. Note that we must do\n    this after checking for out-of-view to avoid being spammed. If we did this check earlier, a peer could provide data\n    out-of-view repeatedly and be rewarded for it.\n    * Construct a `SignedApprovalVote` using the candidates hashes and check against the validator's approval key,\n      based on the session info of the block. If invalid or no such validator, return `Err(InvalidVoteError)`.\n    * If the result of checking the signature is `Ok(CheckedIndirectSignedApprovalVote)`:\n      * Dispatch `ApprovalVotingMessage::ImportApproval(approval)` .\n      * Give the peer a positive reputation boost and add the fingerprint to both our and the peer's knowledge.\n    * If the result is `Err(InvalidVoteError)`:\n      * Report the peer and return.\n  * Load the candidate entry for the given candidate index. It should exist unless there is a logic error in the\n    approval voting subsystem.\n  * Set the approval state for the validator index to `ApprovalState::Approved`. It should already be in the `Assigned`\n    state as our `BlockEntry` knowledge contains a fingerprint for the assignment.\n  * Dispatch a `ApprovalDistributionV1Message::Approval(approval)` to all peers in the `BlockEntry`'s `known_by` set,\n    excluding the peer in the `source`, if `source` has kind `MessageSource::Peer`. Add the fingerprint of the\n    assignment to the knowledge of each peer. Note that this obeys the politeness conditions:\n    * We guarantee elsewhere that all peers within `known_by` are aware of all assignments relative to the block.\n    * We've checked that this specific approval has a corresponding assignment within the `BlockEntry`.\n    * Thus, all peers are aware of the assignment or have a message to them in-flight which will make them so.\n\n### `unify_with_peer(peer: PeerId, view)`\n\n1. Initialize a set `missing_knowledge = {}`\n\nFor each block in the view:\n  1. Load the `BlockEntry` for the block. If the block is unknown, or the number is less than or equal to the view's\n     finalized number go to step 6.\n  1. Inspect the `known_by` set of the `BlockEntry`. If the peer already knows all assignments/approvals, go to step 6.\n  1. Add the peer to `known_by` and add the hash and missing knowledge of the block to `missing_knowledge`.\n  1. Return to step 2 with the ancestor of the block.\n\n1. For each block in `missing_knowledge`, send all assignments and approvals for all candidates in those blocks to the\n   peer."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain incoming messages\ninput: "
      },
      {
        "role": "assistant",
        "content": "### `OverseerSignal::BlockFinalized`\n\nOn receiving an `OverseerSignal::BlockFinalized(h)`, we fetch the block number `b` of that block from the `ChainApi`\nsubsystem. We update our `StoredBlockRange` to begin at `b+1`. Additionally, we remove all block entries and candidates\nreferenced by them up to and including `b`. Lastly, we prune out all descendants of `h` transitively: when we remove a\n`BlockEntry` with number `b` that is not equal to `h`, we recursively delete all the `BlockEntry`s referenced as\nchildren. We remove the `block_assignments` entry for the block hash and if `block_assignments` is now empty, remove the\n`CandidateEntry`. We also update each of the `BlockNumber -> Vec<Hash>` keys in the database to reflect the blocks at\nthat height, clearing if empty.\n\n### `OverseerSignal::ActiveLeavesUpdate`\n\nOn receiving an `OverseerSignal::ActiveLeavesUpdate(update)`:\n  * We determine the set of new blocks that were not in our previous view. This is done by querying the ancestry of all\n    new items in the view and contrasting against the stored `BlockNumber`s. Typically, there will be only one new\n    block. We fetch the headers and information on these blocks from the `ChainApi` subsystem. Stale leaves in the\n    update can be ignored.\n  * We update the `StoredBlockRange` and the `BlockNumber` maps.\n  * We use the `RuntimeApiSubsystem` to determine information about these blocks. It is generally safe to assume that\n    runtime state is available for recent, unfinalized blocks. In the case that it isn't, it means that we are catching\n    up to the head of the chain and needn't worry about assignments to those blocks anyway, as the security assumption\n    of the protocol tolerates nodes being temporarily offline or out-of-date.\n    * We fetch the set of candidates included by each block by dispatching a `RuntimeApiRequest::CandidateEvents` and\n      checking the `CandidateIncluded` events.\n    * We fetch the session of the block by dispatching a `session_index_for_child` request with the parent-hash of the\n      block.\n    * If the `session index - APPROVAL_SESSIONS > state.earliest_session`, then bump `state.earliest_sessions` to that\n      amount and prune earlier sessions.\n    * If the session isn't in our `state.session_info`, load the session info for it and for all sessions since the\n      earliest-session, including the earliest-session, if that is missing. And it can be, just after pruning, if we've\n      done a big jump forward, as is the case when we've just finished chain synchronization.\n    * If any of the runtime API calls fail, we just warn and skip the block.\n  * We use the `RuntimeApiSubsystem` to determine the set of candidates included in these blocks and use BABE logic to\n    determine the slot number and VRF of the blocks.\n  * We also note how late we appear to have received the block. We create a `BlockEntry` for each block and a\n    `CandidateEntry` for each candidate obtained from `CandidateIncluded` events after making a\n    `RuntimeApiRequest::CandidateEvents` request.\n  * For each candidate, if the amount of needed approvals is more than the validators remaining after the backing group\n    of the candidate is subtracted, then the candidate is insta-approved as approval would be impossible otherwise. If\n    all candidates in the block are insta-approved, or there are no candidates in the block, then the block is\n    insta-approved. If the block is insta-approved, a [`ChainSelectionMessage::Approved`][CSM] should be sent for the\n    block.\n  * Ensure that the `CandidateEntry` contains a `block_assignments` entry for the block, with the correct backing group\n    set.\n  * If a validator in this session, compute and assign `our_assignment` for the `block_assignments`\n    * Only if not a member of the backing group.\n    * Run `RelayVRFModulo` and `RelayVRFDelay` according to the the approvals protocol\n      section. Ensure that the assigned core derived from the output is\n      covered by the auxiliary signature aggregated in the `VRFPRoof`.\n  * Handle Wakeup for each new candidate in each new block - this will automatically broadcast a\n    0-tranche assignment, kick off approval work, and schedule the next delay.\n  * Dispatch an `ApprovalDistributionMessage::NewBlocks` with the meta information filled out for each new block.\n\n### `ApprovalVotingMessage::ImportAssignment`\n\nOn receiving a `ApprovalVotingMessage::ImportAssignment` message, we assume the assignment cert itself has already been\nchecked to be valid we proceed then to import the assignment inside the block entry. The cert itself contains\ninformation necessary to determine the candidate that is being assigned-to. In detail:\n  * Load the `BlockEntry` for the relay-parent referenced by the message. If there is none, return\n    `AssignmentCheckResult::Bad`.\n  * Fetch the `SessionInfo` for the session of the block\n  * Determine the assignment key of the validator based on that.\n  * Determine the claimed core index by looking up the candidate with given index in `block_entry.candidates`. Return\n    `AssignmentCheckResult::Bad` if missing.\n  * Import the assignment.\n    * Load the candidate in question and access the `approval_entry` for the block hash the cert references.\n    * Ignore if we already observe the validator as having been assigned.\n    * Ensure the validator index is not part of the backing group for the candidate.\n    * Ensure the validator index is not present in the approval entry already.\n    * Create a tranche entry for the delay tranche in the approval entry and note the assignment within it.\n    * Note the candidate index within the approval entry.\n  * Schedule a wakeup for this block, candidate pair.\n  * return the appropriate `AssignmentCheckResult` on the response channel.\n\n### `ApprovalVotingMessage::ImportApproval`\n\nOn receiving a `ImportApproval(indirect_approval_vote, response_channel)` message:\n  * Fetch the `BlockEntry` from the indirect approval vote's `block_hash`. If none, return `ApprovalCheckResult::Bad`.\n  * Fetch all `CandidateEntry` from the indirect approval vote's `candidate_indices`. If the block did not trigger\n    inclusion of enough candidates, return `ApprovalCheckResult::Bad`.\n  * Send `ApprovalCheckResult::Accepted`\n  * Import the checked approval vote for all candidates\n\n### `ApprovalVotingMessage::ApprovedAncestor`\n\nOn receiving an `ApprovedAncestor(Hash, BlockNumber, response_channel)`:\n  * Iterate over the ancestry of the hash all the way back to block number given, starting from the provided block hash.\n    Load the `CandidateHash`es from each block entry.\n  * Keep track of an `all_approved_max: Option<(Hash, BlockNumber, Vec<(Hash, Vec<CandidateHash>))>`.\n  * For each block hash encountered, load the `BlockEntry` associated. If any are not found, return `None` on the\n    response channel and conclude.\n  * If the block entry's `approval_bitfield` has all bits set to 1 and `all_approved_max == None`, set `all_approved_max\n    = Some((current_hash, current_number))`.\n  * If the block entry's `approval_bitfield` has any 0 bits, set `all_approved_max = None`.\n  * If `all_approved_max` is `Some`, push the current block hash and candidate hashes onto the list of blocks and\n    candidates `all_approved_max`.\n  * After iterating all ancestry, return `all_approved_max`."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain updates and auxiliary logic\ninput: "
      },
      {
        "role": "assistant",
        "content": "### Import Checked Approval\n  * Import an approval vote which we can assume to have passed signature checks and correspond to an imported\n    assignment.\n  * Requires `(BlockEntry, CandidateEntry, ValidatorIndex)`\n  * Set the corresponding bit of the `approvals` bitfield in the `CandidateEntry` to `1`. If already `1`, return.\n  * Checks the approval state of a candidate under a specific block, and updates the block and candidate entries\n    accordingly.\n  * Checks the `ApprovalEntry` for the block.\n    * determine the tranches to inspect of the candidate,\n    * the candidate is approved under the block, set the corresponding bit in the\n      `block_entry.approved_bitfield`.\n    * If the block is now fully approved and was not before, send a [`ChainSelectionMessage::Approved`][CSM].\n    * Otherwise, schedule a wakeup of the candidate\n  * If the approval vote originates locally, set the `our_approval_sig` in the candidate entry.\n\n### Handling Wakeup\n  * Handle a previously-scheduled wakeup of a candidate under a specific block.\n  * Requires `(relay_block, candidate_hash)`\n  * Load the `BlockEntry` and `CandidateEntry` from disk. If either is not present, this may have lost a race with\n    finality and can be ignored. Also load the `ApprovalEntry` for the block and candidate.\n  * determine the `RequiredTranches` of the candidate.\n  * Determine if we should trigger our assignment.\n    * If we've already triggered or `OurAssignment` is `None`, we do not trigger.\n    * If we have  `RequiredTranches::All`, then we trigger if the candidate is not approved. We have\n      no next wakeup as we assume that other validators are doing the same and we will be implicitly woken up by\n      handling new votes.\n    * If we have `RequiredTranches::Pending { considered, next_no_show, uncovered, maximum_broadcast, clock_drift }`,\n      then we trigger if our assignment's tranche is less than or equal to `maximum_broadcast` and the current tick,\n      with `clock_drift` applied, is at least the tick of our tranche.\n    * If we have `RequiredTranches::Exact { .. }` then we do not trigger, because this value indicates that no new\n      assignments are needed at the moment.\n  * If we should trigger our assignment\n    * Import the assignment to the `ApprovalEntry`\n    * Broadcast on network with an `ApprovalDistributionMessage::DistributeAssignment`.\n    * Launch approval work for the candidate.\n  * Schedule a new wakeup of the candidate.\n\n### Schedule Wakeup\n\n  * Requires `(approval_entry, candidate_entry)` which effectively denotes a `(Block Hash, Candidate Hash)` pair - the\n    candidate, along with the block it appears in.\n  * Also requires `RequiredTranches`\n  * If the `approval_entry` is approved, this doesn't need to be woken up again.\n  * If `RequiredTranches::All` - no wakeup. We assume other incoming votes will trigger wakeup and potentially\n    re-schedule.\n  * If `RequiredTranches::Pending { considered, next_no_show, uncovered, maximum_broadcast, clock_drift }` - schedule at\n    the lesser of the next no-show tick, or the tick, offset positively by `clock_drift` of the next non-empty tranche\n    we are aware of after `considered`, including any tranche containing our own unbroadcast assignment. This can lead\n    to no wakeup in the case that we have already broadcast our assignment and there are no pending no-shows; that is,\n    we have approval votes for every assignment we've received that is not already a no-show. In this case, we will be\n    re-triggered by other validators broadcasting their assignments.\n  * If `RequiredTranches::Exact { next_no_show, latest_assignment_tick, .. }` - set a wakeup for the earlier of the next\n    no-show tick or the latest assignment tick + `APPROVAL_DELAY`.\n\n### Launch Approval Work\n\n* Requires `(SessionIndex, SessionInfo, CandidateReceipt, ValidatorIndex, backing_group, block_hash, candidate_index)`\n* Extract the public key of the `ValidatorIndex` from the `SessionInfo` for the session.\n* Issue an `AvailabilityRecoveryMessage::RecoverAvailableData(candidate, session_index, Some(backing_group),\nSome(core_index), response_sender)`\n* Load the historical validation code of the parachain by dispatching a\n  `RuntimeApiRequest::ValidationCodeByHash(descriptor.validation_code_hash)` against the state of `block_hash`.\n* Spawn a background task with a clone of `background_tx`\n  * Wait for the available data\n  * Issue a `CandidateValidationMessage::ValidateFromExhaustive` message with `APPROVAL_EXECUTION_TIMEOUT` as the\n    timeout parameter.\n  * Wait for the result of validation\n  * Check that the result of validation, if valid, matches the commitments in the receipt.\n  * If valid, issue a message on `background_tx` detailing the request.\n  * If any of the data, the candidate, or the commitments are invalid, issue on `background_tx` a\n    `DisputeCoordinatorMessage::IssueLocalStatement`\n    with `valid = false` to initiate a dispute.\n\n### Issue Approval Vote\n  * Fetch the block entry and candidate entry. Ignore if `None` - we've probably just lost a race with finality.\n  * Import the checked approval vote. It is \"checked\" as we've just issued the signature.\n  * IF `MAX_APPROVAL_COALESCE_COUNT`  candidates are in the waiting queue\n    * Construct a `SignedApprovalVote` with the validator index for the session and all candidate hashes in the waiting queue.\n    * Construct a `IndirectSignedApprovalVote` using the information about the vote.\n    * Dispatch `ApprovalDistributionMessage::DistributeApproval`.\n  * ELSE\n    * Queue the candidate in the `BlockEntry::candidates_pending_signature`\n    * Arm a per BlockEntry timer with latest tick we can send the vote."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain determining approval of candidate\ninput: "
      },
      {
        "role": "assistant",
        "content": "### Determine Required Tranches\n\nThis logic is for inspecting an approval entry that tracks the assignments received, along with information on which\nassignments have corresponding approval votes. Inspection also involves the current time and expected requirements and\nis used to help the higher-level code determine the following:\n  * Whether to broadcast the local assignment\n  * Whether to check that the candidate entry has been completely approved.\n  * If the candidate is waiting on approval, when to schedule the next wakeup of the `(candidate, block)` pair at a\n    point where the state machine could be advanced.\n\nThese routines are pure functions which only depend on the environmental state. The expectation is that this\ndetermination is re-run every time we attempt to update an approval entry: either when we trigger a wakeup to advance\nthe state machine based on a no-show or our own broadcast, or when we receive further assignments or approvals from the\nnetwork.\n\nThus it may be that at some point in time, we consider that tranches 0..X is required to be considered, but as we\nreceive more information, we might require fewer tranches. Or votes that we perceived to be missing and require\nreplacement are filled in and change our view.\n\nRequires `(approval_entry, approvals_received, tranche_now, block_tick, no_show_duration, needed_approvals)`\n\nenum RequiredTranches {\n  // All validators appear to be required, based on tranches already taken and remaining no-shows.\n  All,\n  // More tranches required - We're awaiting more assignments.\n  Pending {\n    /// The highest considered delay tranche when counting assignments.\n    considered: DelayTranche,\n    /// The tick at which the next no-show, of the assignments counted, would occur.\n    next_no_show: Option<Tick>,\n    /// The highest tranche to consider when looking to broadcast own assignment.\n    /// This should be considered along with the clock drift to avoid broadcasting\n    /// assignments that are before the local time.\n    maximum_broadcast: DelayTranche,\n    /// The clock drift, in ticks, to apply to the local clock when determining whether\n    /// to broadcast an assignment or when to schedule a wakeup. The local clock should be treated\n    /// as though it is `clock_drift` ticks earlier.\n    clock_drift: Tick,\n  },\n  // An exact number of required tranches and a number of no-shows. This indicates that the amount of `needed_approvals`\n  // are assigned and additionally all no-shows are covered.\n  Exact {\n    /// The tranche to inspect up to.\n    needed: DelayTranche,\n    /// The amount of missing votes that should be tolerated.\n    tolerated_missing: usize,\n    /// When the next no-show would be, if any. This is used to schedule the next wakeup in the\n    /// event that there are some assignments that don't have corresponding approval votes. If this\n    /// is `None`, all assignments have approvals.\n    next_no_show: Option<Tick>,\n    /// The last tick at which a needed assignment was received.\n    last_assignment_tick: Option<Tick>,\n  }\n}\n\n**Clock-drift and Tranche-taking**\n\nOur vote-counting procedure depends heavily on how we interpret time based on the presence of no-shows - assignments\nwhich have no corresponding approval after some time.\n\nWe have this is because of how we handle no-shows: we keep track of the depth of no-shows we are covering.\n\nAs an example: there may be initial no-shows in tranche 0. It'll take `no_show_duration` ticks before those are\nconsidered no-shows. Then, we don't want to immediately take `no_show_duration` more tranches. Instead, we want to take\none tranche for each uncovered no-show. However, as we take those tranches, there may be further no-shows. Since these\ndepth-1 no-shows should have only been triggered after the depth-0 no-shows were already known to be no-shows, we need\nto discount the local clock by `no_show_duration` to  see whether these should be considered no-shows or not. There may\nbe malicious parties who broadcast their assignment earlier than they were meant to, who shouldn't be counted as instant\nno-shows. We continue onwards to cover all depth-1 no-shows which may lead to depth-2 no-shows and so on.\n\nLikewise, when considering how many tranches to take, the no-show depth should be used to apply a depth-discount or\nclock drift to the `tranche_now`.\n\n**Procedure**\n\n  * Start with `depth = 0`.\n  * Set a clock drift of `depth * no_show_duration`\n  * Take tranches up to `tranche_now - clock_drift` until all needed assignments are met.\n  * Keep track of the `next_no_show` according to the clock drift, as we go.\n  * Keep track of the `last_assignment_tick` as we go.\n  * If running out of tranches before then, return `Pending { considered, next_no_show, maximum_broadcast, clock_drift\n    }`\n  * If there are no no-shows, return `Exact { needed, tolerated_missing, next_no_show, last_assignment_tick }`\n  * `maximum_broadcast` is either `DelayTranche::max_value()` at tranche 0 or otherwise by the last considered tranche +\n    the number of uncovered no-shows at this point.\n  * If there are no-shows, return to the beginning, incrementing `depth` and attempting to cover the number of no-shows.\n    Each no-show must be covered by a non-empty tranche, which are tranches that have at least one assignment. Each\n    non-empty tranche covers exactly one no-show.\n  * If at any point, it seems that all validators are required, do an early return with `RequiredTranches::All` which\n    indicates that everyone should broadcast.\n\n### Check Approval\n  * Check whether a candidate is approved under a particular block.\n  * Requires `(block_entry, candidate_entry, approval_entry, n_tranches)`\n  * If we have `3 * n_approvals > n_validators`, return true. This is because any set with f+1 validators must have at\n    least one honest validator, who has approved the candidate.\n  * If `n_tranches` is `RequiredTranches::Pending`, return false\n  * If `n_tranches` is `RequiredTranches::All`, return false.\n  * If `n_tranches` is `RequiredTranches::Exact { tranche, tolerated_missing, latest_assignment_tick, .. }`, then we\n    return whether all assigned validators up to `tranche` less `tolerated_missing` have approved and\n    `latest_assignment_tick + APPROVAL_DELAY >= tick_now`.\n    * e.g. if we had 5 tranches and 1 tolerated missing, we would accept only if all but 1 of assigned validators in\n      tranches 0..=5 have approved. In that example, we also accept all validators in tranches 0..=5 having approved,\n      but that would indicate that the `RequiredTranches` value was incorrectly constructed, so it is not realistic.\n      `tolerated_missing` actually represents covered no-shows. If there are more missing approvals than there are\n      tolerated missing, that indicates that there are some assignments which are not yet no-shows, but may become\n      no-shows, and we should wait for the validators to either approve or become no-shows.\n    * e.g. If the above passes and the `latest_assignment_tick` was 5 and the current tick was 6, then we'd return\n      false."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain glossary\ninput: "
      },
      {
        "role": "assistant",
        "content": "- **Relay-parent:**\n  - A particular relay-chain block which serves as an anchor and reference point for processes and data which depend on\n    relay-chain state.\n- **Active Leaf:**\n  - A relay chain block which is the head of an active fork of the relay chain.\n  - Block authorship provisioning jobs are spawned per active leaf and concluded for any leaves which become inactive.\n- **Candidate Selection:**\n  - The process by which the provisioner selects backable parachain block candidates to pass to block authoring.\n  - Two versions, prospective parachains candidate selection and legacy candidate selection. See their respective\n    protocol sections for details.\n- **Availability Core:**\n  - Often referred to simply as \"cores\", availability cores are an abstraction used for resource management. For the\n    provisioner, availability cores are most relevant in that core states determine which `para_id`s to provision\n    backable candidates for.\n  - For more on availability cores see Scheduler Module: Availability\n    Cores\n- **Availability Bitfield:**\n  - Often referred to simply as a \"bitfield\", an availability bitfield represents the view of parablock candidate\n    availability from a particular validator's perspective. Each bit in the bitfield corresponds to a single\n    availability core.\n  - For more on availability bitfields see availability\n- **Backable vs. Backed:**\n  - Note that we sometimes use \"backed\" to refer to candidates that are \"backable\", but not yet backed on chain.\n  - Backable means that a quorum of the candidate's assigned backing group have provided signed affirming statements."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain possible attacks / threat model\ninput: "
      },
      {
        "role": "assistant",
        "content": "Webassembly is already sandboxed, but there have already been reported multiple\nCVEs enabling remote code execution. See e.g. these two advisories from\nMar 2023\nand Jul 2022.\n\nSo what are we actually worried about? Things that come to mind:\n\n1. **Consensus faults** - If an attacker can get some source of randomness they\n   could vote against with 50% chance and cause unresolvable disputes.\n2. **Targeted slashes** - An attacker can target certain validators (e.g. some\n   validators running on vulnerable hardware) and make them vote invalid and get\n   them slashed.\n3. **Mass slashes** - With some source of randomness they can do an untargeted\n   attack. I.e. a baddie can do significant economic damage by voting against\n   with 1/3 chance, without even stealing keys or completely replacing the\n   binary.\n4. **Stealing keys** - That would be pretty bad. Should not be possible with\n   sandboxing. We should at least not allow filesystem-access or network access.\n5. **Taking control over the validator.** E.g. replacing the `polkadot` binary\n   with a `polkadot-evil` binary. Should again not be possible with the above\n   sandboxing in place.\n6. **Intercepting and manipulating packages** - Effect very similar to the\n   above, hard to do without also being able to do 4 or 5.\n\nWe do not protect against (1), (2), and (3), because there are too many sources\nof randomness for an attacker to exploit.\n\nWe provide very good protection against (4), (5), and (6)."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain cumulus sdk\ninput: "
      },
      {
        "role": "assistant",
        "content": "A set of tools for writing Substrate-based Polkadot\nparachains. Refer to the included overview\nfor architectural details, and the Connect to a relay chain how-to\nguide for a guided walk-through\nof using these tools.\n\nIt's easy to write blockchains using Substrate, and the overhead of writing parachains' distribution, p2p, database, and\nsynchronization layers should be just as low. This project aims to make it easy to write parachains for Polkadot by\nleveraging the power of Substrate.\n\nCumulus clouds are shaped sort of like dots; together they form a system that is intricate, beautiful and functional."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain consensus\ninput: "
      },
      {
        "role": "assistant",
        "content": "`parachain-consensus`\nis a consensus engine for Substrate that follows a Polkadot relay\nchain. This will run a Polkadot node internally,\nand dictate to the client and synchronization algorithms which chain to follow,\nfinalize, and treat as best."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain relay chain interaction\ninput: "
      },
      {
        "role": "assistant",
        "content": "To operate a parachain node, a connection to the corresponding relay chain is necessary. This can be achieved in one of\nthree ways:\n1. Run a full relay chain node within the parachain node (default)\n2. Connect to an external relay chain node via WebSocket RPC\n3. Run a light client for the relay chain\n\n### In-process Relay Chain Node\nIf an external relay chain node is not specified (default behavior), then a full relay chain node is spawned within the\nsame process.\n\nThis node has all of the typical components of a regular Polkadot node and will have to fully sync with the relay chain\nto work.\n\n### Example command\npolkadot-parachain \\\n\t--chain parachain-chainspec.json \\\n\t--tmp \\\n\t-- \\\n\t--chain relaychain-chainspec.json\n\n### External Relay Chain Node\nAn external relay chain node is connected via WebSocket RPC by using the `--relay-chain-rpc-urls` command line\nargument. This option accepts one or more space-separated WebSocket URLs to a full relay chain node. By default, only\nthe first URL will be used, with the rest as a backup in case the connection to the first node is lost.\n\nParachain nodes using this feature won't have to fully sync with the relay chain to work, so in general they will use\nfewer system resources.\n\n**Note:** At this time, any parachain nodes using this feature will still spawn a significantly cut-down relay chain\nnode in-process. Even though they lack the majority of normal Polkadot subsystems, they will still need to connect\ndirectly to the relay chain network.\n\n### Example command\n\npolkadot-parachain \\\n\t--chain parachain-chainspec.json \\\n\t--tmp \\\n\t--relay-chain-rpc-urls \\\n\t\t\"ws://relaychain-rpc-endpoint:9944\" \\\n\t\t\"ws://relaychain-rpc-endpoint-backup:9944\" \\\n\t-- \\\n\t--chain relaychain-chainspec.json\n\n### Relay Chain Light Client\nAn internal relay chain light client provides a fast and lightweight approach for connecting to the relay chain network.\nIt provides relay chain notifications and facilitates runtime calls.\n\nTo specify which chain the light client should connect to, users need to supply a relay chain chain-spec as part of the\nrelay chain arguments.\n\n**Note:** At this time, any parachain nodes using this feature will still spawn a significantly cut-down relay chain\nnode in-process. Even though they lack the majority of normal Polkadot subsystems, they will still need to connect\ndirectly to the relay chain network.\n\n### Example command\npolkadot-parachain \\\n\t--chain parachain-chainspec.json \\\n\t--tmp \\\n\t--relay-chain-light-client \\\n\t-- \\\n\t--chain relaychain-chainspec.json"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain runtime\ninput: "
      },
      {
        "role": "assistant",
        "content": "Each Substrate blockchain provides a runtime. The runtime is the state transition function of the\nblockchain. Cumulus provides interfaces and extensions to convert a Substrate FRAME runtime into a\nParachain runtime. Polkadot expects each runtime exposes an interface for validating a\nParachain's state transition and also provides interfaces for the Parachain to send and receive\nmessages of other Parachains.\n\nTo convert a Substrate runtime into a Parachain runtime, the following code needs to be added to the\nruntime:\ncumulus_pallet_parachain_system::register_validate_block!(Block, Executive);\n\nThis macro call expects the `Block` and `Executive` type. It generates the `validate_block` function\nthat is expected by Polkadot to validate the state transition.\n\nWhen compiling a runtime that uses Cumulus, a WASM binary is generated that contains the *full* code\nof the Parachain runtime plus the `validate_block` functionality. This binary is required to\nregister a Parachain on the relay chain.\n\nWhen the Parachain validator calls the `validate_block` function, it passes the PoVBlock (See Block\nbuilding for more information) and the parent header of the Parachain that is\nstored on the relay chain. From the PoVBlock witness data, Cumulus reconstructs the partial trie.\nThis partial trie is used as storage while executing the block. Cumulus also redirects all storage\nrelated host functions to use the witness data storage. After the setup is done, Cumulus calls\n`execute_block` with the transactions and the header stored in the PoVBlock. On success, the new\nParachain header is returned as part of the `validate_block` result."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain node\ninput: "
      },
      {
        "role": "assistant",
        "content": "Parachains support light-clients, full nodes, and authority nodes. Authority nodes are called\nCollators in the Polkadot ecosystem. Cumulus provides the consensus implementation for a\nParachain and the block production logic.\n\nThe Parachain consensus will follow the relay chain to get notified about which Parachain blocks are\nincluded in the relay-chain and which are finalized. Each block that is built by a Collator is sent\nto a validator that is assigned to the particular Parachain. Cumulus provides the block production\nlogic that notifies each Collator of the Parachain to build a Parachain block. The\nnotification is triggered on a relay-chain block import by the Collator. This means that every\nCollator of the Parachain can send a block to the Parachain validators. For more sophisticated\nauthoring logic, the Parachain will be able to use Aura, BABE, etc. (Not supported at the moment)\n\nA Parachain Collator will join the Parachain network and the relay-chain network. The Parachain\nnetwork will be used to gossip Parachain blocks and to gossip transactions. Collators will only\ngossip blocks to the Parachain network that have a high chance of being included in the relay\nchain. To prove that a block is probably going to be included, the Collator will send along side\nthe notification the so-called candidate message. This candidate message is issued by a Parachain\nvalidator after approving a block. This proof of possible inclusion prevents spamming other collators\nof the network with useless blocks.\nThe Collator joins the relay-chain network for two reasons. First, the Collator uses it to send the\nParachain blocks to the Parachain validators. Secondly, the Collator participates as a full-node\nof the relay chain to be informed of new relay-chain blocks. This information will be used for the\nconsensus and the block production logic."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain block building\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot requires that a Parachain block is transmitted in a fixed format. These blocks sent by a\nParachain to the Parachain validators are called proof-of-validity blocks (PoVBlock). Such a\nPoVBlock contains the header and the transactions of the Parachain as opaque blobs (`Vec<u8>`). They\nare opaque, because Polkadot can not and should not support all kinds of possible Parachain block\nformats. Besides the header and the transactions, it also contains the witness data and the outgoing\nmessages.\n\nA Parachain validator needs to validate a given PoVBlock, but without requiring the full state of\nthe Parachain. To still make it possible to validate the Parachain block, the PoVBlock contains the\nwitness data. The witness data is a proof that is collected while building the block. The proof will\ncontain all trie nodes that are read during the block production. Cumulus uses the witness data to\nreconstruct a partial trie and uses this as storage when executing the block.\n\nThe outgoing messages are also collected at block production. These are messages from the Parachain\nthe block is built for to other Parachains or to the relay chain itself."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain runtime upgrade\ninput: "
      },
      {
        "role": "assistant",
        "content": "Every Substrate blockchain supports runtime upgrades. Runtime upgrades enable a blockchain to update\nits state transition function without requiring any client update. Such a runtime upgrade is applied\nby a special transaction in a Substrate runtime. Polkadot and Cumulus provide support for these\nruntime upgrades, but updating a Parachain runtime is not as easy as updating a standalone\nblockchain runtime. In a standalone blockchain, the special transaction needs to be included in a\nblock and the runtime is updated.\n\nA Parachain will follow the same paradigm, but the relay chain needs to be informed before\nthe update. Cumulus will provide functionality to notify the relay chain about the runtime update. The\nupdate will not be enacted directly; instead it takes `X` relay blocks (a value that is configured\nby the relay chain) before the relay chain allows the update to be applied. The first Parachain\nblock that will be included after `X` relay chain blocks needs to apply the upgrade.\nIf the update is applied before the waiting period is finished, the relay chain will reject the\nParachain block for inclusion. The Cumulus runtime pallet will provide the functionality to\nregister the runtime upgrade and will also make sure that the update is applied at the correct block.\n\nAfter updating the Parachain runtime, a Parachain needs to wait a certain amount of time `Y`\n(configured by the relay chain) before another update can be applied.\n\nThe WASM blob update not only contains the Parachain runtime, but also the `validate_block`\nfunction provided by Cumulus. So, updating a Parachain runtime on the relay chain involves a\ncomplete update of the validation WASM blob."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain init bridge and run relayer between bridgehubrococo and bridgehubwestend\ninput: "
      },
      {
        "role": "assistant",
        "content": "**Accounts of BridgeHub parachains:**\n- `Bob` is pallet owner of all bridge pallets\n\n### Run with script\ncd <polkadot-sdk-git-repo-dir>\n\n./bridges/testing/environments/rococo-westend/bridges_rococo_westend.sh run-finality-relay\n\n**Check relay-chain headers relaying:**\n- Rococo parachain: - https://polkadot.js.org/apps/?rpc=ws%3A%2F%2F127.0.0.1%3A8943#/chainstate - Pallet:\n  **bridgeWestendGrandpa** - Keys: **bestFinalized()**\n- Westend parachain: - https://polkadot.js.org/apps/?rpc=ws%3A%2F%2F127.0.0.1%3A8945#/chainstate - Pallet:\n  **bridgeRococoGrandpa** - Keys: **bestFinalized()**\n\n**Check parachain headers relaying:**\n- Rococo parachain: - https://polkadot.js.org/apps/?rpc=ws%3A%2F%2F127.0.0.1%3A8943#/chainstate - Pallet:\n  **bridgeWestendParachains** - Keys: **parasInfo(None)**\n- Westend parachain: - https://polkadot.js.org/apps/?rpc=ws%3A%2F%2F127.0.0.1%3A8945#/chainstate - Pallet:\n  **bridgeRococoParachains** - Keys: **parasInfo(None)**"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain the planck unit\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The smallest unit of account balance on Polkadot SDK-based blockchains is Planck, named after the Planck Length. DOT equals 1010 Planck, while Kusama's KSM equals 1012 Planck.\nPolkadotKusama\n\n\n\n\n\nUnit\nDecimal Places\nConversion to Planck\nConversion to DOT\n\n\n\n\nPlanck\n0\n1 Planck\n0.0000000001 DOT\n\n\nMicrodot (uDOT)\n4\n104 Planck\n0.0000010000 DOT\n\n\nMillidot (mDOT)\n7\n107 Planck\n0.0010000000 DOT\n\n\nDot (DOT)\n10\n1010 Planck\n1.0000000000 DOT\n\n\nMillion (MDOT)\n16\n1016 Planck\n1,000,000.00 DOT\n\n\n\n\n\n\n\n\nUnit\nDecimal Places\nConversion to Planck\nConversion to KSM\n\n\n\n\nPlanck\n0\n1 Planck\n0.000000000001 KSM\n\n\nPoint\n3\n103 Planck\n0.000000001000 KSM\n\n\nMicroKSM (uKSM)\n6\n106 Planck\n0.000001000000 KSM\n\n\nMilliKSM (mKSM)\n9\n109 Planck\n0.001000000000 KSM\n\n\nKSM\n12\n1012 Planck\n1.000000000000 KSM"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain dot inflation\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "DOT is an inflationary token, with\nfixed annual expansion of the token supply of 120,000,000 DOT,\nof which 15% goes to the treasury and 85% to\nstakers.\nIt is essential to understand that the primary objective of inflation is to incentivize network\nparticipants through\nNominated Proof of Stake (NPoS) and to grow the\nnetwork through funding the on-chain treasury. The token inflation rate can be updated through\non-chain governance based on thorough tokenomics research.\nBelow is a 25-year prediction of DOT gross annual inflation (red line) and DOT total issuance (blue\nline), assuming the current fixed inflation rate.\nThe total issuance takes into account the gross DOT inflation and thus does not consider tokens that\nare burned.\nNet DOT inflation depends on treasury burns and\ncoretime sales that are variables and\nthus cannot be predicted. Net inflation can be defined as follows:\nNet Inflation = Gross fixed inflation - burned supply (treasury + coretime sales)\nWhere Gross fixed inflation is the annual inflation of 120M DOT and the burned supply is the\nannual burn supply due to treasury burns and coretime sale burns."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain obtaining testnet tokens\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Testnet tokens allow experimentation on Polkadot's features. Obtain testnet tokens on the official faucet. For faucet issues, use the support chat or create an issue.\nPaseoWestend\n\n\nPaseo mirrors Polkadot's runtime. Obtain PAS tokens here or via !drip <PASEO_ADDRESS> in the Matrix chatroom.\n\n\n\nUnit\nDecimal Places\nConversion to Planck\nConversion to PAS\n\n\n\n\nPlanck\n0\n1 Planck\n0.0000000001 PAS\n\n\nMicrodot (uPAS)\n4\n104 Planck\n0.0000010000 PAS\n\n\nMillidot (mPAS)\n7\n107 Planck\n0.0010000000 PAS\n\n\nDot (PAS)\n10\n1010 Planck\n1.0000000000 PAS\n\n\nMillion (MPAS)\n16\n1016 Planck\n1,000,000.00 PAS\n\n\n\n\n\nWestend is Polkadot's testnet. Obtain WND tokens via the faucet or !drip <WESTEND_ADDRESS> in the Matrix chatroom. Validators can also earn WND. Watch the video guide.\n\n\n\nUnit\nDecimal Places\nConversion to Planck\nConversion to WND\n\n\n\n\nPlanck\n0\n1 Planck\n0.000000000001 WND\n\n\nPoint\n3\n103 Planck\n0.000000001000 WND\n\n\nMicroWND (uWND)\n6\n106 Planck\n0.000001000000 WND\n\n\nMilliWND (mWND)\n9\n109 Planck\n0.001000000000 WND\n\n\nWND\n12\n1012 Planck\n1.000000000000 WND"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain proof-of-stake (pos)\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Blockchain networks use consensus mechanisms to\nfinalize blocks on the chain. Consensus is the process of agreeing on something, in this case, the\nprogression of the blockchain or how blocks are added to the chain. Consensus consists of two\nactions:\nBlock production, i.e. the way multiple blocks candidates are produced, and\nBlock finality, i.e. the way only one block out of many candidates is selected and added to\n  the canonical chain (see this article\n  for more information about finality).\nProof-of-Work (PoW) and Proof-of-Stake (PoS) are well-known mechanisms used to reach consensus in a\nsecure and trustless way on public blockchains, where there are many participants who do not know\neach other (and probably never will). In PoW, network security relies on the fact that the miners\nwho are responsible for adding blocks to the chain must compete to solve difficult mathematic\npuzzles to add blocks - a solution that has been criticized for the wastage of energy. For doing\nthis work, miners are typically rewarded with tokens.\nIn PoS networks like Polkadot, the security of the network depends on the amount of capital locked\non the chain: the more the capital locked, the lower the chance of an attack on the network, as the\nattacker needs to incur a heavy loss to orchestrate a successful attack (more on this later on). The\nprocess of locking tokens on the chain is called staking.\nSimilar to the miners in PoW networks, PoS networks have validators, but they do not have to\ncompete with each other to solve mathematical puzzles. They are instead pre-selected to produce the\nblocks based on the stake backing them. Token holders can lock funds on the chain and for doing so,\nthey are getting staking rewards. There is thus an economic incentive for token holders to\nbecome active participants who contribute to the economic security and stability of the network. PoS\nnetworks in general are therefore more inclusive than PoW networks, as participants do not need to\nhave either technical knowledge about blockchain technology or experience in running mining\nequipment.\nPoS ensures that everybody participating in the staking process has \"skin in the game\" and thus can\nbe held accountable. In case of misbehavior, participants in the staking process can be punished or\nslashed, and depending on the gravity of the situation, their stake can\nbe partly or fully confiscated by the network. It is not in a staker's economic interest to\norchestrate an attack and risk losing tokens. Any rational actor staking on the network would want\nto get rewarded, and the PoS network rewards good behavior and punishes bad behavior."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain nominated proof-of-stake (npos)\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot implements\nNominated Proof-of-Stake (NPoS), a relatively novel\nand sophisticated mechanism to select the validators who are allowed to participate in its\nconsensus protocol. NPoS encourages token holders to participate as\nnominators.\nAny potential validators can indicate their intention to be a validator candidate. Their candidacies\nare made public to all nominators, and a nominator, in turn, submits a\ncapped list of candidates that it\nsupports, and the network will automatically distribute the stake among validators in an even manner\nso that the economic security is maximized. In the next era, a certain number of validators having\nthe highest backing get elected and become active. For more information about the election algorithm\ngo to this page on the wiki or\nthis research article. As a\nnominator, a minimum bond\nis required to submit an intention to nominate, which can be thought of as registering to be a\nnominator. Note that in NPoS the stake of both nominators and validators can be\nslashed. For an in-depth review of NPoS see\nthis research article.\nMinimum Nomination to Receive Staking Rewards\nThe minimum nomination intent does not guarantee staking rewards. The nominated amount has to be greater than minimum active nomination, which is a dynamic value that can be much higher than the minimum nomination intent. This dynamic value depends on the amount of tokens being staked, in addition to the selected nominations."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain nominating validators\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Nominating requires 2 actions:\nLocking tokens on-chain.\nSelecting a set of validators, to whom these locked tokens will automatically be allocated to.\nHow many tokens you lock up is completely up to you - as are the validators you wish to select. The\naction of locking tokens is also known as bonding. You can also refer to your locked tokens as\nyour bonded tokens, or staked tokens. Likewise, selecting validators is also known as backing or\nnominating validators. These terms are used interchangeably by the community. From now on locked\ntokens will be referred to as bonded tokens.\nOnce the previous 2 steps are completed and you are nominating, your bonded tokens could be\nallocated to one or more of your selected validators, and this happens every time the active\nvalidator set changes. This validator set is updated every era.\nUnlike other staking systems, Polkadot automatically chooses which of your selected validators will\nbe backed by your bonded tokens. Selecting a group of validators increases your chances of\nconsistently backing at least one who is active. This results in your bonded tokens being allocated\nto validators more often, which means more network security and more rewards. This is in strong\ncontrast to other staking systems that only allow you to back one validator; if that validator is\nnot active, you as a staker will also not be.\nPolkadot's nomination model solves this. It uses tools ranging from election theory to game theory\nto discrete optimization, to develop an efficient validator selection process that offers fair\nrepresentation and security, thus avoiding uneven power and influence among validators. The election\nalgorithms are based on the Proportional Justified Representation (PJR) methods like\nPhragmen. For more information about PJR methods visit\nthis research article."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain eras and sessions\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The stake from nominators is used to increase the number of tokens held by such candidates,\nincreasing their chance of being selected by the election algorithm for block production during a\nspecific era. An era is a period of 24 hours (6 hours on Kusama) during which an active set\nof validators is producing blocks and performing other actions on the chain. This means that not all\nvalidators are in the active set and such set changes between eras. Each era is divided into 6\nepochs or sessions during which validators are assigned as block producers to specific time\nframes or slots. This means that validators know the slots when they will be required to produce\na block within a specific session, but they do not know all the slots within a specific era. Having\nsessions adds a layer of security because it decreases the chance of having multiple validators\nassigned to a slot colluding to harm the network."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain staking rewards\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Validators who produce a block are rewarded with tokens, and they can share rewards with their\nnominators. Both validators and nominators can stake their tokens on chain and receive staking\nrewards at the end of each era. The staking system pays out rewards equally to all validators\nregardless of stake. Thus, having more stake in a validator does not influence the amount of block\nrewards it receives. This avoids the centralization of power to a few validators. There is a\nprobabilistic component in the calculation of rewards, so they may not be exactly equal for all\nvalidators. In fact, during each era validators can earn era points by doing different tasks on\nchain. The more the points, the higher the reward for a specific era. This promotes validators'\nactivity on chain. To know more about era points, and how and on which basis they are distributed\nvisit the dedicated page. Distribution of the\nrewards is pro-rata to all stakers after the validator's commission is deducted."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain skin in the game when staking\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The security of PoS networks depends on the amount of staked tokens. To successfully attack the\nnetwork, a malicious actor would need to accrue a large number of tokens or would need different\nparticipants to collude and act maliciously. If there is an attack in the case of NPoS, both the\nvalidator(s) and nominators will be slashed resulting in their stake being partially or fully\nconfiscated by the network and then deposited to the treasury. There is little interest for a\nrational network participant to act in a harmful way because NPoS ensures that all participants can\nbe held accountable for their bad actions. In NPoS, validators are paid equal rewards regardless of\nthe amount of stake backing them, thus avoiding large payouts to few large validators which might\nlead to centralization."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain tasks and responsibilities of a nominator\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Validators. Since validator slots are limited, most of those who wish to stake their tokens and\ncontribute to the economic security of the network will be nominators, thus here we focus on the\nrole of nominators. However, it is worth mentioning that validators do most of the heavy lifting:\nthey run the validator nodes and manage\nsession keys, produce new block\ncandidates in BABE, vote and come to consensus in\nGRANDPA, validate the state transition function of\nparachains, and possibly some other responsibilities regarding data availability and\nXCM. For more information, you can take a look at the\nvalidator docs to understand what you need to do as a validator. If you want\nto become a validator you can consult\nthis guide.\nNominators. Nominators have far fewer responsibilities than validators. These include selecting\nvalidators and monitoring their performance, keeping an eye on changing commission rates (a\nvalidator can change commission at any time), and general health monitoring of their validators'\naccounts. Thus, while not being completely set-it-and-forget-it, a nominator's experience is\nrelatively hands-off compared to that of a validator, and even more with\nnomination pools. For more information, you can take a look at the\nnominator guide to understanding your responsibilities as a nominator.\nIf you want to become a nominator, see this guide. If you are a\nbeginner and would like to securely stake your tokens using the Polkadot-JS UI, refer to\nthis\nsupport article. The tutorial presented in the support article is demonstrated on Polkadot, but the\nprocedure is the same for Kusama.\nPolkadot Staking Dashboard\nThe Staking Dashboard provides a more user-friendly alternative to staking. See the instructions in this support article to learn how to stake with the dashboard.\nPools. Pools are \"built\" on top of NPoS to provide a very low barrier to entry to staking,\nwithout sacrificing Polkadot's strict security model."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain selection of validators\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The task of choosing validators is not simple, as it should take into account nominator reward and\nrisk preferences. Ideally one aims to maximize the reward-to-risk ratio by maximizing rewards and\nminimizing risks, with sometimes having to compromise between the two, as minimizing risks might\ndecrease rewards as well. Nominators should pay attention, especially to six criteria when\nnominating validators (not in order of importance):\nrecent history of the era points earned across eras\nvalidator's self stake (shows skin in the game)\ntotal stake backing the validator (which is the sum of self stake and the stake coming from\n  nominators)\ncommission fees (i.e. how much validators charge nominators)\nverified identity\nprevious slashes\nThe diagram below shows how the selection of those criteria affects the reward-to-risk ratio.\nValidator Selection Criteria\u00b6\nTo maximize rewards and minimize risk, one could select those validators that:\nhave era points above average (because they will get more rewards for being active),\nhave the total stake backing the validator below the average active validator stake (because they\n  will pay out more rewards per staked token),\nhave high own stake (because if slashed they have something to lose),\nhave low commission fees but not 0% (because it makes sense that for doing the heavy lifting,\n  validators ask for a small commission),\nhave on-chain registered identity (because it adds a layer of trust and possibly provides access\n  to their website and contact details),\nand have not been slashed (meaning that their on-chain behavior is genuine).\nNetwork Providers\u00b6\nFor successful operation, a Validator node should always be ensured to meet the required\nsoftware, hardware, and network bandwidth specifications.\nUnderstandably, most of the validator nodes run on cloud service providers that guarantee high\nhardware specifications and high levels of availability and connectivity. Keep in mind that a\nvalidator in the active set is supposed to be fully online and available for producing blocks. If\nthe active validator node goes offline due to network interruptions or a power outage, that\nvalidator will get fewer rewards.\nChecking Validators using Network Providers\nYou can connect your stash account to the Polkawatch app. The app will show your rewards earned in the past 60 eras divided by network provider and country. You will be able to see networks used by each validator and verify if your validators are using providers who support PoS. This is also a great tool to explore how decentralized your nominations are and act accordingly.\nKeeping Track of Nominated Validators\u00b6\nNominators must periodically check their validators\nNominating is not a \"set and forget\" operation. The whole NPoS system is dynamic and nominators should periodically monitor the performance and reputation of their validators. Failing to do so could result in applied slashes and/or rewards not being paid out, possibly for a prolonged period.\nAlthough the theory can be used as a general guideline, in practice it is more complicated and\nfollowing the theory might not necessarily lead to the desired result. Validators might have the\ntotal stake backing them below average, low commission and above average era points in one era and\nthen have a different profile in the next one. Selection based on the criteria like on-chain\nidentity, slash history and low commission make the staking rewards deterministic. But some criteria\nvary more than others, with era points being the most variable and thus one of the key probabilistic\ncomponents of staking rewards. Part of this probability is directly related to the fact that a\nvalidator can produce blocks for a parachain (i.e. para-validators) or the relay chain, with\npara-validators earning more era points per unit time (see\nthis page for more information). The\nrole can switch between sessions, and you can look at\nthe staking tab on the Polkadot-JS UI to know which\nvalidator is producing blocks for the relay chain or parachains.\nIt is not recommended to change nominations because of the low era points of a validator in a single\nera. Variability in rewards due to the era points should level out over time. If a validator\nconsistently gets era points below average, it makes sense to nominate a better-performing validator\nfor the health of the network and increased staking rewards. See\nthis\nsupport article to understand in detail how to select the set of validators to nominate."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain stash account and staking proxy\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Two different accounts can be used to securely manage your funds while staking.\nStash: This account holds funds bonded for staking, but delegates all staking functions to a\n  staking proxy account. You may actively participate in staking with a stash private key kept in a\n  cold wallet like Ledger, meaning it stays offline all the time. Having a staking proxy will allow\n  you to sign all staking-related transactions with the proxy instead of using your Ledger device.\n  This will allow you:\n\n\nto avoid carrying around your Ledger device just to sign staking-related transactions, and\n\n\nto keep the transaction history of your stash clean\n\n\nStaking Proxy: This account acts on behalf of the stash account, signalling decisions about\n  nominating and validating. It can set preferences like commission (for validators) and the staking\n  rewards payout account. The earned rewards can be bonded (locked) immediately for bonding on your\n  stash account, which would effectively compound the rewards you receive over time. You could also\n  choose to have them deposited to a different account as a free (transferable) balance. If you are\n  a validator, it can also be used to set your session keys. Staking\n  proxies only need sufficient funds to pay for the transaction fees.\nWarning\nNever leave a high balance on a proxy account which are usually \"hot\" as their private key is stored on the device (PC, phone) and it is always exposed to the internet for potential hacks and scams. It is good practice to deposit rewards on the stash account or to send them to another account on a cold wallet.\nThis hierarchy of separate keys for stash and staking accounts was designed to add a layer of\nprotection to nominators and validator operators. The more often one exposes and uses a private key,\nthe higher its vulnerability for hacks or scams. So, if one uses a key for multiple roles on a\nblockchain network, it is likely that the account can get compromised. Note that the damage linked\nto stolen private keys is different depending on the type of account derivation. In the case of soft\nderivation, all derived accounts are compromised. More information about account derivation can be\nfound here.\nInfo\nFor Ledger users staking directly on Ledger Live, currently, there is no option to use separate stash and staking proxy accounts.\nLedger devices are now supported in SubWallet,\nTalisman, and PolkaGate extension. Users can\nimport their Ledger accounts in the extension and use them as a stash in staking. You can find more\ninformation about, SubWallet, Talisman, PolkaGate and other wallets that officially secured funding\nfrom the treasury here."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain claiming staking rewards\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Note that Kusama runs approximately 4x as fast as Polkadot, except for block production times.\nPolkadot will also produce blocks at approximately six-second intervals.\nRewards are calculated per era (approximately six hours on Kusama and twenty-four hours on\nPolkadot). These rewards are calculated based on era points, which have a probabilistic component.\nIn other words, there may be slight differences in your rewards from era to era, and even amongst\nvalidators in the active set at the same time. These variations should cancel out over a long enough\ntimeline. See the page on Validator Payout Guide.\nThe distribution of staking rewards to the nominators is not automatic and needs to be triggered by\nsomeone. Typically the validators take care of this, but anyone can permissionlessly trigger rewards\npayout for all the nominators whose stake has backed a specific validator in the active set of that\nera. Staking rewards are kept available for\na limited amount of time.\nFor more information on why this is so, see the page on simple payouts.\nPayouts\nPayouts are unclaimed rewards waiting to be paid out to both validators and nominators. If you go to the Staking payouts page on Polkadot-JS, you will see a list of all validators that you have nominated in the past 84 eras and for which you have not yet received a payout. The payout page is visible only to stakers.\nEach validator as well as their nominators have the option to trigger the payout for all unclaimed\neras. Note that this will pay everyone who was nominating that validator during those eras.\nTherefore, you may not see anything in this tab, yet still have received a payout if somebody\n(generally, but not necessarily, another nominator or the validator operator) has triggered the\npayout for that validator for that era.\nTime limit to claim staking rewards\nIf nobody claims your staking rewards within 84 eras, then you will not be able to claim them and they will be lost. Additionally, if the validator unbonds all their own stake, any pending payouts will also be lost.\nRewards can be directed to the same account used to sign the payout or to a completely unrelated\naccount. It is also possible to top-up / withdraw some bonded tokens without having to un-stake all\nstaked tokens.\nIf you wish to know if you received a payout, you will have to check via a block explorer. See\nthe relevant Support page\nfor details. For specific details about validator payouts, please see\nthis guide."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain chilling\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Chilling is the act of stepping back from any nominating or validating. It can be done by a\nvalidator or nominator at any time, taking effect in the next era.\nChilling can be validator-initiated, e.g. if there is a planned outage in the validator's\nsurroundings or hosting provider, and the validator wants to exit to protect themselves against\nslashing. Chilling will keep the validator active in the current era, but will move them to the\ninactive set in the next. The validator will not lose their nominators.\nFor more on chilling, see the How to Chill page on the main website."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain fast unstake\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Fast Unstaking feature is live!\nIf you accidentally bonded your tokens or your bonded tokens never backed any active validator, you can now unbond them immediately.\nIf your bonded balance did not back any validators for a\npre-determined period, you are eligible to\nperform fast unstaking. The staking dashboard will\nautomatically check if you qualify. For more information, visit the\n\"Fast Unstake\" section in this support article."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain pros of staking\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Earn rewards for contributing to the network's security through staking.\nLow barrier of entry through Nomination Pools.\nCan choose multiple validators\n  which can help to decentralize the network through the sophisticated\n  NPoS system\n85% of inflation/year of the tokens is primarily intended for staking rewards. Check the\n  inflation section on the Wiki for more information."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain cons of staking\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Tokens will be locked during the\n  unbonding period and no rewards will be\n  earned if you unbond.\nPossible punishment in case of the active validator found to be misbehaving (see\n  slashing).\nLack of liquidity i.e. You would not be able to use the tokens for participating in crowdloans or\n  transfer them to different account etc.\nUnbonding Period Length\u00b6\nThe unbonding period provides a safety net\nfor slashing offenses identified in\npast eras,\nwhich can hold the respective validators and their nominators accountable. The unbonding period is\ncrucial in mitigating ex post facto slashing, particularly in guarding against long-range attacks.\nWhen a client encounters a chain finalized by\nGRANDPA that originates more than one\nunbonding period in the past, it lacks the\nsecurity of slashing protection.\nEssentially, this period establishes a cadence for synchronizing with the chain or acquiring a\ncheckpoint within a timeframe that engenders trust. It's worth noting that while the choice of\nunbonding period length is somewhat\narbitrary, it unquestionably provides a higher level of security compared to a shorter period."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain how many validators?\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The top bound on the number of validators\nhas not been determined yet, but should only be limited by the bandwidth strain of the network due\nto peer-to-peer message passing.\nThe estimate of the number of validators that Polkadot will have at maturity is around 1000, while\nKusama is already operating at this threshold."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain why am i not receiving rewards?\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Nominating is not a set-and-forget action. Nominators need to monitor their nominations and ensure\nthey are eligible to receive staking rewards. Otherwise, they would be risking their funds to secure\nthe chain with no reward. If you are bonding significantly more than the Minimum Active Bond and yet\nnot receiving rewards, your nominations are all waiting, or your active validator has 100%\ncommission. However, if you bond funds close to the Minimum Active Bond, there could be several\npossibilities for not receiving staking rewards. The table below can be used to troubleshoot why you\nmight not be receiving staking rewards using Polkadot-JS UI.\nNomination Status\nWhat's happening?\nCauses\nWhat to do?\n\n\n\n\nNominated validators are all in waiting status.\nYour stake has not been assigned to any of the nominated validators. You cannot earn rewards, nor be slashed in that era.\nWaiting validators are not in the active set in the current era and the stake backing them is not used to secure the network. In simple words, NPoS \"does not see them\".\nChange your nominations. Try to select validators (with reasonable commission) that have high chances to end up in the active set.\n\n\nYou have some inactive, and some waiting nominations.\nValidators shown as \"Inactive\" in your staking dashboard are still in the active set and are producing blocks in the current era, but your stake has not been assigned to any of them. You will not earn rewards if your stake is not backing an active validator. In this case, you cannot be slashed either.\nScenario 1: You have bonded less than the Minimum Active Bond. Scenario 2: You have more than the Minimum Active Bond, but your account is at the tail end of the bags list and within your bag there are accounts with less stake than you, in front of you.\nScenario 1: Try bonding more funds. Scenario 2: Try to put your account in front of the accounts with less stake than you. Instructions available here\nJoin a Nomination Pool\nBy joining a nomination pool that is active and earning rewards, you can start earning staking rewards with as low as 1 DOT. The nomination pools typically have a dedicated pool operator who ensures that the pool's stake is always backing an active validator and is receiving rewards.\nBags List & Minimum Active Bond\nYou can find information about why you might not receive staking rewards on this support page and this video tutorial."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain resources\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "How Nominated Proof of Stake will work in Polkadot -\n  Blog post by Web3 Foundation researcher Alfonso Cevallos covering NPoS in Polkadot.\nValidator setup\nPolkadot validator selector tool - A tool\n  that helps nominators find reliable validators that meet quality-control criteria, including\n  commission rates, verified identity, etc.\nPolkadot-JS Guides\nIf you are an advanced user, see the Polkadot-JS guides about staking."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain data ownership\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In web3, ownership is achieved and validated through cryptography. Each user has a digital identity\nbound to a set of cryptographic keys usually based on the public key cryptographic scheme, i.e., the\nfamous public and private key pair.\nUnlike Web2 which is driven by email IDs, phone numbers, and passwords, users onboarding to Web3\njust need to generate a key pair. The public key can be the identity that can be shared with anybody\nto send you messages or assets, while the private key is used to access your account, sign messages,\ntransfer funds, edit identity details, etc. Keeping your private key secure is\nessential to avoid identity theft or consequent loss of funds. Currently, scams are one of the main\nfactors hindering web3 adoption. No legitimate person or entity will ever ask you to share your\nprivate key, and those who attempt to do so are likely trying to steal your digital identity and\nanything you own related to it.\nTo mitigate risks of key mismanagement (for non-custodial accounts, i.e. when you have custody\nof your keys) there are account abstraction solutions that\nseparate the key management from the user experience. To mitigate key hacks, there are cold wallet\nsolutions where the private key is generated and stored on dedicated devices with secure elements\nthat are not exposed to the internet (see Ledger), or dedicated applications that can\nbe installed on air-gapped devices such as phones (see Polkadot Vault). For\ncustodial accounts, you trust third parties to manage your keys and give you access whenever\nneeded.\nTo summarize, data ownership comes from the fact that any message you sign with your private key\ncomes from your digital identity, and the signature proof can be cryptographically verified. Unless\nsomeone else stole your keys, you and only you are held accountable for signing the messages and are\nresponsible for the information on your account. Transferring an NFT between\ntwo accounts is essentially a transfer of ownership."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain data immutability\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "But what if the data we own can be easily modified or tampered with after they have been signed and\nstored?\nHere is where blockchain technology plays an important role. Blockchain networks comprise of\ndistributed state machines where increments of data are stored within blocks that build on each\nother using hash functions. For example, the hash of block N + 1 contains data of that block\ntogether with the hash of the previous block N. This creates the situation where if you modify the\ncontent of block N you will change the hash of block N + 1, N + 2, etc. essentially breaking\nthe chain. If a blockchain network is not sufficiently decentralized, it can be possible to add an\ninvalid block (a block with invalid transactions) or to censor certain transactions. In\ndecentralized proof-of-stake blockchains like Polkadot however, such attacks are financially\nexpensive and attempting them can get you slashed.\nSo, with blockchain as a means of storing data and transactions permanently without an option to\nmodify them, we can ensure what we cryptographically sign with our digital identity is set in stone\ndigitally."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain data retrievability\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "But what if our data are stored in a blockchain, but that blockchain is run on a centralized server\nor by different computers belonging to the same operator?\nThat server or those computers can be easily shut down, the blockchain can be stopped from running\nand its data wiped out. This can be achieved from the inside by the malicious network participants\nor from the outside by regulatory rules and other forces. Though blockchain offers immutability,\nthere would be little sense in using a centralized blockchain to prove ownership as it can possibly\ncease to exist in the future.\nData retrievability is dependent on how resilient the blockchain is. Resiliency is achieved through\nelements such as decentralization, economic incentives, and on-chain governance to ensure the\nnetwork can sustain on its own.\nData Retrievability vs. Data Availability\nData retrievability is the ability of nodes to retrieve\u00a0historical information\u00a0from the blockchain. Historical data is not needed to verify new blocks; it is only required for synching full nodes from the Genesis block or serving specific historical requests.\nData availability assures full nodes can access and verify the full transactions associated with\na specific block. It does not necessarily imply that the data is accessible forever. For more\ninformation about data availability on Polkadot, see the\ndedicated section on the parachain protocol page."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain decentralization\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Having multiple nodes belonging to numerous independent identities increases network resiliency and\nthus data retrievability.\nBlockchain is a state machine, and consensus must be achieved on every single state transition by\nevery node on the blockchain network. In Proof of Work (PoW) based blockchains, which let any node\nin the network produce a block, consensus is achieved probabilistically by building on the longest\nchain (at the cost of energy-intensive computations). Proof of Stake (PoS) based blockchains like\nPolkadot enable deterministic consensus by allowing only a limited number of privileged nodes to\nproduce blocks. A PoW blockchain can be considered centralized if a single entity can capture 51% of\nnetwork nodes. Similarly, a PoS blockchain can be considered centralized if a single entity controls\nmore than one-third of nodes, as a two-thirds majority is required to arrive at a deterministic\nconsensus. Different blockchains have different levels of decentralization.\nNowadays, most of the nodes cannot be run on consumer-grade hardware. Node running equipment is\ntypically rented through service providers. Resiliency is also achieved by ensuring nodes run on as\nmany different providers as possible and avoiding a significant share of the nodes being run under\nthe same provider in the same geographic region. A legislation change or a natural disaster could\nimpact a considerable fraction of the nodes and potentially stop the network. Polkadot's level of\ndecentralization can be explored through the Polkawatch app.\nThe Decentralized Nodes program aims to incentivize the creation\nof new validator nodes to increase the level of node decentralization."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain decentralized storage\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Blockspace is limited and valuable. Not all data we have can be stored on\nthe blockchain. Large files like pictures, music, movies, etc., typically will never be held on the\nblockchain. But where can we stored those files? To stick to the web3 vision, we need a resilient\nand decentralized storage solution.\nThe most important thing is that the proof of ownership is stored on the blockchain through the\nhashes of data and metadata. The files are uploaded on decentralized storage networks hosting\nprotocols like IPFS."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain stake allocation\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In Proof-of-Stake blockchains, security is dictated by how much stake is locked on-chain (financial\nsecurity). In a decentralized network, you want to ensure that the difficulty level for a financial\nattack to happen is equally difficult across all nodes. Polkadot's\nelection algorithm makes sure that the stake is maximized across all\nactive validators, and the variance in stake across validators is minimized as much as possible."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain economic incentives\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Strong incentives are essential to incentivize network participants to run nodes and secure the\nnetwork. Strong incentives are possible because blockchain is a trustless system where there are no\nintermediaries between who sends a message and who receives it. Such incentives, coupled with\npunishment for bad behavior, ensure that most of the participants make the interest of the network\nand work together to improve it.\nBut from where are those incentives coming from? Polkadot's native token\nDOT is inflationary. Inflation is used to pay validators for running\nnodes and reward nominators for providing the necessary stake to secure the network."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain governance and treasury\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In Polkadot, an on-chain treasury together with an\nopen governance model allow to access funds in a fully\ndecentralized manner without any bank transaction whatsoever. This opens up the possibility to come\nto a decision through on-chain voting mechanism, promoting a sense of community and creating an\nindependent socio-economical environment."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain decentralized access points\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "But what if we have data we own stored on a resilient blockchain, but the only way to access the\nblockchain is through an RPC server? Whoever is behind the server or an attacker could present us\ndata that is not the truth. How can we trustlessly verify that the data is true?\nHere is where light clients play a key role. Light clients are clients that can sit on a web browser\nand can fetch data directly from blockchain. The figure below shows the architectural difference\nbetween web2 and web3 applications.\nIn web2 applications, data are stored on a centralized server, while in web3 applications, data (or\nbetter data proofs) are stored on the blockchain. With light clients, it is possible to access\nblockchain data through a full node and verify the validity of such data. They efficiently\nsynchronize (warp sync in case of Polkadot) with a full node to obtain (Merkle Root) commitment of\nthe latest chain state, and hence can trustlessly verify any response by full node against the\ncommitment. In this way, we can always verify that the data we see is the truth, which is done\nautomatically by the light client. Polkadot has a browser-embedded light client\nSubstrate connect that uses the\nsmoldot codebase. Most web3 applications today access\nblockchain data through a centralized RPC server.\nFor more details about the inner workings of Smoldot, see\nthis blog post and\nthis video."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain interoperability\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The Web3 landscape's expansion into a multi-layered ecosystem highlights the need for\ninteroperability. Blockchains compete and differentiate themselves based on decentralization,\nthroughput, and specific use case focus. Some aim for a single high-performance base-layer\nblockchain, while others focus on decentralization through layer-2 networks. With such diverse\napproaches, it's crucial for distinct on-chain environments to interoperate, especially for\ndevelopers building cross-chain applications and traditional systems interacting with multiple\nblockchains.\nVarious cross-chain interactions are employed to achieve interoperability, including token swaps,\ntoken bridges, native payments, contract calls, and programmable token bridges. Each mechanism\nserves specific functions, such as facilitating the exchange of tokens between different blockchains\nor enabling smart contract interactions across chains. Other interoperability solutions validate the\nstate of a source blockchain and relay transactions to the destination blockchain, which is\nessential for completing cross-chain interactions.\nInteroperability between chains having different consensus has been a challenging task. Most of\nhacks have exploited vulnerabilities in interoperability protocols. Polkadot provides secure\ninteroperability through XCM and XCMP to\nall blockchains attached to it. For more information, see the Polkadot 1.0 page\nand\nthe section about XCM and Accords in Polkadot Direction page."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain data ownership\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In web3, ownership is achieved and validated through cryptography. Each user has a digital identity\nbound to a set of cryptographic keys usually based on the public key cryptographic scheme, i.e., the\nfamous public and private key pair.\nUnlike Web2 which is driven by email IDs, phone numbers, and passwords, users onboarding to Web3\njust need to generate a key pair. The public key can be the identity that can be shared with anybody\nto send you messages or assets, while the private key is used to access your account, sign messages,\ntransfer funds, edit identity details, etc. Keeping your private key secure is\nessential to avoid identity theft or consequent loss of funds. Currently, scams are one of the main\nfactors hindering web3 adoption. No legitimate person or entity will ever ask you to share your\nprivate key, and those who attempt to do so are likely trying to steal your digital identity and\nanything you own related to it.\nTo mitigate risks of key mismanagement (for non-custodial accounts, i.e. when you have custody\nof your keys) there are account abstraction solutions that\nseparate the key management from the user experience. To mitigate key hacks, there are cold wallet\nsolutions where the private key is generated and stored on dedicated devices with secure elements\nthat are not exposed to the internet (see Ledger), or dedicated applications that can\nbe installed on air-gapped devices such as phones (see Polkadot Vault). For\ncustodial accounts, you trust third parties to manage your keys and give you access whenever\nneeded.\nTo summarize, data ownership comes from the fact that any message you sign with your private key\ncomes from your digital identity, and the signature proof can be cryptographically verified. Unless\nsomeone else stole your keys, you and only you are held accountable for signing the messages and are\nresponsible for the information on your account. Transferring an NFT between\ntwo accounts is essentially a transfer of ownership."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain data immutability\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "But what if the data we own can be easily modified or tampered with after they have been signed and\nstored?\nHere is where blockchain technology plays an important role. Blockchain networks comprise of\ndistributed state machines where increments of data are stored within blocks that build on each\nother using hash functions. For example, the hash of block N + 1 contains data of that block\ntogether with the hash of the previous block N. This creates the situation where if you modify the\ncontent of block N you will change the hash of block N + 1, N + 2, etc. essentially breaking\nthe chain. If a blockchain network is not sufficiently decentralized, it can be possible to add an\ninvalid block (a block with invalid transactions) or to censor certain transactions. In\ndecentralized proof-of-stake blockchains like Polkadot however, such attacks are financially\nexpensive and attempting them can get you slashed.\nSo, with blockchain as a means of storing data and transactions permanently without an option to\nmodify them, we can ensure what we cryptographically sign with our digital identity is set in stone\ndigitally."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain data retrievability\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "But what if our data are stored in a blockchain, but that blockchain is run on a centralized server\nor by different computers belonging to the same operator?\nThat server or those computers can be easily shut down, the blockchain can be stopped from running\nand its data wiped out. This can be achieved from the inside by the malicious network participants\nor from the outside by regulatory rules and other forces. Though blockchain offers immutability,\nthere would be little sense in using a centralized blockchain to prove ownership as it can possibly\ncease to exist in the future.\nData retrievability is dependent on how resilient the blockchain is. Resiliency is achieved through\nelements such as decentralization, economic incentives, and on-chain governance to ensure the\nnetwork can sustain on its own.\nData Retrievability vs. Data Availability\nData retrievability is the ability of nodes to retrieve\u00a0historical information\u00a0from the blockchain. Historical data is not needed to verify new blocks; it is only required for synching full nodes from the Genesis block or serving specific historical requests.\nData availability assures full nodes can access and verify the full transactions associated with\na specific block. It does not necessarily imply that the data is accessible forever. For more\ninformation about data availability on Polkadot, see the\ndedicated section on the parachain protocol page."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain decentralization\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Having multiple nodes belonging to numerous independent identities increases network resiliency and\nthus data retrievability.\nBlockchain is a state machine, and consensus must be achieved on every single state transition by\nevery node on the blockchain network. In Proof of Work (PoW) based blockchains, which let any node\nin the network produce a block, consensus is achieved probabilistically by building on the longest\nchain (at the cost of energy-intensive computations). Proof of Stake (PoS) based blockchains like\nPolkadot enable deterministic consensus by allowing only a limited number of privileged nodes to\nproduce blocks. A PoW blockchain can be considered centralized if a single entity can capture 51% of\nnetwork nodes. Similarly, a PoS blockchain can be considered centralized if a single entity controls\nmore than one-third of nodes, as a two-thirds majority is required to arrive at a deterministic\nconsensus. Different blockchains have different levels of decentralization.\nNowadays, most of the nodes cannot be run on consumer-grade hardware. Node running equipment is\ntypically rented through service providers. Resiliency is also achieved by ensuring nodes run on as\nmany different providers as possible and avoiding a significant share of the nodes being run under\nthe same provider in the same geographic region. A legislation change or a natural disaster could\nimpact a considerable fraction of the nodes and potentially stop the network. Polkadot's level of\ndecentralization can be explored through the Polkawatch app.\nThe Decentralized Nodes program aims to incentivize the creation\nof new validator nodes to increase the level of node decentralization."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain decentralized storage\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Blockspace is limited and valuable. Not all data we have can be stored on\nthe blockchain. Large files like pictures, music, movies, etc., typically will never be held on the\nblockchain. But where can we stored those files? To stick to the web3 vision, we need a resilient\nand decentralized storage solution.\nThe most important thing is that the proof of ownership is stored on the blockchain through the\nhashes of data and metadata. The files are uploaded on decentralized storage networks hosting\nprotocols like IPFS."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain stake allocation\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In Proof-of-Stake blockchains, security is dictated by how much stake is locked on-chain (financial\nsecurity). In a decentralized network, you want to ensure that the difficulty level for a financial\nattack to happen is equally difficult across all nodes. Polkadot's\nelection algorithm makes sure that the stake is maximized across all\nactive validators, and the variance in stake across validators is minimized as much as possible."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain economic incentives\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Strong incentives are essential to incentivize network participants to run nodes and secure the\nnetwork. Strong incentives are possible because blockchain is a trustless system where there are no\nintermediaries between who sends a message and who receives it. Such incentives, coupled with\npunishment for bad behavior, ensure that most of the participants make the interest of the network\nand work together to improve it.\nBut from where are those incentives coming from? Polkadot's native token\nDOT is inflationary. Inflation is used to pay validators for running\nnodes and reward nominators for providing the necessary stake to secure the network."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain governance and treasury\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In Polkadot, an on-chain treasury together with an\nopen governance model allow to access funds in a fully\ndecentralized manner without any bank transaction whatsoever. This opens up the possibility to come\nto a decision through on-chain voting mechanism, promoting a sense of community and creating an\nindependent socio-economical environment."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain decentralized access points\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "But what if we have data we own stored on a resilient blockchain, but the only way to access the\nblockchain is through an RPC server? Whoever is behind the server or an attacker could present us\ndata that is not the truth. How can we trustlessly verify that the data is true?\nHere is where light clients play a key role. Light clients are clients that can sit on a web browser\nand can fetch data directly from blockchain. The figure below shows the architectural difference\nbetween web2 and web3 applications.\nIn web2 applications, data are stored on a centralized server, while in web3 applications, data (or\nbetter data proofs) are stored on the blockchain. With light clients, it is possible to access\nblockchain data through a full node and verify the validity of such data. They efficiently\nsynchronize (warp sync in case of Polkadot) with a full node to obtain (Merkle Root) commitment of\nthe latest chain state, and hence can trustlessly verify any response by full node against the\ncommitment. In this way, we can always verify that the data we see is the truth, which is done\nautomatically by the light client. Polkadot has a browser-embedded light client\nSubstrate connect that uses the\nsmoldot codebase. Most web3 applications today access\nblockchain data through a centralized RPC server.\nFor more details about the inner workings of Smoldot, see\nthis blog post and\nthis video."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain interoperability\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The Web3 landscape's expansion into a multi-layered ecosystem highlights the need for\ninteroperability. Blockchains compete and differentiate themselves based on decentralization,\nthroughput, and specific use case focus. Some aim for a single high-performance base-layer\nblockchain, while others focus on decentralization through layer-2 networks. With such diverse\napproaches, it's crucial for distinct on-chain environments to interoperate, especially for\ndevelopers building cross-chain applications and traditional systems interacting with multiple\nblockchains.\nVarious cross-chain interactions are employed to achieve interoperability, including token swaps,\ntoken bridges, native payments, contract calls, and programmable token bridges. Each mechanism\nserves specific functions, such as facilitating the exchange of tokens between different blockchains\nor enabling smart contract interactions across chains. Other interoperability solutions validate the\nstate of a source blockchain and relay transactions to the destination blockchain, which is\nessential for completing cross-chain interactions.\nInteroperability between chains having different consensus has been a challenging task. Most of\nhacks have exploited vulnerabilities in interoperability protocols. Polkadot provides secure\ninteroperability through XCM and XCMP to\nall blockchains attached to it. For more information, see the Polkadot 1.0 page\nand\nthe section about XCM and Accords in Polkadot Direction page."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain definition of a parachain\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "A parachain is an application-specific data structure that is globally coherent and can be validated\nby the validators of the relay chain. They take their name from the concept of parallelized chains\nthat run parallel to the relay chain. Most commonly, a parachain will take the form of a blockchain,\nbut there is no specific need for them to be actual blockchains.\nDue to their parallel nature, they can parallelize transaction processing and achieve scalability of\nthe protocol. They inherit the security of the entire network and can\ncommunicate with other parachains through the XCM format.\nParachains are maintained by a network maintainer known as a collator. The role\nof the collator node is to maintain a full node of the parachain, retain all necessary information\nabout the parachain, and produce new block candidates to pass to the relay chain validators for\nverification and inclusion in the shared state. The incentivization of a collator node is an\nimplementation detail of the parachain. They are not required to be staked on the relay chain or own\nthe native token unless stipulated by the parachain implementation."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain state transitions\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Like other blockchains, parachains are deterministic state machines. Each parachain has a\nstate, executes a batch of transactions grouped into a block, and achieves a new state. Joe\nPetrowski provided in this article a\ngood analogy of a state with a light switch that can be either on or off, which is one of the\nsimplest examples of how a state machine functions. Each parachain has its own state, and the Relay\nChain links all those states into one state, i.e. a state of states. A multi-chain network like\nPolkadot can be viewed like one computer's state with many light switches where a state transition\nfunction is the logic to decide which switches should be toggled. Parachains have their own\ntransition rule, separate economies, governance mechanisms, and users.\nA parachain's state is stored in a Merkle tree. Merkle\ntrees have the convenient property that if some values within the tree change, this will be\nreflected in the Merkle root (in this case, the state root). One can verify the change by only\nlooking at the new values and the paths that are affected within the tree.\nThe Polkadot Host requires that the state transitions performed on parachains be specified as a\nWasm executable. Proofs of new state transitions that occur on a parachain must be\nvalidated against the registered state transition function (STF) that is stored on the relay chain\nby the validators before the relay chain acknowledges a state transition has occurred on a\nparachain. The key constraint regarding the logic of a parachain is that it must be verifiable by\nthe relay chain validators. Verification most commonly takes the form of a bundled proof of a state\ntransition known as a Proof-of-Verification (PoV) block, which is submitted for checking to the\nvalidators from one or more parachain collators."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain why parachains?\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Parachains are a solution to two fundamental problems in blockchains:\nScalability: Having one blockchain for many purposes makes it difficult to scale as future\n  implementations and upgrades will likely advantage some purposes and disadvantage others.\n  Conversely, having different blockchains will allow them to implement features without affecting\n  other chains.\nFlexibility: It is reasonable to state a blockchain will either be really good at solving one\n  problem or not so good at trying to solve many problems. A blockchain specializing in solving a\n  specific problem has more leverage toward itself and its users. Parachains are purpose-built\n  blockchains are highly specialized and can take advantage of each other through cooperation."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain parachain benefits\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Parachains contain their own runtime/STF logic and benefit from the shared security and the\ncross-consensus messaging provided by the relay chain. Parachains permit high flexibility and\ncustomization but require more effort to create and maintain over time. A production-grade parachain\nis typically more involved to create due to the complexity involved in blockchain networks'\ntechnical and economic aspects.\nParachains grant the creators more space to build the monetary system and other chain aspects from\nthe ground up. They will allow for a more concise and efficient execution of complex logic than a\nsmart contract platform could offer. Parachains also provide more flexibility in the form of\ngovernance and can perform complete upgrades in a less controversial way than the current process of\nhard forks.\nSome examples of features you can have on a parachain or parathread:\nCustom fee structure (for example, pay a flat transaction fee or pay per byte).\nShared security and finalization via the relay chain (Polkadot or Kusama).\nCustom monetary policy for the native token and local economy.\nTreasury to be funded through transitions in your state function.\nA governance mechanism that could manage a DAO that is responsible for allocating your on-chain\n  treasury."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain shared security\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Shared security, sometimes referred as pooled security, is one of the unique value propositions\nfor chains considering becoming a parachain and joining the network. On a\nhigh level, shared security means that all parachains that are connected to the relay chain by\naccessing a core will benefit from the economic security provided by the relay chain\nvalidators.\nThe notion of shared security is different from inter-chain protocols that build on an architecture\nof bridges. For bridge protocols, each chain is considered sovereign and must maintain its own\nvalidator set and economic security. One concern in these protocols is the point of scalability of\nsecurity. For example, one suggestion to scale blockchains is that of scale by altcoins, which\nsuggests that transaction volumes will filter down to lower market cap altcoins as the bigger ones\nfill their blocks. A major flaw in this idea is that the lower market cap coins will have less\neconomic security attached and be easier to attack. A real-life example of a 51% attack occurred\nrecently (\nEthereum Classic attack on January 10, 2019\n), in which an unknown attacker double spent 219_500 ETC (~1.1 million USD). This was followed by\ntwo more 51% attacks on ETC.\nPolkadot overcomes security scalability concerns since it gravitates all the economic incentives to\nthe relay chain and allows the parachains to tap into stronger guarantees at genesis. Sovereign\nchains must expend much more effort to grow the value of their coin so that it is sufficiently\nsecure against well-funded attackers."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain pow vs parachain model\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Let's compare the standard sovereign security model that exists on current proof-of-work (PoW)\nchains to Polkadot's shared security model. Bitcoin, Zcash, and their derivatives, must bootstrap\ntheir independent network of miners and maintain a competitive portion of honest hashing power.\nSince mining is becoming a larger industry that increasingly centralizes key players, it is becoming\nmore real that a single actor may control enough hash power to attack a chain.\nThis means that smaller chains that cannot maintain a secure amount of hash power on their networks\ncould potentially be attacked by a large mining cartel at the simple whim of redirecting its hash\npower away from Bitcoin and toward a new and less secure chain.\n51% attacks are viable today with attacks having been reported on\nEthereum Classic (see above),\nVerge,\nBitcoin Gold, and other cryptocurrencies.\nOn Polkadot, this disparity between chain security will not be present. When a parachain connects to\nthe relay chain, validators become the securers of that parachain's state transitions. The parachain\nwill only have the overhead of running a few collator nodes to keep the validators informed with the\nlatest state transitions and proofs/witness. Validators will then check these for the parachains to\nwhich they are assigned. In this way, new parachains instantly benefit from the overall security\nprovided by the relay chain even if they have just been launched."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain parachain economies\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Parachains may have their economies with their native tokens. Schemes such as Proof-of-Stake are\nusually used to select the validator set to handle validation and finalization; parachains will not\nbe required to do either of those things. However, since Polkadot is not overly particular about\nwhat the parachain can implement, it may be the choice of the parachain to implement a staking\ntoken, but it's not generally necessary.\nCollators may be incentivized through the inflation of a native parachain token. There may be other\nways to incentivize the collator nodes that do not involve inflating the native parachain token.\nTransaction fees in a native parachain token can also be an implementation choice of parachains.\nPolkadot makes no hard and fast rules for how the parachains decide on the original validity of\ntransactions. For example, a parachain may be implemented so that transactions must pay a minimum\nfee to collators to be valid. The relay chain will enforce this validity. Similarly, a parachain\ncould not include that in their implementation, and the relay chain would still enforce its\nvalidity.\nParachains are not required to have their token. If they do, it is up to the parachain (and not the\nrelay chain) to make the economic case for their token."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain coretime\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Parachains can access the relay chain via cores.\nThere are two ways to allocate relay chain cores:\nVia Governance only to system chains.\nVia coretime purchase with DOT (KSM on Kusama) for non-system chains.\n  Coretime is used to rent computation time on a relay chain core. This is the only way to access\n  Polkadot's shared security and interoperability.\nSystem parachains are allocated by Polkadot's on-chain\ngovernance and are part of the network's protocol, such as bridges to\nother networks or chains. These typically do not have an economic model and help remove transactions\nfrom the relay chain, allowing for more efficient parachain processing.\nNon-system chains can access the relay chain's cores via bulk or on-demand coretime purchased with\nDOT (or KSM on Kusama)."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain coretime expiration\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The DOT (or KSM on Kusama) used to purchase coretime are burned. Before the coretime expires,\nparachains can renew it at a fixed cost through a bulk coretime purchase. If the parachain does not\npurchase bulk coretime, it has an option to purchase coretime on-demand (at a variable price per\nblock, depending on the demand and other market conditions) when they need to access the relay\nchain. Parachains without coretime to extend time on a relay chain core will be deprecated to the\nstatus of a parathread (i.e., a chain with a registered ParaID but without access to a core)."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain system parachains\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "System parachains are parachains that use execution cores allocated by\nthe network's governance. These chains remove transactions from the relay chain, allowing network\nvalidators to allocate resources to validating parachains. System chains are Polkadot using its\nscaling technology to host itself."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain on-demand parachains\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "On-demand parachains were previously named parathreads\nOn-demand parachains (previously called parathreads) are parachains that acquire on-demand coretime.\nOn-demand parachains temporarily participate (on a block by block basis) in network security without\nneeding to lease a dedicated relay chain core. This is done through economically sharing the scarce\nresource of a core among several competing resources (parachains). Chains that otherwise would not\nbe able to acquire a full core or do not find it economically sensible to do so, can participate in\nshared security, as the on-demand coretime offers a\ngraceful off-ramp to parachains that no longer require a dedicated core, but would like to continue\nusing the relay chain."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain historical context of on-demand parachains\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "According to this talk in Chengdu back in 2019, the\norigin of the idea for on-demand parachains came from similar notions in the limited resource of\nmemory on early personal computers of the late '80s and '90s. Since computers have a limited amount\nof physical memory, when an application needs more, the computer can create virtual memory by using\nswap space on a hard disk. Swap space allows the capacity of a computer's memory to expand and for\nmore processes to run concurrently with the trade-off that some processes will take longer to\nprogress."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain parachains vs. on-demand parachains\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Parachains and on-demand parachains are very similar from a development perspective. One can imagine\nthat a chain developed with Substrate can at different points in its lifetime assume one of three\nstates:\nan independent chain with secured bridge,\na parachain continuously connected to the relay chain,\nor a parachain intermittently connected to the relay chain (i.e. on-demand)\nIt can switch between these states with relatively minimal effort since the difference is more of an\neconomic distinction than a technological one.\nOn-demand parachains have the exact same benefits for connecting to the relay chain that a full\nparachain has. Namely, it is able to send messages to other para-objects through\nXCMP and it is secured under the full economic security of the relay chain\nvalidator set."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain parachains' use cases\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Note that we still have to see the true potential of parachains and what it is listed below are just\na few examples.\nEncrypted Consortium Chains: These are possibly private chains that do not leak any\n  information to the public but still can be interacted with trustlessly due to the nature of the\n  XCMP protocol.\nHigh-Frequency Chains: These chains can compute many transactions in a short amount of time by\n  taking certain trade-offs or making optimizations.\nPrivacy Chains: These chains do not leak any information to the public through novel\n  cryptography.\nSmart Contract Chains: These chains can have additional logic implemented through the\n  deployment of code known as smart contracts."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain parachain host\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "A blockchain is a Directed Acyclic Graph\n(DAG) of state transitions, where every added block can be viewed as the head of the chain or fork\nwith cumulative state. All paths through the DAG terminate at the Genesis Block. A blockchain is a\ntree, as each block can have only one parent.\nA blockchain network is made of nodes that have a view of many forks of the chain and must decide\nwhich fork to follow. To construct the parachain host we need to answer two categories of questions\naddressed by two different components:\nWhat is the state transition function of the blockchain? This is handled by the Runtime, which\n  defines the state transition logic of the chain. The Runtime logic is divided into:\n\n\nModules encapsulate particular behavior of the protocol and consist of:\n\nStorage\nRoutines are invoked by entry points and other modules upon block initialization or closing.\n  Routines can alter the storage of a module.\nThe entry point defines how new information is introduced to a module and can limit the origin\n  from which they are called (user, root, parachain).\n\n\nAPI provides means for the node-side behavior to extract meaningful information from the\n    state of a single fork.\n!!!info The Polkadot Parachain Host Implementers' Guide provides details about\n  Runtime Architecture and\n  Runtime API.\nKnowing various forks of the blockchain, what behaviors should a node take? What information\n  should a node extract from the state of which forks, and how should that information be used? This\n  is handled by the Node-side behavior, which defines all activities a node undertakes given its\n  view of the blockchain. The node-side behavior can be divided into two categories:\n\n\nNetworking behaviors, relate to how information is distributed between nodes but not how the\n    information is used afterward.\n\nCore behaviors, relate to internal work that a specific node does. Such behavior cares about\n    that information is distributed and received, but not how these two are achieved.\nThese two categories often interact, but they can be heavily abstracted from each other. The\n  node-side behavior is split into various subsystems, which perform a particular category of\n  work. Subsystems can communicate with each other through an\n  Overseer that prevents race\n  conditions.\n!!!info\n      The Polkadot Parachain Host Implementers' Guide provides details about node architecture the main subsystems:\n- [Collator subsystem](https://paritytech.github.io/polkadot/book/node/collators/index.html)\n  - [Backing subsystem](https://paritytech.github.io/polkadot/book/node/backing/index.html)\n  - [Availability subsystem](https://paritytech.github.io/polkadot/book/node/availability/index.html)\n  - [Approval subsystem](https://paritytech.github.io/polkadot/book/node/approval/index.html)\n  - [Dispute subsystem](https://paritytech.github.io/polkadot/book/node/disputes/index.html)\n  - [Utility subsystem](https://paritytech.github.io/polkadot/book/node/utility/index.html)\nThe Runtime and Node-side behavior are dependent on each other. The Runtime depends on Node-side\nbehavior to author blocks, and to include extrinsics which trigger the\ncorrect entry points. The Node-side behavior relies on the Runtime APIs to extract information\nnecessary to determine which action to take."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain parachain hubs\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "While the relay chain enables crosschain functionality amongst the parachains, it necessitates that\nthere is some latency between the dispatch of a message from one parachain until the destination\nparachain receives the message. In the optimistic scenario, the latency for this message should be\nat least two blocks - one block for the message to be dispatched and one block for the receiving\nparachain to process and produce a block that acts upon the message. However, in some cases, we may\nsee that the latency for messages is higher if many messages are in queue to be processed or if no\nnodes are running both parachain networks that can quickly gossip the message across the networks.\nDue to the necessary latency in sending crosschain messages, some parachains plan to become hubs\nfor an entire industry (see the Asset Hub and\nBridge Hub). For example, many DeFi applications could take\nadvantage of a property known as composability which means that functions of one application can\nbe synergistically composed with others to create new applications. One example of this includes\nflash loans, which borrow funds to execute some on-chain logic as long as the loan is repaid at the\nend of the transaction.\nAn issue with crosschain latency means that composability property weakens among parachains compared\nto a single blockchain. This implication is common to all sharded blockchain designs, including\nPolkadot, Ethereum, and others. The solution to this is the introduction of parachain hubs, which\nmaintain the stronger property of single block composability."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain resources\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot: The Parachain -\n  Blog post by Polkadot co-founder Rob Habermeier who introduced parachains in 2017 as \"a simpler\n  form of blockchain, which attaches to the security provided by a relay chain rather than providing\n  its own. The relay chain provides security to attached parachains, but also provides a guarantee\n  of secure message-passing between them.\"\nThe Path of a Parachain Block - A\n  technical walk-through of how parachains interact with the relay chain."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain data ownership\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In web3, ownership is achieved and validated through cryptography. Each user has a digital identity\nbound to a set of cryptographic keys usually based on the public key cryptographic scheme, i.e., the\nfamous public and private key pair.\nUnlike Web2 which is driven by email IDs, phone numbers, and passwords, users onboarding to Web3\njust need to generate a key pair. The public key can be the identity that can be shared with anybody\nto send you messages or assets, while the private key is used to access your account, sign messages,\ntransfer funds, edit identity details, etc. Keeping your private key secure is\nessential to avoid identity theft or consequent loss of funds. Currently, scams are one of the main\nfactors hindering web3 adoption. No legitimate person or entity will ever ask you to share your\nprivate key, and those who attempt to do so are likely trying to steal your digital identity and\nanything you own related to it.\nTo mitigate risks of key mismanagement (for non-custodial accounts, i.e. when you have custody\nof your keys) there are account abstraction solutions that\nseparate the key management from the user experience. To mitigate key hacks, there are cold wallet\nsolutions where the private key is generated and stored on dedicated devices with secure elements\nthat are not exposed to the internet (see Ledger), or dedicated applications that can\nbe installed on air-gapped devices such as phones (see Polkadot Vault). For\ncustodial accounts, you trust third parties to manage your keys and give you access whenever\nneeded.\nTo summarize, data ownership comes from the fact that any message you sign with your private key\ncomes from your digital identity, and the signature proof can be cryptographically verified. Unless\nsomeone else stole your keys, you and only you are held accountable for signing the messages and are\nresponsible for the information on your account. Transferring an NFT between\ntwo accounts is essentially a transfer of ownership."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain data immutability\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "But what if the data we own can be easily modified or tampered with after they have been signed and\nstored?\nHere is where blockchain technology plays an important role. Blockchain networks comprise of\ndistributed state machines where increments of data are stored within blocks that build on each\nother using hash functions. For example, the hash of block N + 1 contains data of that block\ntogether with the hash of the previous block N. This creates the situation where if you modify the\ncontent of block N you will change the hash of block N + 1, N + 2, etc. essentially breaking\nthe chain. If a blockchain network is not sufficiently decentralized, it can be possible to add an\ninvalid block (a block with invalid transactions) or to censor certain transactions. In\ndecentralized proof-of-stake blockchains like Polkadot however, such attacks are financially\nexpensive and attempting them can get you slashed.\nSo, with blockchain as a means of storing data and transactions permanently without an option to\nmodify them, we can ensure what we cryptographically sign with our digital identity is set in stone\ndigitally."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain data retrievability\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "But what if our data are stored in a blockchain, but that blockchain is run on a centralized server\nor by different computers belonging to the same operator?\nThat server or those computers can be easily shut down, the blockchain can be stopped from running\nand its data wiped out. This can be achieved from the inside by the malicious network participants\nor from the outside by regulatory rules and other forces. Though blockchain offers immutability,\nthere would be little sense in using a centralized blockchain to prove ownership as it can possibly\ncease to exist in the future.\nData retrievability is dependent on how resilient the blockchain is. Resiliency is achieved through\nelements such as decentralization, economic incentives, and on-chain governance to ensure the\nnetwork can sustain on its own.\nData Retrievability vs. Data Availability\nData retrievability is the ability of nodes to retrieve\u00a0historical information\u00a0from the blockchain. Historical data is not needed to verify new blocks; it is only required for synching full nodes from the Genesis block or serving specific historical requests.\nData availability assures full nodes can access and verify the full transactions associated with\na specific block. It does not necessarily imply that the data is accessible forever. For more\ninformation about data availability on Polkadot, see the\ndedicated section on the parachain protocol page."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain decentralization\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Having multiple nodes belonging to numerous independent identities increases network resiliency and\nthus data retrievability.\nBlockchain is a state machine, and consensus must be achieved on every single state transition by\nevery node on the blockchain network. In Proof of Work (PoW) based blockchains, which let any node\nin the network produce a block, consensus is achieved probabilistically by building on the longest\nchain (at the cost of energy-intensive computations). Proof of Stake (PoS) based blockchains like\nPolkadot enable deterministic consensus by allowing only a limited number of privileged nodes to\nproduce blocks. A PoW blockchain can be considered centralized if a single entity can capture 51% of\nnetwork nodes. Similarly, a PoS blockchain can be considered centralized if a single entity controls\nmore than one-third of nodes, as a two-thirds majority is required to arrive at a deterministic\nconsensus. Different blockchains have different levels of decentralization.\nNowadays, most of the nodes cannot be run on consumer-grade hardware. Node running equipment is\ntypically rented through service providers. Resiliency is also achieved by ensuring nodes run on as\nmany different providers as possible and avoiding a significant share of the nodes being run under\nthe same provider in the same geographic region. A legislation change or a natural disaster could\nimpact a considerable fraction of the nodes and potentially stop the network. Polkadot's level of\ndecentralization can be explored through the Polkawatch app.\nThe Decentralized Nodes program aims to incentivize the creation\nof new validator nodes to increase the level of node decentralization."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain decentralized storage\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Blockspace is limited and valuable. Not all data we have can be stored on\nthe blockchain. Large files like pictures, music, movies, etc., typically will never be held on the\nblockchain. But where can we stored those files? To stick to the web3 vision, we need a resilient\nand decentralized storage solution.\nThe most important thing is that the proof of ownership is stored on the blockchain through the\nhashes of data and metadata. The files are uploaded on decentralized storage networks hosting\nprotocols like IPFS."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain stake allocation\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In Proof-of-Stake blockchains, security is dictated by how much stake is locked on-chain (financial\nsecurity). In a decentralized network, you want to ensure that the difficulty level for a financial\nattack to happen is equally difficult across all nodes. Polkadot's\nelection algorithm makes sure that the stake is maximized across all\nactive validators, and the variance in stake across validators is minimized as much as possible."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain economic incentives\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Strong incentives are essential to incentivize network participants to run nodes and secure the\nnetwork. Strong incentives are possible because blockchain is a trustless system where there are no\nintermediaries between who sends a message and who receives it. Such incentives, coupled with\npunishment for bad behavior, ensure that most of the participants make the interest of the network\nand work together to improve it.\nBut from where are those incentives coming from? Polkadot's native token\nDOT is inflationary. Inflation is used to pay validators for running\nnodes and reward nominators for providing the necessary stake to secure the network."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain governance and treasury\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In Polkadot, an on-chain treasury together with an\nopen governance model allow to access funds in a fully\ndecentralized manner without any bank transaction whatsoever. This opens up the possibility to come\nto a decision through on-chain voting mechanism, promoting a sense of community and creating an\nindependent socio-economical environment."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain decentralized access points\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "But what if we have data we own stored on a resilient blockchain, but the only way to access the\nblockchain is through an RPC server? Whoever is behind the server or an attacker could present us\ndata that is not the truth. How can we trustlessly verify that the data is true?\nHere is where light clients play a key role. Light clients are clients that can sit on a web browser\nand can fetch data directly from blockchain. The figure below shows the architectural difference\nbetween web2 and web3 applications.\nIn web2 applications, data are stored on a centralized server, while in web3 applications, data (or\nbetter data proofs) are stored on the blockchain. With light clients, it is possible to access\nblockchain data through a full node and verify the validity of such data. They efficiently\nsynchronize (warp sync in case of Polkadot) with a full node to obtain (Merkle Root) commitment of\nthe latest chain state, and hence can trustlessly verify any response by full node against the\ncommitment. In this way, we can always verify that the data we see is the truth, which is done\nautomatically by the light client. Polkadot has a browser-embedded light client\nSubstrate connect that uses the\nsmoldot codebase. Most web3 applications today access\nblockchain data through a centralized RPC server.\nFor more details about the inner workings of Smoldot, see\nthis blog post and\nthis video."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain interoperability\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The Web3 landscape's expansion into a multi-layered ecosystem highlights the need for\ninteroperability. Blockchains compete and differentiate themselves based on decentralization,\nthroughput, and specific use case focus. Some aim for a single high-performance base-layer\nblockchain, while others focus on decentralization through layer-2 networks. With such diverse\napproaches, it's crucial for distinct on-chain environments to interoperate, especially for\ndevelopers building cross-chain applications and traditional systems interacting with multiple\nblockchains.\nVarious cross-chain interactions are employed to achieve interoperability, including token swaps,\ntoken bridges, native payments, contract calls, and programmable token bridges. Each mechanism\nserves specific functions, such as facilitating the exchange of tokens between different blockchains\nor enabling smart contract interactions across chains. Other interoperability solutions validate the\nstate of a source blockchain and relay transactions to the destination blockchain, which is\nessential for completing cross-chain interactions.\nInteroperability between chains having different consensus has been a challenging task. Most of\nhacks have exploited vulnerabilities in interoperability protocols. Polkadot provides secure\ninteroperability through XCM and XCMP to\nall blockchains attached to it. For more information, see the Polkadot 1.0 page\nand\nthe section about XCM and Accords in Polkadot Direction page."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain introduction\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot\u2019s unique value lies in its ability to enable interoperability between parachains and other blockchain systems. At the core of this capability is XCM (Cross-Consensus Messaging)\u2014a flexible messaging format that facilitates communication and collaboration between independent consensus systems.\nWith XCM, one chain can send intents to another one, fostering a more interconnected ecosystem. Although it was developed specifically for Polkadot, XCM is a universal format, usable in any blockchain environment. This guide provides an overview of XCM\u2019s core principles, design, and functionality, alongside practical examples of its implementation."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain messaging format\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "XCM is not a protocol but a standardized messaging format. It defines the structure and behavior of messages but does not handle their delivery. This separation allows developers to focus on crafting instructions for target systems without worrying about transmission mechanics.\nXCM messages are intent-driven, outlining desired actions for the receiving blockchain to consider and potentially alter its state. These messages do not directly execute changes; instead, they rely on the host chain's environment to interpret and implement them. By utilizing asynchronous composability, XCM facilitates efficient execution where messages can be processed independently of their original order, similar to how RESTful services handle HTTP requests without requiring sequential processing."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain the four principles of xcm\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "XCM adheres to four guiding principles that ensure robust and reliable communication across consensus systems:\nAsynchronous - XCM messages operate independently of sender acknowledgment, avoiding delays due to blocked processes\nAbsolute - XCM messages are guaranteed to be delivered and interpreted accurately, in order, and timely. Once a message is sent, one can be sure it will be processed as intended\nAsymmetric - XCM messages follow the 'fire and forget' paradigm meaning no automatic feedback is provided to the sender. Any results must be communicated separately to the sender with an additional message back to the origin\nAgnostic - XCM operates independently of the specific consensus mechanisms, making it compatible across diverse systems\nThese principles guarantee that XCM provides a reliable framework for cross-chain communication, even in complex environments."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain core functionalities of xcm\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "XCM enhances cross-consensus communication by introducing several powerful features:\nProgrammability - supports dynamic message handling, allowing for more comprehensive use cases. Includes branching logic, safe dispatches for version checks, and asset operations like NFT management\nFunctional Multichain Decomposition - enables mechanisms such as remote asset locking, asset namespacing, and inter-chain state referencing, with contextual message identification \nBridging - establishes a universal reference framework for multi-hop setups, connecting disparate systems like Ethereum and Bitcoin with the Polkadot relay chain acting as a universal location\nThe standardized format for messages allows parachains to handle tasks like user balances, governance, and staking, freeing the Polkadot relay chain to focus on shared security. These features make XCM indispensable for implementing scalable and interoperable blockchain applications."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain xcm example\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The following is a simplified XCM message demonstrating a token transfer from Alice to Bob on the same chain (ParaA).\nlet message = Xcm(vec![\n    WithdrawAsset((Here, amount).into()),\n    BuyExecution { \n        fees: (Here, amount).into(), \n        weight_limit: WeightLimit::Unlimited \n    },\n    DepositAsset {\n        assets: All.into(),\n        beneficiary: MultiLocation {\n            parents: 0,\n            interior: Junction::AccountId32 {\n                network: None,\n                id: BOB.clone().into()\n            }.into(),\n        }.into()\n    }\n]);\nThe message consists of three instructions described as follows:\nWithdrawAsset - transfers a specified number of tokens from Alice's account to a holding register\nWithdrawAsset((Here, amount).into()),\n\n\nHere - the native parachain token\namount - the number of tokens that are transferred\n\nThe first instruction takes as an input the MultiAsset that should be withdrawn. The MultiAsset describes the native parachain token with the Here keyword. The amount parameter is the number of tokens that are transferred. The withdrawal account depends on the origin of the message. In this example the origin of the message is Alice. The WithdrawAsset instruction moves amount number of native tokens from Alice's account into the holding register.\n\n\nBuyExecution - allocates fees to cover the execution weight of the XCM instructions\nBuyExecution { \n    fees: (Here, amount).into(), \n    weight_limit: WeightLimit::Unlimited \n},\n\n\nfees - describes the asset in the holding register that should be used to pay for the weight \nweight_limit - defines the maximum fees that can be used to buy weight\n\n\n\nDepositAsset - moves the remaining tokens from the holding register to Bob\u2019s account\nDepositAsset {\n    assets: All.into(),\n    beneficiary: MultiLocation {\n        parents: 0,\n        interior: Junction::AccountId32 {\n            network: None,\n            id: BOB.clone().into()\n        }.into(),\n    }.into()\n}\n\n\nAll - the wildcard for the asset(s) to be deposited. In this case, all assets in the holding register should be deposited\nThis step-by-step process showcases how XCM enables precise state changes within a blockchain system. You can find a complete XCM message example in the XCM repository."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain overview\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "XCM revolutionizes cross-chain communication by enabling use cases such as:\nToken transfers between blockchains\nAsset locking for cross-chain smart contract interactions\nRemote execution of functions on other blockchains\nThese functionalities empower developers to build innovative, multi-chain applications, leveraging the strengths of various blockchain networks. To stay updated on XCM\u2019s evolving format or contribute, visit the XCM repository.\nLast update:\nApril 22, 2025\n\n|\nCreated:\nOctober 18, 2024"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain introduction\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot's Proof of Stake consensus model leverages a unique hybrid approach by design to promote decentralized and secure network operations. In traditional Proof of Stake (PoS) systems, a node's ability to validate transactions is tied to its token holdings, which can lead to centralization risks and limited validator participation. Polkadot addresses these concerns through its Nominated Proof of Stake (NPoS) model and a combination of advanced consensus mechanisms to ensure efficient block production and strong finality guarantees. This combination enables the Polkadot network to scale while maintaining security and decentralization."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain nominated proof of stake\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot uses Nominated Proof of Stake (NPoS) to select the validator set and secure the network. This model is designed to maximize decentralization and security by balancing the roles of validators and nominators.\nValidators - play a key role in maintaining the network's integrity. They produce new blocks, validate parachain blocks, and ensure the finality of transactions across the relay chain\nNominators - support the network by selecting validators to back with their stake. This mechanism allows users who don't want to run a validator node to still participate in securing the network and earn rewards based on the validators they support\nIn Polkadot's NPoS system, nominators can delegate their tokens to trusted validators, giving them voting power in selecting validators while spreading security responsibilities across the network."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain hybrid consensus\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot employs a hybrid consensus model that combines two key protocols: a finality gadget called GRANDPA and a block production mechanism known as BABE. This hybrid approach enables the network to benefit from both rapid block production and provable finality, ensuring security and performance.\nThe hybrid consensus model has some key advantages:\nProbabilistic finality - with BABE constantly producing new blocks, Polkadot ensures that the network continues to make progress, even when a final decision has not yet been reached on which chain is the true canonical chain\n\n\nProvable finality - GRANDPA guarantees that once a block is finalized, it can never be reverted, ensuring that all network participants agree on the finalized chain\nBy using separate protocols for block production and finality, Polkadot can achieve rapid block creation and strong guarantees of finality while avoiding the typical trade-offs seen in traditional consensus mechanisms."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain block production - babe\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Blind Assignment for Blockchain Extension (BABE) is Polkadot's block production mechanism, working with GRANDPA to ensure blocks are produced consistently across the network. As validators participate in BABE, they are assigned block production slots through a randomness-based lottery system. This helps determine which validator is responsible for producing a block at a given time. BABE shares similarities with Ouroboros Praos but differs in key aspects like chain selection rules and slot timing.\nKey features of BABE include:\nEpochs and slots - BABE operates in phases called epochs, each of which is divided into slots (around 6 seconds per slot). Validators are assigned slots at the beginning of each epoch based on stake and randomness\n\n\nRandomized block production - validators enter a lottery to determine which will produce a block in a specific slot. This randomness is sourced from the relay chain's randomness cycle\n\n\nMultiple block producers per slot - in some cases, more than one validator might win the lottery for the same slot, resulting in multiple blocks being produced. These blocks are broadcasted, and the network's fork choice rule helps decide which chain to follow\n\n\nHandling empty slots - if no validators win the lottery for a slot, a secondary selection algorithm ensures that a block is still produced. Validators selected through this method always produce a block, ensuring no slots are skipped\nBABE's combination of randomness and slot allocation creates a secure, decentralized system for consistent block production while also allowing for fork resolution when multiple validators produce blocks for the same slot."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain validator participation\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In BABE, validators participate in a lottery for every slot to determine whether they are responsible for producing a block during that slot. This process's randomness ensures a decentralized and unpredictable block production mechanism.\nThere are two lottery outcomes for any given slot that initiate additional processes:\nMultiple validators in a slot - due to the randomness, multiple validators can be selected to produce a block for the same slot. When this happens, each validator produces a block and broadcasts it to the network resulting in a race condition. The network's topology and latency then determine which block reaches the majority of nodes first. BABE allows both chains to continue building until the finalization process resolves which one becomes canonical. The Fork Choice rule is then used to decide which chain the network should follow\n\n\nNo validators in a slot - on occasions when no validator is selected by the lottery, a secondary validator selection algorithm steps in. This backup ensures that a block is still produced, preventing skipped slots. However, if the primary block produced by a verifiable random function (VRF)-selected validator exists for that slot, the secondary block will be ignored. As a result, every slot will have either a primary or a secondary block\nThis design ensures continuous block production, even in cases of multiple competing validators or an absence of selected validators."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain finality gadget - grandpa\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "GRANDPA (GHOST-based Recursive ANcestor Deriving Prefix Agreement) serves as the finality gadget for Polkadot's relay chain. Operating alongside the BABE block production mechanism, it ensures provable finality, giving participants confidence that blocks finalized by GRANDPA cannot be reverted.\nKey features of GRANDPA include:\nIndependent finality service \u2013 GRANDPA runs separately from the block production process, operating in parallel to ensure seamless finalization\nChain-based finalization \u2013 instead of finalizing one block at a time, GRANDPA finalizes entire chains, speeding up the process significantly\nBatch finalization \u2013 can finalize multiple blocks in a single round, enhancing efficiency and minimizing delays in the network\nPartial synchrony tolerance \u2013 GRANDPA works effectively in a partially synchronous network environment, managing both asynchronous and synchronous conditions\nByzantine fault tolerance \u2013 can handle up to 1/5 Byzantine (malicious) nodes, ensuring the system remains secure even when faced with adversarial behavior\nWhat is GHOST?\nGHOST (Greedy Heaviest-Observed Subtree) is a consensus protocol used in blockchain networks to select the heaviest branch in a block tree. Unlike traditional longest-chain rules, GHOST can more efficiently handle high block production rates by considering the weight of subtrees rather than just the chain length."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain probabilistic vs. provable finality\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In traditional Proof of Work (PoW) blockchains, finality is probabilistic. As blocks are added to the chain, the probability that a block is final increases, but it can never be guaranteed. Eventual consensus means that all nodes will agree on a single version of the blockchain over time, but this process can be unpredictable and slow.\nConversely, GRANDPA provides provable finality, which means that once a block is finalized, it is irreversible. By using Byzantine fault-tolerant agreements, GRANDPA finalizes blocks more efficiently and securely than probabilistic mechanisms like Nakamoto consensus. Like Ethereum's Casper the Friendly Finality Gadget (FFG), GRANDPA ensures that finalized blocks cannot be reverted, offering stronger consensus guarantees."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain fork choice\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The fork choice of the relay chain combines BABE and GRANDPA:\nBABE must always build on the chain that GRANDPA has finalized\nWhen there are forks after the finalized head, BABE builds on the chain with the most primary blocks to provide probabilistic finality\nIn the preceding diagram, finalized blocks are black, and non-finalized blocks are yellow. Primary blocks are labeled '1', and secondary blocks are labeled '2.' The topmost chain is the longest chain originating from the last finalized block, but it is not selected because it only has one primary block at the time of evaluation. In comparison, the one below it originates from the last finalized block and has three primary blocks."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain bridging - beefy\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Bridge Efficiency Enabling Finality Yielder (BEEFY) is a specialized protocol that extends the finality guarantees provided by GRANDPA. It is specifically designed to facilitate efficient bridging between Polkadot relay chains (such as Polkadot and Kusama) and external blockchains like Ethereum. While GRANDPA is well-suited for finalizing blocks within Polkadot, it has limitations when bridging external chains that weren't built with Polkadot's interoperability features in mind. BEEFY addresses these limitations by ensuring other networks can efficiently verify finality proofs.\nKey features of BEEFY include:\nEfficient finality proof verification - BEEFY enables external networks to easily verify Polkadot finality proofs, ensuring seamless communication between chains\nMerkle Mountain Ranges (MMR) - this data structure is used to efficiently store and transmit proofs between chains, optimizing data storage and reducing transmission overhead\nECDSA signature schemes - BEEFY uses ECDSA signatures, which are widely supported on Ethereum and other EVM-based chains, making integration with these ecosystems smoother\nLight client optimization - BEEFY reduces the computational burden on light clients by allowing them to check for a super-majority of validator votes rather than needing to process all validator signatures, improving performance"
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain nominating vs joining a pool\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Nominating\nJoining a Pool\n\n\n\n\nMinimum 250 DOT to nominate.\nMinimum 1 DOT to be a member.\n\n\nRewards can be compounded automatically or sent to any account.\nRewards can be manually claimed to the pool member's account and be bonded in the pool again to compound them.\n\n\nIf the active validator gets slashed, all active nominators are subjected to slashing.\nIf the active validator gets slashed, all pool members are subjected to slashing.\n\n\nCan bond and stake DOT indefinitely.\nCan bond and stake DOT until the pool exists.\n\n\nMaximum unbonding period of 28 days. Can switch validators without unbonding.\nMaximum unbonding period of 28 days. Need to unbond before switching to a different pool.\n\n\nMaximum uncapped.\nMaximum uncapped.\n\n\nShould bond more than the minimum active nomination in an era to be eligible to earn staking rewards, although it can depend on multiple other factors outlined in the linked document.\nA nomination pool earns rewards in an era if it satisfies all the conditions mentioned for the nominator (as the nomination pool is just a nominator from the NPoS system perspective).\n\n\nStaked tokens can be used for participation in Governance.\nStaked tokens can be used for participation in Governance.\n\n\nRewards payout can be triggered permissionlessly by anyone (typically done by the validator).\nA pool member can self claim the rewards or can grant permission to any other account to claim and compound rewards on your behalf. See Claim Permissions.\n\n\nBonded funds remain in your account.\nBonded funds remain in your account.\n\n\nNominator manages the list of staked validators (up to 16).\nNominations managed by the pool operator."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain join a pool\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Ledger users\nJoining a nomination pool is possible only with the XL version of the Polkadot Ledger App. This should be installed by default on Ledger Nano X and S Plus, but not on the Nano S.\nBefore joining a nomination pool, you must ensure that the\npool is earning rewards and nominating the validators that match your preferences. Participating in\npools is more of a set-and-forget action than nominating by yourself. The pool operator maintains\nthe list of validators nominated by the pool, and so, in a way, you are trusting the pool operator\nto act in your best interests. However, it is advised to check the validators nominated by the pool\nfrom time to time and change the pool if necessary.\nA member delegates funds to a pool with the join extrinsic. The pool then increases its bond with the new funds. A member is afforded the\nability to bond additional funds or re-stake rewards as long as they are already actively bonded.\nNote that a member may only belong to one pool at a time.\nThe current minimum bond to join a pool can be seen\nhere.\nUse Proxy Accounts to join Nomination Pools\nDepending on how much control you want to give your proxy, you might choose between any > non-transfer > staking > nomination pool proxy, with the latter being only able to sign transactions related to the NominationPool pallet.\nCheck the \"How to join a pool\" section in\nthis support article\nfor guidelines."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain claim permissions\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "As a pool member, you can grant permission to any other account to claim and compound rewards on\nyour behalf. There are four permission options:\nPermissioned (default): you need to claim and compound your rewards.\nPermissionlessCompound: you grant permission to any other account to compound (claim and bond)\n  your rewards on your behalf.\nPermissionlessWithdraw: you grant permission to any other account to withdraw (claim and keep as\n  a free balance) your rewards on your behalf.\nPermissionlessAll: you grant permission to any other account to compound or withdraw your\n  rewards on your behalf.\nSee the Staking Dashboard page for more information about how to set your claim permissions.\nSee the advanced guides to\nlearn how to claim rewards for another pool member."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain vote in opengov\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Nomination pool members can vote in Polkadot OpenGov with funds they delegated to the pool. In the past, pool members' funds were transferred to the pool system account. A delegation staking system was introduced to allow keeping ownership of your funds and voting in governance.\nDual Staking\nFor pool members who were dual staking (i.e., pool members and nominators) before the introduction of delegation staking, follow these guides to migrate manually to the new system."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain unbond and withdraw funds\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "At any point in time after joining the pool, a member can start the process of exiting by unbonding.\nunbond will unbond part or all of the member's funds. After unbond has been called and the\nunbonding duration has passed a member may\nwithdraw their funds with withdrawUnbonded. Withdrawing effectively ends a member's relationship\nwith their pool, allowing them to join a different pool if desired. Check the \"Withdraw unbonded\nfunds\" section in\nthis support article\nfor guidelines.\nUnbonding transaction automatically triggers withdrawal of rewards\nWhen there is a change in the bonded balance, the accumulated rewards in the pool thus far are automatically withdrawn to the account. The rewards are then accrued based on the updated bonded balance."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain nomination pools - lazy slashing\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Because pool funds are spread to all its members and each member need to be slashed proportionally, slashes are applied to pool members lazily. The protocol keeps track of how much a pool and its members need to be slashed. There is a permissionless extrinsic to apply any pending slash to the pool member. If successful, the caller gets part of slash as reward (if configured), incentivising free market bots to monitor and apply slashes swiftly.\nThe advantage is, the slashing (computation) cost is spread over multiple blocks. A disadvantage is that a member might have more funds in their account locked than their actual pool contribution, which they can use to vote, until these pending slashes are applied.\nSuppose the staking system slashes a pool\u2019s underlying nomination account. In\nthat case, the slash is distributed evenly across the bonded pool, and the unbonding pools from\nslash era+1 through the slash apply era. Thus, any member who either a) was unbonding or b) was\nactively bonded in the aforementioned range of eras will be affected by the slash. In other words, a\nmember who may have been actively bonded during the offence is slashed pro rata based on its stake\nrelative to the total slash amount.\nUnbonding pools need to be slashed to ensure all nominators who were in the bonded pool while it was\nbacking a validator that committed an offense are punished. Without these measures a nominator could\nunbond right after a validator equivocated with no consequences.\nThis strategy is unfair to members who joined after the slash because they get slashed as well, but\nit spares members who unbond. The latter is much more important for security: if a pool's validators\nattack the network, their members need to unbond fast! Avoiding additional slashes gives them an\nincentive to do that if validators get repeatedly slashed."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain roles\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Depositor: Creates the pool and is the initial member. The depositor can only leave the pool once\n  all other members have left. Once they leave by withdrawing, the pool is fully removed from the\n  system.\nNominator: Can select the validators the pool nominates.\nBouncer: Can change the pool\u2019s state and kick (permissionlessly unbond/withdraw) members if the\n  pool is blocked.\nRoot: Can change the nominator, bouncer, or itself. Further, it can perform any of the actions the\n  nominator or bouncer can."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain pool commissions\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "As the pool root role, you can set pool commissions that will be applied to the staking rewards paid\nout to the pool's system account before rewards are allocated for the pool members. You can set pool\ncommissions through the Polkadot Staking Dashboard.\nThree methods can be used when setting the pool commission:\nCommission Rate (nominationPools.setCommission extrinsic): the start or new commission rate\n  (newCommission parameter) that can be set between 0% and the\n  max commission parameter\n  (decided through governance referendum) via the\n  globalMaxCommission\n  parameter. You will need to specify an Input Payee Account, i.e. the account that will receive the\n  commission.\nMax Commission (nominationPools.setCommissionMax extrinsic): the maximum commission\n  (maxCommission parameter) the pool will apply to its members (between 0% and Max Commission).\n  Note that once set, the pool admin can only lower it.\nChange Rate (nominationPools.setCommissionChangeRate extrinsic): the maximum rate increase\n  (maxIncrease parameter) allowed for a single commission update. Note that once set, the pool\n  admin can only lower it. When setting the Change Rate, it will also be possible to set a\n  minDelay quantified as the number of blocks (since last commission update) after which it is\n  possible to change the commission (i.e. the minimum delay between commission updates). Note that\n  once set, the pool admin can only increase it.\nMax Commission and Change Rate must not be necessarily set. It is the choice of the pool admin to\nset those parameters and provide transparency to the pool members about the pool's commission\npolicy.\nMax Commission and Change Rate are currently permanent\nOnce the Max Commission and the Change Rate are set, the pool admin currently can only decrease those values. The minimum delay between commission updates can only be increased. The situation can change in the future and a forceSetCommissionMax method can be proposed through governance referendum.\nLet's take, for example, Pool A, which sets the Commission Rate to 10%, the Max Commission to 100%,\nand the Change Rate to 1% every 300 blocks (which equates to approximately 30 minutes). The\nfollowing statements are true:\nThe pool commission can be increased by 1% every 30 minutes. Bigger increases are not allowed.\n  Increases of less than or equal to 1% are not allowed sooner than 30 minutes since the last\n  commission update.\nThe Max Commission can only be decreased from 100%. Once decreased, it can be decreased again but\n  it cannot be increased.\nThe Change Rate's maximum increase can only be decreased from 1%. Once decreased, it can be\n  decreased again but it cannot be increased.\nThe Change Rate's minimum delay between updates of 30 min can only be increased. Once increased,\n  it can be increased again but it cannot be decreased."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain sub-identities\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Users can also link accounts by setting \"sub accounts\", each with its own identity, under a primary\naccount. The system reserves a bond for each sub account. An example of how you might use this would\nbe a validation company running multiple validators. A single entity, \"My Staking Company\", could\nregister multiple sub accounts that represent the Stash accounts of each of\ntheir validators.\nAn account can have a maximum of 100 sub-accounts. Note that a\ndeposit is required for every sub-account."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain judgements\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "After a user injects their information on chain, they can request judgement from a registrar. Users\ndeclare a maximum fee that they are willing to pay for judgement, and registrars whose fee is below\nthat amount can provide a judgement.\nWhen a registrar provides judgement, they can select up to six levels of confidence in their\nattestation:\nUnknown: The default value, no judgement made yet.\nReasonable: The data appears reasonable, but no in-depth checks (e.g. formal KYC process) were\n  performed (all the currently verified identities on-chain).\nKnown Good: The registrar has certified that the information is correct (this step involves\n  verification of state issued identity documents, and at the moment no account has known good\n  identity, with the exception of registrars).\nOut of Date: The information used to be good, but is now out of date.\nLow Quality: The information is low quality or imprecise, but can be fixed with an update.\nErroneous: The information is erroneous and may indicate malicious intent.\nA seventh state, \"fee paid\", is for when a user has requested judgement and it is in progress.\nInformation that is in this state or \"erroneous\" is \"sticky\" and cannot be modified; it can only be\nremoved by the complete removal of the identity.\nRegistrars gain trust by performing proper due diligence and would presumably be replaced for\nissuing faulty judgments."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain registrars\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Registrars can set a fee for their services and limit their attestation to certain fields. For\nexample, a registrar could charge 1 DOT to verify one's legal name, email, and GPG key. When a user\nrequests judgement, they will pay this fee to the registrar who provides the judgement on those\nclaims. Users set a maximum fee they are willing to pay and only registrars below this amount would\nprovide judgement.\nThere are multiple registrars on Polkadot and Kusama. Unless no additional information is available\nhere, you must reach out to specific registrars individually if you want to be judged by those.\nDecommissioned Registrar Service\nFrom the 1st of April 2024 onwards, Registrar 0 will still exist on-chain but will not accept any new judgment requests. The registrar fee is set to a substantial amount to dissuade identity judgement requests. Identities judged by the registrar before that date will not be affected. For new identity judgment, please use the other registrars.\nPolkadotKusama\n\n\nRegistrar 0 :  URL: NA  Account:\n12j3Cz8qskCGJxmSJpVL2z2t3Fpmw3KoBaBaRGPnuibFc7o8  Fee: 0 DOT \nRegistrar 1:  URL: https://registrar.d11d.net/  Account:\n1Reg2TYv9rGfrQKpPREmrHRxrNsUDBQKzkYwP1UstD97wpJ  Fee: 20 DOT \nRegistrar 2:  Account: 1EpXirnoTimS1SWq52BeYx7sitsusXNGzMyGx8WPujPd1HB  Fee: 0\nDOT \nRegistrar 3:  Account: 13SceNt2ELz3ti4rnQbY1snpYH4XE4fLFsW8ph9rpwJd6HFC  Fee:\n0.5 DOT  Polkassembly (Registrar 3) provides setting on-chain ID as a service on their\nwebsite.\nRegistrar 4:  URL: https://polkaidentity.com/  Account:\n16LYBUcQKWZjAYE4oAPWx9XFaEYnCAffwpPuPWrUvU1mqBZT  Fee: 0.5 DOT  PolkaIdentity\n(Registrar 4) provides setting on-chain ID as a service on their\nwebsite.\n\n\nRegistrar 0 :  URL: NA  Account:\nH4XieK3r3dq3VEvRtqZR7wN7a1UEkXxf14orRsEfdFjmgkF  Fee: 0.04 KSM \nRegistrar 1:  URL: https://registrar.d11d.net/  Account:\nFom9M5W6Kck1hNAiE2mDcZ67auUCiNTzLBUdQy4QnxHSxdn  Fee: 4.5 KSM \nRegistrar 2: is no longer offering registrar services on Kusama.  Account:\nEK8veMNH6sVtvhSRo4q1ZRh6huCDm69gxK4eN5MFoZzo3G7  Fee: 1 KSM \nRegistrar 3:  Account: GLiebiQp5f6G5vNcc7BgRE9T3hrZSYDwP6evERn3hEczdaM  Fee: 1\nKSM  Polkassembly (Registrar 3) provides setting on-chain ID as a service on their\nwebsite.\nRegistrar 4:  Account: GhmpzxUyTVsFJhV7s2wNvD8v3Bgikb6WvYjj4QSuSScAUw6  Fee:\n0.04 KSM \nRegistrar 5:  Account: F1wAMxpzvjWCpsnbUMamgKfqFM7LRvNdkcQ44STkeVbemEZ  Fee:\n0.04 KSM  Polkassembly (Registrar 5) provides setting on-chain ID as a service on their\nwebsite.\nRegistrar 6:  URL: https://polkaidentity.com/  Account:\nHurhThD66KBUf2zcE9Zhx46sCqNJXviKhWAct95rBCkPuix  Fee: 0.04 KSM  PolkaIdentity\n(Registrar 6) provides setting on-chain ID as a service on their\nwebsite.\nSee this page to learn how to become a Registrar.\nPolkadot-JS Guides\nIf you are an advanced user, see the Polkadot-JS guides about account identity.\nSee also these Polkadot-JS support guides."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain premise\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot's first governance system Governance V1 included three\nmain components: the Technical Committee, the Council, the Public (i.e. all token holders).\nOver the first few years of operation, Governance V1 ensured the appropriate usage of treasury funds\nand enabled timely upgrades and fixes. Like most early technologies, protocols must evolve as they\nmature to improve their shortcomings and keep up with modern advancements. In Governance V1, all\nreferenda carried the same weight as only one referendum could be voted on at a time (except for\nemergency proposals), and the voting period could last multiple weeks. Also, an\nalternating voting timetable allowed to vote either for a public referendum or a council motion every 28 days (7 days on Kusama). This\nresulted in the system favoring careful consideration of very few proposals instead of broad\nconsideration of many.\nPolkadot OpenGov changes how the practical means of day-to-day decisions are made, making the\nrepercussions of referenda better scoped and agile to increase the number of collective decisions\nthe system can make at any given time.\nThe following content is focused on Polkadot OpenGov, and on the main differences with previous\ngovernance versions."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain summary\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "In Governance v1, active token holders (public) and the Council administrated the network's upgrade\ndecisions. Whether the public or the council initiated the proposal, it would eventually have to go\nthrough a referendum to let all holders (weighted by stake and conviction) make the decision.\nThe Council fulfilled its role as the representative of the public, guardian of the treasury and\ninitiator of legislation, but it was often seen as a centralized entity. To further decentralize the\nnetwork, Polkadot OpenGov proposes the following main changes:\nMigrating all responsibilities of the Council to the public via a direct democracy voting system.\nDissolving the Council collective\nAllowing users to delegate voting power in more ways to community members\nDissolving the Technical Committee and establishing the broader Polkadot Technical Fellowship\nThe figure below shows an overview of Polkadot OpenGov's structure.\nIn Polkadot OpenGov, all the proposals are initiated by the public. The proposal will enter a\nLead-in period (for more information, see Referenda Timeline), after which it\nwill follow a specific Track which has a dedicated Origin. There are\n15 Origins, each with a different\ntrack. The origins and tracks parameters are preset values that set the duration of a referendum as\nwell as how many referenda can be voted on simultaneously. For example, a treasury proposal can now\nbe submitted in different tracks depending on the amount requested. A proposal for a small tip will\nneed to be submitted to the Small Tipper track, while a proposal requiring substantial funds will\nneed to be submitted to the Medium or Big Spender track.\nThe Polkadot Technical Fellowship can decide to\nwhitelist a proposal that will be enacted through the Whitelist Caller origin.\nThose proposals will have a shorter Lead-in, Confirmation, and Enactment period when compared to the\nRoot Origin track.\nEach track has its own preset Approval and Support curves based on the\norigin's privileges. When both the approval and support criteria are satisfied for a specific period\n(called the confirmation period), the referendum passes and will be executed after the enactment\nperiod.\nAll referenda within each track and across tracks can be voted on simultaneously (assuming the\ntrack's maximum capacity is not reached).\nPolkadot OpenGov also comes with multi-role delegations where the token holder can assign voting\npower on different tracks to different entities who are experts in judging the referenda submitted\nto those tracks. For example, suppose a token holder does not have the technical background to\nconsider the merits and vote on the referenda submitted to the Root track. In that case, they can\ndelegate their voting power just for the Root track to a trusted expert who (according to them) acts\nin the best interest of the network protocol. In this way, token holders do not need to be\nup-to-date with governance matters and can still make their votes count through delegates."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain gov1 vs. polkadot opengov\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Governance V1\nPolkadot OpenGov\nPolkadot OpenGov Benefit\n\n\n\n\nIncludes the Council, the Technical Committee, and the Public (i.e. token holders).\nIncludes the Public and the Technical Fellowship.\nSimpler and more decentralized structure.\n\n\nReferenda executed only from one origin (Root). Referenda in this origin must be carefully scrutinized. Therefore, there is only one track (i.e., only one referendum at a time can be executed).\nReferenda executed from multiple origins, each with a different track that shapes proposals\u2019 timelines. Depending on the origin, multiple referenda within the same track are possible.\nPossibility to categorize proposals (based on importance and urgency) and execute them simultaneously within and between origin tracks.\n\n\nProposals can be submitted by either the Council or the Public.\nThe public submits proposals.\nMore democratic.\n\n\nUses Adaptive Quorum Biasing to define the approval threshold based on turnout. Given the same turnout, council-initiated referenda require fewer Aye votes to pass compared to public referenda.\nUses origin-specific approval and support curves defining the amount of approval and support (i.e. turnout) needed as a function of time. The same curves are applied to all referenda within the same origin track.\nReferenda timeline depends on the origin and not on who submitted the proposal (i.e. Council or Public). This is a more democratic and equalitarian system.\n\n\nUses alternating voting timetable allowing voters to cast votes for either council or public referenda every 28 eras.\nMultiple referenda can be voted at the same time.\nMore flexible and agile governance system.\n\n\nExcept for emergency proposals, all referenda have fixed voting and enactment periods of 28 eras.\nPeriods' length is customizable and has pre-defined limits for each origin. The same limits apply to all tracks with the same origin. For example, the track in the origin Root will be longer than the track within the Small Tipper origin.\nReferenda\u2019s timeline is tailored to their importance and urgency. Flexible enactment period based on origin.\n\n\nEmergency proposals turned referenda can be simultaneously voted on and executed with other referenda and have shorter enactment periods. They must be proposed by the Technical Committee and approved by the Council.\nNo emergency proposals. The Technical Fellowship can whitelist proposals that will have their origin with shorter lead-in, confirmation, and enactment periods.\nThe Technical Fellowship is a more decentralized entity than the Technical Committee. Whitelisting a proposal requires a majority of approval from the fellowship.\n\n\nOnly the most endorsed proposal is able to transit from Launch to Voting period. The time for the transition is indeterminate, and (with no possibility of canceling endorsements) proposers and endorsers might wait a long time before a referendum is tabled, and getting their deposits back.\nAll proposals will eventually be voted on (given track capacity and deposit are met and the Lead-in period has ended).\nIt allows all proposals to get a chance to be voted on in a timely, predictive manner.\n\n\nOnly aye or nay votes possible.\nVoters can have the additional voting options of abstaining or splitting votes.\nMore ways to engage in voting and increase turnout.\n\n\nVoters can decide to delegate votes to another account.\nVoters can use multirole delegations and delegate votes to different accounts depending on origins.\nMore agile delegations tailored by expertise."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain referenda timeline\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The figure above provides a summary view of the referenda timeline for Polkadot OpenGov.\nIn (1), when a referendum is initially created, the community can immediately vote on it. However,\nit is not immediately in a state where it can end or otherwise have its votes counted, approved, and\nultimately enacted. Instead, the proposal will stay within a Lead-in Period until it fulfills\nthree criteria:\nProposals must stay within the lead-in period for a pre-defined minimum amount of time. This helps\n  mitigate against the possibility of \"decision sniping\" where an attacker controlling a substantial\n  amount of voting power might seek to have a proposal passed immediately after proposing, not\n  allowing the overall voting population adequate time to consider and participate.\nThere must be enough room for the decision within the origin. Different origins have their limit\n  on the number of proposals that can be decided simultaneously. Tracks that have more potent\n  abilities will have lower limits. For example, the Root level Origin has a limit of one, implying\n  that only a single proposal may be decided on at once.\nA decision deposit must be submitted. Creating a referendum is cheap as the deposit value consists\n  of only the value required for the on-chain storage needed to track it. But, having a referendum\n  reviewed and decided upon carries the risk of using up the limited spots available in the\n  referenda queue. Having a more significant but refundable deposit requirement makes sense to help\n  mitigate spam. Failing to submit the decision deposit will lead to a referendum timeout.\nDecision Deposit Amounts\nIn Polkadot OpenGov, someone must submit the Decision Deposit for a referendum to enter its Decision Period. The number of tokens required for the Decision Deposit depends on the track\u2019s privilege level. The higher the privilege, the higher the deposit. For example, malicious referenda posted on the Small Tipper track inflict low economic damage to the network. In contrast, malicious referenda on the Root track can inflict more significant harm, such as changing the entire network's runtime.\nUntil they are in the lead-in period, proposals remain undecided. Once the criteria above are met,\nthe referendum moves to the deciding state. The votes of the referendum are now counted towards\nthe outcome.\nIn (2), the proposal enters the Decision Period, where voting can continue. For a proposal to be\napproved, votes must satisfy the approval and support criteria for at least the Confirmation\nPeriod; otherwise, the proposal is automatically rejected. A rejected proposal can be resubmitted\nanytime and as many times as needed.\nIn (3), approved proposals will enter the Enactment Period, after which proposed changes will be\nexecuted.\nNote how the length of the lead-in, decision, confirmation, and enactment periods vary depending on\nthe track. Root origin track has more extended periods than the other tracks. Also, the number of\nreferenda within each track differs, with the Root origin track only accepting one proposal at a\ntime (see below).\nThis directly affects the number of proposals that can be voted on and executed simultaneously.\nContinuing the comparison between Root and Small Tipper, Small Tipper will allow many proposals on\nits track to be executed simultaneously. In contrast, Root will allow only one proposal to be on its\ntrack. Once the track capacity is filled, additional proposals in the lead-in period will queue\nuntil place is available to enter the decision period.\nFor examples of collectives, see the Polkadot Alliance and the Polkadot Technical Fellowship."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain origins and tracks\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "An Origin is a specific level of privilege that will determine the Track of all referenda\nexecuted with that origin. The track is a pipeline in which the proposal lives and proceeds,\nindependent of other origins' tracks. The proposer of the referenda now selects an appropriate\nOrigin for their request based on the proposal\u2019s requirements.\nAlthough the track structure is the same for all origins, track parameters are not. Such parameters\ninclude:\nMaximum Deciding or Capacity: the limit for the number of referenda that can be decided at\n  once (i.e., the number of tracks within each origin).\nDecision deposit: the amount of funds that must be placed on deposit to enter the Decision\n  Period (note that more requirements must be met to enter the Decision Period).\nPreparation Period: the minimum amount of voting time needed before entering the Decision\n  Period (given capacity and deposit are met).\nDecision Period: the time interval during which a proposal's outcome can be decided.\nConfirmation Period: the minimum amount of time the approval and support criteria must hold\n  before the proposal is approved and moved to the enactment period. The confirmation period should\n  start before the end of the decision period.\nExample Scenario of an Edge Case\nA referendum may enter the confirmation period just one block before the decision period ends. In this scenario, the referendum will pass if it satisfies approval and support thresholds for the minimum confirmation period (track-dependent).\nVoting Period: The period in which voting is allowed on a referendum, which includes\n  preparation, decision, and confirmation periods.\nMinimum Enactment Period: the minimum amount of waiting time before the proposed changes are\n  applied\nApproval Curve: the curve describing the minimum % of aye votes as a function of time within\n  the Decision Period. The approval % is the portion of aye votes (adjusted for conviction) over\n  the total votes (aye, nay, and abstained).\nSupport Curve: the curve describing the minimum % of all votes in support of a proposal as a\n  function of time within the Decision Period. The support % is defined as the portion of all votes\n  (aye and abstained) without conviction over the total possible amount of votes in the system\n  (i.e., the total active issuance).\nFor example, a runtime upgrade (requiring a set_code call, if approved) does not have the same\nimplications for the ecosystem as the approval of a treasury tip (reportAwesome call) and\ntherefore, different Origins for these two actions are needed in which different deposits, support,\napproval, and a minimum enactment periods will be predetermined on the pallet.\nFor detailed information about origin and tracks, and parameter values in Kusama, see\nthis page."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain voluntary locking (conviction voting)\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Conviction Voting Locks created during Gov 1\nConviction voting locks in Governance v1 will not be carried over to OpenGov. Voting with conviction in OpenGov will create a new lock (as this will use the convictionVoting pallet), while any existing lock under Governance v1 (using the deprecated democracy pallet) will be left to expire. Delegations under Governance v1 will need to be re-issued under OpenGov.\nPolkadot utilizes an idea called voluntary locking that allows token holders to increase their\nvoting power by declaring how long they are willing to lock up their tokens; hence, the number of\nvotes for each token holder will be calculated by the following formula:\nvotes = tokens * conviction_multiplier\nThe conviction multiplier increases the vote multiplier by one every time the number of lock periods\ndouble.\nLock Periods\nVote Multiplier\nLength in Days\n\n\n\n\n0\n0.1\n0\n\n\n1\n1\n7\n\n\n2\n2\n14\n\n\n4\n3\n28\n\n\n8\n4\n56\n\n\n16\n5\n112\n\n\n32\n6\n224\nThe maximum number of \"doublings\" of the\nlock period is set to 6 (and thus\n32 lock periods in total). For additional information regarding the timeline of governance events, see the origins and tracks information.\nVotes are always \"counted\" at the same time (at the end of the voting period), no matter how long\nthe tokens are locked.\nSee below an example that shows how voluntary locking works.\nPeter: Votes No with 10 DOT for a 32-week lock period => 10 x 6 = 60 Votes\nLogan: Votes Yes with 20 DOT for one week lock period => 20 x 1 = 20 Votes\nKevin: Votes Yes with 15 DOT for a 2-week lock period => 15 x 2 = 30 Votes\nEven though both Logan and Kevin vote with more DOT than Peter, the lock period for both of them is\nless than Peter\u2019s, leading to their voting power counting as less.\nStaked tokens can be used in governance\nWhile the tokens are locked, you can still use them for voting and staking. You are only prohibited from transferring these tokens to another account. See the section about OpenGov locks, and learn more about locks on the Balances page."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain approval and support\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "The figure above provides a summary view of how the approval and support system works during the\nDecision Period.\nOnce the proposal exits the Lead-in Period and enters the Voting Period, to be approved, it must\nsatisfy the approval and support criteria for the Confirmation Period.\nApproval is defined as the share of conviction-weighted aye votes\n  against the conviction-weighted total of aye and nay votes. The code implementation can be\n  viewed\n  here\nSupport is the total number of aye and abstain votes (ignoring any adjustment for\n  conviction) compared to the total possible votes (active issuance)\n  that could be made in the system. In case of split votes, only aye and abstain will count.\nFor example, let us consider a hypothetical example where the total active issuance is 100 DOT.\nAn account A votes \"Aye\" with 10 DOT with 4x conviction\nAn account B votes \"Nay\" with 5 DOT with 2x conviction\nAn account C votes \"Abstain\" with 20 DOT. (no conviction can be applied to \"Abstain\" votes)\nIn this scenario, only 35 DOT from the total active issuance participated in voting on the\nreferendum. Now, let us calculate the Approval and Support values for that referendum.\nApproval is calculated as (Aye') / (Aye' + Nay\u2019), where Aye' and Nay' are the votes after applying\n  the conviction multiplier. Hence, Approval = (10 x 4) / (10 x 4 + 5 x 2) = 40/50 which is 80%.\nSupport is calculated as (Aye + Abstain) / (total active issuance), where \"Aye\" and \"Abstain\" are\n  the votes without the conviction multiplier. Hence, Support = (10 + 20) / 100 which is 30%.\nNay votes are not counted towards Support\nSupport is a measure of voters who turned out either in favor of the referenda or consciously abstained from it. Support does not include nay votes. This avoids edge situations where nay votes could push a referendum into a confirming state. For example, imagine current approval is high (near 100%, way above the approval curve), and current support is just below the support curve. A nay could bump support above the support curve but not reduce approval below the approval curve. Therefore, someone voting against a proposal would make it pass. Hence, a decrease in % of current approval through new votes does not directly translate into increasing support because Support needs to consider nay votes.\nThe figure above shows the following:\nEven if the approval threshold is reached (i.e., % of current approval is greater than the\n  approval curve), the proposal only enters the confirmation period once the support threshold is\n  also reached (i.e., % current support is greater than the underlying support curve).\nIf the referendum meets the approval and support thresholds for the duration of the confirmation\n  period, the proposal will be approved and will be scheduled for enactment. Each track has a\n  default minimum Enactment Period, and the approved referendum needs to wait till the end of it to\n  be executed. Powerful Tracks like Root enforce a larger Enactment Period to ensure the network\n  has ample time to prepare for any changes the proposal may bring. The referendum proposers can\n  also set the enactment period higher than its default value.\nA referendum may exit the confirmation period when the thresholds are no longer met due to new\n  Nay votes or a change of existing Aye or Abstain votes to Nay . Each time it exits, the\n  confirmation period clock is reset. For example, suppose the confirmation period is 20 minutes,\n  and a referendum enters it just for 5 min before exiting. The next time it enters, it must be\n  confirmed for 20 minutes (not 15 minutes).\nIt is possible that a referendum meets the approval and support thresholds almost at the end of\n  the decision period. In this case, even though the decision period elapses, the referendum can\n  pass if it stays confirming for the duration of the track-specific confirmation period. It is\n  rejected immediately if it exits the confirmation period after the decision period elapses.\nThe approval curve starts at 100% and gradually decreases to 50%, but never below 50%. Assuming\n  all the active token supply has voted on a proposal, the conviction vote-weighted support should\n  always be above 50% to pass.\nNote that support may not increase monotonically, as shown in the figure, as people might switch\nvotes.\nDifferent Origins' tracks have different Confirmation Periods and requirements for approval and\nsupport. For additional details on the various origins and tracks, check out\nthis table. With proposals that use\nless privileged origins, it is far more reasonable to drop the required support to a more realistic\namount earlier than those which use highly privileged classes such as Root."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain cancelling, killing & blacklisting\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot OpenGov has two origins dedicated to rejecting ongoing referenda:\nReferendum Canceller and\nReferendum Killer.\nReferendum Canceller aims to cancel an already ongoing referendum. When this origin cancels a\nreferendum, the Submission and Decision Deposit are refunded to their originators. An example of\nwhen a referendum might be considered to be canceled is if the originator has made some errors in\ncreating the preimage and did not necessarily do anything malicious. Cancellation has a lower\nDecision Period, and Approval and Support criteria are much easier to meet over time than most other\nOrigins. This is because the cancellation of a referendum usually comes with a sense of urgency.\nReferendum Killer aims to instantly kill an ongoing referendum, slashing submission and decision\ndeposit (the account(s) that posted these deposits will lose those funds). This origin can be\nengaged if, for example, a malicious actor submits a referendum on the Root Track to set the code of\nthe chains' runtime to stop block production.\nThe Decision Deposit for the Referendum Killer track itself is high to prevent malicious actors from\nattempting to slash deposits of good referenda. A subsequent Referendum Killer can kill an existing\nReferendum Killer.\nFor more information about how to cancel or kill a referendum, see the\nadvanced how-to guides.\nA proposal can be blacklisted by Root Origin. A blacklisted proposal and its related referendum (if any) are immediately canceled. Additionally, a blacklisted proposal's hash cannot re-appear in the proposal queue. Blacklisting is useful when removing erroneous proposals that could be submitted with the same hash."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain voting on a referendum\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "If you are a voter, it means that you will vote with your tokens on each single referendum.\nIn Governance V1, voters could cast only an aye or nay vote. In Polkadot OpenGov, voters can\nadditionally cast a abstain and split votes.\nVote splitting allows voters to allocate\ndifferent votes for aye, nay, and abstain. Voting with conviction is not possible when\nabstaining or splitting the votes.\nOnly the last vote counts\nVoting a second time replaces your original vote, e.g. voting with 10 DOT, then a second extrinsic to vote with 5 DOT, means that you are voting with 5 DOT, not 10 DOT.\nNote that to successfully cast votes you need to have the\nexistential deposit and some additional funds\nto pay for transaction fees.\nIn general, you can remove your vote:\nWhile a referendum is ongoing (your vote does not count)\nAfter a referendum ended (your vote counts)\nIf you voted without conviction, there's no conviction lock in either case. If you voted with\nconviction, you only get a conviction lock if the referendum ended and you voted with the winning\nside.\nRevoke your delegation on a track if you like to vote on your own\nIf you want to vote on a referendum on a specific track on your own, you will need to revoke any existing delegation on that track (i.e. undelegate). You can have a conviction lock on the track, but you cannot have an active delegation."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain voting without conviction\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "If you vote without conviction, the referendum is ongoing, and you remove the vote, you can unlock\nyour tokens immediately. If the referendum ended, you can remove your vote and unlock your tokens\nimmediately, regardless of whether you are on the winning or losing side of the referendum. The\ngovernance app or interface you used for participating in Polkadot OpenGov should show an option to\nunlock your tokens."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain voting with conviction\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "If you voted with conviction, the referendum is ongoing, and you removed the vote, you can unlock\nyour tokens immediately. If the referendum ended and you are on the losing side, you can remove your\nvote and unlock the tokens immediately. However, if you are on the winning side of the referendum,\nyou will get a conviction lock.\nConviction locks are calculated from the time the referendum ended but are applied when you remove\nthe vote.\nFor example, if you voted with conviction 1x with 10 DOT, those 10 DOT will be locked for 7 days\nafter the referendum ends (assuming you are on the winning side). If you remove the vote 3 days\nafter the referendum ended, your tokens will be locked for 4 more days. If you remove it on the 8th\nday after the end of the referendum, the tokens can be unlocked right away (after you remove the\nvote). When you remove the vote, the lock expiration block is calculated and added to the chain\nstate.\nIf you voted on multiple referenda, and you are on the winning side of all those referenda, you will\nget multiple conviction voting locks for all those referenda. Locks do not stack; the length and\nsize of the lock decides. This means that - assuming you used the same conviction on the same number\nof tokens - when the conviction lock on the latest referendum (see below, Ref 4) expires, you will\nbe able to unlock your tokens. In the meantime, the previous locks (1 to 3) might have expired, and\nyou can remove those locks (after removing the votes).\nWhen you delegate your votes, the locking mechanism differs slightly. Please check the next section\non Multirole Delegation for more information."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain multirole delegation\u00b6 in Polkadot\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot OpenGov builds on the vote delegation feature from Governance v1 where a\nvoter can delegate their voting power to another voter. It does so by introducing a feature known as\nmultirole delegation, where voters can specify a different delegate for every class of\nreferendum in the system. Delegation can be done per track, and accounts can choose to select\ndifferent delegates (or no delegation) for each track.\nFor example, a voter could delegate one entity for managing a less potent referenda class, choose a\ndifferent delegate for another class with more powerful consequences and still retain full voting\npower over any remaining classes.\nContrary to solo voting, with delegations, any conviction locks are applied as soon as you\nundelegate, regardless of whether your delegated votes were used for voting during that time. If\nyour delegated votes were used in any ongoing referenda, they would be removed from those referenda\nwhen you undelegate. Alternatively, after undelegating, you can delegate to another person or modify\nyour delegation. The only way to modify the delegation is to undelegate and delegate again. You do\nnot have to do this yourself; wallets and extensions should have implemented UI to modify delegation\nwithout you knowing this.\nIf you delegate without conviction and you undelegate, you can unlock your tokens immediately.\nAlternatively, after undelegating, you can always delegate to another person or modify your\ndelegation.\nIn the case you delegated with 1x conviction, you undelegate and re-delegate with 2x conviction; the\ntime you undelegate again, you will have created two conviction locks: one for the 1x and one for\nthe 2x conviction. If you re-delegate immediately with 1x conviction and undelegate, you will get a\nsecond 1x conviction lock, but the 2x conviction lock will be the one deciding when your token can\nbe unlocked.\nInfo\nIf the account delegated votes to different delegates using different convictions, then after undelegating those delegates, there will be different unlocking periods with lengths dependent on the conviction multipliers.\nBefore delegating a specific track, you must remove any vote on that\ntrack.\nIt is worth noting that a user delegating their voting power does not imply that the delegate will\nhave control over the funds of the delegating user's account. That delegate's account can vote with\na user's voting power but won't be able to transfer balances, nominate a different set of\nvalidators, or execute any call other than voting on the tracks defined by the user.\nThe goal of delegations is to ensure the required support for proposals to be enacted is reached\nwhile keeping the overall design censorship-free. Also, voters might not have the technical\nknowledge to judge some referenda or might not have the time to read all referenda. Delegations\nallow voters to participate in OpenGov hands-free by delegating their voting power to trusted\nentities."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: What is the economic security model of Polkadot?\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot's economic security model is based on shared security where all parachains benefit from the collective economic security of the relay chain. Validators stake DOT tokens and are randomly assigned to validate parachain blocks, with their stake at risk if they behave maliciously. This creates a security model where the cost of attacking any parachain is proportional to the total value staked on the relay chain."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: How does Polkadot's auction mechanism work for parachain slots?\ninput: "
      },
      {
        "role": "assistant",
        "content": "Polkadot uses a candle auction mechanism for parachain slot allocation. Projects bid DOT tokens for lease periods, with auctions having a random ending time within a specified range. The highest bidder at the random end time wins the slot. This mechanism prevents auction sniping and ensures fair price discovery while creating long-term DOT demand through the bonding mechanism."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain the role of DOT token in Polkadot's governance system\ninput: "
      },
      {
        "role": "assistant",
        "content": "DOT tokens serve as the primary governance mechanism in Polkadot through OpenGov. Token holders can propose referenda, vote on proposals, and delegate their voting power. The system uses conviction voting where users can increase their voting power by locking tokens for longer periods. This creates a time-weighted voting system that balances immediate participation with long-term commitment to the network."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: What are the inflation dynamics of DOT tokens?\ninput: "
      },
      {
        "role": "assistant",
        "content": "DOT has a fixed inflation rate of approximately 10% annually, designed to incentivize staking and fund the treasury. The inflation is distributed between staking rewards (about 8-9%) and treasury funding (1-2%). When staking participation is optimal (around 75% of supply), validators and nominators receive the highest rewards. Lower staking participation results in higher individual returns but reduced overall security."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: How does slashing work in Polkadot's NPoS system?\ninput: "
      },
      {
        "role": "assistant",
        "content": "Slashing in Polkadot penalizes validators and their nominators for malicious behavior or protocol violations. The severity depends on the offense: equivocation (double-signing) can result in 0.1% slash, while coordinated attacks can trigger up to 100% slashing. The punishment affects both the validator's own stake and all nominator stakes backing that validator, creating strong incentives for nominators to choose reliable validators."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Analyze the validator selection game in Polkadot's NPoS system\ninput: "
      },
      {
        "role": "assistant",
        "content": "The validator selection in Polkadot creates a multi-player game where nominators choose validators to maximize returns while minimizing slashing risk. The Nash equilibrium involves nominators distributing stake across reliable validators with lower commission rates. Validators compete by offering competitive commission rates and demonstrating reliability. The algorithm optimizes for both security (avoiding concentration) and fairness (proportional representation), creating incentives for decentralization."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: What are the game-theoretic implications of Polkadot's slashing mechanism?\ninput: "
      },
      {
        "role": "assistant",
        "content": "Slashing creates a coordination game between validators and nominators. Validators have incentives to maintain high uptime and avoid equivocation, as slashing affects both their own stake and nominator stake. Nominators must evaluate validator behavior and past performance. The mechanism creates a deterrent effect where the cost of misbehavior exceeds potential gains, establishing a stable equilibrium where honest behavior is dominant strategy."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: How does the parachain auction mechanism prevent strategic manipulation?\ninput: "
      },
      {
        "role": "assistant",
        "content": "The candle auction format prevents last-second bidding strategies by having a random, unknown end time. This eliminates the advantage of waiting until the last moment to bid, as bidders cannot know when the auction actually ends. The mechanism incentivizes truthful bidding early in the auction period, as strategic waiting may result in missing the actual end time. This creates a more fair price discovery process."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: Explain the Nash equilibrium in Polkadot's nomination pools\ninput: "
      },
      {
        "role": "assistant",
        "content": "Nomination pools create a coordination game where pool operators compete for delegators while delegators seek optimal returns. The Nash equilibrium emerges when pool operators set commission rates that balance profitability with competitiveness, while delegators distribute stake across pools based on historical performance and commission rates. This creates market efficiency where poorly performing pools lose delegation and high-performing pools attract more stake."
      }
    ]
  },
  {
    "conversations": [
      {
        "role": "user",
        "content": "instruction: How does conviction voting in Polkadot governance solve collective action problems?\ninput: "
      },
      {
        "role": "assistant",
        "content": "Conviction voting addresses the collective action problem in governance by allowing token holders to multiply their voting power by locking tokens for longer periods. This mechanism ensures that those with long-term interests in the network have proportionally more influence, while preventing short-term actors from manipulating governance. The time-locking requirement creates a credible commitment mechanism that aligns voting incentives with network health."
      }
    ]
  }
]